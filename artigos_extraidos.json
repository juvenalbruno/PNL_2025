{
    "artigos": [
        {
            "titulo": "Formulações de programação inteira para o problema da coloração de Grundy conexa",
            "informacoes_url": "https://proceedings.science/p/193659?lang=pt-br",
            "idioma": "pt-br",
            "storage_key": "galoa-proceedings--sbpo-2024--193659.pdf",
            "autores": [
                {
                    "nome": "Mateus C. Silva",
                    "afiliacao": "Instituto de Computação, Universidade Federal da Bahia",
                    "orcid": ""
                },
                {
                    "nome": "Rafael A. Melo",
                    "afiliacao": "Instituto de Computação, Universidade Federal da Bahia",
                    "orcid": ""
                },
                {
                    "nome": "Mauricio G. C. Resende",
                    "afiliacao": "Industrial & Systems Engineering, University of Washington",
                    "orcid": ""
                },
                {
                    "nome": "Marcio C. Santos",
                    "afiliacao": "Departamento de Ciência da Computação, Universidade Federal de Minas Gerais",
                    "orcid": ""
                },
                {
                    "nome": "Rodrigo F. Toso",
                    "afiliacao": "Microsoft Corporation, One Microsoft Way",
                    "orcid": ""
                }
            ],
            "data_publicacao": "",
            "resumo": "Dado um grafo G = (V, E), o problema da coloração de Grundy conexa consiste em encontrar uma coloração que possa ser obtida pela heurística first-fit através de uma sequência conexa dos vértices que maximize o número de cores.",
            "keywords": [
                "Coloração de vértices",
                "Programação inteira",
                "Algoritmos gulosos",
                "Otimização Combinatória",
                "Teoria e Algoritmos em Grafos",
                "Programação Matemática"
            ],
            "referencias": [
                "Bahiense, L., Frota, Y. A. M., Noronha, T. F., e Ribeiro, C. C. (2014). A branch-and-cut algorithm for the equitable coloring problem using a formulation by representatives. Discrete Applied Mathematics, 164:34–46.",
                "Benevides, F., Campos, V., Dourado, M., Griffiths, S., Morris, R., Sampaio, L., e Silva, A. (2014). Connected greedy colourings. In Pardo, A. e Viola, A., editors, LATIN 2014: Theoretical Informatics, p. 433–441, Berlin, Heidelberg. Springer Berlin Heidelberg.",
                "Bonamy, M., Groenland, C., Muller, C., Narboni, J., Pekárek, J., e Wesolek, A. (2021). A note on connected greedy edge colouring. Discrete Applied Mathematics, 304:129–136.",
                "Bonnet, É., Foucaud, F., Kim, E. J., e Sikora, F. (2018). Complexity of Grundy coloring and its variants. Discrete Applied Mathematics, 243:99–114.",
                "Brélaz, D. (1979). New methods to color the vertices of a graph. Communications of the ACM, 22 (4):251–256.",
                "Campelo, M., Campos, V., e Corrêa, R. (2005). On the asymmetric representatives formulation for the vertex coloring problem. Electronic Notes in Discrete Mathematics, 19:337–343.",
                "Corrêa, R. C., Campelo, M., e Frota, Y. A. M. (2004). Cliques, holes and the vertex coloring polytope. Information Processing Letters, 89:159–164.",
                "de Freitas, R., Dias, B., Maculan, N., e Szwarcfiter, J. (2021). On distance graph coloring problems. International Transactions in Operational Research, 28(3):1213–1241.",
                "Dias, B., de Freitas, R., Maculan, N., e Michelon, P. (2021). Integer and constraint programming approaches for providing optimality to the bandwidth multicoloring problem. RAIRO: Recherche Opérationnelle, 55:S1949 – S1967.",
                "Frota, Y., Maculan, N., Noronha, T. F., e Ribeiro, C. C. (2010). A branch-and-cut algorithm for partition coloring. Networks: An International Journal, 55:194–204.",
                "Furini, F., Malaguti, E., e Santini, A. (2018). An exact algorithm for the partition coloring problem. Computers & Operations Research, 92:170–181.",
                "He, Y., Gao, C., Sang, N., Qu, Z., e Han, J. (2017). Graph coloring based surveillance video synopsis. Neurocomputing, 225:64–79.",
                "Hedetniemi, S. M., Hedetniemi, S. T., e Beyer, T. (1982). A linear algorithm for the Grundy (coloring) number of a tree. Congressus Numerantium, 36:351–363.",
                "Jovanović, P., Pavlović, N., Belošević, I., e Milinković, S. (2020). Graph coloring-based approach for railway station design analysis and capacity determination. European Journal of Operational Research, 287(1):348–360.",
                "Marzo, R. G., Melo, R. A., Ribeiro, C. C., e Santos, M. C. (2022). New formulations and branch-and-cut procedures for the longest induced path problem. Computers & Operations Research, 139:105627.",
                "Melo, R. A., Queiroz, M. F., e Santos, M. C. (2021). A matheuristic approach for the b-coloring problem using integer programming and a multi-start multi-greedy randomized metaheuristic. European Journal of Operational Research, 295(1):66–81.",
                "Melo, R. A. e Ribeiro, C. C. (2015). Improved solutions for the freight consolidation and containerization problem using aggregation and symmetry breaking. Computers & Industrial Engineering, 85:402–413.",
                "Melo, R. A. e Ribeiro, C. C. (2023). MIP formulations for induced graph optimization problems: a tutorial. International Transactions in Operational Research, 30(6):3159–3200.",
                "Morgenstern, C. (s.d.). Graph generator ggen. Online reference at http://iridia.ulb.ac.be/~fmascia/files/ggen.tar.bz2, último acesso em 25 de Julho de 2023.",
                "Mota, E., Rocha, L., e Silva, A. (2020). Connected greedy coloring of H-free graphs. Discrete Applied Mathematics, 284:572–584.",
                "Shi, Z., Goddard, W., Hedetniemi, S. T., Kennedy, K., Laskar, R., e McRae, A. (2005). An algorithm for partial Grundy number on trees. Discrete Mathematics, 304(1-3):108–116.",
                "Silva, M. C., Melo, R., Santos, M. C., Toso, R. F., e Resende, M. G. (2023a). Algoritmos genéticos de chaves aleatórias enviesadas para o problema da coloração de Grundy. In Anais do LV Simpósio Brasileiro de Pesquisa Operacional, São José dos Campos. SOBRAPO.",
                "Silva, M. C., Melo, R., M. C., Toso, R. F., e Resende, M. G. (2023b). Formulações de programação inteira para o problema da coloração de Grundy. In Anais do LV Simpósio Brasileiro de Pesquisa Operacional, São José dos Campos. SOBRAPO.",
                "Silva, M. C., Melo, R. A., Santos, M. C., Toso, R. F., e Resende, M. G. C. (2024). Obtaining the Grundy chromatic number: How bad can my greedy heuristic coloring be? Computers & Operations Research. URL https://doi.org/10.1016/j.cor.2024.106703.",
                "Telle, J. A. e Proskurowski, A. (1997). Algorithms for vertex partitioning problems on partial k-trees. SIAM Journal on Discrete Mathematics, 10(4):529–550.",
                "Zaker, M. (2008). New bounds for the chromatic number of graphs. Journal of Graph Theory, 58 (2):110–122.",
                "Zhu, X., Dai, L., e Wang, Z. (2015). Graph coloring based pilot allocation to mitigate pilot contamination for multi-cell massive MIMO systems. IEEE Communications Letters, 19(10):1842–1845."
            ],
            "artigo_completo": "Formulações de programação inteira para o problema da coloração de Grundy conexa. RESUMO Dado um grafo G = (V, E), o problema da coloração de Grundy conexa consiste em en- contrar uma coloração que possa ser obtida pela heurística first-fit através de uma sequência conexa dos vértices que maximize o número de cores. Uma sequência conexa dos vértices é uma na qual cada elemento, com exceção do primeiro, está conectado a algum elemento que o antecede. Neste artigo, são propostas duas formulações de programação inteira para o problema da coloração de Grundy conexa, uma formulação padrão e uma baseada na ideia de representativos. Experimentos computacionais preliminares indicam que a formulação por representativos apresenta desempenho melhor, em especial para grafos com densidade acima de 80%. Juntas, as formulações conseguiram encontrar a solução ótima para 61.25% dos casos. Ademais, no conjunto de instâncias analisadas, observa-se que a mediana da diferença percentual para as melhores soluções conhecidas para o pro- blema da coloração de Grundy (no qual as restrições de conexidade são relaxadas) fica próximo de 2.5%. PALAVRAS CHAVE. Coloração de vértices. Programação inteira. Algoritmos gulosos. Tópicos (Otimização Combinatória, Teoria e Algoritmos em Grafos, Programação Matemática) https://proceedings.science/p/193659?lang=pt-br DOI: 10.59254/sbpo-2024-193659 1. Introdução 1.1. Definições básicas Dado um grafo G = (V, E) e um conjunto de cores K, uma coloração é um mapeamento c : V →K. Uma coloração própria é uma coloração na qual c(u) ̸= c(v) para toda aresta uv ∈E. No restante do trabalho, uma coloração é própria a não ser que dito o contrário. Uma k- coloração é uma coloração com exatamente k cores. O número cromático de G, χ(G), é o menor k tal que G admite uma k-coloração. Considere a vizinhança de v, N(v), como o conjunto de vértices adjacentes a v e sua anti-vizinhança, ¯N(v), como o conjunto de vértices não adjacentes a v. Além disso, denote por ¯N[v] = ¯N(v) ∪{v} a anti-vizinhança fechada de v. Seja d(v) = |N(v)| o grau do vértice v e ∆(G) o maior grau em G. A densidade de um grafo é definida como dens(G) = 2×|E| |V |×(|V |−1). Dada uma ordem σ = (v1, v2, . . . , vn) para os vértices de um grafo, a heurística de coloração gulosa first-fit atribui a cada vértice vi a cor de menor índice não utilizada para os seus vi- zinhos em (v1, . . . , vi−1). Uma coloração de Grundy é uma coloração que respeita as propriedades da heurística first-fit, i.e., se c(v) = k então existe algum vizinho u ∈N(v) tal que c(u) = k′ para todo k′ < k. O número de Grundy, Γ(G), é o maior k tal que G admite um k-coloração de Grundy. O problema da coloração de Grundy consiste em obter uma coloração de Grundy maximizando o número de cores. Uma sequência conexa σc = (v1, . . . , vn) é uma sequência dos vértices garantindo que ∀i ≥2, vi tem pelo menos um vizinho no intervalo (v1, . . . , vi−1). Uma coloração de Grundy conexa é uma coloração que pode ser obtida sobre uma sequência conexa dos vértices respeitando as propriedades da heurística first-fit. O problema da coloração de Grundy conexa consiste em obter uma coloração de Grundy conexa maximizando o número de cores. A solução ótima para o problema é o número de Grundy conexo, Γc(G). Já o número cromático conexo, χc(G), denota o menor k tal que G aceita uma k-coloração conexa que respeita a propriedade da heurística first-fit. Note que χ(G) ≤Γc(G) ≤Γ(G) ≤∆(G) + 1. Limites superiores combinatórios foram propostos para Γ(G). Aos leitores interessados, recomendamos os artigos referenciados para mais detalhes. Shi et al. [2005] definiram o stair factor, ζ(G). Dado u ∈V (G), considere o conjunto N≤(u) = {v ∈V (G) : uv ∈E(G), dG(v) ≤ dG(u)}. Seja ∆2(G) = maxu∈V (G) maxv∈N≤(u) d(v). Zaker [2008] demonstrou a validade do https://proceedings.science/p/193659?lang=pt-br DOI: 10.59254/sbpo-2024-193659 limite ∆2(G) + 1. Recentemente, Silva et al. [2024] definiram um novo limite, representado por Ψ(G). A ideia deste é estabelecer que um vértice pode receber uma dada cor se os graus de seus vizinhos formarem uma sequência que lhe permita recebê-la. Isso pode ser calculado definindo-se uma função recursiva ψ, em que ψ(v, k) contém um limite superior para a maior cor menor ou igual a k que o vértice v pode receber. 1.2. Literatura relacionada A coloração de grafos encontra aplicações em diversas áreas. Alguns exemplos mais re- centes incluem redes de comunicação [Zhu et al., 2015], sinopse de vídeos [He et al., 2017], e projeto de estações ferroviárias [Jovanovi´c et al., 2020]. Heurísticas de coloração first-fit, especi- almente as heurísticas conexas (e.g., baseadas em busca em largura), são amplamente empregadas para obtenção de soluções para esses problemas. Portanto, o número de Grundy e o número de Grundy conexo possuem aplicabilidades significativas, já que fornecem uma medida teórica de qualidade das soluções no pior caso. É importante ressaltar que o problema da coloração de Grundy conexa é NP-difícil [Benevides et al., 2014]. Diversos trabalhos se concentraram na complexidade do problema da coloração de Grundy para classes de grafos específicas [Hedetniemi et al., 1982; Telle e Proskurowski, 1997]. Recente- mente, alguns trabalhos se propuseram a resolver o problema para grafos quaisquer. Silva et al. [2023b, 2024] propuseram formulações de programação inteira. Silva et al. [2023a, 2024] elabora- ram um algoritmo genético de chaves aleatórias viesado (BRKGA). O problema da coloração de Grundy conexa foi menos explorado na literatura. Colorações conexas foram estudas em Benevides et al. [2014], onde foi demonstrado que computar Γc(G) é NP-difícil mesmo para grafos cordais e complementar do bipartido. Por outro lado, Γc(G) = 2 quando o grafo é bipartido. Os autores também demostraram que χc(G) ≤χ(G) + 1 e que determinar se χc(G) = χ(G) é NP-difícil. Mota et al. [2020] focaram em estudar quando χc(G) = χ(G) e no problema de decisão χc(G) ≤k para grafos livres de H (um grafo é livre de H se não contém uma cópia de H como um subgrafo induzido). Já Bonamy et al. [2021] estudaram colorações de arestas conexas. Bonnet et al. [2018] provaram que o problema da coloração de Grundy conexa já é NP-completo para k = 7 cores. Silva et al. [2023a] aplicaram um BRKGA para o problema da coloração de Grundy e sua versão conexa e mostraram que nas classes de grafos investigadas existe uma diferença percentual pequena entre as soluções encontradas para os dois problemas. 1.3. Contribuições do trabalho e organização Neste estudo, são apresentadas duas formulações de programação inteira para abordar o problema da coloração de Grundy conexa. A primeira formulação visa particionar os vértices em classes de cores, seguindo uma abordagem padrão, enquanto a segunda adota a estratégia de formulação por representativos. Essas técnicas representam os primeiros esforços em abordar o problema via programação inteira. O restante do trabalho é organizado como segue. A Seção 2 apresenta as formulações de programação inteira. A Seção 3 descreve os experimentos computacionais. A Seção 4 discute algumas considerações finais. 2. Formulações de programação inteira Nesta seção, apresentamos duas formulações de programação inteira (PI) para o problema da coloração de Grundy conexa. Formulações de PI têm se mostrado efetivas para a resolução de diversos problemas de otimização em grafos [Furini et al., 2018; de Freitas et al., 2021; Dias et al., 2021; Marzo et al., 2022; Melo e Ribeiro, 2023]. No que segue, a Seção 2.1 apresenta a formulação padrão, enquanto a Seção 2.2 descreve a formulação por representativos. No restante do texto, denotaremos o conjunto de vértices por V = {1, . . . , n}. Além disso, considere o conjunto de cores disponíveis como K = (1, . . . , min(ζ(G), Ψ(G), ∆2(G)+1), https://proceedings.science/p/193659?lang=pt-br DOI: 10.59254/sbpo-2024-193659 e a sequência de possíveis cores do vértice v por Kv = (1, . . . , min(ζ(G), ψ(v, ∆(G)+1), ∆2(G)+ 1)), e a sequência de possíveis cores do vértice v no tempo t por Kvt = {k′ ∈Kv | k′ ≤t}. Lembramos que os limites estão definidos na Seção 1.1. Por fim, define-se Vk = {v ∈V | k ∈Kv} como o conjunto de vértices que podem receber a k-ésima cor. As formulações propostas utilizam, para algumas variáveis, um índice representando o tempo no qual um vértice é colorido. Esse tempo está associado à posição do vértice na sequência conexa determinada, i.e., um vértice colorido no tempo t é o t-ésimo elemento na sequência. 2.1. Formulação padrão Para formular o problema da coloração de Grundy conexa utilizando programação inteira, considere as variáveis de decisão: zvkt = \u001a 1, se o vértice v ∈V recebe a cor k ∈Kvt no tempo t ∈T, 0, caso contrário. wk = \u001a 1, se a cor k ∈K é usada, 0, caso contrário. Assim, o problema pode ser expresso como: max X k∈K wk (1) X t∈T, t≥k zukt + X t∈T, t≥k zvkt ≤wk, ∀k ∈Kv ∩Ku, uv ∈E, (2) X t∈T X k∈Kvt zvkt = 1, ∀v ∈V, (3) wk ≤ X v∈V X t∈T, t≥k zvkt, ∀k ∈K, (4) X t′∈{k′,...,t} zvk′t′ ≤ X u∈N(v), u∈Vk X t′∈{k,...,t−1} zukt′, ∀v ∈V, k, k′ ∈Kv, t ∈T \\ {1}, com k < k′, (5) X v∈V X k∈Kvt zvkt = 1, ∀t ∈T, (6) X k∈Kvt zvkt ≤ X u∈N(v) t−1 X t′=1 X k∈Kut′ zukt′, ∀v ∈V, t ∈T \\ {1}, (7) wk ∈{0, 1}, ∀k ∈K. (8) zvkt ∈{0, 1}, ∀v ∈V, t ∈T, k ∈Kvt. (9) A função objetivo (1) maximiza o total de cores utilizadas. As restrições (2) garantem que vértices adjacentes não recebam a mesma cor. As restrições (3) asseguram que cada vértice receba exata- mente uma cor em um único período. As restrições (4) determinam que wk assuma o valor um apenas se a cor k é usada. As restrições (5) garantem a propriedade de Grundy. Observe que eles implicam que se um vértice v ∈V recebe uma cor no período t, todas as cores com índice menor precisam ser usadas na vizinhança de v nos períodos de um até t −1. As restrições (6) estabelecem https://proceedings.science/p/193659?lang=pt-br DOI: 10.59254/sbpo-2024-193659 que um único vértice receba uma cor em cada período. As restrições (7) certificam que um vértice só seja colorido, se pelo menos um de seus vizinhos foi colorido antes, com exceção do primeiro vértice, ou seja, garante que a coloração é conexa. As restrições (8)-(9) definem os requisitos de integralidade sobre as variáveis de decisão. 2.2. Formulação por representativos Formulações por representativos [Corrêa et al., 2004; Frota et al., 2010] têm sido aplicadas com sucesso para coloração em grafos e diversos outros problemas de particionamento [Campêlo et al., 2005; Bahiense et al., 2014; Melo e Ribeiro, 2015; Melo et al., 2021]. A seguir, apresenta- mos uma formulação de programação inteira por representativos para o problema da coloração de Grundy conexa. Considere as variáveis de decisão: Zvut = \u001a 1, se o vértice u ∈V é representado pelo vértice v ∈¯N[u] no tempo t ∈T, para v ≤u, 0, caso contrário; yvu = \u001a 1, se os vértices v, u ∈V são representativos e a cor de v precede a de u, para v ̸= u, 0, caso contrário. Uma formulação de PI por representativos pode ser definida como: max X v∈V X t∈T Zvvt (10) X t∈T Zuvt + X t∈T Zuwt ≤ X t∈T Zuut, ∀u ∈V, v, w ∈¯N[u], s.t. vw ∈E e u ≤v < w, (11) X t∈T Zuvt ≤ X t∈T Zuut, ∀u ∈V, v ∈¯N(u), s.t. N(v) ∩¯N(u) = ∅e u < v, (12) X v∈¯ N[u], v≤u X t∈T Zvut = 1, ∀u ∈V, (13) X t′∈{1,...,t} Zuvt′ ≤ X w∈N(v)∩¯ N[p], p≤w X t′∈{1,...,t−1} Zpwt′ + 1 −ypu, ∀u, p ∈V, v ∈¯N[u], t ∈T \\ {1}, s.t. p ̸= u e u ≤v, (14) X u∈¯ N[v], u≤v Zuvt ≤ X v′∈N(v) X u∈¯ N[v′], u≤v′ t−1 X t=1 Zuv′t, ∀v ∈V, t ∈T \\ {1}, (15) yvu + yuv ≥ X t∈T Zuut + X t∈T Zvvt −1, ∀u, v ∈V, s.t. u < v, (16) yuv + yvu ≤ X t∈T Zuut, ∀u, v ∈V, s.t. u ̸= v, (17) X u∈V X t∈T Zuut ≤min(Ψ(G), ζ(G), ∆2(G) + 1), (18) Zuvt ∈{0, 1}, ∀u ∈V, v ∈¯N[u], t ∈T, s.t. u ≤v, (19) yuv ∈{0, 1}, ∀u, v ∈V, s.t. u ̸= v. (20) A função objetivo (10) maximiza o número total de vértices representativos. As restrições (11) garantem que vértices adjacentes não recebam a mesma cor. As restrições (12) indicam que um https://proceedings.science/p/193659?lang=pt-br DOI: 10.59254/sbpo-2024-193659 vértice só pode representar outro se o primeiro for representativo. As restrições (13) garantem que cada vértice recebe uma cor em um único período. As restrições (14) implicam a propriedade de Grundy. Eles estabelecem que se p, u ∈V são representativos, p precede u, e u representa v ∈¯N[u], então p deve representar um dos vizinhos de v antes que u possa representar v. As restrições (15) asseguram que um vértice só seja colorido se pelo menos um de seus vizinhos foi colorido antes, com exceção do primeiro vértice. As restrições (16)-(17) garantem uma ordem entre dois vértices se e somente se ambos forem representativos. A restrição (18) limita o número total de vértices representativos. As restrições (19)-(20) determinam a integralidade das variáveis. 3. Experimentos computacionais preliminares Os experimentos computacionais foram conduzidos em um computador com sistema ope- racional Ubuntu x86-64 GNU/Linux, processador Intel Core i7-10700 Octa-Core 2.90 Ghz, e 16GB de RAM. As formulações foram implementadas em Julia empregando o pacote JuMP e o resolve- dor Gurobi v. 10.0.1. Foram adotadas as configurações padrão do Gurobi, com exceção do parale- lismo que foi desativado. Foi estabelecido um tempo limite de 3600 segundos (uma hora) para as formulações. Uma solução viável inicial foi fornecida para as formulações (detalhes serão descritos na Seção 3.2). 3.1. Instâncias Os testes foram realizados em um conjunto de instâncias usadas por Silva et al. [2024] para o problema da coloração de Grundy. As instâncias foram geradas com o gerador de grafos ggen [Morgenstern, s.d.] e seguem o mesmo padrão do conjunto de instâncias utilizado anteriormente para outra variante do problema de coloração de vértices [Melo et al., 2021]. O conjunto é formado por duas classes de grafos: geométricos e randômicos. Os grafos possuem |V | ∈{15, 20, 25, 30} e foram gerados considerando as probabi- lidades de possuir uma aresta (para os grafos randômicos) e a distância euclidiana (para grafos geométricos) dentre {0.2, 0.4, 0.6, 0.8}. Cada grupo de instâncias, definido para uma combinação entre número de vértices e distância euclidiana (ou probabilidade para grafos randômicos) possui 5 instâncias. Cada grupo será identificado como C n p, em que C representa a classe do grafo: randômicos (rand), geométricos (geo); n o número de vértices, e p a probabilidade para os grafos randômicos, e a distância euclidiana para os grafos geométricos, e corresponde aproximadamente à densidade do grafo. Portanto, foram gerados 16 grupos para cada classe, totalizando 160 instâncias. O resultado para cada grupo será apresentado como a média para as suas 5 instâncias. É necessário ressaltar que as instâncias deste conjunto não são necessariamente conexas. Dessa forma, as instâncias desconexas foram conectadas usando o seguinte procedimento. O vértice de maior grau com menor índice de cada componente conexa é selecionado e um caminho é criado entre esses vértices do menor índice até aquele com maior índice entre eles, tornando a instância conexa. Essa heurística tenta manter o número de Grundy conexo do grafo resultante próximo daquele da componente conexa da instância original com o maior valor. 3.2. Geração de solução inicial A solução inicial fornecida para os modelos consiste naquela que apresenta o maior número de cores entre as soluções obtidas utilizando três critérios gulosos de forma conexa. Dois desses são critérios gulosos amplamente estabelecidos na literatura para o problema da coloração de vértices (a-b), enquanto o outro visa maximizar o número de cores (c). Especificamente, con- sideramos os critérios: (a) connected maximum-degree first (CMDF), que define uma sequência (v1, . . . , vn) na qual prioriza os vértices de maior grau de forma conexa; (b) DSatur [Brélaz, 1979], que define uma sequência (v1, . . . , vn) usando um critério adaptativo baseado no grau máximo de saturação dos vértices, definido pela quantidade de vértices com cores diferentes adjacentes a eles; e (c) connected minimum-degree first (CMinDF), que define uma sequência (v1, . . . , vn) priorizando os vértice de menor grau. https://proceedings.science/p/193659?lang=pt-br DOI: 10.59254/sbpo-2024-193659 3.3. Resultados preliminares As Tabelas 1-2 resumem os resultados obtidos. Nessas tabelas, a primeira coluna repre- senta o grupo de instâncias, de modo que cada linha corresponde aos valores médios de suas cinco instâncias. A segunda coluna (lsc) fornece o melhor limite superior combinatório, considerando ζ(G), ∆2(G) + 1 e Ψ(G). A terceira coluna (h) indica a média dos valores da solução heurística inicial fornecidos para a formulação. A seguir, para cada uma das formulações, as colunas indicam a média das melhores soluções obtidas (melhor), a média dos limites duais alcançado pelo resol- vedor no final da execução (ls), a média dos gaps de otimalidade em porcentagem, calculado para cada instância individual como 100 × ls−melhor melhor (observe que aqui nos referimos à melhor solução e ao limite para uma instância específica, não à média), o tempo médio de execução (tempo), e o número de instâncias resolvidas até a otimalidade (#opt). As duas últimas linhas nas tabelas indicam a média dos valores entre todas as linhas e o número total de instâncias resolvidas até a otimalidade. Os maiores valores nas colunas melhor são destacados em negrito. A Tabela 1 mostra que a formulação por representativos conseguiu provar a otimalidade em 30 casos contra 27 da formulação padrão. Contudo, o gap e o tempo total médio final é me- nor com a formualção padrão. Vale destacar que a maior parte das instâncias provadas ótimas pela formulação padrão tem η = 0.2, ou seja, são esparsas. Já a formulação por representativos teve van- tagem nas mais densas com η = 0.8. Nas instâncias randômicas (Tabela 2) percebe-se uma relação similar quanto a densidade e prova de otimalidade principalmente para a formulação por represen- tativos. Nesse grupo, a formulação padrão encontrou mais dificuldades, provando 8 soluções como ótimas, contra 29 do representativo. Além disso, o gap e tempo total médio final foram melhores para a formulação por representativos. Considerando as duas formulações, foi possível provar a otimalidade para 77 instâncias. Tabela 1: Resultados das formulações para os grafos geométricos padrão rep grupo lsc h melhor ls gap tempo #opt melhor ls gap tempo #opt geo 15 0.2 4.4 3.6 3.6 3.6 0.0 2.0 5 3.6 3.8 6.7 1291.6 4 geo 15 0.4 7.5 6.0 6.8 7.0 3.6 1137.0 3 6.8 7.2 7.2 2464.6 2 geo 15 0.6 10.8 9.6 10.2 10.8 6.0 2211.7 2 10.2 10.6 4.2 1449.4 3 geo 15 0.8 12.8 12.0 12.4 12.8 3.5 1445.2 3 12.4 12.4 0.0 1.0 5 geo 20 0.2 4.4 3.6 3.8 3.8 0.0 37.9 5 3.6 4.8 33.3 2880.3 2 geo 20 0.4 11.2 8.2 9.2 11.2 22.0 3600.0 0 9.6 11.2 17.3 3600.0 0 geo 20 0.6 13.2 10.6 12.0 13.2 10.2 3600.0 0 12.2 13.0 6.8 3027.8 1 geo 20 0.8 16.6 15.0 15.6 16.6 6.6 2886.5 1 16.0 16.0 0.0 30.9 5 geo 25 0.2 5.0 4.4 4.6 4.6 0.0 110.2 5 4.6 6.0 32.9 3600.0 0 geo 25 0.4 12.6 9.4 10.6 12.6 20.0 3600.0 0 10.2 12.6 24.4 3600.1 0 geo 25 0.6 17.6 14.4 15.8 17.6 11.5 3600.1 0 15.6 17.6 13.0 3600.1 0 geo 25 0.8 20.8 18.0 19.4 20.8 7.3 3600.1 0 19.6 19.8 1.1 998.3 4 geo 30 0.2 6.8 5.0 5.6 6.2 10.7 2509.8 2 5.4 7.0 32.3 3600.1 0 geo 30 0.4 15.2 10.8 12.6 15.2 21.6 3600.1 0 12.0 15.2 27.7 3600.2 0 geo 30 0.6 22.2 17.4 18.8 22.2 18.5 3600.3 0 18.4 22.0 20.0 3600.1 0 geo 30 0.8 25.0 21.6 22.8 25.0 9.9 3600.5 0 23.4 23.8 1.9 2198.9 4 Média 12.8 10.6 11.4 12.7 9.4 2455.8 11.4 12.7 14.3 2485.6 Total 27 30 Essa predominância da formulação por representativos em grafos densos também foi visto para o problema de coloração de Grundy [Silva et al., 2024], e se deve ao fato que quanto mais denso o grafo, menores as anti-vizinhanças e menos variáveis Xuv serão geradas e consequentemente o número total de restrições também irá diminuir. O contrário ocorre para as instâncias mais esparsas, em que a anti-vizinhança será maior; além disso, os limites podem restringir mais a quantidade https://proceedings.science/p/193659?lang=pt-br DOI: 10.59254/sbpo-2024-193659 total de cores para um vértice e ao todo na formulação padrão gerando uma quantidade reduzida de variáveis e restrições. Tabela 2: Resultados das formulações para os grafos randômicos padrão rep grupo lsc h melhor ls gap tempo #opt melhor ls gap tempo #opt rand 15 0.2 5.4 3.8 4.2 4.2 0.0 24.1 5 4.2 4.6 9.0 2102.4 3 rand 15 0.4 8.4 5.4 6.6 7.6 14.3 3159.9 1 6.6 7.0 6.9 1983.6 3 rand 15 0.6 10.4 6.6 8.8 10.4 18.0 3600.0 0 8.8 9.0 2.5 856.5 4 rand 15 0.8 12.6 9.6 10.8 12.6 16.9 3600.0 0 10.8 10.8 0.0 5.3 5 rand 20 0.2 6.8 4.2 5.4 6.4 17.3 2975.3 1 5.2 6.8 31.0 3600.0 0 rand 20 0.4 11.8 6.8 8.4 10.8 28.3 3600.0 0 8.6 10.8 25.5 3600.0 0 rand 20 0.6 14.0 9.2 10.2 14.0 37.3 3600.0 0 11.0 11.6 5.8 2486.0 3 rand 20 0.8 17.2 11.4 12.8 17.2 34.7 3600.0 0 13.2 13.2 0.0 79.8 5 rand 25 0.2 9.4 5.4 6.8 8.4 23.8 3516.6 1 6.8 9.4 38.6 3600.0 0 rand 25 0.4 13.8 7.6 8.8 13.8 56.7 3600.0 0 8.8 13.6 54.7 3600.0 0 rand 25 0.6 18.0 10.6 11.8 18.0 53.1 3600.1 0 12.6 15.6 24.6 3600.0 0 rand 25 0.8 21.6 13.4 15.2 21.6 42.3 3600.1 0 16.6 16.6 0.0 978.6 5 rand 30 0.2 9.6 5.8 6.8 9.0 32.4 3600.0 0 6.6 9.6 46.2 3600.2 0 rand 30 0.4 16.0 8.2 9.6 16.0 66.9 3600.1 0 9.6 16.0 67.1 3600.2 0 rand 30 0.6 21.4 11.8 13.8 21.4 56.0 3600.2 0 13.8 19.0 38.1 3600.2 0 rand 30 0.8 25.6 15.2 17.6 25.6 45.7 3600.3 0 18.4 20.2 10.1 3561.6 1 Média 13.8 8.4 9.8 13.5 33.9 3304.7 10.1 12.1 22.5 2553.4 Total 8 29 3.4. Comparação entre Γc(G) e Γ(G) Nesta seção, focamos na avaliação de otimalidade atráves da comparação com a versão não conexa e em reportar os desvios entre soluções obtidas utilizando formulações de programação inteira para as duas variantes do problema: a coloração de Grundy e a coloração de Grundy conexa. Para isso, são considerados os maiores valores encontrados entre as formulações para cada instância usada nesse artigo e comparado com a melhor solução de cada instância entre as formulações da versão genérica [Silva et al., 2024]. Denote por maxCG e maxCGC os maiores valores encontrados pelas formulações para uma dada instância do problema da coloração de Grundy e do problema da coloração de Grundy conexa, respectivamente; e lsmin como o melhor limite encontrado para o problema conexo para uma instância. Considere que os desvios para uma dada instância podem ser dados por diff = 100 −100 × maxCGC maxCG e diff2 = 100 −100 × maxCGC min(maxCG,lsmin), sendo o primeiro o desvio entre as melhores soluções para cada problema e o segundo o quão longe do ótimo a melhor solução do conexo está. A Figura 1 apresenta os boxplots com os desvios para cada classe de grafos utilizada, com a Figura 1(a) representando o desvio diff e a Figura 1(b) com diff2. Na Figura 1(a), a mediana dos desvios para os grafos geométricos e randômicos foram respectivamente 0.0% e 2.5%; e mesmo o último tendo uma amplitude interquartis maior ainda é possível avaliar as soluções do problema conexo utilizando a versão não conexa para essas classes de grafos, visto que ela fornece um limite superior justo pela diferença percentual. Pela Figura 1(b), para os grafos geométricos, pode-se notar que se alcançou o ótimo para a maior parte das instâncias e as demais representam um comportamento anômalo, caracterizando-as como outliers. Já para as randômicas se preserva parte da distribuição, só que agora a mediana foi para 0.0%. Na Seção 3.3 foi dito que se provou a otimalidade para 77 instâncias. Deve-se lembrar que Γc(G) ≤Γ(G) e como consequência se para uma dada instância sabemos o valor de Γ(G) e se encontramos a solução do problema conexo com mesmo valor, então para essa instância Γc(G) = https://proceedings.science/p/193659?lang=pt-br DOI: 10.59254/sbpo-2024-193659 0 10 20 geo rand class diff(%) (a) Boxplots comparativos do desvio entre as me- lhores soluções das formulações para Γ(G) e Γc(G). 0 10 20 geo rand class diff2(%) (b) Boxplots comparativos do desvio do me- lhor limite superior com a melhor solução para Γc(G); Figura 1: Boxplots comparativos entre os resultados das formulações para Γ(G) e Γc(G). Γ(G) e a solução é ótima. Portanto, pode se afirmar que foi encontrado o ótimo para 98 instâncias, o que dá 61.25% dos casos de teste. 4. Comentários finais Neste artigo, foram propostas formulações de programação inteira para o problema da coloração de Grundy conexa. Uma das formulações adota uma técnica tradicional para particionar os vértices em classes de cores, enquanto a outra emprega a abordagem de vértices representativos. Até onde sabemos, esta é a primeira vez em que o problema foi formulado utilizando programação inteira. Além disso, foi proposto um método que permite reutilizar instâncias desconexas da litera- tura, tentando preservar o valor da solução. Os experimentos computacionais preliminares mostraram que a formulação por repre- sentativos apresenta um desempenho superior à formulação padrão. O problema da coloração de Grundy conexa demonstrou ser desafiador para as abordagens propostas, especialmente quando se trata de provar a otimalidade. No entanto, observou-se que, na maioria dos casos, é possível encon- trar a solução ótima. Em especial, as instâncias com densidade de aproximadamente 20% mostram ser mais fáceis para a formulação padrão e as com densidade em torno de 80% para a formulação por representativos. Como foi visto, a formulação por representativos consegue ter vantagem em instâncias mais densas porque gera modelos com uma quantidade reduzida de variáveis e com me- nos simetria do que a formulação padrão. O oposto ocorre em instâncias mais esparsas. Agradecimentos O presente trabalho foi realizado com apoio da Coordenação de Aperfeiçoamento de Pessoal de Nível Supe- rior – Brasil (CAPES) – Código de Financiamento 001. Este trabalho foi parcialmente apoiado pelo Conselho Nacional de Desenvolvimento Científico e Tecnológico (CNPq), processos 314662/2020-0 e 314718/2023-0. Este trabalho foi parcialmente apoiado pelo projeto FAPESB INCITE PIE0002/2022."
        },
        {
            "titulo": "Uma abordagem Rápida e Competitiva para o Problema de Minimização de Trocas de Ferramentas",
            "informacoes_url": "https://proceedings.science/p/193410?lang=pt-br",
            "idioma": "pt",
            "storage_key": "galoa-proceedings--sbpo-2024--193410.pdf",
            "autores": [
                {
                    "nome": "Leonardo Cabral da Rocha Soares",
                    "afiliacao": "Instituto Federal do Sudeste de Minas Gerais",
                    "orcid": ""
                },
                {
                    "nome": "Marco Antonio Moreira de Carvalho",
                    "afiliacao": "Departamento de Ciência da Computação, Universidade Federal de Ouro Preto",
                    "orcid": ""
                }
            ],
            "data_publicacao": "",
            "resumo": "Aborda-se o problema industrial prático conhecido na literatura como problema de minimização de trocas de ferramentas, cujo objetivo é determinar uma ordem de processamento de tarefas que minimize o número total de operações em setups.",
            "keywords": [
                "manufatura flexível",
                "busca local iterativa",
                "trocas de ferramentas"
            ],
            "referencias": [
                "Ahmadi, E., Goldengorin, B., Süer, G. A., e Mosadegh, H. (2018). A hybrid method of 2-tsp and novel learning-based ga for job sequencing and tool switching problem. Applied Soft Computing, 65:214 – 229. ISSN 1568-4946.",
                "Applegate, D., Bixby, R., Chvatal, V., e Cook, W. (2006). Concorde TSP solver. URL http://www.math.uwaterloo.ca/tsp/concorde/",
                "Bard, J. F. (1988). A heuristic for minimizing the number of tool switches on a flexible machine. IIE Transactions, 20(4):382–391. ISSN 0740-817X.",
                "Beezão, A. C., Cordeau, J.-F., Laporte, G., e Yanasse, H. H. (2017). Scheduling identical parallel machines with tooling constraints. European Journal of Operational Research, 257(3):834–844.",
                "Calmels, D. (2019). The job sequencing and tool switching problem: state-of-the-art literature review, classification, and trends. International Journal of Production Research, 57(15-16):5005–5025.",
                "Calmels, D. (2022). An iterated local search procedure for the job sequencing and tool switching problem with non-identical parallel machines. European Journal of Operational Research, 297(1):66–85.",
                "Catanzaro, D., Gouveia, L., e Labbé, M. (2015). Improved integer linear programming formulations for the job sequencing and tool switching problem. European Journal of Operational Research, 244(3):766 – 777. ISSN 0377-2217.",
                "Chaves, A. A., Lorena, L. A. N., Senne, E. L. F., e Resende, M. G. C. (2016). Hybrid method with CS and BRKGA applied to the minimization of tool switches problem. Computers & Operations Research, 67:174–183. ISSN 0305-0548.",
                "Crama, Y., Kolen, A. W. J., Oerlemans, A. G., e Spieksma, F. C. R. (1994). Minimizing the number of tool switches on a flexible machine. International Journal of Flexible Manufacturing Systems, 6(1):33–54. ISSN 0920-6299, 1572-9370.",
                "Cura, T. (2023). Hybridizing local searching with genetic algorithms for the job sequencing and tool switching problem with non-identical parallel machines. Expert Systems with Applications, 223:119908.",
                "Djellab, H., Djellab, K., e Gourgand, M. (2000). A new heuristic based on a hypergraph representation for the tool switching problem. International Journal of Production Economics, 64(1):165–176.",
                "González, M. A., Oddi, A., Rasconi, R., e Varela, R. (2015). Scatter search with path relinking for the job shop with time lags and setup times. Computers & Operations Research, 60:37–54.",
                "Hamming, R. W. (1986). Coding and information theory. Prentice-Hall, Inc.",
                "Helsgaun, K. (2000). An effective implementation of the Lin-Kernighan traveling salesman heuristic. European Journal of Operational Research, 126(1):106 – 130. ISSN 0377-2217.",
                "Helsgaun, K. (2018). Lin-Kernighan heuristic. URL http://akira.ruc.dk/~keld/research/LKH/",
                "Hertz, A., Laporte, G., Mittaz, M., e Stecke, K. E. (1998). Heuristics for minimizing tool switches when scheduling part types on a flexible machine. IIE Transactions, 30(8):689–694. ISSN 0740-817X.",
                "Laporte, G., Salazar-González, J. J., e Semet, F. (2004). Exact algorithms for the job sequencing and tool switching problem. IIE Transactions, 36(1):37–45. ISSN 0740-817X.",
                "López-Ibáñez, M., Dubois-Lacoste, J., Cáceres, L. P., Birattari, M., e Stützle, T. (2016). The irace package: Iterated racing for automatic algorithm configuration. Operations Research Perspectives, 3:43–58.",
                "Lourenço, H. R., Martin, O. C., e Stützle, T. (2019). Iterated local search: Framework and applications. In Handbook of metaheuristics, p. 129–168. Springer.",
                "Mecler, J., Subramanian, A., e Vidal, T. (2021). A simple and effective hybrid genetic search for the job sequencing and tool switching problem. Computers & Operations Research, 127:105153.",
                "Paiva, G. S. e Carvalho, M. A. M. (2017). Improved heuristic algorithms for the job sequencing and tool switching problem. Computers & Operations Research, 88:208–219.",
                "Rifai, A. P., Mara, S. T. W., e Norcahyo, R. (2022). A two-stage heuristic for the sequence-dependent job sequencing and tool switching problem. Computers & Industrial Engineering, 163:107813.",
                "Senne, E. L. F. U. e Yanasse, H. H. (2009). Beam search algorithms for minimizing tool switches on a flexible manufacturing system. Proceedings of The 11th Wseas International Conference on Mathematical and Computational Methods In Science and Engineering (MACMESE ’09), p. 68–72.",
                "Shirazi, R. e Frizelle, G. D. M. (2001). Minimizing the number of tool switches on a flexible machine: an empirical study. International Journal of Production Research, 39(15):3547–3560. ISSN 0020-7543.",
                "Silva, T. T. d., Chaves, A. A., e Yanasse, H. H. (2020). A new multicommodity flow model for the job sequencing and tool switching problem. International Journal of Production Research, p. 1–16.",
                "Soares, L. C. R. e Carvalho, M. A. M. (2020). Biased random-key genetic algorithm for scheduling identical parallel machines with tooling constraints. European Journal of Operational Research, 285(3):955–964.",
                "Soares, L. C., Reinsma, J. A., Nascimento, L. H., e Carvalho, M. A. (2020). Heuristic methods to consecutive block minimization. Computers & Operations Research, 120:104948.",
                "Stecke, K. E. (1983). Formulation and solution of nonlinear integer production planning problems for flexible manufacturing systems. Management Science, 29(3):273–288.",
                "Tang, C. (1986). A job scheduling model for a flexible manufacturing machine. In Proceedings. 1986 IEEE International Conference on Robotics and Automation, volume 3, p. 152–155. IEEE.",
                "Tang, C. S. e Denardo, E. V. (1988). Models arising from a flexible manufacturing machine, part I: Minimization of the number of tool switches. Operations Research, 36(5):767–777. ISSN 0030-364X.",
                "Van Hop, N. e Nagarur, N. N. (2004). The scheduling problem of pcbs for multiple non-identical parallel machines. European Journal of Operational Research, 158(3):577–594.",
                "Yanasse, H. H. e Lamosa, M. J. P. (2006a). An application of the generalized travelling salesman problem: the minimization of tool switches problem. In International Annual Scientific Conference of the German Operations Research Society, p. 90–100, Bremen, Germany.",
                "Yanasse, H. H. e Lamosa, M. J. P. (2006b). On solving the minimization of tool switches problem using graphs. In XII International Conference on Industrial Engineering and Operations Management, p. 1–9, Fortaleza, Brazil.",
                "Yanasse, H. H., Rodrigues, R. d. C. M., e Senne, E. L. F. (2009). Um algoritmo enumerativo baseado em ordenamento parcial para resolução do problema de minimização de trocas de ferramentas. Gestão & Produção, 16(3):370–381. ISSN 0104-530X.",
                "Zeballos, L. (2010). A constraint programming approach to tool allocation and production scheduling in flexible manufacturing systems. Robotics and Computer-Integrated Manufacturing, 26(6):725–743."
            ],
            "artigo_completo": "Uma abordagem rápida e competitiva para o problema de minimização de trocas de ferramentas. RESUMO Aborda-se o problema industrial prático conhecido na literatura como problema de minimização de trocas de ferramentas, cujo objetivo é determinar uma ordem de processamento de tarefas que minimize o número total de operações em setups. Para abordar este problema NP-difícil, apresenta-se uma implementação da meta-heurística busca local iterativa. O método proposto é comparado ao método atual estado da arte para o problema, considerando-se todas as instâncias disponíveis na literatura. Os experimentos realizados demonstram que a qualidade das soluções reportadas são equivalentes aos melhores resultados conhecidos. Entretanto, o método proposto supera substancialmente o atual estado da arte quando consideramos o tempo de execução necessário para obtenção das soluções. Dada a natureza prática do problema, métodos mais rápidos são preferíveis para utilização em indústrias visando o planejamento da produção. Adicionalmente, apresentam-se novos melhores resultados para algumas instâncias amplamente utilizadas na litera- tura. PALAVRAS CHAVE. manufatura flexível, busca local iterativa, trocas de ferramentas. Tópicos: OC, POI, MH https://proceedings.science/p/193410?lang=pt-br DOI: 10.59254/sbpo-2024-193410 1. Introdução Sistemas de manufatura flexíveis (SMFs) têm sido amplamente utilizados por indústrias para lidar com requisitos de produção complexos e variáveis desde a década de 1980 [Calmels, 2019]. Um SMF é constituído por um conjunto de máquinas flexíveis interligadas por um sistema automático de manuseio de materiais. Cada máquina flexível é capaz de executar diversas operações diferentes, como lixar, cortar, furar, entre outras [Zeballos, 2010], desde que as ferramentas ne- cessárias para tais operações estejam previamente carregadas em um compartimento específico, denominado magazine. Estes sistemas produtivos estão presentes em diversos segmentos industri- ais, tais como, indústrias siderúrgicas, automotivas, químicas, farmacêuticas, entre outras [González et al., 2015; Shirazi e Frizelle, 2001]. Entretanto, a literatura demonstra que o gerenciamento de produção em um SMF não é trivial [Stecke, 1983]. De fato, mesmo se considerarmos um ambiente industrial simples, composto por apenas uma máquina flexível, diversas decisões de escalonamento devem ser tomadas para que a produção possa ocorrer de forma eficiente. Considera-se um SMF constituído por uma única máquina flexível. A produção é divida em estágios. A cada estágio, um conjunto de operações, aqui nomeado como processamento de uma tarefa, precisa ser executado sobre uma determinada matéria prima ou produto semi-acabado. Cada conjunto de operações requer um conjunto de ferramentas específico. Embora limitada, a ca- pacidade do magazine da máquina flexível é suficiente para conter todas as ferramentas necessárias para o processamento de uma tarefa. Entretanto, dado o processamento sequencial de uma série de tarefas, pode ser necessário realizar trocas de ferramentas no magazine antes que a próxima tarefa possa ser iniciada. De acordo com Van Hop e Nagarur [2004], as trocas de ferramentas consomem mais tempo do que qualquer outra operação de configuração em um SMF. Ademais, Beezão et al. [2017] menciona que entre 25% e 30% dos custos fixos e variáveis de um SMF ocorrem devido as trocas de ferramentas. Assim, para o SMF exemplificado, o planejamento de produção deve considerar a minimização das trocas de ferramentas visando diminuir o custo de produção e aumentar a produ- tividade do sistema. Na literatura, este planejamento de produção é conhecido como o problema de minimização de trocas de ferramentas (job sequencing and tool switching problem, SSP). Introduzido por Tang [1986], o SSP consiste de dois problemas combinatórios: a definição da ordem de processamento para um conjunto de tarefas em uma máquina flexível e a determinação do plano de trocas de ferramentas. O primeiro problema é NP-difícil [Crama et al., 1994], ou seja, não se conhece algoritmo determinístico polinomial para sua solução, sendo responsável pela com- plexidade do SSP. Para o segundo problema, dada uma ordem de processamento para as tarefas, o plano ótimo de trocas de ferramentas pode ser obtido utilizando-se a política de manter no magazine as ferramentas que serão utilizadas mais cedo (keep tool needed soonest, KTNS), apresentada por Tang e Denardo [1988]. Neste estudo, explora-se a conexão entre o SSP e um problema relacionado, o problema de minimização de blocos de uns consecutivos (consecutive block minimization problem, CBM). Apresenta-se uma implementação da meta-heurística busca local iterativa (iterated local search, ILS). Extensos experimentos computacionais consideraram todas as instâncias disponíveis na lite- ratura e novos melhores resultados inéditos são reportados para algumas instâncias, além de uma redução substancial no tempo de execução quando comparado ao método estado da arte. O restante do artigo é organizado da seguinte forma. O problema abordado é formalmente descrito na Seção 2. A Seção 3 apresenta a revisão da literatura sobre o SSP. O método proposto é descrito em detalhes na Seção 4. A Seção 5 descreve os experimentos realizados e os resultados obtidos. Por último, a Seção 6 apresenta as conclusões e trabalhos futuros. https://proceedings.science/p/193410?lang=pt-br DOI: 10.59254/sbpo-2024-193410 2. Descrição do problema Formalmente, considerando-se um SMF constituído por uma única máquina flexível cujo magazine pode conter até C ferramentas simultaneamente, um conjunto J = {1, ..., n} de tarefas a serem processadas, um conjunto T = {1, ..., m } de ferramentas e um subconjunto Tj (Tj ∈T) de ferramentas necessárias para processar a tarefa j (j ∈J), em que |Tj| ≤C, o SSP consiste em determinar a ordem de processamento das tarefas de forma que o número total de trocas de ferramentas seja minimizado. Dada sua ampla aplicação prática em diversos ambiente industriais, o SSP possui diversas variações e problemas relacionados [Calmels, 2019]. Em sua versão padrão, também conhecida na literatura como SSP uniforme, o SSP possui as seguintes características [Bard, 1988; Crama et al., 1994]: (i) todas as ferramentas são consideradas idênticas e portanto podem ocupar qual- quer posição livre no magazine; (ii) somente uma ferramentas pode ser trocada por vez e o tempo necessário para a troca de uma ferramenta é considerado constante e idêntico para todas as ferra- mentas; (iii) o conjunto de tarefas e o subconjunto de ferramentas necessárias para o processamento de cada tarefa é conhecido à priori; (iv) o número de ferramentas requeridas para processar uma tarefa é menor ou igual à capacidade do magazine; e (v) não são consideradas trocas de ferramentas originadas por desgastes ou quebras. Uma instância do SSP pode ser representada por uma matriz binária Q. Cada linha da matriz corresponde a uma tarefa e cada coluna corresponde a uma ferramenta. Se uma tarefa j requer a ferramenta t, então qjt = 1. Caso contrário, qjt = 0. A Tabela 1 apresenta um exemplo de instância para o SSP com n = 6, T = {1, . . . , 10} e C = 6. A solução para o problema é obtida a partir da permutação π das colunas do plano de trocas de ferramentas que também pode ser representado por uma matriz binária Rπ = {rtj} com t ∈{1, . . . , m}, j ∈{1, . . . , n}. A cada etapa do plano de trocas de ferramentas, representada por suas colunas, uma tarefa é processada. As linhas do plano de trocas de ferramentas indicam as ferramentas carregadas no magazine antes do início do processamento de cada etapa. Um ele- mento rtj = 1 indica que a ferramenta t está carregada no magazine da máquina flexível durante o processamento da tarefa j, e rtj = 0 indica o contrário. Considere a instância apresentada na Tabela 1 e a permutação π = {1,3,5,2,4,6}. A Tabela 2 apresenta o plano de trocas de ferramentas correspondente. Ferramentas inseridas ou removidas imediatamente antes do processamento de uma tarefa são apresentadas sublinhadas. Por exemplo, antes do processamento da tarefa 2, no quarto estágio, a ferramenta 9 foi removida e a ferramenta 4 inserida no magazine, assim, ambas os elementos aparecem sublinhados. Tabela 1: Instância do SSP. Tarefas Ferramentas 1 2 3 4 5 6 7 8 9 10 1 0 0 0 0 1 1 1 0 1 1 2 0 1 0 1 0 1 0 0 0 0 3 1 1 1 0 1 1 0 0 0 0 4 1 0 1 0 1 0 1 0 0 0 5 0 0 1 0 0 1 1 1 1 0 6 0 1 0 0 0 0 0 1 0 0 Tabela 2: Plano de trocas de ferramentas. Ferramentas Estágios/Tarefas 1 3 5 2 4 6 1 0 1 0 0 1 1 2 0 1 1 1 1 1 3 1 1 1 1 1 1 4 0 0 0 1 0 0 5 1 1 0 0 1 1 6 1 1 1 1 0 0 7 1 0 1 1 1 1 8 0 0 1 1 1 1 9 1 1 1 0 0 0 10 1 0 0 0 0 0 De acordo com a permutação π = {1, 3, 5, 2, 4, 6}, a primeira tarefa a ser processada https://proceedings.science/p/193410?lang=pt-br DOI: 10.59254/sbpo-2024-193410 (j = 1) requer somente cinco ferramentas {5, 6, 7, 9, 10}. Como a capacidade do magazine permite uma ferramenta adicional (C = 6), uma ferramenta requerida pelo próximo estágio de produção deve ser carregada. Neste exemplo, a ferramenta 3 foi selecionada. Para evitar trocas de ferramentas desnecessárias, uma ferramenta não utilizada no estágio atual mas requerida nos estágios futuros, deve ser mantida no magazine sempre que possível. O plano de trocas de ferramentas é avaliado utilizando-se a Equação (1) proposta por Crama et al. [1994]. Esta equação calcula o número de inversões de zero para um na representação matricial, que representam as inserções de ferramentas no magazine. Para que o carregamento ini- cial de ferramentas seja considerado, uma coluna artificial com todos os elementos iguais a zero deve ser adicionada ao plano de trocas de ferramentas, ou seja, Rπ t0 = 0. Para o exemplo apresen- tado, são realizadas 13 trocas de ferramentas. ZSSP (Rπ) = X t∈T X j∈J rπ tj(1 −rπ tj−1) (1) O objetivo do SSP é obter uma permutação π ∈Π para o escalonamento de tarefas que minimize o total de trocas de ferramentas. A função objetivo do SSP é representada pela Equação (2), em que Π é o conjunto de todas as possíveis permutações de tarefas. min π∈Π ( Zπ SSP (R) ) (2) Conforme mencionado, para evitar trocas de ferramentas desnecessárias, sempre que possível, uma ferramenta necessária nos estágios de produção futuros deve ser mantida no ma- gazine. Quando uma ferramenta é removida e posteriormente reinserida no magazine, isto é eviden- ciado por uma descontinuidade na representação matricial do plano de trocas de ferramentas. Uma descontinuidade ocorre sempre que um elemento nulo ocorre entre dois conjuntos de elementos não-nulos em uma matriz binária. O estudo de descontinuidades em matrizes binárias define o problema NP-difícil co- nhecido na literatura como CBM. Embora o CBM e o SSP não sejam equivalentes, as estratégias utilizadas para solução do CBM podem resultar em boas soluções para o SSP. Assim, neste estudo, recentes avanços no estudo do CBM [Soares et al., 2020] são considerados como parte da estratégia para abordagem ao SSP. 3. Revisão da literatura Desde sua publicação seminal na década de 1980, diversos autores têm abordado o SSP e suas variações [Soares e Carvalho, 2020; Rifai et al., 2022; Calmels, 2022; Cura, 2023]. Uma revisão ampla, contendo as principais variações pode ser encontrada em Calmels [2019]. A seguir, apresenta-se as principais contribuições para a versão original do SSP em ordem cronológica. O SSP foi formalmente definido por Tang e Denardo [1988]. Neste estudo, o problema é modelado e resolvido como uma instância do problema do caixeiro viajante (traveling salesman problem, TSP). Além disso, os autores apresentam a política KTNS que permite definir em tempo determinístico polinomial a solução ótima o plano de trocas de ferramentas para uma dada sequência fixa de tarefas. Crama et al. [1994] provou que o SSP pertence a classe de problemas NP-difícil para qualquer instância com C ≥2. Novamente, modela-se o problema como uma instância do TSP. Tal modelagem se tornou recorrente na literatura [Hertz et al., 1998; Djellab et al., 2000; Shirazi e Frizelle, 2001; Laporte et al., 2004; Ahmadi et al., 2018]. Entretanto, em um trabalho teórico, Yanasse e Lamosa [2006a,b] demonstram que esta abordagem é ineficiente, pois o SSP e o TSP não são equivalentes. https://proceedings.science/p/193410?lang=pt-br DOI: 10.59254/sbpo-2024-193410 Um novo modelo de programação linear inteira para o SSP foi proposto por Laporte et al. [2004]. O modelo apresentado apresenta melhores valores de relaxação linear quando comparados ao modelo de Tang e Denardo [1988]. Além disso, são apresentados e comparados dois algoritmos para o problema, um método de branch-and-bound e um de branch-and-cut. Os experimentos rea- lizados utilizaram instâncias geradas no próprio artigo. O método branch-and-cut mostrou-se apto a resolver de forma ótima instâncias com até nove tarefas e o método branch-and-bound instâncias com até 25 tarefas. Um algoritmo enumerativo para o SSP é apresentado por Yanasse et al. [2009]. Os resul- tados obtidos foram comparados e superam os reportados por Laporte et al. [2004]. Em um trabalho subsequente, Senne e Yanasse [2009] apresentam três implementações de beam search baseadas no mesmo esquema enumerativo. Entretanto, os resultados obtidos pelos algoritmos propostos não foram comparados com outros métodos da literatura. Chaves et al. [2016] apresentam um algoritmo híbrido combinando um algoritmo de busca de agrupamento (clustering search, CS) com um algoritmo genético de chaves aleatórias viciadas (biased random-key genetic algorithm, BRKGA). Os experimentos computacionais utilizaram 1510 instâncias [Yanasse et al., 2009; Crama et al., 1994]. Novos melhores valores foram publicados para todos os problemas. Paiva e Carvalho [2017] apresentam uma nova representação em grafos, uma heurística construtiva e uma nova implementação da meta-heurística ILS para o SSP. Entre as buscas locais utilizadas pela ILS, os autores introduzem uma busca local por agrupamento de blocos de uns con- secutivos em uma matriz binária, explorando a conexão entre o SSP e o CBM. Os experimentos computacionais utilizaram 1670 instâncias [Yanasse et al., 2009; Crama et al., 1994; Catanzaro et al., 2015]. Os resultados obtidos foram comparados com os melhores valores conhecidos para to- dos os problemas. De acordo com os experimentos realizados, o método proposto reportou soluções equivalentes ou melhores para todas as instâncias consideradas. Ahmadi et al. [2018] modelam o SSP como uma instância do TSP de segunda ordem (2- TSP) e o resolvem com uma implementação do algoritmo genético q-learning. Entretanto, os auto- res não detalham a métrica utilizada para determinação das distâncias utilizadas na modelagem. Os experimentos consideraram apenas apenas um subconjunto das instâncias disponíveis [Catanzaro et al., 2015; Crama et al., 1994]. Os resultados foram comparados com Paiva e Carvalho [2017] e apresentaram melhorias marginais. Uma nova formulação linear inteira para o SSP, utilizando um modelo de multi-fluxo é apresentada por Silva et al. [2020]. Os experimentos utilizaram um subconjunto das instâncias disponíveis na literatura [Yanasse et al., 2009; Catanzaro et al., 2015]. Os resultados reportados superam os obtidos por modelos anteriores, entretanto, considerando-se o tempo limite estabelecido em uma hora, a modelagem não é capaz de resolver os maiores problemas dentre as instâncias utilizadas. Mecler et al. [2021] apresentam um algoritmo de pesquisa genética híbrida (ou hybrid ge- netic search, HGS) para o SSP. Além do benchmark de instâncias disponível na literatura [Yanasse et al., 2009; Crama et al., 1994; Catanzaro et al., 2015], os experimentos computacionais utilizaram um novo conjunto contendo 60 instâncias com maiores dimensões, propostas no próprio artigo. Os resultados obtidos foram comparados com os reportados pelos métodos apresentados por [Chaves et al., 2016; Paiva e Carvalho, 2017; Ahmadi et al., 2018]. O método proposto reportou melhores resultados médios para todos os conjuntos de instâncias, tornando-se o atual estado da arte para o SSP. https://proceedings.science/p/193410?lang=pt-br DOI: 10.59254/sbpo-2024-193410 4. Métodos Em um trabalho recente, Soares et al. [2020] apresentam um método exato para solução do CBM. O método consiste em (i) transformar o CBM em uma instância do problema de minimização de blocos circulares (circular block minimization problem, CIR); (ii) transformar o CIR em uma instância do TSP em que a matriz de distância é calculada utilizando-se a distância de Hamming [Hamming, 1986]; e, (iii) solução do problema com o resolvedor exato Concorde [Applegate et al., 2006]. Embora o SSP e o CBM sejam equivalentes apenas para o caso especial em que cada tarefa do SSP requer exatamente C ferramentas para ser processada, a conexão entre estes dois problemas tem sido explorada com sucesso na literatura [Paiva e Carvalho, 2017; Soares e Carvalho, 2020]. Entretanto, não é esperado que esta modelagem, isoladamente, produza soluções de alta qualidade. Assim, apresenta-se uma implementação da meta-heurística ILS que explora o espaço de busca a partir de uma solução inicial gerada por esta modelagem. O método proposto é descrito a seguir. 4.1. Busca local iterativa Conceitualmente simples, a meta-heurística ILS, a partir de uma dada solução inicial, explora o espaço de busca aplicando alternadamente mecanismos de intensificação e diversificação à procura de uma solução final de alta qualidade. Apesar de sua simplicidade conceitual, esta meta-heurística tem sido aplicada com sucesso a diversos problemas computacionalmente difíceis [Lourenço et al., 2019], incluindo aplicações diretas ao CBM [Soares et al., 2020] e ao próprio SSP [Paiva e Carvalho, 2017]. A implementação da meta-heurística ILS proposta para abordagem ao SSP é descrita a seguir. Uma solução inicial é gerada utilizando-se a modelagem proposta por Soares et al. [2020] para o CBM. Para solução da modelagem, optou-se por utilizar o método Lin-Kernighan heuristic, LKH [Helsgaun, 2018], reconhecido na literatura como um dos métodos mais bem sucedidos na geração de soluções ótimas e subótimas para o TSP [Helsgaun, 2000]. Embora o resolvedor Con- corde tenha sido utilizado na abordagem original, sua aplicação sucessiva nas instâncias disponíveis para o SSP mostrou-se instável. Diante disso, optou-se por utilizar o método LKH. Uma análise preliminar mostrou que tal diferença não impactou a qualidade das soluções iniciais obtidas. Na etapa de intensificação, são utilizados os métodos de busca local inversão de elemen- tos adjacentes, 2-opt e busca local de maior arrependimento, nesta ordem. O método busca local inversão de elementos adjacentes é uma variação do tradicional método 2-swap. Um movimento desta busca local consiste na troca de dois elementos diretamente adjacentes na solução. O método 2-opt consiste na inversão de todos os elementos em um intervalo selecionado aleatoriamente. O método busca local de maior arrependimento, classifica cada tarefa de acordo com o número de tro- cas de ferramentas gerado pelo seu escalonamento em sua posição atual. Posteriormente, esta busca local reposiciona cada tarefa na posição em que gerar o menor número de trocas de ferramentas. As tarefas são reposicionadas de acordo com a ordem estabelecida pela classificação, garantido que as tarefas que mais originavam trocas de ferramentas sejam reposicionadas primeiro. Para a etapa de diversificação foi utilizado o método ponte dupla. Proposto originalmente para o TSP, quando aplicado ao SSP este método divide o escalonamento de tarefas em quatro pontos. Em seguida, os componentes contendo os segmentos da solução são reordenados gerando uma solução vizinha que mantém a estrutura interna de cada componente. Foram utilizados três critérios de aceitação, a saber, soluções com melhor valor de avaliação; soluções com igual valor de avaliação mas com maior número de ferramentas removidas e reinse- ridas ao longo do plano de trocas de ferramentas; e, soluções com valor de avaliação e número de reinserções de ferramentas iguais à solução atual mas com maior número de reinserções de uma mesma ferramenta. Os critérios adicionais de aceitação foram incorporados com o objetivo de guiar a trajetória do ILS por soluções com características que indicam um maior potencial de melhoria. https://proceedings.science/p/193410?lang=pt-br DOI: 10.59254/sbpo-2024-193410 Como critério de parada do método foi utilizado o número máximo de iterações. A quan- tidade máxima de iterações e a ordem de aplicação das buscas locais foram definidos nos experi- mentos preliminares descritos na Seção 5. As etapas do método proposto são descritas no Algoritmo 1. A solução inicial é construída utilizando-se a modelagem proposta para o CBM (linha 1). As buscas locais inversão de elementos adjacentes, 2-opt e maior arrependimento são aplicadas à solução inicial (linhas 2 a 4). O laço principal (linhas 5 a 13) assegura a execução da método até que o critério de parada seja alcançado. A solução atual s é perturbada utilizando-se um movimento do método ponte dupla, resultando na solução vizinha s′ (linha 6). A etapa de intensificação da meta-heurística é conduzida pela aplicação sequencial dos métodos de buscas locais inversão de elementos adjacentes (linha 7), 2-opt (linha 8) e maior arrependimento (linha 9). Caso s′ atenda aos critérios de aceitação para uma nova solução, a solução atual é atualizada com s′ (linhas 10 a 12). Após alcançado o critério de parada, a solução atual s é retornada (linha 14). Algoritmo 1: Busca local iterativa Entrada: Instância do problema; Saída: Solução s; 1 s ←soluçãoInicial(); 2 aplique a busca local inversão de elementos adjacentes a s; 3 aplique a busca local 2-opt a s; 4 aplique a busca local maior arrependimento a s; 5 enquanto critério de parada não for encontrado faça 6 s′ ←execute um movimento do método ponte dupla em s; 7 aplique a busca local inversão de elementos adjacentes a s′; 8 aplique a busca local 2-opt a s′; 9 aplique a busca local maior arrependimento a s′; 10 se s′ atende aos critérios de aceitação então 11 s ←s′; 12 fim 13 fim 14 retorne s; 5. Experimentos Uma série de experimentos computacionais foi realizada para mensurar a qualidade das soluções reportadas pelo método proposto e avaliar seu comportamento. O ambiente computacional utilizado consiste de um computador com processador Intel Xeon E5-2660 de 2.2 GHz com 384 GB de memória RAM sob o sistema operacional CentOS 6.8. Todos os métodos foram implementados em C++, compilados com GCC 11.2.0 e as opções de otimização -O3 e -march = native. Os parâmetros do ILS foram definidos utilizando-se o método offline de configuração automática de algoritmos de otimização irace [López-Ibáñez et al., 2016], a saber, a ordem de aplicação das buscas locais e o número máximo de iterações, definido como 1500. Conforme mencionado, o SSP possui quatro conjuntos de instâncias disponíveis na lite- ratura, sendo os três primeiros considerados instâncias clássicas e o último um conjunto recente contendo os maiores problemas. Em ordem cronológica, o primeiro conjunto de instâncias foi pro- posto por Crama et al. [1994] e contém 160 problemas divididos em quatro grupos (C1, C2, C3, C4). O segundo, proposto por Yanasse et al. [2009], contém 1350 problemas divididos em cinco grupos https://proceedings.science/p/193410?lang=pt-br DOI: 10.59254/sbpo-2024-193410 (A, B, C, D, E). O terceiro, introduzido por Catanzaro et al. [2015], possui 160 instâncias divi- didas em quatro grupos (datA, datB, datC, datD). O quarto, proposto por Mecler et al. [2021], divide-se em três grupos (F1, F2, F3) e, conforme mencionado, possui os problemas com as maiores dimensões. Todas as instâncias foram consideradas nos experimentos realizados. A Tabela 3 apresenta, para os conjuntos de instâncias clássicos, os resultados que consti- tuem o atual estado da arte bem como os valores médios obtidos a partir de dez execuções individu- ais do método proposto. Seguindo o padrão adotado por Mecler et al. [2021], os valores reportados apresentam a média das médias de cada subconjunto. Para o método detentor do estado da arte (HGS), os valores médios das soluções reportadas no trabalho original foram aumentados em C unidades para considerar as trocas de ferramentas iniciais, conforme considerado pelo método aqui proposto. Para ambos os métodos, apresenta-se a média das melhores soluções reportadas (S∗) e a média das soluções (S). Em adição, para o ILS apresenta-se a média das soluções iniciais (I), o desvio padrão de S (σ), e a distância percentual (gap) entre a melhor solução reportada pelos métodos ILS e HGS, calculada como 100 × ILS(S∗) - HGS(S∗) HGS(S∗) . Os melhores valores de solução são destacados em negrito. Tabela 3: Resultados para as instâncias clássicas. HGS ILS Grupo S∗ S I S∗ S σ gap(%) C1 11,18 11,18 12,18 11,18 11,18 0,00 0,00 C2 22,00 22,00 24,58 22,00 22,00 0,01 0,00 C3 79,33 79,72 103,76 79,35 79,44 0,08 0,03 C4 157,03 157,24 183,23 157,00 157,22 0,22 -0,02 A 23,18 23,18 24,18 23,18 23,18 0,00 0,00 B 23,87 23,87 25,14 23,87 23,87 0,00 0,00 C 28,02 28,02 30,70 27,80 27,80 0,00 -0,79 D 25,05 25,05 28,56 25,05 25,08 0,04 0,00 E 16,89 16,89 18,38 16,89 16,89 0,00 0,00 datA 10,85 10,85 11,55 10,85 10,85 0,00 0,00 datB 21,78 21,78 24,00 21,78 21,78 0,00 0,00 datC 74,68 74,73 89,93 74,70 74,99 0,29 0,03 datD 157,10 157,36 186,58 157,15 157,88 0,63 0,03 Considerando-se todo o benchmark de instâncias clássicas, o ILS reportou um gap médio de -0,06%, variando entre -0,79% e 0,03%. Embora a diferença entre as soluções seja apenas marginal, novos melhores resultados inéditos são apresentados para os grupos C4 e C. Em média, o ILS precisou de 147,29 iterações para melhorar a solução inicial em 14,68%. Entre as buscas locais, 2-opt é a que mais contribuiu para a qualidade final da solução, respondendo em média por 67,89% das melhorias. Em seguida, tem-se a busca local inversão de elementos adjacentes e a busca local maior arrependimento, responsáveis, por 20,02% e 12,09% das melhorias, respectivamente. O desvio padrão médio reportado para este conjunto é de apenas 0,10, indicando a capacidade do método de gerar soluções independentes com baixa variação. Para este conjunto de instâncias, o tempo de execução é pequeno, sendo considerado desprezível. Ambos os métodos reportam tempo de execução não superior a cinco minutos para resolver todas as instâncias. Seguindo o mesmo padrão apresentado para a tabela anterior, a Tabela 4 apresenta os re- sultados para o novo conjunto de instâncias. Para uma comparação justa do tempo de execução dos algoritmos, o método HGS original, disponibilizado pelos autores, foi executado para este conjunto https://proceedings.science/p/193410?lang=pt-br DOI: 10.59254/sbpo-2024-193410 de instâncias no mesmo ambiente computacional utilizado por este estudo. Os resultados reportados pelo HGS são compatíveis com os reportados pelo trabalho original. Em acréscimo aos dados apre- sentados pela tabela anterior, apresenta-se o número de tarefas (n), ferramentas (m), capacidade do magazine (C), e tempo médio de execução (T) em segundos. Tabela 4: Resultados para o conjunto de instâncias proposto por Mecler et al. [2021]. HGS ILS n m C S∗ S T I S∗ S T σ gap(%) 50 75 25 293,60 293,82 3303,42 331,80 293,60 293,64 2240,41 0,08 0,00 50 75 30 226,40 227,10 2694,11 266,80 226,80 226,96 1983,58 0,26 0,18 50 75 35 182,40 183,08 2731,85 222,00 182,60 183,22 1755,40 0,43 0,11 50 75 40 149,80 150,42 2300,50 188,00 150,20 150,86 1612,24 0,55 0,27 60 90 35 449,60 450,60 12082,73 515,80 450,60 451,60 7137,42 0,71 0,22 60 90 40 360,00 361,14 10979,21 425,60 360,20 361,50 6138,69 0,67 0,06 60 90 45 292,20 293,70 9304,33 358,80 292,80 294,18 5337,49 0,74 0,21 60 90 50 241,20 242,88 8107,61 303,80 242,40 243,76 4609,05 0,86 0,50 70 105 40 616,60 617,58 23693,08 704,20 617,20 618,58 13029,04 0,77 0,10 70 105 45 504,00 505,10 21302,32 594,80 504,60 505,52 11773,04 0,67 0,12 70 105 50 419,60 421,06 17612,52 510,20 419,80 421,76 10821,81 0,88 0,05 70 105 55 353,60 355,02 16899,57 441,40 354,00 355,88 9799,70 1,06 0,11 Comparado com o HGS, o ILS reportou um gap médio de 0,16%, variando entre -0,41% e 1,26%. Considerando-se os valores individuais, o ILS apresenta gap menor ou igual a zero para 58,33% das instâncias deste conjunto. A ausência de diferenças substanciais entre os resultados reportados para este novo conjunto de instâncias assemelha-se ao estado das instâncias clássicas, dificultando a análise das diferenças entre os métodos. Além disso, a falta de soluções ótimas co- nhecidas ou limites inferiores de boa qualidade torna impossível determinar se há espaço disponível para uma melhoria significativa nos resultados gerados. Para tentar resolver esta limitação, solicita- mos aos autores de Silva et al. [2020] que executassem o modelo de multi-fluxo para as instâncias deste conjunto. Infelizmente, dentro de um limite de tempo de 3600 segundos, não foram reporta- dos resultados ótimos e os limitantes inferiores reportados não foram justos, com valores próximos de m −C em geral. Em um resultado notável, o tempo de execução do ILS é 41,81% menor do que o reque- rido por HGS, em média. Dada a origem industrial do SSP, um tempo de execução excessivamente elevado pode apresentar-se como um obstáculo à aplicação de métodos computacionais no planeja- mento prático da produção. Considerando todas as execuções individuais para todas as instâncias deste conjunto, o tempo máximo de execução reportado pelo HGS foi de 47.486,00 segundos en- quanto o tempo máximo de execução do ILS foi de 14.601,50 segundos, portanto, 69,25% menor. A convergência média do ILS ocorreu com 913,83 iterações tendo melhorado a solução inicial em 19,01%. O comportamento das buscas locais é similar ao reportado para o conjunto de instâncias clássicas. A busca local 2-opt é a que mais contribuiu para a qualidade final da solução respondendo por 79,20% das melhorias. Em seguida, tem-se as buscas locais inversão de elementos adjacentes e a busca local maior arrependimento, responsáveis por 13,65% e 7,14% das melhorias, respectivamente. Novamente, o baixo desvio padrão reportado, em média apenas 0,64, confirma a consistência do ILS em gerar soluções de alta qualidade com baixa variação. Uma segunda versão do ILS usando soluções iniciais aleatórias (ILSr) foi implementada para avaliar a convergência do método proposto. Em média, o ILSr precisou de 907 iterações para melhorar a solução inicial aleatória em 47,63%. Apesar da piora significativa na qualidade das https://proceedings.science/p/193410?lang=pt-br DOI: 10.59254/sbpo-2024-193410 soluções iniciais, o ILSr convergiu para soluções com qualidade equiparável à sua versão ante- rior, reportando um gap médio de 0,28% sem aumentar significativamente o tempo de execução, demonstrando a robustez do método proposto. 6. Conclusão Neste estudo, apresentou-se uma nova abordagem para o SSP, um problema NP-difícil com grande aplicação prática em diversos segmentos industriais. Avanços recentes em um pro- blema relacionado, CBM, foram considerados na implementação da meta-heurística busca local iterativa. O método proposto foi comparado ao atual estado da arte para o SSP considerando-se todas as instâncias disponíveis na literatura. Embora as diferenças entre os métodos sejam apenas marginais, apresentou-se novos melhores resultados para dois grupos de instâncias clássicas am- plamente utilizadas. Ademais, o método proposto mostrou-se, em média, 41,87% mais rápido que o atual método estado da arte para o problema. Dada a característica prática do SSP, a obtenção de soluções com qualidade equiparável em menor tempo computacional apresenta-se como uma vantagem estratégia para utilização do método em cenários reais. Os trabalhos futuros diretamente derivados deste estudo se concentrarão em uma análise profunda das instâncias disponíveis, bus- cando evidências que apontem para possibilidade ou não de melhorias nos resultados já publicados. 7. Agradecimentos Esta pesquisa foi apoiada pelo Conselho Nacional de Desenvolvimento Científico e Tec- nológico, CNPq, 408341/2018-1, pela Universidade Federal de Ouro Preto e Instituto Federal do Sudeste de Minas Gerais. Os autores expressam seu especial agradecimento à Tiago Tibúrcio da Silva e Antônio Augusto Chaves, que gentilmente executaram o modelo de multi-fluxo para as maiores instâncias utilizadas nos experimentos computacionais."
        },
        {
            "titulo": "Otimização Multiobjetivo de Custos e Qualidade de Simulações de CFD: Explorando a Fronteira de Pareto",
            "informacoes_url": "https://proceedings.science/p/193796?lang=pt-br",
            "idioma": "português",
            "storage_key": "galoa-proceedings--sbpo-2024--193796.pdf",
            "autores": [
                {
                    "nome": "Tiago Martins de Azevedo",
                    "afiliacao": "Universidade Federal de Itajubá",
                    "orcid": ""
                },
                {
                    "nome": "Anderson Paulo de Paiva",
                    "afiliacao": "Universidade Federal de Itajubá",
                    "orcid": ""
                },
                {
                    "nome": "Matheus Costa Pereira",
                    "afiliacao": "Universidade Federal de Itajubá",
                    "orcid": ""
                },
                {
                    "nome": "Ana Carolina Gonçalves da Silva",
                    "afiliacao": "Universidade Federal de Itajubá",
                    "orcid": ""
                },
                {
                    "nome": "Ana Izabella Freire",
                    "afiliacao": "Universidade Federal de Itajubá",
                    "orcid": ""
                },
                {
                    "nome": "Matheus Francisco Brendon",
                    "afiliacao": "Universidade Federal de Itajubá",
                    "orcid": ""
                }
            ],
            "data_publicacao": "",
            "resumo": "Ao integrar a Dinâmica de Fluidos Computacional (CFD) com técnicas de planejamento de experimentos (DOE) aplicadas à hidráulica, é possível otimizar sistemas ao explorar o espaço de soluções e identificar os fatores críticos de desempenho.",
            "keywords": [
                "Planejamento de experimentos",
                "Otimização Multiobjetivo",
                "Custos de simulação"
            ],
            "referencias": [
                "Aboujaoude, H., Bogard, F., Beaumont, F., Murer, S., e Polidori, G. (2023). Aerodynamic Performance Enhancement of an Axisymmetric Deflector Applied to Savonius Wind Turbine Using Novel Transient 3D CFD Simulation Techniques. Energies, 16(2). https://doi.org/10.3390/en16020909",
                "Azevedo, T. M. de. (2020). Validação Numérica-Experimental do Comportamento Hidrodinâmico de uma Turbina Hélice em Escala Reduzida [Universidade Federal de Itajubá]. https://repositorio.unifei.edu.br/jspui/handle/123456789/2202",
                "Azevedo, T. M. de, e Paiva, A. P. de. (2024). Parametrização do CFD Utilizando Planejamento de Experimentos. https://doi.org/10.29327/1342182.1-2",
                "Becerra, D., Zambrano, A., Asuaje, M., e Ratkovich, N. (2024). Experimental and CFD modeling of a progressive cavity pump (PCP) using overset unstructured mesh part 1: Single-phase flow. Geoenergy Science and Engineering, 234(October 2023), 212602. https://doi.org/10.1016/j.geoen.2023.212602",
                "Bhonsale, S., Mores, W., Nimmegeers, P., Hashem, I., e Van Impe, J. (2022). Ellipsoid based Pareto filter for multiobjective optimisation under parametric uncertainty: A beer study. IFAC-PapersOnLine, 55(20), 409–414. https://doi.org/10.1016/j.ifacol.2022.09.129",
                "Botan, A. C. B. (2014). Desenvolvimento de uma turbina de fluxo reversível para uso em usina maremotriz com operação em duplo efeito. Universidade Federal de Itajubá.",
                "Cavazzini, G., Giacomel, F., Ardizzon, G., Casari, N., Fadiga, E., Pinelli, M., Suman, A., e Montomoli, F. (2020). CFD-based optimization of scroll compressor design and uncertainty quantification of the performance under geometrical variations. Energy, 209, 118382. https://doi.org/10.1016/j.energy.2020.118382",
                "Clempner, J. B., e Poznyak, A. S. (2017). Multiobjective Markov chains optimization problem with strong Pareto frontier: Principles of decision making. Expert Systems with Applications, 68, 123–135. https://doi.org/10.1016/J.ESWA.2016.10.027",
                "Das, I., e Dennis, J. E. (1998). Normal-boundary intersection: A new method for generating the Pareto surface in nonlinear multicriteria optimization problems. SIAM Journal on Optimization, 8(3), 631–657. https://doi.org/10.1137/S1052623496307510",
                "Jamaleddine, T. J., e Ray, M. B. (2010). Application of computational fluid dynamics for simulation of drying processes: A review. Drying Technology, 28(2), 120–154. https://doi.org/10.1080/07373930903517458",
                "Karkaba, H., Dbouk, T., Habchi, C., Russeil, S., Lemenand, T., & Bougeard, D. (2024). Multiobjective optimization of Vortex Generators for heat transfer enhancement in turbulent flows. International Journal of Thermofluids, 22. https://doi.org/10.1016/j.ijft.2024.100633",
                "Knotek, S., Schmelter, S., e Olbrich, M. (2021). Assessment of different parameters used in mesh independence studies in two-phase slug flow simulations. Measurement: Sensors, 18(September), 3–6. https://doi.org/10.1016/j.measen.2021.100317",
                "Marjavaara, B. D., Lundström, T. S., Goel, T., Mack, Y., e Shyy, W. (2007). Hydraulic turbine diffuser shape optimization by multiple surrogate model approximations of Pareto fronts. Journal of Fluids Engineering, Transactions of the ASME, 129(9), 1228–1240. https://doi.org/10.1115/1.2754324",
                "Montgomery, D. C. (2009). Design and Analysis of Experiments (7th ed). John Wiley & Sons.",
                "Shrestha, U., e Choi, Y. Do. (2020). Improvement of flow behavior in the spiral casing of Francis hydro turbine model by shape optimization. Journal of Mechanical Science and Technology, 34(9), 3647–3656. https://doi.org/10.1007/s12206-020-0817-9",
                "Zhu, Z., Wang, X., Jiang, C., Wang, L., e Gong, K. (2021). Multi-objective optimal operation of pumped-hydro-solar hybrid system considering effective load carrying capability using improved NBI method. International Journal of Electrical Power and Energy Systems, 129(January), 106802. https://doi.org/10.1016/j.ijepes.2021.106802"
            ],
            "artigo_completo": "Otimização Multiobjetivo de Custos e Qualidade de Simulações de CFD: Explorando a Fronteira de Pareto. RESUMO Ao integrar a Dinâmica de Fluidos Computacional (CFD) com técnicas de planejamento de experimentos (DOE) aplicadas à hidráulica, é possível otimizar sistemas ao explorar o espaço de soluções e identificar os fatores críticos de desempenho. A análise multiobjetivo, combinada com o método Normal Boundary Intersection (NBI), revela-se fundamental para identificar soluções ótimas que equilibrem as metas de desempenho. O estudo demonstra que o aumento do número de réplicas aprimorou a qualidade da malha de 90,060% para 91,492%, embora também tenha elevado os custos de simulação, tradicionalmente tratados de maneira subjetiva, destacando a compensação entre as funções objetivo. A análise da Fronteira de Pareto, com pesos igualitários, resultou em uma qualidade de 84,473% e um custo de R$ 175,07 para três réplicas. Conclui-se que a metodologia foi eficaz na identificação de soluções Pareto-ótimas, proporcionando suporte decisório mais robusto. PALAVRAS CHAVE. Planejamento de experimentos, Otimização Multiobjetivo, Custos de simulação https://proceedings.science/p/193796?lang=pt-br DOI: 10.59254/sbpo-2024-193796 1. Introdução A Fluidodinâmica Computacional (Computational Fluid Dynamics) revolucionou a indústria ao oferecer uma abordagem avançada, nos mesmos moldes da indústria 4.0, na modelagem de fluxos de fluido e transferência de calor, para as diversas áreas do conhecimento [Jamaleddine & Ray 2010]. Seu impacto se estende por diversas áreas, como aerodinâmica de veículos, design de aeronaves, otimização de processos industriais, climatização de edifícios, entre outros exemplos, como pode ser visto em [Marjavaara et al. 2007] e [Shrestha & Choi 2020]. Assim, a Fluidodinâmica Computacional (CFD) desempenha um papel relevante no âmbito da hidráulica, possibilitando análises minuciosas e o aprimoramento de sistemas de fluxo de fluidos. A integração do CFD com técnicas de Design of Experiments (DOE) na hidráulica, proporciona uma abordagem sistemática para otimizar sistemas hidráulicos, auxiliando na exploração eficiente do espaço de solução [Cavazzini et al. 2020] e na identificação dos principais fatores que influenciam o desempenho do sistema [Azevedo, 2020]. Os requisitos computacionais para sua utilização abrangem desde características do hardware até aspectos relacionados à malha utilizada na simulação, questionando sobre a mensuração do custo de operação e simulação que softwares da área promovem, dado que, trabalhos como de [Knotek et al. 2021] e [Aboujaoude et al. 2023] corroboraram a constatação de que o custo de simulação é elevado. Em contrapartida, parâmetros como tamanho e densidade de malha, afetam diretamente na precisão de previsão de resultados, o que conflita com a ideologia industrial de redução de custos. Nesse contexto, a análise multiobjetivo torna-se uma estratégia fundamentalmente empregada na otimização de sistemas complexos caracterizados pela presença de múltiplos objetivos, os quais frequentemente entram em conflito [Karkaba et al. 2024]. Desse modo, a análise multiobjetivo aplicada em CFD, segue os mesmos fundamentos para a resolução de problemas complexos nos quais múltiplos critérios devem ser considerados. Ao contrário das abordagens tradicionais de otimização, que visam à obtenção de um único ponto ótimo, a análise multiobjetivo busca identificar conjuntos de soluções que representem os compromissos entre diferentes objetivos de desempenho, assim a fronteira de Pareto desempenha um papel fundamental neste contexto. Em outras palavras, representa o conjunto de soluções onde não é possível obter um ganho em um objetivo sem sacrificar outro [Bhonsale et al. 2022]. Para a análise de otimização, utiliza-se o método Normal Boundary Intersection (NBI) sendo uma ferramenta empregada na análise multiobjetivo para a determinação das soluções ótimas de Pareto. Esta técnica apresenta vantagens significativas, uma vez que não é sensível à escala das funções objetivo, possibilitando assim a geração de pontos que estão uniformemente distribuídos na Fronteira de Pareto [Zhu et al. 2021]. O método busca identificar soluções que equilibrem as funções objetivo, permitindo uma análise abrangente dos trade-offs entre eles. Além do NBI, outras técnicas podem ser empregadas na análise multiobjetivo em CFD, incluindo algoritmos genéticos, otimização por enxame de partículas e otimização baseada em gradientes (também utilizada neste trabalho). A escolha da técnica mais adequada depende das características específicas do problema em questão e das preferências da indústria [Bhonsale et al. 2022]. Da teoria de CFD, quanto maior a qualidade da malha, mais preciso é a previsão que a simulação alcança, porém, maior é o custo para esta simulação. Considerando a indústria, na maior parte do tempo, não há tempo hábil para simulações de longa duração, como ocorre em ambientes de pesquisa, assim como, não é vantajoso aplicar o uso de simulação em uma previsão falha, portanto definir pontos que proponham uma melhor tomada de decisão, é de fundamental importância para a indústria, principalmente quando relaciona-se com o tempo de simulação e o custo operacional. Além do mais, a qualidade da malha impacta diretamente no consumo de recursos computacionais, como poder de processamento e capacidade de armazenamento, de modo que, muitas vezes, malhas com maior refino, exigem uso de computadores de maior desempenho, como clusters, o que impacta no custo operacional da simulação. Desse modo, encontrar um ponto em que equilibre precisão e custo torna-se necessário, na indústria e no contexto de melhoria contínua. https://proceedings.science/p/193796?lang=pt-br DOI: 10.59254/sbpo-2024-193796 2. Materiais e Métodos 2.1 Preparação do modelo De maneira geral, o CFD permite simular e analisar numericamente o comportamento de fluidos com geometrias complexas, proporcionando análises para aprimorar o desempenho e a eficiência dos sistemas. Para o estudo de caso, o objetivo está em propor melhorias no processo de desenvolvimento da simulação, tomando como base fatores de pré-processamento e simulação que podem influir significativamente no resultado de análise. Para isso, utilizou-se do modelo desenvolvido por [Azevedo 2020], aliado à modelagem, simulação e análise presentes nas ferramentas do software ANSYS ®, que, por meio de fatores pré-definidos, geraram os resultados para avaliação estatística. A escolha do modelo mais simples, comparando com situações como sistemas rotor-diretor que implicam em análises de rotação, promove modelagens cujo tempo de pré-processamento, ou geração de malha, e simulação será menor, porém, que permite extrapolação do método, para sistemas mais complexos. Segundo [Becerra et al. 2024] uma malha em CFD se refere à discretização da geometria em pequenos elementos (hexaédricos, tetraédricos, piramidais, prismáticos e outros) para resolver numericamente as equações governantes, sendo crucial para representar com precisão a geometria e a física do fluxo, possuindo classificações como malha estruturada (hexaédricas dominantes) ou não estruturada (com a presença de elementos piramidais ou tetraédricos), sendo a última mais flexível para geometrias complexas, pois possuem capacidade de adaptação a qualquer geometria (como exemplo a Figura 1). Figura 1 – Exemplo de malha não estruturada. Fonte: Autoria própria (2024) O modelo de estudo, apresentado na Figura 2, é referente a parte de tubulação de entrada da turbina do Laboratório Hidrodinâmico de Pequenas Centrais Hidrelétricas (LHPCH) da UNIFEI, consistindo em um tubo de aço carbono Schedule 40 de 8 polegadas, bulbo e um suporte de montagem retangular [Botan 2014], modelado virtualmente para análise numérica. Figura 2 – Modelo virtual de análise Fonte: Autoria própria (2024) https://proceedings.science/p/193796?lang=pt-br DOI: 10.59254/sbpo-2024-193796 As ferramentas utilizadas para modelagem do problema, compõe o pacote do ANSYS® sendo o ICEM para importação da geometria e geração da malha, e o CFX para aplicação de fatores de simulação e análise de resultados, de modo que, esses fatores foram aplicados na metodologia de DOE. 2.2 Otimização pela Função de Regressão A metodologia de DOE, é uma metodologia estruturada, que tem por objetivo propor níveis de análise de determinado problema, e zelar por todas as configurações que o problema oferece, por meio de fatores independentes. Essas configurações variadas geram resultados específicos e com isso é permitido refletir sobre a região de solução que a problemática oferece. Para a análise de dados, a metodologia resulta em uma função de regressão (equação 1) que descreve o comportamento dos fatores no problema, permitindo a análise matemática e por consequência, a permissividade de encontrar a resposta ótima de resultados, afinal permite identificar áreas de curvatura e criar funções quadráticas [Montgomery 2009]. A metodologia apresentada neste trabalho é conhecida como Metodologia de Superfície de Resposta (RSM), que consiste em analisar toda a região de solução disponível. Essa proposição é devido a sua capacidade de agrupar os arranjos fatoriais (pontos verdes de +1 e -1), axiais (pontos vermelhos definidos pelo raio “ρ”) e centrais (ponto azul referente ao meio 0) do sistema, considerando o arranjo CCD (Central Composite Design) (Figura 3), definindo a curvatura da região de solução [Azevedo e Paiva 2024] e promovendo a validação dos dados por meio de análises de variância e métricas como R2 e R2adj. 𝑓𝑓(𝐱𝐱) = 𝜷𝜷𝑇𝑇𝒛𝒛(𝐱𝐱) (1) Figura 3 - Representação da região de solução. Fonte: Autoria própria (2024) Em posse da função de regressão diversas análises podem ser feitas, como significância de fatores no modelo, a interação dos fatores e como eles afetam o modelo, além de definir qual a convexidade da função de regressão, podendo ser côncava, convexa ou sela. Além disso, o modelo retorna resultados codificados, e precisam ser decodificados para a análise e repetição. Para a decodificação, utiliza-se a equação 2. 𝑋𝑋𝑑𝑑𝑑𝑑𝑑𝑑𝑑𝑑𝑑𝑑𝑑𝑑𝑑𝑑𝑑𝑑𝑑𝑑𝑑𝑑𝑑𝑑𝑑𝑑= 𝑥𝑥𝑐𝑐𝑐𝑐𝑐𝑐𝑐𝑐𝑐𝑐𝑐𝑐𝑐𝑐𝑐𝑐𝑐𝑐𝑐𝑐× ൫𝑋𝑋𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠−𝑋𝑋𝑖𝑖𝑖𝑖𝑖𝑖𝑖𝑖𝑖𝑖𝑖𝑖𝑖𝑖𝑖𝑖൯+ ൫𝑋𝑋𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠𝑠−𝑋𝑋𝑖𝑖𝑖𝑖𝑖𝑖𝑖𝑖𝑖𝑖𝑖𝑖𝑖𝑖𝑖𝑖൯ 2 (2) Além disso, é possível utilizar de metodologias de otimização de único objetivo para encontrar pontos de estagnação, pontos de máximo ou de mínimo, a depender da concavidade do modelo de regressão da resposta analisada e da função de restrição (equação 3). 𝑀𝑀𝑀𝑀𝑀𝑀 𝑓𝑓(𝐱𝐱) = 𝜷𝜷𝑇𝑇𝒛𝒛(𝐱𝐱) = 𝛽𝛽0 + ෍𝛽𝛽𝑖𝑖𝑥𝑥𝑖𝑖 𝑘𝑘 𝑖𝑖=1 + ෍𝛽𝛽𝑖𝑖𝑖𝑖𝑥𝑥𝑖𝑖 2 𝑘𝑘 𝑖𝑖=1 + ෍෍𝛽𝛽𝑖𝑖𝑖𝑖𝑥𝑥𝑖𝑖𝑥𝑥𝑗𝑗 𝑖𝑖<𝑗𝑗 𝑆𝑆. 𝑡𝑡. : 𝑔𝑔(𝐱𝐱) = 𝐱𝐱𝑇𝑇𝐱𝐱≤0 (3) https://proceedings.science/p/193796?lang=pt-br DOI: 10.59254/sbpo-2024-193796 Para isso utiliza-se de métodos de programação não-linear voltado para resolução tanto de funções objetivo quanto restrições que apresentem não-linearidade, ou seja, funções frequentemente modeladas por um polinômio não-linear. Tais problemas de otimização apresentam desafios significativos devido à complexidade intrínseca das funções não-lineares envolvidas. Em resposta a essa complexidade, foram desenvolvidos métodos específicos de programação não-linear, tais como o Método de Newton e o modelo utilizado neste trabalho, o Método do Gradiente Reduzido Não-Generalizado (GRG não linear) que utiliza de uma combinação de busca direta (utilizando gradientes) e busca direcionada às restrições ativas para encontrar a solução ideal. Esse método está presente em diversos softwares de otimização, além do Solver do Microsoft Excel. 2.3 Fronteira de Pareto pelo NBI De certa forma, problemáticas no mundo real dificilmente envolvem soluções ótimas únicas, e isso ocorre devido a variação de múltiplos objetivos que precisam ser alcançados, como: redução de custo, diminuição do tempo de produção, diminuição de tempo ocioso, entre outros exemplos, de modo que, torna-se comum a melhora de um índice e piora de outros sucessivamente. Ao aplicar-se o DOE, as funções objetivo raramente exibem uma curvatura significativa, necessitando inicialmente de uma busca por essas áreas a partir de modelos lineares para cada função, como pode ser visto pelo problema genérico de otimização multiobjetivo com restrição de desigualdade (equação 4). 𝑀𝑀𝑀𝑀𝑀𝑀𝑀𝑀𝑀𝑀𝑀𝑀𝑀𝑀𝑀𝑀𝑀𝑀 𝑓𝑓1(𝐱𝐱), 𝑓𝑓2(𝐱𝐱), … , 𝑓𝑓𝑝𝑝(𝐱𝐱) 𝑆𝑆𝑆𝑆𝑆𝑆𝑆𝑆𝑆𝑆𝑆𝑆𝑆𝑆 𝑎𝑎: 𝑔𝑔𝑗𝑗(𝐱𝐱) ≤0, 𝑗𝑗= 1,2, … , 𝑚𝑚 (4) Em geral, não há solução única que minimize simultaneamente todas as funções a serem analisadas, assim, o objetivo da otimização neste contexto é determinar a direção que leva à região de máximo ou de mínimo. Ao replicar o GRG não linear para cada resposta individual, considera- se que um conjunto de gradientes individuais promova o equilíbrio entre as direções de melhoria dessas respostas. Para que essa análise de equilíbrio seja feita, é preciso entender o conceito de Fronteira de Pareto (Figura 4), usualmente associado a problemas de otimização multiobjetivo. Desse modo, o conceito de Fronteira de Pareto define que os pontos da fronteira sejam o conjunto de soluções não dominadas no espaço objetivo [Clempner e Poznyak 2017], de maneira que só exista uma melhora em um objetivo, se pelo menos um dos demais houver piora. Para isso, são considerados pesos para cada uma das funções envolvidas (W1 para f1(x) e W2 para f2(x)), de modo que a soma entre esses pesos seja 1. Figura 4 – Representação da Fronteira de Pareto. https://proceedings.science/p/193796?lang=pt-br DOI: 10.59254/sbpo-2024-193796 Fonte: Autoria própria (2024). Assim, para que seja construída a Fronteira de Pareto, utiliza-se do método conhecido por Intersecção Normal a Fronteira (NBI), desenvolvida por [Das e Dennis 1998] que consiste em otimizar uma função global 𝐹𝐹(𝐱𝐱) que agregava todas as funções individuais ponderadamente considerando alvos específicos e escalonando as funções individuais, promovendo a capacidade de apresentar fronteiras contínuas e distribuídas de maneira uniforme, independendo da distribuição dos pesos. Os alvos do modelo incluem os pontos ótimos individuais, aliado aos efeitos que esses ótimos causam nas funções adjacentes, e para isso, é chamado o resultado de Matriz Payoff. Esta matriz (Tabela 1) contém o ponto de ótimo de uma função (chamada de ponto de Utopia) e os pontos de Nadir (oposto do ponto de Utopia), sendo esses, também chamados de pontos de ancoragem. Tabela 1 – Representação da Matriz Payoff. 𝑓𝑓1 𝑈𝑈(𝒙𝒙) 𝑓𝑓1 𝑁𝑁(𝒙𝒙) 𝑓𝑓2 𝑁𝑁(𝒙𝒙) 𝑓𝑓2 𝑈𝑈(𝒙𝒙) A partir dessa matriz, é possível calcular as funções escalonadas para cada função individual. Além de definir a função para geração da Fronteira de Pareto, por meio da metodologia de NBI, promovendo uma fronteira capaz de ser representada por pontos equiespaçados, definidos a partir da variação de pesos (𝑤𝑤) de 0 a 1, representando todas as respostas referentes às soluções multiobjetivo. 𝑓𝑓𝚤𝚤ഥ(𝑥𝑥) = 𝑓𝑓𝑖𝑖(𝑥𝑥) −𝑓𝑓𝑖𝑖 𝑈𝑈 𝑓𝑓𝑖𝑖 𝑁𝑁−𝑓𝑓𝑖𝑖 𝑈𝑈 (5) 𝑀𝑀𝑀𝑀𝑀𝑀 𝑓𝑓1ഥ(𝐱𝐱) 𝑆𝑆. 𝑡𝑡.: 𝑓𝑓1ഥ(𝐱𝐱) −𝑓𝑓2ഥ(𝐱𝐱) + 2𝑤𝑤−1 = 0 𝑔𝑔𝑗𝑗(𝐱𝐱) ≥0 0 ≤𝑤𝑤≤1 (6) 2.4 Otimização na Industria 4.0 Pensando no contexto de indústria 4.0, o CFD representa uma evolução significativa no que se refere ao gerenciamento e otimização dos processos, afinal, permite a integração de abordagens sistêmicas, como DOE para testar e otimizar múltiplos parâmetros de maneira simultânea. Além disso, propor um método de tomada de decisão baseada em dados alia a conjuntura do contexto, permitindo, junto a métodos de Machine Learning, em considerar grandes quantidade de critérios de desempenho, utilizando dados em tempo real, equilibrando funções objetivo e otimizando o desempenho global. Além disso, utilizar o NBI neste processo, auxilia no desenvolvimento de soluções Pareto-ótimas para problemas complexos, facilitando a otimização e adaptação dos processos industriais de maneira contínua. Aplicando todas essas metodologias a técnicas avançadas de computação de alta performance (HPC), temas costumeiramente abordados pela Industria 4.0, há a possibilidade de promover linhas de produção científica, tecnológica e industrial completamente atrelados ao processo de melhoria contínua. Portanto, atrelar o estudo com a indústria 4.0, estimula empresas do setor em alcançar níveis de eficiência, adaptabilidade e inovação sem precedentes, reduzindo custos e melhorando a qualidade dos processos, tornando-os mais resilientes e sustentáveis. 3. Resultados e Discussão Em um DOE, cada linha conta como um experimento distinto, a ser pré-processado e simulado. Assim, foram utilizados os fatores de tamanho de volume de malha (𝑥𝑥1), tamanho de malha da superfície de entrada do modelo (𝑥𝑥2), tamanho de malha da superfície de saída (𝑥𝑥3), vazão mássica de entrada (𝑥𝑥4) e critério de convergência mínimo (𝑥𝑥5). A escolha dos fatores inclui compreender de forma intrínseca, o comportamento do fluído, a dissipação de energia que https://proceedings.science/p/193796?lang=pt-br DOI: 10.59254/sbpo-2024-193796 determinadas estruturas causam ao fluxo e a energia que pode ser armazenada se aplicada às máquinas hidráulicas. Para o trabalho proposto então, foram utilizados RSM de 3 réplicas, e tamanho do raio de resposta de 0,5 do modelo padrão. A escolha de diminuição do raio, foi necessária devido às limitações do modelo, desde que, no modelo padrão, tenha gerado valores incongruentes de x. As escolhas dos níveis superior e inferior do modelo, são apresentados na Tabela 2, gerando respostas em 32 experimentos para 1 réplica, 64 para 2 réplicas e 96 para 3 réplicas. Tabela 2 - Níveis dos fatores pré-definidos. Volume de malha [mm] Tamanho na Entrada [mm] Tamanho na Saída [mm] Vazão de entrada [kg/s] Critério de convergência Nível Inferior 1,50 1,50 1,50 22,455 1 x 10-5 Nível Superior 4,00 4,00 4,00 34,930 1 x 10-4 Fonte: Autoria própria (2024) Após o planejamento dos experimentos e a coleta das respostas, foi possível fazer a análise dos dados, com os R2 e R2adj mantendo um padrão de 99% para as réplicas, o que permite avaliar que a variabilidade dos dados pode ser explicada pela regressão, assim, desenvolveu-se as funções individuais de regressão, nos moldes da equação 1 e 2. Assim, os valores dos coeficientes de cada réplica são apresentados na Tabela 3. Tabela 3 – Coeficientes das funções objetivo. Réplica 1 Réplica 2 Réplica 3 Termos Qualidade Custo de simulação Qualidade Custo de simulação Qualidade Custo de simulação β0 0,7336 48,4226 0,7336 48,6544 0,7336 49,1216 β1 -0,0325 -57,2077 -0,0324 -56,9897 -0,0324 -56,6589 β2 0,0002 -1,4939 0,0002 -1,1429 0,0002 -1,1228 β3 0,0001 -2,4193 0,0001 -1,9559 0,0001 -1,3571 β4 -0,0001 1,2231 -0,0001 1,1005 -0,0001 1,1850 β5 0,0000 -29,0064 0,0000 -29,1702 0,0000 -28,8744 β11 0,0094 34,1636 0,0108 36,5777 0,0112 35,5910 β22 -0,0030 -1,2444 -0,0029 -1,1739 -0,0031 -0,8370 β33 -0,0012 -0,3445 -0,0014 -0,1907 -0,0014 0,0766 β44 -0,0025 4,6036 -0,0020 3,9615 -0,0025 2,6891 β55 -0,0006 0,6924 -0,0024 -1,6528 -0,0022 -0,8358 β12 0,0003 0,2698 0,0003 0,3370 0,0003 0,2924 β13 0,0000 1,1625 0,0000 0,9642 0,0001 0,5870 β14 0,0000 -0,1011 0,0000 -1,0875 0,0000 -0,8993 β15 0,0000 24,6724 0,0000 25,0935 0,0000 24,4644 β23 0,0001 -0,1505 0,0001 -0,1949 0,0001 0,0958 β24 0,0000 -0,5166 0,0000 -0,8765 0,0000 -0,6129 β25 0,0000 0,6220 0,0000 0,2585 0,0000 -0,0368 β34 0,0000 -0,8019 0,0000 -0,0231 0,0000 0,0737 β35 0,0000 -0,5616 0,0000 0,2101 0,0000 0,3866 β45 0,0001 1,2613 0,0001 0,2830 0,0000 -0,0565 Fonte: Autoria própria (2024) Já com essas primeiras análises, fica visível entre os coeficientes, o apuramento que as réplicas causam no modelo de regressão, afinal, ao analisarmos os coeficientes, separadamente, percebe-se a conjuntura de graduação dos valores, seja para mais ou para menos, de modo a https://proceedings.science/p/193796?lang=pt-br DOI: 10.59254/sbpo-2024-193796 promover uma melhoria da estimativa do erro experimental, aumento da previsão das estimativas e melhoria do poder estatístico. Em posse dos coeficientes da equação 1, inicia-se a proposição das funções objetivo e restrições das três réplicas, apresentadas na equação 7. O objetivo de cada função está em maximizar a qualidade da malha (𝑓𝑓1(𝐱𝐱)) e minimizar o custo de simulação (𝑓𝑓2(𝐱𝐱)), de modo que as restrições aplicadas estão sujeitas a evitar o sobreajuste, restringindo o tamanho da solução promovendo a estabilidade numérica. Além disso, é aplicado uma segunda restrição em que evita que o custo final tenha valor negativo. 𝑀𝑀𝑀𝑀𝑀𝑀𝑀𝑀𝑀𝑀𝑀𝑀𝑀𝑀𝑀𝑀𝑀𝑀 𝑓𝑓1(𝐱𝐱) 𝑆𝑆𝑆𝑆𝑆𝑆𝑆𝑆𝑆𝑆𝑆𝑆𝑆𝑆 𝑎𝑎: 𝐱𝐱𝑇𝑇𝐱𝐱−𝜌𝜌1 2 ≤0 𝑓𝑓2(𝐱𝐱) ≥0,01 𝑀𝑀𝑀𝑀𝑀𝑀𝑀𝑀𝑀𝑀𝑀𝑀𝑀𝑀𝑀𝑀𝑀𝑀 𝑓𝑓2(𝐱𝐱) 𝑆𝑆𝑆𝑆𝑆𝑆𝑆𝑆𝑆𝑆𝑆𝑆𝑆𝑆 𝑎𝑎: 𝐱𝐱𝑇𝑇𝐱𝐱−𝜌𝜌1 2 ≤0 𝑓𝑓2(𝐱𝐱) ≥0,01 (7) Provendo então a aplicação do GRG não linear para ambas as funções objetivo, e armazenando seus valores de utopia e nadir, encontra-se para as 3 réplicas, as matrizes Payoff, apresentadas na Tabela 4. Tabela 4 – Matriz Payoff das réplicas. 1 Réplica 2 Réplicas 3 Réplicas 90,060% 72,106% 91,146% 71,626% 91,492% 71,673% R$ 483,68 R$ 0,01 R$ 502,57 R$ 0,01 R$ 494,33 R$ 0,01 Fonte: Autoria própria (2024) Analogamente ao que foi visto na definição dos coeficientes, a apresentação das matrizes Payoff para 1 réplica, 2 réplicas e 3 réplicas, também demonstrou certo apuramento de dados, afinal houve melhora, quando se analisa a qualidade da malha de 90,060% da primeira réplica, para 91,492% quando se considera as 3 réplicas, enquanto inversamente ocorre para o ponto de nadir que vai de 72,160% para 71,673%. Na apresentação das matrizes fica evidente que, seguindo a metodologia de Fronteira de Pareto, enquanto melhora uma função objetivo, consequentemente irá piorar a segunda função. Isso é visível em situações como das matrizes da Tabela 4, de modo que, para aumentar a qualidade da malha em 91,492% é necessário que se promova uma simulação que tenha um custo de R$494,33, porém minimizando o custo a quase zero, piora a qualidade da malha, reduzindo o poder de precisão. Assim, encontrar formas de ponderar essa decisão frente as dificuldades da indústria, torna-se essencial esse estudo. Seguindo então esse contexto, aplica-se a Metodologia de NBI, minimizando a 𝑓𝑓1ഥ(𝐱𝐱) para a definição da Fronteira de Pareto para cada uma das situações (uma, duas ou três réplicas), conforme Figura 5, Figura 6 e Figura 7. Figura 5 – Fronteira de Pareto para uma réplica. Fonte: Autoria própria (2024) https://proceedings.science/p/193796?lang=pt-br DOI: 10.59254/sbpo-2024-193796 Figura 6 – Fronteira de Pareto para duas réplicas. Fonte: Autoria própria (2024) Figura 7 – Fronteira de Pareto para três réplicas. Fonte: Autoria própria (2024) Promovendo uma análise individual das 3 figuras anteriores, é possível observar que há uma particularidade na Fronteira de Pareto, a ser notada próxima do valor de 0,8 de 𝑓𝑓1ഥ(𝐱𝐱) Essa resultante ocorre devido a restrição de não negatividade na função objetivo de custo, e ela é análoga para os 3 casos. Além disso, fica visível que o comportamento para a tomada de decisão é semelhante entre eles, mas por possuírem dados de resposta, além de utopia e nadir diferentes, apresentam também variações dos pontos. Essas variações ficam evidentes quando se sobrepõem as 3 curvas em um único gráfico, como apresentado na Figura 8. https://proceedings.science/p/193796?lang=pt-br DOI: 10.59254/sbpo-2024-193796 Figura 8 – Fronteira de Pareto em comparação aos três casos. Fonte: Autoria própria (2024) Para a definição de Fronteira de Pareto, fica claro que o manejo dos pontos entre utopia e nadir apresentada na matriz Payoff é feito por meio de pesos complementares, ou seja, enquanto é ponderado que é importante alcançar 25% da melhor qualidade (W1=25%), consequentemente é priorizado alcançar 75% do menor custo de simulação (W2=75%). Para o planejamento de experimentos, aplicar o maior número de réplicas ajuda no aumento de precisão dos dados, o que é análogo para a área de otimização multiobjetivo. Na Figura 8 fica claro essa proposta, ao analisar a diferença de resultados entre as ponderações de 5% a 70% para a 𝑓𝑓1ഥ(𝐱𝐱), em que as resposta da fronteira apresentam variação entre os casos com uma réplica, duas réplicas e três réplicas, principalmente em relação a primeira. Isso é posto devido aos resultados alcançados, afinal, conforme pode ser visto na Tabela 5, há uma variação de aproximadamente 4% a 20% no aumento do custo de simulação ao aumentar o número de réplicas. Essa variação pode causar a falsa impressão, de que o custo é menor do que parece, e contabilmente, pode gerar situação de prejuízo, caso não seja avaliado de forma correta. Tabela 5 – Relação das respostas em função das ponderações. 1 Réplica 3 Réplicas Qualidade Custo de simulação Qualidade Custo de simulação W1=25% W2=75% W1=25% W2=75% 79,450% R$ 44,01 79,473% R$ 52,62 W1=50% W2=50% W1=50% W2=50% 83,976% R$ 163,90 84,473% R$ 175,07 W1=75% W2=25% W1=75% W2=25% 87,682% R$ 305,91 88,692% R$ 317,02 Fonte: Autoria própria (2024) Por isso, enquanto possível, aumentar o número de réplicas, permite apurar os resultados das análises, permitindo alcançar resultados mais próximos da realidade, afinal, uma diferença de 20% no gasto previsto, pode resultar em um déficit significativo nas finanças do setor industrial. 4. Conclusões O estudo teve como objetivo utilizar metodologias de otimização, envolvendo a aplicação do DOE em respostas de simulações por métodos CFD, a modelos lineares para cada função, e aplicar a esses modelos a otimização multiobjetivo com restrições de desigualdade. De maneira geral, a pesquisa se concentrou em melhorar a estimativa do modelo de regressão analisando as https://proceedings.science/p/193796?lang=pt-br DOI: 10.59254/sbpo-2024-193796 variações dos coeficientes devido às réplicas, aprimorando a estimativa de erros experimentais, a precisão da previsão e o poder estatístico. Assim, o estudo buscou propor funções objetivos e restrições para três réplicas para maximizar a qualidade da malha numa tubulação com fluxo de água e minimizar o custo que essa simulação gera, evitando o sobreajuste, restringindo o tamanho da solução e garantindo a estabilidade numérica. Além da melhoria dos coeficientes, o trabalho demonstrou melhoras na possibilidade de qualidade da malha com o aumento de réplicas, e por consequência, um aumento na despesa de custo de simulação, destacando de forma simples a compensação entre as funções objetivo. Apresentando que a análise correta dos modelos permite prever com maior precisão os pontos de melhoria que, aplicado de forma contínua, gera ganhos de desempenho e monitoramento de processos, bases da indústria 4.0. Além disso, a análise pelas Fronteiras de Pareto através da metodologia de NBI, permitiu analisar a ponderação pelas funções objetivo, permitindo a escolha ótima de parâmetros para cada solução Pareto-ótima, facilitando a tomada de decisão pela análise de dados, apresentando as diferenças entre um modelo robusto e um modelo mais refinado, evitando que, para custos maiores, haja um prejuízo substancial oculto. 5. Agradecimentos Os autores desejam agradecer as seguintes agências de fomento pelo suporte financeiro durante nossa formação: CNPq (Conselho Nacional de Desenvolvimento Científico e Tecnológico), CAPES (Coordenação de Aperfeiçoamento de Pessoal de Nível Superior) e FAPEMIG (Fundação de Amparo à Pesquisa do Estado de Minas Gerais)."
        },
        {
            "titulo": "Comparação entre abordagens de programação inteira para o problema da coloração Grundy",
            "informacoes_url": "https://proceedings.science/p/193403?lang=pt-br",
            "idioma": "português",
            "storage_key": "galoa-proceedings--sbpo-2024--193403.pdf",
            "autores": [
                {
                    "nome": "Davi Gomes Florêncio",
                    "afiliacao": "Curso de Ciência da Computação, Universidade Federal do Ceará",
                    "orcid": ""
                },
                {
                    "nome": "Wladimir Araújo Tavares",
                    "afiliacao": "Curso de Ciência da Computação, Universidade Federal do Ceará",
                    "orcid": ""
                },
                {
                    "nome": "Fabio Carlos Sousa Dias",
                    "afiliacao": "Curso de Ciência da Computação, Universidade Federal do Ceará",
                    "orcid": ""
                }
            ],
            "data_publicacao": "",
            "resumo": "Dado um grafo G = (V, E), uma k-coloração divide os vértices V em k conjuntos independentes (V1, V2, ..., Vk). Um vértice v ∈Vi é chamado de vértice de Grundy se for adjacente a algum vértice w ∈Vj para todo j < i. O problema da coloração de Grundy busca encontrar o maior valor de k para o qual existe uma k-coloração onde cada vértice seja um vértice de Grundy, chamado número de Grundy (Γ(G)). Este número representa o pior cenário da heurística de coloração gulosa.",
            "keywords": [
                "Teoria e Algoritmos em Grafos",
                "Otimização Combinatória"
            ],
            "referencias": [
                "Campelo, M., Campos, V. A., e Corrêa, R. C. (2008). On the asymmetric representatives formulation for the vertex coloring problem. Discrete Applied Mathematics, 156(7):1097–1111.",
                "Campelo, M., Corrêa, R., e Frota, Y. (2004). Cliques, holes and the vertex coloring polytope. Information Processing Letters, 89(4):159–164.",
                "Carvalho, M., Melo, R., Santos, M. C., Toso, R. F., e Resende, M. G. C. (2023). Formulações de programação inteira para o problema da coloração de Grundy. Anais SBPO 2023.",
                "Christen, C. A. e Selkow, S. M. (1979). Some perfect coloring properties of graphs. Journal of Combinatorial Theory, Series B, 27(1):49–59.",
                "de Araújo, P. H. M., Corrêa, R. C., e Campelo, M. (2023). A parallel Lagrangian heuristic for the fractional chromatic number of a graph. RAIRO-Operations Research, 57(4):1821–1841.",
                "de Werra, D. (1985). An introduction to timetabling. European Journal of Operational Research, 19(2):151–162.",
                "Delle Donne, D., Furini, F., Malaguti, E., e Calvo, R. W. (2021). A branch-and-price algorithm for the minimum sum coloring problem. Discrete Applied Mathematics, 303:39–56.",
                "Frota, Y., Maculan, N., Noronha, T. F., e Ribeiro, C. C. (2010). A branch-and-cut algorithm for partition coloring. Networks: An International Journal, 55(3):194–204.",
                "Goyal, N. e Vishwanathan, S. (1997). NP-completeness of undirected Grundy numbering and related problems. Manuscript, Bombay.",
                "Grundy, P. M. (1939). Mathematics and games. Eureka, 2:6–9.",
                "Havet, F. e Sampaio, L. (2013). On the Grundy and b-chromatic numbers of a graph. Algorithmica, 65(4):885–899.",
                "Hedetniemi, S. M., Hedetniemi, S. T., e Beyer, T. (1982). A linear algorithm for the Grundy (coloring) number of a tree. Congr. Numer, 36:351–363.",
                "Leighton, F. T. (1979). A graph coloring algorithm for large scheduling problems. Journal of Research of the National Bureau of Standards, 84(6):489.",
                "Melo, R. A., Queiroz, M. F., e Santos, M. C. (2021). A matheuristic approach for the b-coloring problem using integer programming and a multi-start multi-greedy randomized metaheuristic. European Journal of Operational Research, 295(1):66–81.",
                "Rodrigues, E. N. H. D. (2020). Coloração k-imprópria gulosa. Disponível em: http://www.repositorio.ufc.br/handle/riufc/50955. Acesso em: 14 fev. 2022.",
                "Telle, J. A. e Proskurowski, A. (1997). Algorithms for vertex partitioning problems on partial k-trees. SIAM Journal on Discrete Mathematics, 10(4):529–550.",
                "Zaker, M. (2005). Grundy chromatic number of the complement of bipartite graphs. Australas. J Comb., 31:325–330.",
                "Zaker, M. (2006). Results on the Grundy chromatic number of graphs. Discrete Mathematics, 306(23):3166–3173."
            ],
            "artigo_completo": "Comparação entre abordagens de programação inteira para o problema da coloração Grundy. RESUMO Dado um grafo G = (V, E), uma k-coloração divide os vértices V em k conjuntos inde- pendentes (V1, V2, . . . , Vk). Um vértice v ∈Vi é chamado de vértice de Grundy se for adjacente a algum vértice w ∈Vj para todo j < i. O problema da coloração de Grundy busca encontrar o maior valor de k para o qual existe uma k-coloração onde cada vértice seja um vértice de Grundy, cha- mado número de Grundy (Γ(G)). Este número representa o pior cenário da heurística de coloração gulosa. O trabalho investiga e compara três formulações de programação inteira para determinar o número de Grundy: duas baseadas no modelo de particionamento de vértices em classes de cores e uma baseada na formulação de representantes assimétrico. PALAVRAS CHAVE. Teoria e Algoritmos em Grafos, Otimização Combinatória https://proceedings.science/p/193403?lang=pt-br DOI: 10.59254/sbpo-2024-193403 1. Introdução Dado um conjunto de objetos com uma relação entre eles, o problema da coloração con- siste em separar os objetos em grupos de modo que objetos relacionados sejam colocados em grupos diferentes. Esse problema surge naturalmente em problemas que precisamos resolver conflitos entre recursos, como no escalonamento de tarefas Leighton [1979], planejamento de quadro de horários de Werra [1985], entre outros . Formalmente, dado um grafo G = (V, E) e um conjunto de cores K = {1, 2, . . . , k}, uma coloração de vértices é um mapeamento sobrejetivo c : V →K. Uma coloração é dita própria quando vértices adjacentes recebem cores diferentes. Uma k-coloração é uma coloração própria com k cores. Uma maneira de obter uma coloração própria de um grafo G é através da heurística de coloração gulosa. Dado uma sequência arbitrária dos vértices σ = (v1, v2, . . . , vn), a heurística gulosa atribui a cada vértice vi a menor cor que não está presente nos vértices já coloridos da vizinhança de vi. Uma coloração é chamada de Coloração Grundy se ela pode ser obtida pela heurística de coloração gulosa. Figura 1: Coloracão gulosa obtida pela sequência (1,2,3,4,5,6) Figura 2: Coloracão gulosa obtida pela sequência (1,2,3,4,6,5) A Figura 1 apresenta uma coloração com 4 cores obtida pela heurística de coloração gu- losa com a sequência (1,2,3,4,5,6). A Figura 2 apresenta uma coloração com 3 cores obtida pela heurística de coloração gulosa com a sequência (1,2,3,4,6,5). O número cromático de G, denotado por χ(G), é o menor k tal que G admite uma k-coloração. O número cromático Grundy, denotado por Γ(G), é o maior k tal que G admite uma k-coloração Grundy. O problema da coloração de Grundy consiste em encontrar Γ(G) de um grafo G. Note que existe uma sequência de vértices para a qual a heurística gulosa obtém uma χ(G)-coloração. O número cromático de Grundy é o maior número de cores usado pelo algoritmo de coloração gulosa considerando todas as ordens possíveis. O grafo mostrado nas Figuras 1 e 2 apresenta χ(G) = 3 e Γ(G) = 4. O número Grundy foi primeiramente estudado por Grundy em 1939 no contexto de grafos orientados na análise de jogos combinatáriosGrundy [1939]. Em 1979, o problema foi formalmente apresentado em Christen e Selkow [1979]. O problema de decisão associado número de Grundy é NP-Completo para grafos em ge- ralGoyal e Vishwanathan [1997] e permanece NP-completo para várias classes de grafos como https://proceedings.science/p/193403?lang=pt-br DOI: 10.59254/sbpo-2024-193403 grafos bipartidos Havet e Sampaio [2013] e grafos complementos de grafos bipartidosZaker [2005, 2006]. Do ponto de vista prático, temos algumas abordagens exatas para computar o número Grundy para árvores Hedetniemi et al. [1982] e para k-árvores parciais Telle e Proskurowski [1997]. Recentemente, temos algumas abordagens determinar o número de Grundy para grafos gerais utilizando programação inteira. Rodrigues [2020] estudou o problema da coloração k- imprópria em que a cor de um vértice pode ser compartilhada com até k vizinhos. O autor também apresenta uma heurística gulosa de coloração k-imprópria e introduz o conceito de número Grundy k-impróprio. Além disso, é apresentada uma formulação de programação inteira para o número de Grundy e também para a versão k-imprópria. A grande vantagem desse modelo para número de Grundy é que a restrição relacionada com a propriedade Grundy é garantida através de um número quadrático de restrições. Em Carvalho et al. [2023], os autores apresentam dois modelos de programação inteira para a obtenção do número de Grundy para grafos gerais. O primeiro modelo baseado na abordagem padrão de particionamento dos vértices em classes de cores e o segundo baseado no modelo de representantes. Nos resultados reportados, o modelo de representantes tem um desempenho melhor do que a formulação padrão. A contribuição deste trabalho consiste em realizar uma análise computacional dos três modelos de programação inteira propostos para resolver o problema da obtenção do número de Grundy em grafos gerais. Além disso, estamos propomos modificações no modelo apresentado em Carvalho et al. [2023] na restrição relacionada com a propriedade Grundy. O restante do trabalho será organizado da seguinte maneira: Na Seção 2, apresentamos as notações que serão utilizadas ao longo do texto. Na Seção 3, apresentamos os três modelos de programação inteira para o problema do número de Grundy. Na Seção 4, apresentamos os experimentos computacionais comparando as três formulações conhecidas para o problema. 2. Preliminares Um grafo G é um par ordenado (V, E) composto por um conjunto finito V , cujos elemen- tos são denominados vértices, e por um conjunto E ⊆{{u, v} : u, v ∈V, u ̸= v}, cujos elementos são denominados arestas. Para todo grafo G, denotamos V (G) e E(G), respectivamente, os con- juntos de vértices e arestas de G. As seguintes notações serão utilizadas neste artigo: • grauG[v] é o grau do vértice v em G e ∆(G) é o valor do grau máximo de G. • N(v) = {u ∈V : {v, u} ∈E} é a vizinhança aberta do vértice v em G. • N[v] = N(v) ∪{v} é a vizinhança fechada do vértice v em G. • N(v) = {u ∈V : {v, u} ̸∈E} é a anti-vizinhança aberta do vértice v em G. • N[v] = N(v) ∪{v} é a anti-vizinhança fechada do vértice v em G. • Se U ⊆V , então G[U] = (U, E[U]) denota o subgrafo de G induzido por U, onde E[U] = {{u, v} ∈E : u, v ∈U}. • S é um conjunto independente de G se somente se ∀u, v ∈S, {u, v} ̸∈E(G). • Uma k-coloração própria de G é uma partição de V (G) em conjuntos independentes S = {V1, V2, . . . , Vk}. https://proceedings.science/p/193403?lang=pt-br DOI: 10.59254/sbpo-2024-193403 • O número cromático, χ(G), é o menor número de cores que pode ser usado em uma coloração própria de um grafo G. • Dada uma k-coloração, um vértice v ∈Vi é chamado um vértice Grundy se v é adjacente a pelo menos um vértice na classe de cor Vj para todo j < i. • Uma k-coloração Grundy é uma k-coloração em que todos os vértices de todas as classes são Grundy. • O número de Grundy, Γ(G), é o maior número de cores em uma coloração em que todos os vértices são vértices Grundy. Na Figura 3, temos uma coloração de Grundy de um grafo. Os vértices do grafo estão rotulados com o rótulo da classe de cor que ele pertence. Note que todos os vértices são Grundy. Figura 3: Coloração Grundy. O número de Grundy determina o pior caso do número de cores do algoritmo de coloração gulosa. A seguir, apresentaremos a formulação padrão para o Problema de Coloração de Vértices (PCV). 2.1. Formulação padrão para PCV A formulação padrão para a coloração utiliza as seguintes variáveis de decisão: xvç = ( 1, se o vértice v recebe a cor c 0, caso contrário zc = ( 1, se a cor c é usada 0, caso contrário O problema de coloração pode ser modelado pela seguintes restrições: https://proceedings.science/p/193403?lang=pt-br DOI: 10.59254/sbpo-2024-193403 min X c∈C zc (2.1.1) s.a. X c∈C xvç = 1 ∀v ∈V (2.1.2) xvç + xuç ≤zc ∀{u, v} ∈E, ∀c ∈C (2.1.3) zc ≤ X v∈V xvç ∀c ∈C (2.1.4) zc ≤zc−1 ∀c ∈{2, . . . , |C|} (2.1.5) xvç ∈{0, 1} ∀v ∈V (G), ∀c ∈C (2.1.6) zc ∈{0, 1} ∀c ∈C (2.1.7) A restrição (2.1.2) garante que cada vértice só pode receber uma cor. A restrição (2.1.3) garante que a coloração obtida será uma coloração própria. A restrição (2.1.4) garante que uma cor k só pode ser usada se algum vértice v recebeu a cor k. A restrição (2.1.5) assegura que as primeiras cores serão usadas. A partir de uma solução viável (x′, z′) da Formulação padrão para PCV podemos en- contrar uma coleção de subconjuntos V1, . . . , Vk de V tal que Vi = {v | xv,i = 1 ∀v ∈V }. É fácil ver que V1, . . . , Vk é uma k-coloração própria de G. 3. Formulação de Programação Inteira Nesta seção, apresentaremos as três formulações de programação inteira conhecidas para o problema de determinação do número de Grundy. Nas duas formulações seguintes, vamos consi- derar o conjunto de cores disponíveis C = {1, 2, . . . , ∆(G) + 1}. 3.1. Formulação Padrão de Rodrigues Rodrigues [2020] Nesta subseção, apresentaremos uma modificação do modelo de programação inteira apre- sentado em Rodrigues [2020]. Na formulação de programação inteira, utilizamos as mesmas variáveis de decisão apre- sentadas na Formulação Padrão para o problema de coloração apresentada na Subseção 2.1. O problema pode ser modelado através das seguintes restrições: ΓR = max X c∈C zc (3.1.1) s.a. X c∈C xvç = 1 ∀v ∈V (G) (3.1.2) xvç + xuç ≤zc ∀{u, v} ∈E(G), ∀c ∈C (3.1.3) zc ≤ X v∈V xvç ∀c ∈C (3.1.4) xvç ≥1 − c−1 X d=1 xv,d − X u∈N(v) xuç ∀v ∈V (G), ∀c ∈C (3.1.5) xv,1 = 1 ∀v ∈V (G) se |N(v)| = 0 (3.1.6) zc ≤zc−1 ∀c ∈{2, . . . , |C|} (3.1.7) xvç ∈{0, 1} ∀v ∈V (G), ∀c ∈C (3.1.8) zc ∈{0, 1} ∀c ∈C (3.1.9) https://proceedings.science/p/193403?lang=pt-br DOI: 10.59254/sbpo-2024-193403 A função objetivo (3.1.1) é maximizar o número de cores usadas pela coloração de Grundy. As restrições (3.1.2), (3.1.3), (3.1.4), (3.1.7) são as mesmas da formulação padrão apresentada na Subseção 2.1. A restrição (3.1.5) garante que a propriedade Grundy será respeitada. A restrição (3.1.6) estabelece que os vértices isolados devem receber a primeira cor. As restrições (3.1.7) e (3.1.6) foram incorporadas ao modelo apresentado Rodrigues [2020]. Proposição 1. Dada uma solução viável (x′, z′) para o modelo ΓR. A coleção de subconjuntos {V1, . . . , Vk} obtida a partir da solução viável (x, z) é uma coloração Grundy. Prova : Suponha por absurdo que V1, . . . , Vk não é Grundy. Logo, existe um v ∈Vi(xv,i = 1) tal que v não é Grundy, ou seja, v não tem nenhum vizinho para algum Vj para j < i. Sem perda de generalidade, suponha que Vm é o primeiro conjunto que não tem nenhum vizinho de v. Logo, Pm d=1 xv,d = 0 e P u∈N(v) xu,m = 0. Por (3.1.5), xv,m ≥1. O que implica que xv,m = 1. Por (3.1.2), temos xv,i = 0. Absurdo. 3.2. Formulação Padrão de Carvalho Carvalho et al. [2023] Nesta subseção, apresentaremos o modelo apresentado em Carvalho et al. [2023]. O mo- delo utiliza as mesmas variáveis de decisão do modelo anterior e como conjunto de cores disponíveis C = {1, . . . , ∆(G) + 1}. A formulação padrão para o número de Grundy apresentada em Carvalho et al. [2023] é a seguinte: ΓC = max X c∈C zc (3.2.1) s.a. X c∈C xvç = 1 ∀v ∈V (G) (3.2.2) xvç + xuç ≤zc ∀{u, v} ∈E(G), ∀c ∈C (3.2.3) zc ≤ X v∈V xvç ∀c ∈C (3.2.4) xvç ≤zc ∀c ∈C ∀v ∈V (G) se |N(v)| = 0 (3.2.5) zc′ ≤zc ∀c, c′ ∈C se c < c′ (3.2.6) xvç′ ≤ X u∈N(v) xuç ∀v ∈V (G)∀c, c′ ∈C se c < c′ (3.2.7) xvç ∈{0, 1} ∀v ∈V (G), ∀c ∈C (3.2.8) zc ∈{0, 1} ∀c ∈C (3.2.9) As restrições (3.2.2), (3.2.3), (3.2.4) são as mesmas restrições do modelo padrão para o problema de coloração mínima apresentada em 2.1. A restrição (3.2.6) assegura que as primeiras cores serão usadas. A restrição (3.2.5) declara que os vértices isolados podem receber qualquer cor. Já a restrição (3.2.7) garante a propriedade Grundy. Vale destacar que a propriedade Grundy nesse modelo é garantida com uma complexidade de restrições O(|V ||C|2). Proposição 2. Dada uma solução viável (x′, z′) para o modelo ΓC. A coleção de subconjuntos de V obtida da solução viável é uma coloração Grundy. Prova : Suponha por absurdo que V1, . . . , Vk não é uma coloração Grundy, ou seja, existe v ∈Vi tal que v não possui nenhum vizinho em Vj para algum j < i. Sem perda de generalidade, assuma que Vm seja o primeiro subconjunto que não possui nenhum vizinho de v tal que m < i. Logo, P u∈N(v) xu,m = 0. Pela restrição (3.2.7), xv,i ≤0. Pela restrição (3.2.8), temos que xv,i = 0, absurdo uma vez que assumimos que xv,i = 1. https://proceedings.science/p/193403?lang=pt-br DOI: 10.59254/sbpo-2024-193403 3.3. Formulação Padrão de Carvalho Modificada Nesta subseção, apresentamos algumas modificações no modelo padrão de Carvalho apre- sentado na subseção anterior. A formulação padrão de Carvalho modificada é dada pelas seguintes restrições: ΓM = max X c∈C zc (3.3.1) s.a. X c∈C xvç = 1 ∀v ∈V (G) (3.3.2) xvç + xuç ≤zc ∀{u, v} ∈E(G), ∀c ∈C (3.3.3) zc ≤ X v∈V xvç ∀c ∈C (3.3.4) xv,1 = 1 ∀c ∈C ∀v ∈V (G) se |N(v)| = 0 (3.3.5) zc ≤zc−1 ∀c ∈{2, . . . , |C|} (3.3.6) X c′>c xvç′ ≤ X u∈N(v) xuç ∀v ∈V, ∀c ∈C (3.3.7) xvç ∈{0, 1} ∀v ∈V (G), ∀c ∈C (3.3.8) zc ∈{0, 1} ∀c ∈C (3.3.9) As restrições (3.3.2), (3.3.3), (3.3.4) são as mesmas da formulação apresentada subseção 3.2. As restrições (3.3.6) e (3.3.5) são as mesmas da formulação apresentada na subsecção 3.1. Já a restrição (3.3.7) garante a propriedade Grundy com o número de restrições em O(|V ||C|). Proposição 3. Dada uma solução viável (x′, z′) para o modelo padrão de carvalho modificada ΓM. A coleção de subconjuntos de V obtida da solução viável é uma coloração Grundy. Prova : Suponha por absurdo que V1, . . . , Vk não é uma coloração Grundy, ou seja, existe v ∈Vi tal que v não possui nenhum vizinho em Vj para algum j < i. Sem perda de generalidade, assuma que Vm seja o primeiro subconjunto que não possui nenhum vizinho de v tal que m < i. Logo, P u∈N(v) xu,m = 0. Pela restrição (3.3.7), P c′>m xvç′ ≤0. Pela restrição (3.2.8), temos que xv,i = 0, absurdo uma vez que assumimos que xv,i = 1 e i > m. 3.4. Formulação Representantes Carvalho et al. [2023] Nesta subseção, apresentamos a formulação de representantes apresentada em Carvalho et al. [2023] baseada na conhecida formulação de representantes. Campêlo et al. [2004] propuseram a formulação para o problema da coloração chamada Formulação de Representante baseada na ideia de considerar um vértice representante para cada classe de cor e impor a restrição que um vértice u pode representar outro vértice v somente se u e v pertencem a mesma classe de cor. Esta formulação admite várias soluções associadas a uma mesma coloração, uma vez que dada k-coloração V1, V2, . . . , Vk, cada vértice vi ∈Vi pode ser escolhido para representar a cor i formando uma solução para a formulação de representantes. Campêlo et al. [2008] propuseram uma formulação conhecida como formulação de re- presentantes assimétrica com o objetivo de remover as várias soluções associadas a uma mesma k-coloração. Nesta formulação, uma ordem ≺dos vértices é utilizada para estabelecer que o re- presentante de uma classe de cor deve ser o vértice minimal pela ≺entre os vértices de uma dada cor. https://proceedings.science/p/193403?lang=pt-br DOI: 10.59254/sbpo-2024-193403 A formulação de representante já foi aplicada em diversos problemas na literatura como coloração de partição Frota et al. [2010], b-coloração Melo et al. [2021], coloração de soma mínima Delle Donne et al. [2021], número cromático fracionário de Araújo et al. [2023], coloração Grundy Carvalho et al. [2023]. Considere as seguintes variáveis de decisão: xv,u = ( 1, se o vértice v representa o vértice u ∈N(v), para v ≤u 0, caso contrário xv,v = ( 1, se o vértice v é um representante 0, caso contrário yv,u = ( 1, se os vértice v, u são representantes e a cor de v precede a cor de u para v ̸= u 0, caso contrário A formulação de representantes apresentada Carvalho et al. [2023] é dada pelas seguintes restrições: max X v∈V xv,v (3.4.1) xu,v + xu,w ≤xu,u ∀u ∈V, v, w ∈N(u) com {v, w} ∈E e u ≤v < w (3.4.2) xu,v ≤xu,u ∀u ∈V, v ∈N(u) com N(v) ∩N(u) = ∅e u ≤v (3.4.3) X v ∈N(u) v ≤u xv,u = 1 ∀u ∈V (3.4.4) xu,v ≤ X w ∈N(v) ∩N(p) w ≥p xp,w + 1 −ypu ∀u, p ∈V, v ∈N[u] com p ̸= u e u ≤v (3.4.5) yv,u + yu,v ≥xu,u + xv,v −1 ∀u, v ∈V com u < v (3.4.6) yu,v + yv,u ≤xu,u ∀u, v ∈V (G) com u ̸= v (3.4.7) ϕu −ϕv + 1 ≤|V | × (1 −yu,v) ∀u, v ∈V (G) com u ̸= v (3.4.8) 0 ≤ϕv ≤|V | −1 ∀v ∈V (3.4.9) xu,v ∈{0, 1} ∀u, v ∈V, v ∈N[u] com u ≤v (3.4.10) yu,v ∈{0, 1} ∀u, v ∈V, com u ̸= v (3.4.11) ϕv ∈R+ ∀v ∈V (3.4.12) A função objetivo (3.4.1) maximiza o número de vértices representantes. A restrição (3.4.2) garante que vértices adjacentes não podem serem representandos pelo mesmo vértice. A restrição (3.4.3) garante que um vértice só pode representar outro vértice se ele for um representante. A restrição (3.4.4) determina que cada vértice deve ser representado por algum vértice da sua anti- vizinhança. A restrição (3.4.5) assegura que um vértice u representa um vértice v somente se https://proceedings.science/p/193403?lang=pt-br DOI: 10.59254/sbpo-2024-193403 todo vértice representante p que precede a u precisa representar algum vértice w vizinho de v. A restrição (3.4.6) assegura que, se dois vértices u e v são representantes, então a classe de u precede a classe de v ou vice-versa, ou seja, a relação de precedência é assimétrica. A restrição (3.4.7) garante que, se u é um representante, a sua classe antecede ou sucede qualquer outra classe de um representante diferente, assegurando que todos os pares de classes sejam comparáveis na relação de precedência. Já a restrição (3.4.8) garante que se um vértice representante u precede outro, então ele deve ter potencial menor. Na Proposição ??, demonstraremos que o potencial pode ser utilizado para estabelecer a transitividade da relação de precedência. Proposição 4. Se u e v são representantes, então yuv = 1 ou yvu = 1. Prova : Como u e v são representantes, a restrição (3.4.6) garante que yuv + yvu ≥1. Como u é representante, a restrição (3.4.7) assegura que yuv + yvu ≤1. Logo, yuv + yvu = 1. Proposição 5. Dada uma solução viável (x, y, ϕ). A coleção de subconjuntos V1, . . . , Vk obtida a partir de (x, y, ϕ) é Grundy. Prova : Suponha por absurdo que V1, . . . , Vk não é uma coloração Grundy, ou seja, existe v ∈Vi sendo r representante de Vi tal que v não possui nenhum vizinho em Vj sendo que p é representante de Vj tal que ypr = 1 Pela hipótese, temos que xr,v = 1. Sabemos que P w∈N(v)∩N(p),p≤w xp,w = 0. Pela restrição (3.4.5), xr,v ≤0, absurdo com o fato de xr,v = 1. 4. Experimentos computacionais Nesta seção são descritos os experimentos realizados e os resultados obtidos utilizando as formulações de programação inteira da seção anterior. Todos os experimentos reportados aqui foram implementados na linguagem de programação Python e executados em um computador com um processador Intel Xeon E5-2670 v3, 40GB de memória RAM e sistema operacional Windows 11 64 bits. Nos modelos de PLI, utilizamos o pacote networkX, que é um pacote Python utilizado para manipulação de grafos e redes complexas. A documentação da biblioteca, além de exem- plos mais aprofundados, estão disponíveis em: https://networkx.org/. Para a resolução dos modelos de PLI foi utilizada a ferramenta OR-Tools, que é um pacote de software gratuito e de código aberto desenvolvido pelo Google para resolver problemas de Programação Linear, Programação Inteira Mista, Programação Linear por Restrição, roteamento de veículos e proble- mas de otimização relacionados. Todas as formulações foram executadas com limitação de tempo de execução de 1800 se- gundos (30 minutos) para encontrar o valor de Γ(G). Se a instância possuir um tempo de execução maior que 1800 segundos, isso significa que a execução foi interrompida antes de conseguir encon- trar o número de Grundy e o melhor resultado obtido nas sub-soluções é retornado. Em nosso experimento, foram gerados grafos aleatórios, utilizando probabilidade p de geração de arestas, de 20, 50 e 75 por cento, onde para cada probabilidade foram gerados 5 grafos com 10, 15, 20, 25 e 30 vértices, totalizando 75 grafos. As Tabelas 1 e 2 apresentam os resultados dos experimentos para os grafos aleatórios. Na Tabela 1, a segunda, terceira e quarta colunas representam o grupo de 25 instâncias para cada probabilidade p ∈{0.2, 0.5, 0.75}, de forma que cada linha corresponde aos valores médios do tempo de execução em segundos e a quinta coluna apresenta a média do tempo de execução de todas as instâncias. Em negrito, destacamos o melhor tempo de execução para cada faixa de densidade. Nos testes realizados, para instâncias com densidade 0.2, a Formulação Padrão https://proceedings.science/p/193403?lang=pt-br DOI: 10.59254/sbpo-2024-193403 Tabela 1: Média do tempo de execução em segundos das formulações Formulação p=0.2 p=0.5 p=0.75 Média Modelo Padrão Rodrigues [2020] 250.53 876.76 1094.14 740.48 Modelo Padrão Carvalho et al. [2023] 512.87 1094.72 1242.54 950.04 Modelo Representativos Carvalho et al. [2023] 543.73 442.89 37.35 341.32 Modelo Padrão Carvalho Modificada 239.85 899.33 1102.45 747.21 Tabela 2: Quantidade de soluções ótimas encontradas para cada formulação Formulação p=0.2 p=0.5 p=0.75 Total Modelo Padrão Rodrigues [2020] 22 15 10 47 Modelo Padrão Carvalho et al. [2023] 19 15 10 44 Modelo Representativos Carvalho et al. [2023] 20 24 25 69 Modelo Padrão Carvalho Modificada 22 15 10 47 Rodrigues [2020] alcançou o melhor resultado seguido da formulação apresentada neste trabalho. Para as outras faixas de instâncias, a Formulação de Representantes mostrou-se bem superior as demais. Para os grafos com densidade alta, a formulação alcançou resultados impressionantes. Na Tabela 2, cada linha corresponde a quantidade de soluções ótimas encontradas para cada probabilidade. A última coluna representa a quantidade de soluções ótimas encontradas para cada formulação. Em negrito, destacamos a formulação que encontrou o maior número de soluções ótimas. Nestes experimentos, a formulação padrão Rodrigues [2020] e a formulação de Carvalho modificada encontraram o mesmo número de soluções ótimas para a faixa de densidade 0.2. Nas outras faixas de densidade, a formulação de representantes encontrou a solução ótima em 49 das 50 instâncias testadas. 5. Conclusões Nesse trabalho, foram apresentadas formulações de programação inteira para o problema da coloração de Grundy e realizados testes computacionais a fim de comparação. Os experimentos computacionais realizados indicam que a formulação por representativos Carvalho et al. [2023] tem um desempenho melhor comparados aos demais, pois quanto mais denso um grafo, menor será a anti-vizinhança de um vértice, então a quantidade de variáveis e de restrições será bastante reduzida, resultando em um modelo mais enxuto. Nos testes realizados foi observado que para todas as formulações, que para instâncias com 20 e 25 vértices o problema se mostrou desafiador, pois não conseguiram encontrar a solução ótima de todas as instâncias dentro do tempo limite de 1800 segundos."
        },
        {
            "titulo": "Busca Local Eficiente para Problemas de Roteamento de Veículos com Demandas Incertas",
            "informacoes_url": "https://proceedings.science/p/193600?lang=pt-br",
            "idioma": "pt",
            "storage_key": "galoa-proceedings--sbpo-2024--193600.pdf",
            "autores": [
                {
                    "nome": "Carlos Vinícius",
                    "afiliacao": "Universidade Federal da Paraíba – Centro de Informática",
                    "orcid": ""
                },
                {
                    "nome": "Anand Subramanian",
                    "afiliacao": "Universidade Federal da Paraíba – Centro de Informática",
                    "orcid": ""
                },
                {
                    "nome": "Marcelo de Freitas",
                    "afiliacao": "Universidade Federal da Paraíba – Centro de Informática",
                    "orcid": ""
                }
            ],
            "data_publicacao": "",
            "resumo": "Este trabalho aborda a busca local eficiente para problemas de roteamento de veículos sob incerteza na demanda. Estruturas de dados novas foram propostas para calcular de forma eficiente a demanda total de uma rota no pior caso durante a avaliação de movimentos. Usando essas estruturas de dados, novos limites superiores assintóticos para a complexidade temporal de avaliação de um movimento são teoricamente derivados, melhorando os resultados existentes na literatura. Extensos experimentos computacionais demonstram que nosso método reduz significativamente o tempo computacional na prática em comparação com as abordagens atuais.",
            "keywords": [
                "Roteamento de veículos",
                "incertezas",
                "otimização robusta",
                "busca local"
            ],
            "referencias": [
                "Aharon Ben-Tal, Laurent El Ghaoui, e Arkadi Nemirovski (2009). Robust Optimization. Princeton series in applied mathematics. ISBN 978-0-691-14368-2. URL https://press.princeton.edu/books/hardcover/9780691143682/robust-optimization.",
                "Máximo, V. R., Cordeau, J.-F., e Nascimento, M. C. (2022). An adaptive iterated local search heuristic for the Heterogeneous Fleet Vehicle Routing Problem. Computers & Operations Research, 148:105954. ISSN 03050548. URL https://linkinghub.elsevier.com/retrieve/pii/S0305054822002052.",
                "Penna, P. H. V., Subramanian, A., Ochi, L. S., Vidal, T., e Prins, C. (2019). A hybrid heuristic for a broad class of vehicle routing problems with heterogeneous fleet. Annals of Operations Research, 273(1):5–74. ISSN 1572-9338. URL https://doi.org/10.1007/s10479-017-2642-9.",
                "Pessoa, A. A., Poss, M., Sadykov, R., e Vanderbeck, F. (2021). Branch-Cut-and-Price for the Robust Capacitated Vehicle Routing Problem with Knapsack Uncertainty. Operations Research, 69(3):739–754. ISSN 0030-364X, 1526-5463. URL http://pubsonline.informs.org/doi/10.1287/opre.2020.2035.",
                "Savelsbergh, M. W. P. (1985). Local search in routing problems with time windows. Annals of Operations Research, 4(1):285–305. ISSN 0254-5330, 1572-9338. URL http://link.springer.com/10.1007/BF02022044.",
                "Subramanian, A., Penna, P. H. V., Uchoa, E., e Ochi, L. S. (2012). A hybrid algorithm for the Heterogeneous Fleet Vehicle Routing Problem. European Journal of Operational Research, 221(2):285–295. ISSN 03772217. URL https://linkinghub.elsevier.com/retrieve/pii/S0377221712002093.",
                "Subramanian, A., Uchoa, E., e Ochi, L. S. (2013). A hybrid algorithm for a class of vehicle routing problems. Computers & Operations Research, 40(10):2519–2531. ISSN 03050548. URL https://linkinghub.elsevier.com/retrieve/pii/S030505481300021X.",
                "Subramanyam, A., Repoussis, P. P., e Gounaris, C. E. (2018). Robust optimization of a broad class of heterogeneous vehicle routing problems under demand uncertainty. URL http://arxiv.org/abs/1810.04348. arXiv:1810.04348 [cs, math].",
                "Vidal, T., Crainic, T. G., Gendreau, M., e Prins, C. (2013). A hybrid genetic algorithm with adaptive diversity management for a large class of vehicle routing problems with time-windows. Computers & Operations Research, 40(1):475–489. ISSN 0305-0548. URL https://www.sciencedirect.com/science/article/pii/S0305054812001645."
            ],
            "artigo_completo": "Busca Local Eficiente para Problemas de Roteamento de Veículos com Demandas Incertas. RESUMO Este trabalho aborda a busca local eficiente para problemas de roteamento de veículos sob incerteza na demanda. Estruturas de dados novas foram propostas para calcular de forma eficiente a demanda total de uma rota no pior caso durante a avaliação de movimentos. Usando essas es- truturas de dados, novos limites superiores assintóticos para a complexidade temporal de avaliação de um movimento são teoricamente derivados, melhorando os resultados existentes na literatura. Extensos experimentos computacionais demonstram que nosso método reduz significativamente o tempo computacional na prática em comparação com as abordagens atuais. PALAVRAS CHAVE. Roteamento de veículos, incertezas, otimização robusta, busca local. Tópicos: OC - Otimização Combinatória https://proceedings.science/p/193600?lang=pt-br DOI: 10.59254/sbpo-2024-193600 1. Introdução O Problema de Roteamento de Veículos (PRV) é um dos mais famosos problemas na área da Otimização Combinatória (OC). Nele, visa-se obter um conjunto de rotas de custo mínimo para servir um grupo de clientes — cada um dos quais possui uma certa demanda por um produto — empregando-se uma frota de veículos. Além disso, aplicações práticas normalmente incorrem restrições adicionais, como janelas de tempo de atendimento dos clientes, frotas limitadas, etc. Os métodos projetados para resolver problemas de OC como o PRV geralmente consistem em abor- dagens determinísticas, i.e., parte-se do pressuposto de que os parâmetros associados ao problema (e.g., demandas dos clientes, tempos de viagem) são certos, e conhecidos previamente. No entanto, na prática, é comum que esse não seja o caso. Se, por exemplo, as demandas dos clientes de uma rota forem 10% maiores do que o esperado, uma solução obtida por uma abordagem determinística pode acabar violando a restrição de capacidade do veículo, tornando-se inválida. Isso exigiria que a solução fosse “consertada”, ou que uma nova etapa de otimização fosse feita a partir do zero. Uma abordagem comum na resolução de PRVs envolvendo parâmetros incertos consiste na Otimização Robusta (OR) Aharon Ben-Tal et al. [2009]. Nela, parâmetros incertos do problema são tratados como variáveis aleatórias pertencentes a um conjunto de incertezas bem-definido. Uma solução para o problema é considerada viável se e somente se for viável para todas as realizações possíveis de tais variáveis aleatórias. Por consequência, uma grande vantagem da OR é que não é necessário conhecer a natureza da distribuição dos parâmetros incertos associados ao problema. Além disso, o tomador de decisões possui liberdade para projetar os conjuntos de incertezas de acordo com suas necessidades: conjuntos de incertezas mais amplos resultam em soluções mais “conservadoras”, que embora custosas, são protegidas contra diversos cenários, enquanto conjuntos mais restritos resultam em soluções menos protegidas, mas de custo possivelmente menor. Dentre as heurísticas estado-da-arte na resolução da versão determinística do PRV, pode- se citar, por exemplo, os algoritmos propostos por Subramanian et al. [2012]; Penna et al. [2019]; Máximo et al. [2022], que fazem uso da meta-heurística de Busca Local Iterada (Iterated Local Se- arch, ILS) para resolver variantes do PRV com múltiplos atributos (e.g., múltiplos depósitos, frotas heterogêneas). Vidal et al. [2013], por sua vez, empregou um algoritmo genético na resolução de diversas variantes do PRV com janelas de tempo. Quanto a variantes do PRV envolvendo demandas incertas, pode-se destacar a abordagem proposta por Pessoa et al. [2021], que faz uso da meta- heurística ILS para resolver o CVRP com demandas incertas sob o paradigma da OR. De forma similar, Subramanyam et al. [2018] propõe uma abordagem baseada em Programação de Memória Adaptativa (Adaptative Memory Programming, AMP) para resolver uma variante geral do PRV sob demandas incertas, envolvendo vários atributos e conjuntos de incerteza distintos. Embora consistam em meta-heurísticas diversas, no geral, todas as abordagens apresenta- das possuem em comum o uso de buscas locais no decorrer do método. Uma busca local consiste em, dada uma solução corrente, examinar o custo de todas as soluções “vizinhas”, i.e., que diferem da solução atual em apenas um movimento (e.g., trocar a posição de dois clientes em uma rota, mover um cliente de uma posição na rota para outra), e determinar a melhor delas, e trocá-la pela solução atual. Embora isso seja comumente trivial em versões determinística do PRV, a avaliação de soluções vizinhas pode tornar-se custosa quando deseja-se empregar o paradigma de OR. Isso ocorre porque verificar se uma solução vizinha é adequada envolve determinar sua viabilidade. Caso seja feita de forma ingênua, o tempo computacional exigido por essa verificação — que depende do conjunto de incertezas empregado — pode ser proibitivo. Portanto, o objetivo deste trabalho é propor estruturas de dados auxiliares avançadas para verificar de maneira eficiente a viabilidade de soluções vizinhas em problemas de roteamento com demandas incertas sob o paradigma da OR. A abordagem é versátil, podendo ser acoplada a qual- https://proceedings.science/p/193600?lang=pt-br DOI: 10.59254/sbpo-2024-193600 quer meta-heurística que faça uso de etapas de busca local. O restante do trabalho é dividido como segue. Na Seção 2 , a versão robusta do PRV com demandas incertas é caracterizada de forma mais precisa, bem como os conjuntos de incerteza abordados. A Seção 3, por sua vez, descreve as estru- turas auxiliares utilizadas, e as provas de corretude e de complexidade assintótica associadas a elas. Por fim, as Seções 4 e 5 discorrem brevemente acerca dos resultados obtidos, e das considerações finais do trabalho, respectivamente. 2. Definição do problema e conjuntos de incerteza Já que o método proposto neste trabalho visa endereçar especificamente incertezas da de- manda, a versão do PRV utilizada será a versão canônica, denominada Capacitated Vehicle Routing Problem (CVRP), que envolve apenas restrições de capacidade. Note, no entanto, que os concei- tos apresentados (bem como os métodos propostos nas seções seguintes), são gerais e podem ser aplicados a qualquer variante do PRV que envolva demandas incertas e restrições de capacidade. O CVRP é definido como segue. Seja G = (V, A) um grafo, e V e A conjuntos de vértices e arcos, respectivamente. O subconjunto V ′ = {1, . . . , n} representa os clientes, enquanto o vértice 0 é o depósito, i.e., V = V ′ ∪{0}. Cada arco (i, j) ∈A, i ̸= j está associado a um custo cij, e a matriz de custos satisfaz a desigualdade triangular. Cada cliente i ∈V ′ possui uma certa demanda qi. Um conjunto de veículos homogêneos K está disponível no depósito, cada um com capacidade C. O objetivo é minimizar a soma dos custos de viagem considerando: (i) todo cliente deve ser visitado uma única vez; (ii) a capacidade do veículo não é excedida; e (iii) cada rota começa e termina no depósito. Para abordar o problema sob a ótica da OR, define-se, ainda, um conjunto de incertezas U, e diz-se que um elemento de U consiste em um vetor de demandas q = (q1, . . . , qn). Para que uma rota seja considerada robusta viável, ela deve, conforme definido acima, respeitar a restrição de capacidade do veículo associado para todo q ∈U. Note que é necessário apenas encontrar o valor máximo que a soma das demandas em cada rota pode atingir. Note, ainda, que se U for composto por exatamente um único elemento, tem-se a versão determinística do problema. Além do conjunto determinístico U0 = {q0}, três outros conjuntos de incertezas bastante abordados na literatura foram abordados. Cada um desses conjuntos possui vantagens, fundamenta- das em estatística, que os tornam adequados em diferentes situações práticas. Contudo, explorá-las não é o foco do trabalho. Portanto, ao leitor interessado em uma leitura aprofundada sobre os con- juntos de incertezas abordados, bem como as motivações associadas a cada um, recomenda-se que consulte Subramanyam et al. [2018]; Aharon Ben-Tal et al. [2009]. Os conjuntos utilizados foram Uknap (mochila), Ucard (cardinalidade), e Udisc (discreto). Dessa forma, sejam q, q e ˆq vetores pertencentes a Rn, e ∈Rn um vetor em que todas as componentes são iguais a 1, diag(·) uma função que transforma um vetor em uma matriz diagonal, e {B1, . . . , BL} uma partição do conjunto V ′. Os conjuntos de incerteza podem então ser definidos pelas seguintes equações. U0 = \b q0\t Ucard = \b q ∈[q0, q0 + ˆq] : q = q0 + diag(ˆq)ξ, eT ξ ≤Γ, ξ ∈[0, 1]n\t Uknap =   q ∈[q0, q0 + ˆq] : X i∈Bl qi ≤bl, l ∈{1, . . . , L}    Udisc = \b q1, q2, . . . , qD\t Assim, seja S um conjunto de clientes em uma rota arbitrária. A demanda total da rota https://proceedings.science/p/193600?lang=pt-br DOI: 10.59254/sbpo-2024-193600 associada a S no pior-caso pode ser calculada conforme as seguintes equações. Q0(S) = X i∈S q0 i (1) Qknap(S) = X i∈S q0 i + L X l=1 min   bl, X i∈Bl ˆqi    (2) Qcard(S) = X i∈S q0 i + min{Γ,|S|} X k=1 ˆgk (3) Qdisc(S) = max d=1,...,D (X i∈S qd i ) (4) Observe que, no caso específico do conjunto Ucard, o termo ˆgk na equação (3) é o k-ésimo maior desvio de demanda dentre os clientes em S. 3. Cálculo eficiente da demanda no pior-caso Para computar a demanda total no pior-caso durante a avaliação de um movimento de busca local, Subramanyam et al. [2018] faz uso de uma abordagem incremental. Mais precisa- mente, ele propõe um algoritmo que, dado um dos conjuntos de incerteza citados anteriormente e uma rota composta por um conjunto de clientes S, permite computar a demanda total após a adição (ou remoção) de um único cliente. Isso significa que o algoritmo precisa ser executado uma vez para cada cliente adicionado ou removido em um movimento. Em outras palavras, o tempo com- putacional gasto pelo método depende diretamente do número de clientes trocados entre rotas em um movimento de busca local. A Tabela 1 mostra as complexidades assintóticas do método para a avaliação de um movimento que envolve a adição de um conjunto de clientes S′ a uma rota arbitrária associada a um conjunto de clientes S. Tabela 1: Complexidade assintótica de avaliação de movimento ao adicionar (ou remover) um cliente no método de Subramanyam et al. [2018] Conjunto Complexidade Uknap O(|S′|) Ucard O(|S′| log |S|) Udisc O(|S′|D) O método proposto neste trabalho, em contrapartida, faz uso de estruturas auxiliares as- sociadas a cada uma das subsequências de uma rota pertencente à solução corrente, de modo seme- lhante à abordagem originalmente proposta por Savelsbergh [1985] para checagem de viabilidade de rotas do PRV com janelas de tempo. Dessa forma, um movimento que leva a solução corrente a uma solução vizinha (cuja viabilidade deseja-se avaliar) pode ser visto como um rearranjo de tais subsequências. De forma mais precisa, define-se σ = (σi, . . . , σj) e σ′ = (σ′ i′, . . . , σ′ j′) como duas sequências de clientes consecutivos que fazem parte de rotas da solução corrente, e diz-se que a sequência σ ⊕σ′ = (σi, . . . , σj, σ′ i′, . . . , σ′ j′) é obtida “concatenando-se” σ e σ′. Dessa forma, se algumas informações específicas sobre σ e σ′ forem armazenadas previ- amente, é possível obter a demanda total da sequência σ ⊕σ′ no pior-caso de maneira eficiente. Além disso, já que a maioria dos operadores de busca local na literatura consiste em rearranjar um https://proceedings.science/p/193600?lang=pt-br DOI: 10.59254/sbpo-2024-193600 número constante de subsequências, a complexidade assintótica desse método depende apenas do tempo de uma única operação concatenação. Considere, então, que σ = (i) é uma subsequência composta por exatamente um cliente. Define-se as seguintes estruturas de dados auxiliares para σ. Qknap l (σ) = ( ˆqi se i ∈Bl 0 caso contrário l = 1, . . . , L (5) Qdisc d (σ) = qd i d = 1, . . . , D (6) Qcard 0 (σ) = qi (7) Qcard γ (σ) = qi + ˆqi γ = 1, . . . , Γ (8) Em casos nos quais uma subsequência pode ser descrita como uma concatenação de outras duas, i.e., a subsequência é σ ⊕σ′. Qknap l (σ ⊕σ′) = Qknap l (σ) + Qknap l (σ′), l = 1, . . . , L (9) Qdisc d (σ ⊕σ′) = Qdisc d (σ) + Qdisc d (σ′), d = 1, . . . , D (10) Qcard γ (σ ⊕σ′) = max γ′=0,...,γ \b Qcard γ′ (σ) + Qcard γ−γ′(σ′) \t γ = 0, . . . , Γ (11) A partir disso, o seguinte resultado mostra como obter a demanda total da sequência σ⊕σ′ no pior-caso. Proposição 1. Sejam σ e σ′ duas subsequências, a demanda total no pior-caso da subsequência σ ⊕σ′ para cada conjunto de incertezas pode ser calculada como segue: Q0(σ ⊕σ′) = Q0(σ) + Q0(σ′) (12) Qknap(σ ⊕σ′) = Q0(σ ⊕σ′) + L X l=1 min n bl, Qknap l (σ ⊕σ′) o (13) Qcard(σ ⊕σ′) = Qcard Γ (σ ⊕σ′) (14) Qdisc(σ ⊕σ′) = max d=1,...,D \b Qdisc d (σ ⊕σ′) \t (15) Demonstração. Primeiro, note que o caso particular em que a subsequência consiste em um único cliente é trivialmente correto. Para mostrar que as equações (12)–(15) estão correto para os casos restantes, considera-se cada conjunto individualmente. Primeiro, supõe-se que a demanda total no pior-caso é conhecida para duas subsequências arbitrárias σ e σ′. Em seguida, mostra-se que quando S = σ ∪σ′, o lado direito das equações (1)–(4) é equivalente ao do seu respectivo par nas equações (12)–(15). A corretude então segue através de indução no operador de concatenação ⊕. ((1) ⇔(12)) Suponha que Q0(σ) = P i∈σ q0 i e Q0(σ′) = P j∈σ′ q0 j . Então, Q0(σ ⊕σ′) = Q0(σ) + Q0(σ′) = X i∈σ q0 i + X j∈σ′ q0 j . https://proceedings.science/p/193600?lang=pt-br DOI: 10.59254/sbpo-2024-193600 ((2) ⇔(13)) Suponha que Qknap l (σ) = P i∈σ ˆqi, e Qknap l (σ′) = P j∈σ′ ˆqj. Então, Qknap(σ ⊕σ′) = Q0(σ ⊕σ′) + L X l=1 min n bl, Qknap l (σ ⊕σ′) o = X i∈σ q0 i + X j∈σ′ q0 j + L X l=1 min   bl, X i∈σ ˆqi + X j∈σ′ ˆqj   . ((4) ⇔(15)) Suponha que Qdisc d = P i∈σ qd i , e Qdisc d (σ′) = P j∈σ′ qd j . Então, Qdisc(σ ⊕σ′) = max d=1,...,D \b Qdisc d (σ ⊕σ′) \t = max d=1,...,D    X i∈σ qd i + X j∈σ′ qd j   . ((3) ⇔(14)) Suponha que Qcard γ (σ) = P i∈σ q0 i + Pmin{|σ|,γ} i=1 ˆgσ i , e Qcard γ (σ′) = P j∈σ′ q0 j + Pmin{|σ′|,γ} j=1 ˆgσ′ j para todo γ = 0, . . . , Γ. Então, Qcard γ (σ ⊕σ′) = max γ′=0,...,γ \b Qcard γ′ (σ) + Qcard γ−γ′(σ′) \t = max γ′=0,...,γ    X i∈σ q0 i + min{|σ|,γ′} X i=1 ˆgσ i + X j∈σ′ q0 j + min{|σ′|,γ−γ′} X j=1 ˆgσ′ j   , e portanto, Qcard(σ ⊕σ′) = Qcard Γ (σ ⊕σ′) = max γ′=0,...,Γ    X i∈σ q0 i + min{|σ|,γ′} X i=1 ˆgσ i + X j∈σ′ q0 j + min{|σ′|,Γ−γ′} X j=1 ˆgσ′ j   . É fácil verificar que maximizar a última expressão equivale a escolher os min{|σ ⊕σ′|, Γ} maiores elementos do conjunto de desvios ˆgσ 1 , . . . , ˆgσ |σ|, ˆgσ′ 1 , . . . , ˆgσ′ |σ′| e adicioná-los a Q0(σ ⊕σ′), assim concluindo a prova. A Tabela 2 é um resultado direto da Proposição 1, e ilustra a complexidade assintótica de uma operação de concatenação para cada um dos conjuntos de incertezas abordados, através das estruturas propostas acima. Como argumentado anteriormente, se o número de operações de concatenação for constante, a complexidade assintótica da avaliação inteira é a mesma que a de uma única concatenação. No geral, isso torna as estruturas acima mais adequadas, embora exijam muito mais memória, no geral, que as estruturas propostas por Subramanyam et al. [2018]. 4. Resultados Os experimentos computacionais realizados consistem em uma comparação entre as es- truturas propostas e, o método de Subramanyam et al. [2018]. Para isso, um algoritmo de busca local simples foi implementado. No algoritmo, uma única estrutura de vizinhança é explorada de maneira exaustiva, i.e., todos os vizinhos da solução corrente tiverem seu custo e viabilidade ava- liados, e o vizinho de menor custo (ou o de menor violação de capacidade, no caso de soluções https://proceedings.science/p/193600?lang=pt-br DOI: 10.59254/sbpo-2024-193600 Tabela 2: Complexidade assintótica da avaliação dos movimentos Conjunto Complexidade Uknap O(L) Ucard O(Γ) Udisc O(D) inviáveis) é escolhido. Uma vez que o melhor vizinho é determinado, ele passa a ser a solução cor- rente, e o procedimento se repete até que melhoras não sejam mais possíveis. As soluções iniciais usadas nos testes foram obtidas de maneira gulosa e aleatória, de forma similar à proposta em [Su- bramanian et al., 2013]. Três estruturas de vizinhança clássicas na literatura de PRVs foram testadas de forma separada, e para cada uma delas, 500 soluções iniciais foram construídas. As estruturas de vizinhança utilizadas são descritas a seguir. • SHIFT(1,0) – Mover um cliente de uma rota para outra. • SWAP(1,1) – Trocar um cliente de uma rota com um cliente de outra rota. • 2-OPT* – Escolher duas rotas e remover um arco de cada, e reconstruir a solução das duas maneiras possíveis. Os métodos foram implementados na linguagem C++ (g++, 9.4.0) e executados em um processador Intel® Core™i7-3770 com 3,40 GHz e 16 GB de memória RAM. O sistema operacio- nal utilizado foi o Ubuntu 20.04. O conjunto clássico de instâncias A, B, E, F, M, P para o CVRP foi utilizado nos testes. Os conjuntos de incerteza foram gerados conforme descrito por Subramanyam et al. [2018]. Diferentes parâmetros foram testados para gerar os conjuntos de incertezas Ucard e Udisc. Mais precisamente, o conjunto Ucard foi testado com os valores Γ = 0,05n (caso 1), Γ = 0,1n (caso 2), e Γ = 0,2n (caso 3). O conjunto Udisc, por sua vez, foi testado com D = 0,25n (caso 1), D = 0,5n (caso 2), e D = 0,75n (caso 3). As Figuras 1–3 ilustram o tempo médio de uma única busca local (em milissegundos) para cada estrutura de vizinhança, e em cada conjunto de incertezas. As instâncias foram ordenadas em ordem crescente, em função do número de clientes. Assim, cada figura apresenta um gráfico que contém o tempo médio de busca local em função da instância, tanto para a abordagem incremental de Subramanyam et al. [2018] (INCREMENTAL), quanto a abordagem baseada em subsequências proposta neste trabalho (SUBSEQ). Analisando-se as figuras, é possível perceber que, na maioria dos casos, a abordagem baseada em subsequências apresenta tempos de execução inferiores, sobre- tudo em instâncias com um número de clientes maior. Isso é facilmente observado, por exemplo, em todas as vizinhanças para o conjunto Uknap, onde a abordagem baseada em subsequências domina a abordagem incremental. Por outro lado, uma análise mais aprofundada — focando-se em cada conjunto de incerte- zas individualmente — revela que, no conjunto Ucard, o desempenho da abordagem incremental nas vizinhanças 2OPT* e SWAP(1,1) torna-se superior a medida que o número de clientes n aumenta. Note que, especificamente nos casos em que Γ é menor, o desempenho da abordagem baseada em subsequências torna-se superior. Contudo, abordagem baseada em subsequências é mais eficiente para ambas as parametrizações de Γ no caso específico da vizinhança SHIFT(1,0). Para o conjunto Udisc, no caso em que D = 0,25n, o desempenho das duas abordagens é similar. Note, no entanto, que no caso em que D = 0.5n, a diferença entre as duas abordagens torna-se cada vez mais acen- https://proceedings.science/p/193600?lang=pt-br DOI: 10.59254/sbpo-2024-193600 tuada a medida que n cresce, sendo a abordagem de subsequências substancialmente superior na vizinhança 2OPT*, embora seja ligeiramente pior para as vizinhanças SHIFT(1,0) e SWAP(1,1). 0 5 10 15 20 25 10−2.5 10−2 10−1.5 Instância Tempo (ms) INCREMENTAL (0.25n) SUBSEQ (0.25n) (a) Shift(1, 0) 0 5 10 15 20 25 10−2 10−1 Instância Tempo (ms) INCREMENTAL (0.25n) SUBSEQ (0.25n) (b) Swap(1,1) 0 5 10 15 20 25 10−2 10−1 Instância Tempo (ms) INCREMENTAL (0.25n) SUBSEQ (0.25n) (c) 2-OPT* Figura 1: Tempos de execução para o conjunto Uknap 5. Considerações finais Neste trabalho, foram propostas estruturas de aceleração que permitem realizar buscas lo- cais em PRVs com incerteza de maneira mais eficiente. Além disso, os limites assintóticos proporci- onados por tais estruturas são, no geral, melhores que os do método estado-da-arte da literatura para todos os conjuntos de incerteza considerados. Esse resultado teórico também foi complementado por uma análise experimental em instâncias clássicas. Portanto, é possível afirmar que o método proposto é promissor. Dentre as sugestões para trabalhos futuros, propõe-se a adaptação dos métodos a novos conjuntos de incerteza (e.g., conjuntos cuja definição depende da solução corrente). Propõe-se, ainda, acoplar o método a meta-heurísticas estado-da-arte para PRVs com múltiplos atributos, para verificar se novos limitantes superiores podem ser obtidos para instâncias em aberto. Por fim, convém investigar se os métodos utilizados podem ser adaptados (ou servir como base) para lidar com incertezas em outros parâmetros, como tempos de viagem e tempos de serviço. https://proceedings.science/p/193600?lang=pt-br DOI: 10.59254/sbpo-2024-193600 0 5 10 15 20 25 10−1.5 10−1 10−0.5 Instância Tempo (ms) INCREMENTAL (0.05n) SUBSEQ (0.05n) INCREMENTAL (0.1n) SUBSEQ (0.1n) INCREMENTAL (0.2n) SUBSEQ (0.2n) (a) Shift(1, 0) 0 5 10 15 20 25 10−1 100 Instância Tempo (ms) INCREMENTAL (0.05n) SUBSEQ (0.05n) INCREMENTAL (0.1n) SUBSEQ (0.1n) INCREMENTAL (0.2n) SUBSEQ (0.2n) (b) Swap(1,1) 0 5 10 15 20 25 10−1.5 10−1 10−0.5 Instância Tempo (ms) INCREMENTAL (0.05n) SUBSEQ (0.05n) INCREMENTAL (0.1n) SUBSEQ (0.1n) INCREMENTAL (0.2n) SUBSEQ (0.2n) (c) 2-OPT* Figura 2: Tempos de execução para o conjunto Ucard"
        },
        {
            "titulo": "Resoluc¸˜ao do Problema de Minimizac¸˜ao de Trocas de Ferramentas com uma Busca Local Iterada Baseada em Chaves Aleat´orias",
            "informacoes_url": "https://proceedings.science/p/193916?lang=en",
            "idioma": "Português",
            "storage_key": "galoa-proceedings--sbpo-2024--193916.pdf",
            "autores": [
                {
                    "nome": "Humberto Gimenes Macedo",
                    "afiliacao": "Universidade Federal de São Paulo (UNIFESP) / Instituto Tecnológico de Aeronáutica (ITA)"
                },
                {
                    "nome": "Camyla Ferreira Moreno",
                    "afiliacao": "Universidade Federal de São Paulo (UNIFESP) / Instituto Tecnológico de Aeronáutica (ITA)"
                }
            ],
            "data_publicacao": "",
            "resumo": "A resolução de problemas práticos em otimização combinatória muitas vezes esbarra na intratabilidade computacional, requerendo o emprego de meta-heurísticas para encontrar soluções próximas da ótima em tempo viável.",
            "keywords": [
                "Problema de Minimização de Trocas de Ferramentas",
                "Chaves Aleatórias",
                "Busca Local Iterada"
            ],
            "referencias": [
                "Ausiello, G., Marchetti-Spaccamela, A., Crescenzi, P., Gambosi, G., Protasi, M., e Kann, V. (1999). Complexity and Approximation. Springer, Berlin, Heidelberg. ISBN 978-3-642-63581-6 978-3-642-58412-1. URL http://link.springer.com/10.1007/978-3-642-58412-1.",
                "Bean, J. C. (1994). Genetic Algorithms and Random Keys for Sequencing and Optimization. ORSA Journal on Computing, 6(2):154–160. ISSN 0899-1499, 2326-3245. URL https://pubsonline.informs.org/doi/10.1287/ijoc.6.2.154.",
                "Chaves, A. A., Senne, E. L. F., e Yanasse, H. H. (2012). Uma nova heurística para o problema de minimização de trocas de ferramentas. Gestão & Produção, 19:17–30. ISSN 0104-530X, 1806-9649. URL http://www.scielo.br/j/gp/a/PyN9C4V8GDczsxzQndQhX4w/?lang=pt.",
                "Chaves, A., Lorena, L., Senne, E., e Resende, M. (2016). Hybrid method with CS and BRKGA applied to the minimization of tool switches problem. Computers & Operations Research, 67:174–183. ISSN 03050548. URL https://linkinghub.elsevier.com/retrieve/pii/S0305054815002403.",
                "Gendreau, M. e Potvin, J.-Y., editors (2019). Handbook of Metaheuristics, volume 272 of International Series in Operations Research & Management Science. Springer International Publishing, Cham. ISBN 978-3-319-91085-7. URL http://link.springer.com/10.1007/978-3-319-91086-4.",
                "Glover, F. (1986). Future paths for integer programming and links to artificial intelligence. Computers & Operations Research, 13(5):533–549. ISSN 03050548. URL https://linkinghub.elsevier.com/retrieve/pii/0305054886900481.",
                "Gonçalves, J. F. e Resende, M. G. C. (2011). Biased random-key genetic algorithms for combinatorial optimization. Journal of Heuristics, 17(5):487–525. ISSN 1572-9397. URL https://doi.org/10.1007/s10732-010-9143-1.",
                "Holland, J. H. (1975). Adaptation in Natural and Artificial Systems: An Introductory Analysis with Applications to Biology, Control, and Artificial Intelligence. U Michigan Press, Oxford, England. ISBN 978-0-472-08460-9. Pages: viii, 183.",
                "Macedo, H. G. e Bueno, L. F. (2023). Estudo Comparativo de Diferentes Métodos de Solução para o Problema de Minimização de Trocas de Ferramentas. In Anais do Simpósio Brasileiro de Pesquisa Operacional, volume 55, São José dos Campos, SP. Publisher: Galoá.",
                "Mecler, J., Subramanian, A., e Vidal, T. (2021). A simple and effective hybrid genetic search for the job sequencing and tool switching problem. Computers & Operations Research, 127:105153. ISSN 0305-0548. URL https://www.sciencedirect.com/science/article/pii/S0305054820302707.",
                "Schuetz, M. J., Brubaker, J. K., Montagu, H., Van Dijk, Y., Klepsch, J., Ross, P., Luckow, A., Resende, M. G., e Katzgraber, H. G. (2022). Optimization of Robot-Trajectory Planning with Nature-Inspired and Hybrid Quantum Algorithms. Physical Review Applied, 18(5):054045. ISSN 2331-7019. URL https://link.aps.org/doi/10.1103/PhysRevApplied.18.054045.",
                "Sörensen, K. e Glover, F. W. (2013). Metaheuristics. In Gass, S. I. e Fu, M. C., editors, Encyclopedia of Operations Research and Management Science, p. 960–970. Springer US, Boston, MA. ISBN 978-1-4419-1153-7. URL https://doi.org/10.1007/978-1-4419-1153-7_1167.",
                "Taillard, D. (2023). Design of Heuristic Algorithms for Hard Optimization: With Python Codes for the Travelling Salesman Problem. Graduate Texts in Operations Research. Springer International Publishing, Cham. ISBN 978-3-031-13713-6. URL https://link.springer.com/10.1007/978-3-031-13714-3.",
                "Tang, C. S. e Denardo, E. V. (1988). Models Arising from a Flexible Manufacturing Machine, Part I: Minimization of the Number of Tool Switches. Operations Research, 36(5):767–777. ISSN 0030-364X, 1526-5463. URL http://pubsonline.informs.org/doi/10.1287/opre.36.5.767."
            ],
            "artigo_completo": "Resolução do Problema de Minimização de Trocas de Ferramentas com uma Busca Local Iterada Baseada em Chaves Aleatórias. RESUMO A resolução de problemas práticos em otimização combinatória muitas vezes esbarra na intratabilidade computacional, requerendo o emprego de meta-heurísticas para encontrar soluções próximas da ótima em tempo viável. Dentre elas, tem-se aquelas baseadas em processos biológicos da natureza, como é o caso do algoritmo genético. Em um algoritmo genético, uma das formas para codificar a solução do problema consiste em utilizar chaves aleatórias, permitindo que a busca pela solução seja feita indiretamente no espaço de chaves aleatórias. Essa abordagem permite dividir a implementação em uma parte dependente e outra independente do problema. Recentemente, essa abordagem promissora foi estendida para outras meta-heurísticas. Nesse contexto, o objetivo deste trabalho é resolver o Problema de Minimização de Trocas de Ferramentas com uma busca local iterada implementada segundo o formalismo de chaves aleatórias. Os resultados mostraram a eficácia dessa abordagem alternativa em relação a usual em termos de tempo computacional e robustez. PALAVRAS CHAVE. Problema de Minimização de Trocas de Ferramentas, Chaves Aleatórias, Busca Local Iterada. Tópicos (Otimização Combinatória, Meta-heurísticas, PO na Indústria) https://proceedings.science/p/193916?lang=en DOI: 10.59254/sbpo-2024-193916 1. Introdução A maioria dos problemas relevantes de otimização combinatória são computacionalmente intratáveis, ou seja, são classificados como problemas NP-difíceis [Ausiello et al., 1999]. Na prática, isso significa que não há algoritmos conhecidos que sejam eficientes para resolvê-los. Assim, para essa classe de problemas, o usual é empregar métodos capazes de encontrar uma solução ao me- nos próxima da solução ótima em um tempo computacional razoável, como é o caso das meta- heurísticas. Meta-heurística é um termo cunhado por Glover [1986] e trata-se, formalmente, de uma estrutura algorítmica de alto nível e independente do problema que oferece um conjunto de diretrizes para desenvolver um algoritmo de otimização heurístico [S¨orensen e Glover, 2013]. Em geral, uma meta-heurística apresenta três características fundamentais, a saber: (i) procura por uma solução próxima da ótima em vez de tentar encontrar a solução ótima; (ii) usualmente não apre- senta uma prova rigorosa de convergência para a solução ótima; e (iii) geralmente é mais rápida do ponto de vista computacional que uma busca exaustiva. Atualmente, é possível encontrar uma miríade de meta-heurísticas na literatura. Uma parcela dessas meta-heurísticas foi projetada com o intuito de tentar imitar processos biológicos que ocorrem na natureza, como é o caso dos algoritmos evolutivos. Os algoritmos evolutivos foram desenvolvidos com base em ideias de biólogos do século XIX, como Darwin e Mendel, que introduziram a teoria da evolução [Taillard, 2023]. A fim de resolver problemas complexos de otimização combinatória, esses algoritmos tentam reproduzir ar- tificialmente a evolução de seres vivos por meio de operadores matemáticos de aptidão, seleção do mais apto, cruzamento e mutação. Esses operadores atuam em cromossomos (vetores) que repre- sentam as soluções do problema ao longo de várias gerações até a convergência. Entre os algoritmos evolutivos existentes, o algoritmo genético (GA, do inglês Genetic Algorithm) proposto por Holland [1975] é um dos mais proeminentes. Em um GA, a solução do problema de otimização precisa ser codificada em um cromossomo (vetor), onde a forma de codificação influencia significativamente o desempenho do algoritmo. Cada cromossomo consiste em uma cadeia de genes, cujos valores são chamados de alelos. Esses alelos podem ser, por exemplo, números binários, inteiros ou reais. Em particular, caso eles sejam valores reais e aleatórios no intervalo [0,1], tem-se um GA com soluções codificadas por chaves aleatórias. O algoritmo genético com chaves aleatórias (RKGA, do inglês Random-Key Genetic Algo- rithm) foi introduzido por Bean [1994] para resolver problemas de otimização combinatória envol- vendo sequenciamento. Segundo ele, a abordagem de chaves aleatórias é adequada porque elimina o problema de produção de soluções infactíveis durante o cruzamento de soluções factíveis. No RKGA, as soluções codificadas com chaves aleatórias são fornecidas a um decodificador para se- rem transformadas em soluções factíveis. O decodificador é um algoritmo determinístico que tem como entrada um vetor de chaves aleatórias (cromossomo) e associa a ele uma solução factível do problema de otimização cujo valor da função objetivo pode ser prontamente calculado. Recente- mente, Gonçalves e Resende [2011] aprimoraram o RKGA ao introduzir elitismo na forma como os indivíduos da população, representados por cromossomos, são escolhidos para cruzamento. Isso deu origem ao algoritmo genético com chaves aleatórias enviesadas (BRKGA, do inglês Biased Random-Key Genetic Algorithm). Assim, no RKGA os indivíduos são escolhidos aleatoriamente a partir da população como um todo, enquanto no BRKGA um deles deve advir, necessariamente, da elite da população. O sucesso do RKGA e BRKGA na solução de diversos problemas ratifica a eficiência de se utilizar chaves aleatórias para a codificação das soluções dos problemas. Nas meta-heurísticas mencionadas, a busca pela solução do problema ocorre indireta- mente no espaço de chaves aleatórias, o qual consiste de um hipercubo unitário cuja dimensão é igual ao tamanho do cromossomo. Durante a busca, o decodificador é invocado conforme ne- https://proceedings.science/p/193916?lang=en DOI: 10.59254/sbpo-2024-193916 cessário para mapear um cromossomo no espaço de chaves aleatórias para uma solução no espaço das soluções factíveis do problema, tornando possível, a partir disso, avaliar a função objetivo. A implementação da busca no espaço de chaves aleatórias pode ser feita de forma genérica e reuti- lizável, pois ela não depende do problema sendo resolvido. Por outro lado, a implementação do decodificador é altamente dependente do problema e deve ser realizada de forma bastante eficiente, devido à necessidade de mapeamentos frequentes. Assim sendo, tanto o RKGA quanto o BRKGA são meta-heurísticas compostas por uma componente independente do problema para realizar a busca, e uma componente dependente para realizar os mapeamentos. Visto que a componente in- dependente só precisa ser implementada uma única vez, o esforço encontra-se no decodificador, que deve ser acoplado a ela para resolver um problema específico. Schuetz et al. [2022] sugerem uma generalização do formalismo de chaves aleatórias do BRKGA e de sua distinta separação de módulos dependentes e independentes do problema para meta-heurísticas alternativas que operam diretamente sobre o espaço de solução, como é o caso do recozimento simulado. Dada a natureza inovadora e promissora do uso de meta-heurísticas alternativas com o formalismo de chaves aleatórias, este estudo visa reexaminar o problema de minimização de trocas de ferramentas previamente abordado por Macedo e Bueno [2023]. A proposta é aplicar uma busca local iterada baseada em chaves aleatórias em vez da usual que opera diretamente no espaço de solução. O objetivo é demonstrar a viabilidade e a eficiência dessa abordagem em termos de tempo computacional e robustez na resolução do problema em questão. Para alcançar esse propósito, este artigo está organizado da seguinte forma: a Seção 2 apresenta uma descrição detalhada do problema de otimização em análise, juntamente com o funcionamento do decodificador correspondente. Na Seção 3, é fornecida uma visão geral da busca local iterada e uma descrição de como ela foi imple- mentada para o problema em consideração. Em seguida, na Seção 4, são apresentados e discutidos os resultados computacionais obtidos usando a abordagem proposta para resolver as instâncias de tamanho moderado apresentadas por Macedo e Bueno [2023]. Por fim, na Seção 5, são apresentadas as conclusões finais e delineadas possíveis direções para pesquisas futuras. 2. Descrição do Problema Considere um conjunto J = { 1, 2, . . . , N } de N tarefas que devem ser processadas sequencialmente e sem preempção por uma única máquina flexível. Seja T = { 1,2, . . . , M } o conjunto das M ferramentas que precisam ser utilizadas pela máquina para o processamento de todas as tarefas em J. A máquina contém uma caixa de ferramentas capaz de armazenar C < M ferramentas de cada vez, onde a ordem de armazenamento é irrelevante. Cada tarefa j ∈J requer um subconjunto não vazio de ferramentas Tj ⊂T para ser processada, as quais devem estar na caixa de ferramentas no momento em que a tarefa é processada. Assuma que C ≥maxj∈J |Tj| a fim de que a máquina possa processar todas as tarefas em J. Como a máquina não é capaz de armazenar todas as ferramentas de uma vez, algumas trocas podem ser necessárias para o processamento de tarefas consecutivas e distintas. Uma troca consiste da remoção de uma ferramenta da caixa e a subsequente inserção de outra em seu lugar. Por simplicidade, suponha que a máquina tenha um sistema de troca automática de ferramentas e que cada troca seja feita em um tempo desprezível. O Problema de Minimização de Trocas de Ferramentas (MTSP, do inglês Minimization of Tool Switches Problem) visa determinar uma sequência de processamento de tarefas que minimize o número total de trocas de ferramentas. Vale destacar que uma instância do MTSP pode ser repre- sentada por uma quádrupla ordenada (N, M, C, A), em que A ∈RM×N é uma matriz de valores lógicos chamada de matriz incidente. Essa matriz define as ferramentas necessárias para processar cada tarefa, ou seja, a entrada A(p, q) = 1 se, e somente se, a ferramenta p + 1 for requerida para processar a tarefa q+11. Além disso, como as soluções do problema são permutações das N tarefas 1Neste trabalho, os índices que identificam a entrada de um vetor ou matriz começam em 0. https://proceedings.science/p/193916?lang=en DOI: 10.59254/sbpo-2024-193916 em J, o espaço de solução S é formado por todas as N! possibilidades de permutação, enquanto o espaço de chaves aleatórias é X = [0,1]N. 2.1. Decodificador O decodificador para o MTSP empregado neste trabalho é o mesmo sugerido por Chaves et al. [2016], sendo constituído por duas partes. Na primeira, o vetor de chaves aleatórias (cro- mossomo) fornecido é mapeado em uma solução factível do problema, ou seja, em uma sequência de tarefas. Esse mapeamento é feito da seguinte forma: para cada chave aleatória no vetor dado associa-se uma única tarefa. Assim, a primeira chave aleatória é associada com a primeira tarefa, a segunda chave com a segunda tarefa e assim por diante. Por conseguinte, o vetor de chaves aleatórias é posto em ordem crescente. À medida que as chaves são colocadas em ordem crescente, a disposição das tarefas associadas muda em conformidade, dando origem à sequência de tarefas que o vetor de chaves aleatórias dado representa. A Figura 1 ilustra essa parte da decodificação para um exemplar com cinco tarefas. Tarefas 1 2 3 4 5 Chaves desordenadas 0,35 0,85 0,12 0,47 0,74 Chaves ordenadas 0,12 0,35 0,47 0,74 0,85 Sequência de tarefas 3 1 4 5 2 Figura 1: Mapeamento de um vetor de chaves aleatórias em uma solução factível do MTSP. A segunda parte do decodificador consiste em calcular o número total de trocas de ferra- mentas necessárias para processar as tarefas na sequência determinada na primeira parte. Contudo, isso deve ser feito de forma otimizada, ou seja, é preciso que, durante o processamento de cada ta- refa na sequência dada, as ferramentas na caixa sejam selecionadas de modo a minimizar o número total de trocas. Este é um subproblema do MTSP chamado de problema da substituição de ferra- mentas (TRP, do inglês Tool Replacement Problem). Para encontrar uma solução ótima para o TRP, Tang e Denardo [1988] propuseram um algoritmo denominado de política KTNS (do inglês Keep Tool Needed Soonest), que é baseado na ideia de sempre manter na caixa somente as ferramentas que serão necessárias em breve. A política KTNS percorre do início ao fim uma sequência de tarefas seguindo a duas regras simples, a saber: (i) para cada tarefa, apenas as ferramentas requeridas para processá-la são inseridas na caixa de ferramentas da máquina; e (ii) sempre que novas ferramen- tas são carregadas na caixa, mantêm-se nela somente aquelas que serão necessárias o mais breve possível. As ferramentas que serão necessárias o mais tarde possível são removidas conforme a necessidade para dar espaço às ferramentas que entram. A Figura 2 ilustra o pseudocódigo da política KTNS, onde se verifica que seu custo com- putacional é da ordem de O(MN). Observa-se que o algoritmo tem como entrada a matriz incidente A de uma instância e uma sequência de tarefas s ∈S. Além disso, sua implementação requer duas definições: (i) um vetor W ∈{0,1}M cuja entrada W(i) assume o valor 1 se a ferramenta i + 1 está na caixa da máquina no instante n, e 0 caso contrário; e (ii) uma matriz L ∈{0,1}M,N cuja entrada L(i, n) é o primeiro instante, que pode ser o instante n ou algum instante após dele, que a ferramenta i + 1 é requerida2. As linhas 1-20 carregam na caixa as ferramentas necessárias para 2A variável n que representa um instante começa em 0. https://proceedings.science/p/193916?lang=en DOI: 10.59254/sbpo-2024-193916 processar a primeira tarefa, enquanto, se houver espaço, as linhas 21-31 preenchem a caixa com as ferramentas que serão requeridas mais cedo partir do instante de processamento da primeira tarefa. Por fim, para cada tarefa subsequente, as linhas 32-50 colocam na caixa as respectivas ferramentas necessárias, removendo sempre aquelas que serão requeridas o mais tarde possível a partir do ins- tante corrente. Note que a caixa está sempre preenchida com as ferramentas requeridas no instante corrente e por aquelas que serão necessárias o mais breve possível a partir dele. Algoritmo 1: POLÍTICA KTNS Dados: Matriz incidente A ∈{0,1}M×N e sequência de tarefas s ∈S Resultado: Número de trocas p ∈N 1 n ←0, c ←0, p ←0. Defina W ∈{0,1}M e L ∈{0,1}M×N e inicialize cada uma de suas entradas com 0 2 para n = N −1 até 0 faça 3 para i = 0 até M −1 faça 4 se A(i, s(n)) == 1 então 5 L(i, n) ←n 6 senão 7 se n < N −1 então 8 L(i, n) ←L(i, n + 1) 9 senão 10 L(i, n) ←N 11 fim 12 fim 13 fim 14 fim 15 para i = 0 até M −1 faça 16 se L(i, n) == n então 17 W(i) ←1 18 c ←c + 1 19 fim 20 fim 21 enquanto c < C faça 22 ℓ←∞ 23 para i = 0 até M −1 faça 24 se W(i) == 0 e L(i, n) < ℓentão 25 t ←i 26 ℓ= L(i, n) 27 fim 28 fim 29 W(t) ←1 30 c ←c + 1 31 fim 32 para n = 1 até N −1 faça 33 para i = 1 até M −1 faça 34 se W(i) == 0 e L(i, n) == n então 35 W(i) ←1 36 c ←c + 1 37 fim 38 fim 39 enquanto c > C faça 40 k ←n 41 para i = 1 até M −1 faça 42 se W(i) == 1 e L(i, n) > k então 43 t ←i 44 k ←L(i, n) 45 fim 46 fim 47 W(t) ←0, c ←c −1 48 p ←p + 1 49 fim 50 fim Figura 2: Pseudocódigo da política KTNS. https://proceedings.science/p/193916?lang=en DOI: 10.59254/sbpo-2024-193916 A Figura 3 ilustra o funcionamento geral do decodificador para o mesmo exemplar da Figura 1, o qual reune o mapeamento e a política KTNS. 0,35 0,85 0,12 0,47 0,74 Mapeamento 3 1 4 5 2 Política KTNS Trocas Figura 3: Representação pictórica do funcionamento do decodificador. Doravante, o termo decodificador será empregado para designar uma chamada à função que imple- menta o decodificador e retorna o número de trocas. 3. Busca Local Iterada baseada em Chaves Aleatórias Uma busca local iterada (ILS, do inglês Iterated Local Search) é uma meta-heurística que, partindo de uma solução inicial x0 ∈X gerada aleatoriamente ou por uma heurística construtiva, aplica reiteradamente as operações de perturbação, busca local e critério de aceitação para realizar a busca por uma solução melhor para uma instância do problema [Gendreau e Potvin, 2019]. A partir da melhor solução conhecida x∗∈X, a ILS aplica uma perturbação sobre ela a fim de encontrar uma solução perturbada x′ ∈X em uma vizinhança próxima. Por conseguinte, uma busca local é feita sobre x′ para aprimorá-la, atingindo-se, assim, uma solução ótima local x∗′. Por fim, no critério de aceitação, verifica-se se a solução ótima local recém descoberta (x∗′) aprimora a melhor solução conhecida até então (x∗). Em caso afirmativo, a melhor solução conhecida passa a ser a solução ótima local recém encontrada. Caso contrário, mantém-se a melhor solução conhecida. Em seguida, todas as etapas descritas são realizadas novamente a partir da melhor solução conhecida, atualizada ou não, até que o critério de parada seja atendido. A parada pode ocorrer quando um número máximo de iterações é atingido ou quando aprimora-se a melhor de todas as soluções conhecidas da instância. A Figura 4 ilustra o pseudocódigo da ILS baseada em chaves aleatórias utilizada para resolver o MTSP. Como é possível constatar, além do decodificador, três procedimentos precisam ser implementados, a saber: a heurística construtiva, a busca local e a perturbação. Estes serão descritos a seguir. Algoritmo 2: BUSCA LOCAL ITERADA Dados: número máximo de iterações Nmax, valor da função objetivo na melhor solução conhecida v, conjunto de ferramentas T e os subconjuntos T1, T2, . . . , TN. Resultado: Solução ótima local x∗∈X. 1 x0 ←HeurísticaConstrutiva(T, T1, T2, . . . , TN) 2 x∗←BuscaLocal(x0) 3 i ←1 4 enquanto decodificador(x∗) > v e i ≤Nmax faça 5 x′ ←Perturbação(x∗) 6 x∗′ ←BuscaLocal(x′) 7 se decodificador(x∗′) < decodificador(x∗) então 8 x∗←x∗′ 9 fim 10 i ←i + 1 11 fim Figura 4: Pseudocódigo da ILS baseada em chaves aleatórias. https://proceedings.science/p/193916?lang=en DOI: 10.59254/sbpo-2024-193916 Quanto a heurística construtiva, utilizou-se a proposta por Chaves et al. [2012], cujo pseudocódigo se encontra na Figura 5. Trata-se de um algoritmo guloso baseado em um grafo G = (V, E) com múltiplas arestas, em que V = {1, 2, . . . , M} é o conjunto dos vértices e E = {(t1, t2, j) ∈V 2 × J | t1, t2 ∈Tj} é o conjunto das arestas. Dada uma instância do MTSP, constrói-se o grafo G cujos vértices são as ferramentas e cujas arestas entre um par de vértices re- presentam as tarefas que requerem ambas as ferramentas para serem processadas (linha 1). Após a construção do grafo, tem-se uma estrutura de repetição que seleciona os vértices (ferramentas) em ordem crescente de grau e remove as arestas (tarefas) do grafo até que todos os vértices estejam isolados (linhas 2-14). Em cada iteração, escolhe-se o vértice de menor grau e, subsequentemente, remove-se a aresta do vértice escolhido que minimiza o número de trocas de ferramentas, em que cada remoção significa o processamento de uma tarefa. Então, remove-se todas as arestas do grafo associadas a essa tarefa, pois ela já foi processada. Por conseguinte, a caixa de ferramentas é atu- alizada para acomodar as ferramentas que foram requeridas para processá-la. No final do processo iterativo, todos os vértices estão isolados e todas as tarefas processadas em uma sequência que constitui a solução inicial do problema. Esta última é, então, convertida em um vetor de chaves aleatórias (linhas 15-18). Fonte: Adaptado de Chaves et al. [2012]. Algoritmo 3: HEURÍSTICA CONSTRUTIVA Dados: Conjunto de ferramentas T e subconjuntos T1, T2, . . . , TN. Resultado: Solução candidata x ∈X. 1 (V, E) ←ConstruirGrafo(T, T1, T2, . . . , TN); s ←∅; C ←∅ 2 enquanto ∃v ∈V tal que grau(v) > 0 faça 3 Escolha o vértice v ∈V com menor grau diferente de 0 4 se grau(v) > 1 então 5 Selecione a aresta a ∈E cuja tarefa associada minimiza o número de trocas. 6 Se houver empate, escolha a aresta cuja tarefa associada aparece mais vezes no grafo. 7 senão 8 Selecione a única aresta a ∈E conectada ao vértice v. 9 fim 10 j ←tarefa associada à aresta a selecionada. 11 s ←s ∪{ j } 12 E ←atualizarGrafo(E, j) 13 C ←atualizarCaixa(C, Tj) 14 fim 15 x ←vetor com N posições para armazenar as chaves aleatórias que representam s 16 para i = 0 até N −1 faça 17 x[s[i] −1] ←i/N 18 fim Figura 5: Pseudocódigo da heurística construtiva. Esta estratégia é conhecida como busca local de primeira melhoria. Apesar de sua simpli- cidade, essa escolha se justifica pelo fato de que a troca de chaves aleatórias entre dois índices de um vetor de chaves aleatórias tem o mesmo efeito no espaço de solução original do problema, não havendo a necessidade de escrever um código adicional. O pseudocódigo correspondente pode ser encontrado na Figura 6 e será explicado a seguir. A estrutura de repetição nas linhas 3-9 tem por objetivo construir uma sequência de pares ordenados que representam as possibilidades de troca en- tre duas tarefas, levando-se em conta a simetria dessa operação. Uma vez que há N tarefas, tem-se N(N −1)/2 possíveis pares de troca. A busca local de primeira melhora propriamente dita é reali- https://proceedings.science/p/193916?lang=en DOI: 10.59254/sbpo-2024-193916 zada na estrutura de repetição nas linhas 11-22. Inicialmente, uma troca entre duas chaves aleatórias é feita nas linhas 12-16. Caso ela melhore a melhor solução conhecida (x), esta última é atualizada com a solução recém encontrada x′. Caso contrário, mantém-se a melhor solução conhecida. Em todo caso, a busca prossegue a partir da melhor solução conhecida, estando ela atualizada ou não. Esse procedimento é feito até que todas as possibilidades de troca sejam consideradas. Algoritmo 4: BUSCA LOCAL Dados: Solução a ser aprimorada x ∈X. Resultado: Solução ótima local x′ ∈X. 1 Defina c ∈N2×N(N−1)/2, a ∈R e k ∈N0 2 k ←0 3 para i = 1 até N faça 4 para j = i + 1 até N faça 5 c(0, k) = i 6 c(1, k) = j 7 k ←k + 1 8 fim 9 fim 10 x′ ←x 11 para w = 1 até N(N −1)/2 faça 12 i ←c(0, w −1) 13 j ←c(1, w −1) 14 a ←x′(i −1) 15 x′(i −1) ←x′(j −1) 16 x′(j −1) ←a 17 se decodificador(x′) ≤decodificador(x) então 18 x ←x′ 19 senão 20 x′ ←x 21 fim 22 fim Figura 6: Pseudocódigo da busca local. Quanto à estratégia de perturbação adotada, o pseudocódigo correspondente pode ser en- contrado na Figura 7. Este algoritmo oferece quatro opções de perturbação, e a seleção de qual aplicar a um vetor de chaves aleatórias x ∈X é feita aleatoriamente, conforme indicado na linha 3. A primeira opção consiste em tomar o complemento em relação à unidade da chave aleatória armazenada na posição i de x (linha 6), onde i é um inteiro gerado aleatoriamente entre 0 e N −1 (linha 4). A segunda opção, por sua vez, troca de posição as chaves aleatórias nas posições i e j, com j sendo também um inteiro aleatório entre 0 e N −1 (linhas 9-12). Em seguida, a terceira opção simplesmente substitui a chave aleatória na posição i de x por uma outra chave aleatória (li- nha 15). Por fim, a quarta e última opção consiste na troca de duas chaves aleatórias consecutivas, cuja posição da primeira é escolhida de forma aleatória (linhas 17-20). Vale destacar que o número de perturbações que são feitas é controlado por um parâmetro I ∈N que deve ser fornecido. https://proceedings.science/p/193916?lang=en DOI: 10.59254/sbpo-2024-193916 Algoritmo 5: PERTURBAÇ ÃO Dados: Solução a ser perturbada x ∈X e intensidade I da perturbação. Resultado: Solução perturbada x′ ∈X. 1 x′ ←x 2 para k = 1 até I faça 3 t ←inteiro aleatório entre 1 e 4 4 i ←inteiro aleatório entre 0 e N −1 5 se t == 1 então 6 x′(i) = 1 −x′(i) 7 senão 8 se t == 2 então 9 j ←inteiro aleatório entre 0 e N −1 10 a ←x′(i) 11 x′(i) ←x′(j) 12 x′(j) ←a 13 senão 14 se t == 3 então 15 x′(i) ←um número real aleatório entre 0 e 1 16 senão 17 z ←um inteiro aleatório entre 0 e N −2 18 a ←x′(z) 19 x′(z) ←x′(z + 1) 20 x′(z + 1) ←a 21 fim 22 fim 23 fim 24 fim Figura 7: Pseudocódigo da perturbação. 4. Resultados Computacionais A ILS baseada em chaves aleatórias descrita na seção 3, assim como o decodificador detalhado na subseção 2.1, foram implementados em C++ e utilizados para resolver as 20 instâncias de tamanho moderado do MTSP de Macedo e Bueno [2023]. Vale ressaltar, entretanto, que por conta da facilidade de se construir e manipular grafos com múltiplas arestas em Python, para a heurística construtiva utilizou-se o mesmo código escrito por Macedo e Bueno [2023], o qual foi chamado a partir da linguagem C++ por meio de uma interface entre as linguagens Python e C++ escrita pelos autores deste texto. A partir dos resultados obtidos, uma comparação em termos de robustez e tempo computacional foi feita entre a abordagem de baseada em chaves aleatórias, escrita em C++, e a usual de Macedo e Bueno [2023] escrita em Python, a qual opera diretamente sobre o espaço de solução. Para uma comparação justa, os experimentos foram conduzidos no mesmo ambiente computacional, ou seja, em um computador com sistema operacional Windows® 11 de 64 bits, processador Intel Core® i5-11400H 2,70 GHz e 16 GB de RAM. A Tabela 1 apresenta os resultados computacionais obtidos. A primeira coluna identifica as instâncias por meio de quádruplas ordenada (veja a seção 2), enquanto a segunda coluna contém o valor assumido pela função objetivo quando avaliada na melhor solução conhecida (BKS, Best Known Solution) de cada instância. Vale ressaltar que a BKS de cada instância já é a solução ótima, pois elas foram resolvidas até a otimalidade por Macedo e Bueno [2023] com o modelo de Tang e Denardo [1988]. Para cada instância, são reportados quatro valores nas colunas BV, Gap, Média e CPU(s), os quais estão associados a cada uma das abordagens de implementação da ILS. O primeiro valor refere-se ao melhor valor (BV, do inglês Best Value) que a função objetivo adquire ao longo de 10 execuções da respectiva ILS. O segundo valor mensura o erro relativo percentual entre o BV e aquele assumido pela função objetivo na BKS3. O terceiro valor é a média aritmética 3Em outras palavras, Gap (%) = \f\f\f BV BKS −1 \f\f\f × 100. https://proceedings.science/p/193916?lang=en DOI: 10.59254/sbpo-2024-193916 dos valores assumidos pela função objetivo ao final de um conjunto de 10 execuções da respectiva ILS. Por fim, o quarto valor é a média do tempo de CPU requerido para a obtenção de uma solução melhor ou igual à BKS. Essa média temporal também é calculada ao final de um conjunto de 10 execuções. Tabela 1: Resultados computacionais obtidos ao resolver as 20 instâncias de tamanho moderado do MTSP de Macedo e Bueno [2023] por meio de uma ILS usual, implementada em Python, e uma baseada em chaves aleatórias, implementada em C++. ILS usual de Macedo e Bueno [2023] ILS baseada em chaves aleatórias Instância BKS BV Gap (%) Média CPU(s) BV Gap (%) Média CPU(s) (15, 20, 6, B1) 19 19 0,00 19,20 12,530 19 0,00 19,00 0,080 (15, 20, 6, B2) 26 26 0,00 27,50 14,850 26 0,00 26,00 1,694 (15, 20, 6, B3) 22 22 0,00 22,80 12,760 22 0,00 22,00 3,801 (15, 20, 6, B4) 18 18 0,00 20,40 11,940 18 0,00 18,00 8,753 (15, 20, 6, B5) 20 20 0,00 20,90 11,920 20 0,00 20,00 0,047 (15, 20, 8, B6) 14 14 0,00 14,80 11,380 14 0,00 14,00 9,166 (15, 20, 8, B7) 10 10 0,00 10,00 10,990 10 0,00 10,00 0,003 (15, 20, 8, B8) 13 13 0,00 13,00 11,470 13 0,00 13,00 0,108 (15, 20, 8, B9) 15 15 0,00 15,70 12,180 15 0,00 15,00 0,692 (15, 20, 8, B10) 14 14 0,00 14,60 11,290 14 0,00 14,00 0,083 (15, 20, 10, B11) 10 10 0,00 10,00 10,620 10 0,00 10,00 0,011 (15, 20, 10, B12) 8 8 0,00 8,00 10,530 8 0,00 8,00 0,002 (15, 20, 10, B13) 10 10 0,00 10,00 11,160 10 0,00 10,00 0,006 (15, 20, 10, B14) 8 8 0,00 8,10 10,710 8 0,00 8,00 0,002 (15, 20, 10, B15) 9 9 0,00 9,00 11,380 9 0,00 9,00 0,142 (15, 20, 12, B16) 8 8 0,00 8,00 10,360 8 0,00 8,00 0,006 (15, 20, 12, B17) 8 8 0,00 8,00 11,070 8 0,00 8,00 0,036 (15, 20, 12, B18) 7 7 0,00 7,00 11,020 7 0,00 7,00 0,006 (15, 20, 12, B19) 6 6 0,00 6,00 10,540 6 0,00 6,00 0,003 (15, 20, 12, B20) 8 8 0,00 8,00 11,110 8 0,00 8,00 0,006 Com base nos valores da Tabela 1, algumas observações podem ser realizadas. A pri- meira observação diz respeito ao fato da ILS baseada em chaves aleatórias ter demonstrado ser mais robusta que a ILS usual, ao menos para as instâncias em questão. De fato, os valores na coluna Média para a ILS baseada em chaves aleatórias são idênticos aos valores na coluna BKS, o que não acontece com a usual. Como todas as BKS’s são ótimas, isso significa que, para cada instância, o valor ótimo foi atingido em cada uma das 10 execuções da ILS baseada em chaves aleatórias. Essa observação pode ser explicada pelo fato da perturbação implementada conforme a Figura 7 ser mais agressiva do que aquela utilizada por Macedo e Bueno [2023], promovendo uma maior diversificação durante a busca. Além disso, o fato da linguagem C++ ser compilada permite co- brir uma região maior do espaço de busca em um tempo menor, aumentando a probabilidade de encontrar soluções melhores e, eventualmente, a solução ótima. Uma segunda observação relevante é a redução significativa do tempo computacional em praticamente todas as instâncias analisadas. Para a ILS usual, o tempo médio de CPU ao longo das instâncias não varia muito, mesmo quando a capacidade da caixa C aumenta e o problema se torna mais trivial. Por outro lado, para a ILS baseada em chaves aleatórias há uma variação maior do tempo médio de CPU, pois ela foi capaz de capturar melhor a trivialidade das instâncias à medida que C aumenta, resolvendo-as na maioria dos casos em um tempo inferior a 0,1 s. Além disso, a média aritmética dos 20 valores na coluna CPU(s) para a ILS usual é 11,4905 s, enquanto para a baseada em chaves aleatórias ela é de apenas 1,2323 s. Isso indica uma redução percentual de 89,27%. É importante ressaltar, contudo, que para as instâncias associadas às matrizes de incidência https://proceedings.science/p/193916?lang=en DOI: 10.59254/sbpo-2024-193916 B4 e B6, o tempo médio de CPU é semelhante ao da ILS usual. Essa é uma constatação interessante, pois essas instâncias não requereram um tempo tão discrepante em relação as demais instâncias na ILS usual. 5. Conclusões e Trabalhos Futuros Este trabalho apresenta uma ILS que realiza a busca pela solução do MTSP no espaço de chaves aleatórias, uma abordagem alternativa e promissora que é tradicionalmente empregada com sucesso nas meta-heurísticas RKGA e BRKGA para resolver problemas variados. Por conta disso, a ILS baseada em chaves aleatórias proposta foi implementada em C++ e aplicada para re- solver as 20 instâncias de tamanho moderado de Macedo e Bueno [2023], que originalmente as resolveram com uma ILS usual que opera diretamente sobre o espaço de solução. Dessa forma, o objetivo era aprimorar os resultados obtidos em termos de robustez e tempo computacional, além de explorar a viabilidade de integrar chaves aleatórias em uma meta-heurística que normalmente opera apenas com soluções pertencentes ao espaço de busca original do problema. Os resultados computacionais revelaram que a ILS baseada em chaves aleatórias foi capaz de reduzir em 89,27% a média aritmética do tempo médio de CPU de todas as 20 instâncias. Essa redução significativa está relacionado com o fato da linguagem C++ ser compilada e também com o fato de se ter utili- zado uma perturbação mais agressiva que permitiu uma maior diversificação durante a busca. Além disso, a ILS baseada em chaves aleatórias conseguiu capturar melhor a trivialidade das instâncias com as maiores caixas de ferramenta. Nessas instâncias, o tempo médio de CPU é muito menor que nas instâncias mais complexas. Isso também teve sua parcela de contribuição na redução temporal mencionada. Por fim, a ILS baseada em chaves aleatórias não apresentou variabilidade ao longo das execuções em nenhuma das instâncias, consistentemente alcançando a solução ótima em todas elas. Esses resultados evidenciam sua robustez em comparação com a ILS convencional. Para trabalhos futuros, a abordagem proposta será aplicada em instâncias encontradas em estudos acadêmicos de revistas científicas internacionais. Isso nos permitirá avaliar sua eficácia e desempenho em cenários de maior complexidade e escala, frequentemente considerados nes- sas publicações [Mecler et al., 2021]. Essa extensão do escopo de aplicação contribuirá para a generalização dos resultados obtidos até o momento, consolidando a abordagem em questão como uma ferramenta viável e eficiente para que possa ser aplicada na resolução de outros problemas de otimização tão desafiadores quanto o MTSP. Agradecimentos O presente trabalho foi realizado com apoio da Coordenação de Aperfeiçoamento de Pes- soal de Nível Superior (CAPES), processos 88887.669708/2022-00 e 88887.644322/2021-00."
        },
        {
            "titulo": "INTEGRAÇÃO DE DRONES E VEÍCULOS TERRESTRES PARA MONITORAMENTO DE INUNDAÇÕES EM CENTROS URBANOS",
            "informacoes_url": "https://proceedings.science/p/193521?lang=pt-br",
            "idioma": "português",
            "storage_key": "galoa-proceedings--sbpo-2024--193521.pdf",
            "autores": [
                {
                    "nome": "Roberto G. Ribeiro",
                    "afiliacao": "Dep. de Computação e Sistemas (DECSI) - Universidade Federal de Ouro Preto (UFOP) - João Monlevade - MG, 35.931-008, Brasil",
                    "orcid": null
                },
                {
                    "nome": "Martín Gómez Ravetti",
                    "afiliacao": "Dep. de Ciência da Computação (DCC) - Universidade Federal de Minas Gerais (UFMG) - Belo Horizonte, MG, 31270-010, Brasil",
                    "orcid": null
                },
                {
                    "nome": "Frederico Gadelha Guimarães",
                    "afiliacao": "Dep. de Ciência da Computação (DCC) - Universidade Federal de Minas Gerais (UFMG) - Belo Horizonte, MG, 31270-010, Brasil",
                    "orcid": null
                }
            ],
            "data_publicacao": null,
            "resumo": "Recentes tragédias nas grandes metrópoles, causadas por períodos prolongados de chuva, destacam a urgência de estratégias voltadas para a mitigação dos impactos como parte essencial do planejamento das cidades inteligentes do futuro.",
            "keywords": [
                "Programação Linear Inteira Mista",
                "Roteamento de drones e veículos terrestres",
                "Monitoramento de inundações em centros urbanos",
                "Otimização Combinatória",
                "Programação Matemática"
            ],
            "referencias": [
                "Alsamhi, S. H., Shvetsov, A. V., Kumar, S., Shvetsova, S. V., Alhartomi, M. A., Hawbani, A., Rajput, N. S., Srivastava, S., Saif, A., e Nyangaresi, V. O. (2022). Uav computing-assisted search and rescue mission framework for disaster and harsh environment mitigation. Drones.",
                "Alsumayt, A., El-Haggar, N., Amouri, L., Alfawaer, Z. M., e Aljameel, S. S. (2023). Smart flood detection with ai and blockchain integration in Saudi Arabia using drones. Sensors.",
                "Alyassi, R., Khonji, M., Karapetyan, A., Chau, S. C.-K., Elbassioni, K., e Tseng, C.-M. (2022). Autonomous recharging and flight mission planning for battery-operated autonomous drones. IEEE Trans. on Automation Science and Engineering.",
                "Ammous, M., Belakaria, S., Sorour, S., e Abdel-Rahim, A. (2018). Optimal cloud-based routing with in-route charging of mod electric vehicles. IEEE Trans. on Intell. Transp. Syst.",
                "Assis, W. L., Magalhães Junior, A. P., e de Azevedo Lopes, F. W. (2023). Urban flooding in the city of Belo Horizonte, southeastern Brazil. In Urban Flooding in Brazil, p. 107–132. Springer.",
                "Boeing, G. (2017). Osmnx: A python package to work with graph-theoretic openstreetmap street networks. J. of Open Source Software.",
                "Fan, M., Wu, Y., Liao, T., Cao, Z., Guo, H., Sartoretti, G., e Wu, G. (2022). Deep rl for uav routing in multiple charging stations. IEEE Trans. on Vehicular. Technol.",
                "Gonçalves, L. e Damas, B. (2022). Automatic detection of rescue targets in maritime search and rescue missions using uavs. In 2022 Int. Conf. on Unmanned Aircraft Syst., p. 1638–1643. IEEE.",
                "James, J. (2018). Two-stage request scheduling for autonomous vehicle logistic system. IEEE Trans.s on Intell. Transp. Syst.",
                "Jia, X., Song, X., e Yu, C. (2023). Privacy-preserving attestation scheme for revocable uav charging using hybrid state channels. Electronics.",
                "Li, H., Chen, J., Wang, F., e Bai, M. (2021). Ground-vehicle and unmanned-aerial-vehicle routing problems from two-echelon scheme perspective: A review. Eur. J. of Oper.l Res.",
                "Munawar, H. S., Ullah, F., Qayyum, S., Khan, S. I., e Mojtahedi, M. (2021). Uavs in disaster management: Application of integrated aerial imagery and cnn for flood detection. Sustainability.",
                "Ribeiro, R. G., Cota, L. P., Euzébio, T. A., Ramírez, J. A., e Guimarães, F. G. (2021). Uav routing problem with mobile charging stations for assisting search and rescue missions in post-disaster scenarios. IEEE Trans.s on Syst., Man, and Cybernetics: Syst.",
                "Rizk, H., Nishimur, Y., Yamaguchi, H., e Higashino, T. (2021). Drone-based water level detection in flood disasters. Int. J. of environmental Res. and public health.",
                "Shi, J., Mao, H., Zhou, Z., e Zheng, L. (2023). Adaptive large neighborhood search algorithm for the uav routing problem with recharging. Applied Soft Computing.",
                "Yanmaz, E. (2023). Joint or decoupled optimization: Multi-uav path planning for search and rescue. Ad Hoc Networks."
            ],
            "artigo_completo": "INTEGRAÇÃO DE DRONES E VEÍCULOS TERRESTRES PARA MONITORAMENTO DE INUNDAÇÕES EM CENTROS URBANOS. RESUMO Recentes tragédias nas grandes metrópoles, causadas por períodos prolongados de chuva, destacam a urgência de estratégias voltadas para a mitigação dos impactos como parte essencial do planejamento das cidades inteligentes do futuro. Este trabalho integra a malha de tráfego urbano com tecnologias emergentes, apresentando uma metodologia para o monitoramento de áreas inun- dadas que utiliza um drone sobrevoando essas regiões e um veículo terrestre trafegando pelas vias de trânsito não inundadas, oferecendo suporte. Essa integração é representada por um modelo ino- vador de Programação Linear Inteira Mista (MILP - Mixed Integer Linear Programming) de dois níveis, construído para gerar soluções eficientes e garantir o sincronismo entre os dois tipos de veículos. Testes computacionais foram conduzidos em cenários de inundações na cidade de Belo Horizonte, Minas Gerais (MG). Os resultados indicam que a metodologia proposta pode auxiliar as operações da defesa civil, proporcionando respostas rápidas e eficientes em situações de emergência decorrentes desses eventos em centros urbanos. PALAVRAS CHAVE. Programação linear inteira mista. Roteamento de drones e veículos terrestres. Monitoramento de inundações em centros urbanos. Otimização Combinatória. Programação Matemática. https://proceedings.science/p/193521?lang=pt-br DOI: 10.59254/sbpo-2024-193521 1. Introdução Drones autônomos sobrevoando grandes metrópoles para monitorar problemas urbanos são parte das expectativas das cidades inteligentes, não sendo apenas um exemplo contemporâneo de futurismo utópico. Já é inclusive uma realidade nos dias atuais com potencial de atuação em tarefas complexas de grande impacto social. Ao sobrevoarem áreas urbanas, os drones são capazes de realizar inspeções, detectar acidentes, identificar danos em vias e monitorar inundações. Equipados com sensores específicos, podem também medir a qualidade do ar, ruídos e outros aspectos do cotidiano das cidades. Em situações de enchentes, por exemplo, a tecnologia de drones permite o acesso a locais inundados em que o acesso por vias terrestres é praticamente impossível. Eventos recentes têm destacado os impactos de tragédias causadas por ações humanas negligentes, fenômenos naturais, ou ambos, como as enchentes em grandes metrópoles. Compreender a dinâmica dessas ocorrências e mitigá-las é de extrema importância. Portanto, qualquer cidade focada em inovação deve estar preparada para oferecer socorro emergencial e reduzir seus impactos. Em consonância com as expectativas das cidades inteligentes e as demandas emergenciais das áreas urbanas, há uma literatura dedicada ao desenvolvimento de soluções que utilizam drones e modelos preditivos. Para mitigar danos causados por períodos chuvosos prolongados, Rizk et al. [2021] apresentam um sistema de reconhecimento de imagens baseado em drones e redes neurais convolucionais para detectar níveis de água e avaliar danos por enchentes. Outros estudos [Munawar et al., 2021; Alsumayt et al., 2023] também exploram o uso de drones com métodos de Inteligência Artificial (IA) para identificar as regiões mais afetadas por inundações. Devido à complexidade das tarefas onde o tempo de operação é crucial, há trabalhos na literatura que exploram o planejamento espacial de drones. Muitos desses estudos abordam essas tarefas como variantes do problema de roteamento de veículos (VRP - Vehicle Routing Problem) com foco na eficiência. Alsamhi et al. [2022] destaca importância crítica dessas operações medi- ante a ocorrência de desastres, ressaltando como um planejamento ótimo pode agilizar e aprimorar essas missões, mostrando melhorias significativas na eficiência da operação. Já Gonçalves e Damas [2022] aborda o uso estratégico de uma frota de drones para sobrevoar áreas atingidas por terremo- tos, priorizando locais críticos e coordenando esforços de resgate de maneira mais rápida e eficiente do que métodos tradicionais de proteção civil. No mesmo contexto, os trabalhos Yanmaz [2023]; Jia et al. [2023] se concentram no planejamento de trajetórias para equipes de drones, visando detectar alvos, estabelecer comunicação com a equipe de resgate e otimizar o tempo de resposta. Devido às limitações físicas dos drones, que incluem uma autonomia de deslocamento sig- nificativamente menor em comparação com veículos terrestres, a literatura também oferece soluções com recargas ou trocas de baterias durante as missões. Ao abordar os desafios da aplicabilidade em tarefas de missão persistente de longa distância, os trabalhos Alyassi et al. [2022]; Fan et al. [2022]; Shi et al. [2023] apresentam propostas de planejamento que incluem o uso de estações de carrega- mento de drones distribuídas na área de operação. Focados principalmente na eficiência das tarefas, tais estudos empregam modelos de programação linear ou não linear para distribuir de forma ótima os pontos de recarga, minimizando assim o tempo de operação. Abordagens similares fazem parte de estudos que consideram veículos elétricos terrestres, tais como as metodologias apresentadas por James [2018]; Ammous et al. [2018]. Para aprimorar a eficiência de operações de busca e resgate, Ribeiro et al. [2021] avança o estado da arte ao propor uma solução que integra drones e plataformas móveis de recarga, onde os veículos aéreos e terrestres são sincronizados no tempo e espaço. Como resultado, apresentam um modelo de Programação Linear Inteira Mista (MILP - Mixed Integer Linear Programming) para o roteamento dessa integração. Em outros cenários de operações, Alyassi et al. [2022] também https://proceedings.science/p/193521?lang=pt-br DOI: 10.59254/sbpo-2024-193521 apresentam uma variante do VRP dedicado à otimização do sistema de veículos terrestres e drones. Oferecendo uma visão mais ampla e em contextos mais gerais, Li et al. [2021] revisa vários estudos que abordam o sincronismo entre drones e veículos terrestres para o planejamento ótimo de rotas. Segundo os autores, a otimização de rotas de veículos em redes de dois níveis tem recebido crescente atenção na comunidade de pesquisa operacional. Nesta linha de pesquisa se insere o presente estudo. Diante da necessidade de soluções que visem mitigar os impactos de tragédias em centros urbanos, este estudo apresenta uma meto- dologia de planejamento para monitorar áreas inundadas utilizando drones, com veículos terrestres proporcionando suporte para troca de baterias. O resultado é uma formulação inovadora de dois níveis que, como as descritas na literatura, sincroniza os dois tipos de veículos na busca por solu- ções ótimas. No entanto, esta nova abordagem se distingue ao oferecer uma forma mais flexível de definir os locais de suporte. Ao contrário das soluções encontradas na literatura, os locais can- didatos para os veículos não são conhecidos de antemão e, portanto, não são entradas diretas da formulação. Em vez disso, o posicionamento desses veículos é determinado por um conjunto de variáveis contínuas da formulação, conforme detalhado na seção 2. 2. Metodologia Esta seção apresenta um modelo MILP de roteamento de drone com a disposição dinâ- mica e síncrona com um veículo terrestre. Neste modelo, o posicionamento desse veículo não são locais específicos pré-definidos em uma planta de atuação e convertidos em variáveis binárias da formulação. Tal posicionamento é obtido a partir de um conjunto de valores de variáveis, reais e binárias, da formulação. Esta característica é fundamental para o problema em questão uma vez que oferece mais opções de locais de suporte sem necessariamente aumentar substancialmente o número de variáveis do problema. Não sabemos exatamente quais devem ser os locais candidatos para posicionamento do veículo terrestre de modo a tornar a operação mais eficiente. No entanto, podemos presumir que esses locais devem estar situados em pontos estratégicos, como nas proximidades dos locais que demandam monitoramento ou ao longo de rotas terrestres que conectam dois destes mesmos locais. A formulação matemática que abstrai o problema em uma variante do VRP é detalhada nesta seção. 2.1. Parâmetros e variáveis do problema A Tabela 1 sintetiza os parâmetros e as variáveis do problema, os quais são construídos a partir dos conjuntos OOO, CCC e GGG, N1 N1 N1, N2 N2 N2 e N′ 2 N′ 2 N′ 2. Na ocasião, OOO é o local de partida do drone e do veículo terrestre. O conjunto CCC é formado por nós que representam os locais com indícios de enchente que precisam ser monitorados via drone, enquanto o conjunto GGG é composto por locais adjacentes aos pontos de monitoramento, acessíveis via veículos terrestres. Como parâmetros, tal tabela especifica os tempos de deslocamento do veículo terrestre ρij e do drone αij entre dois nós, assim como o tempo gasto necessário para monitorar a área inundada βi. Os termos αij e βi também são úteis para estabelecer o consumo de energia do drone e limitar o tamanho das rotas pela capacidade de bateria, representada por Θ. Por fim, o termo Υ representa o tempo necessário para troca de bateria e o termo M é um parâmetro de grandeza utilizado em restrições da formulação matemática. Em relação as variáveis, a Tabela 1 apresenta conjuntos de termos alinhados com as ca- racterísticas do problema. O termos yij, dij e rin i estão relacionados ao deslocamento do veículo terrestre. Na ocasião, yij ativa ou não a aresta (i, j) e dij determina o tempo mínimo que o veículo terrestre deve permanecer em um ponto localizado entre os nós i e j, com i, j pertencendo ao con- junto N1 N1 N1. O termo rin i representa o instante de chegada ao local i, para todo i no conjunto GGG. Já os termos xij, bij e lij, onde i, j pertencem ao conjunto N2 N2 N2, representam variáveis que determinam o https://proceedings.science/p/193521?lang=pt-br DOI: 10.59254/sbpo-2024-193521 Conjuntos OOO: Base de partida N1 N1 N1: OOO ∪GGG CCC: Locais de enchentes N2 N2 N2: N1 N1 N1 ∪CCC →OOO ∪CCC ∪GGG GGG: Locais marginais aos locais de enchentes N ′ 2 N ′ 2 N ′ 2: N2 N2 N2 −OOO →CCC ∪GGG Parâmetros ρij: Tempo de deslocamento do veículo terrestre do local i para o local j, ∀i, j ∈N1 N1 N1 αij: Tempo de deslocamento do drone do local i para o local j, ∀i, j ∈N2 N2 N2 βi: Tempo de monitoramento do local i, ∀i ∈CCC Υ: Tempo necessário para troca de bateria Θ: Autonomia de voo M: Big M Variáveis yij ∈{0, 1} ∀i, j ∈N1 N1 N1: variável binária representando o uso da aresta (i,j); rin i ∈R+ 0 ∀i ∈GGG : Instante de chegada do veículo terrestre no nó i; dij ∈R+ 0 ∀i ∈GGG : Tempo mínimo de permanência do veículo terrestre no segmento (i,j); xij ∈{0, 1} ∀i, j ∈N2 N2 N2: Variável binária representando o uso da aresta (i,j); bij ∈R+ 0 ∀i ∈N2 N2 N2, ∀j ∈N2 N2 N2: autonomia do drone associada a aresta (i, j); lij ∈R+ 0 ∀i ∈N2 N2 N2, ∀j ∈N2 N2 N2: variável de fluxo do drone associada a aresta (i, j); Fqjk ∈R+ 0 , ∀q ∈N2 N2 N2, ∀j, k ∈N1 N1 N1: distância do nó q até um ponto no segmento (j, k); d Fqjk ∈R+ 0 , ∀q ∈N2 N2 N2, ∀j, k ∈N1 N1 N1: d Fqjk = F 2 qjk; Vjk ∈R+ 0 , ∀j, k ∈N1 N1 N1: distância do nó j até um ponto no segmento (j, k); d Vjk ∈R+ 0 , ∀j, k ∈N1 N1 N1 : d Vjk = V 2 jk; pij ∈{0, 1} ∀i, j ∈N2 N2 N2 : variável binária auxiliar de interseção; zij ∈R+ 0 ∀i, j ∈N2 N2 N2: variável contínua auxiliar de atribuição; uqjk ∈{0, 1} ∀q ∈N2 N2 N2, ∀j, k ∈N1 N1 N1: variável binária auxiliar de linearização; Aij ∈R+ 0 ∀i, j ∈N2 N2 N2: variável contínua auxiliar de linearização; Tabela 1: Variáveis do problema roteamento do drone. Nesse contexto, xij define a ativação da aresta (i, j), bij denota o consumo do drone até chegar ao nó j e lij tempo de voo acumulado associado a aresta (i, j). A Tabela 1 também inclui as variáveis Fqjk, d Fqjk, Vjk e c Vjk, onde q pertence ao conjunto N2 N2 N2 e j, k ao conjunto N1 N1 N1. Essas variáveis são empregadas para calcular distâncias entre locais de monitoramento e nós que não fazem diretamente parte da formulação. Esses nós, em síntese, são definidos a partir da relação entre tais variáveis e alguns parâmetros do problema, não fazendo parte diretamente da formulação principal - a subseção 2.2 oferece uma explicação detalhada. Os demais termos apresentados na Tabela 1 definem algumas variáveis auxiliares úteis na formulação. Neste contexto, pij e zij, com i, j pertencendo ao conjunto N2 N2 N2 representam expressões de interseção e de atribuição convertidas em restrições, respectivamente. Já uqjk, onde q pertence ao conjunto N2 N2 N2 e i, k pertencem ao conjunto N1 N1 N1, é uma variável que lineariza o produto entre duas variáveis binárias. Por fim, Aij, com i, j pertencendo ao conjunto N2 N2 N2 denota uma variável de linearização do produto entre uma variável binária e uma contínua. 2.2. Definição dos nós fictícios Conforme mencionado previamente, o roteamento do veículo terrestre que oferecem su- porte aos drone não é definido a partir de locais pré-definidos na área de operação convertidos em variáveis binárias da formulação. Como não são previamente conhecidos, aqui, são nomeados como nós fictícios. Sendo assim, uma aresta que conecta um nó i ∈N2 N2 N2 com um nó fictício é denomi- nada aresta fictícia. Assumindo a existência de nós e arestas fictícias, a rota ideal para um drone é definida com base nos valores de variáveis do modelo Fqjk e Vij. Para este cálculo, recorremos a leis trigonométricas para estabelecer a relação entre estas variáveis e determinar a posicionamento desses nós e arestas, tal como ilustrado na Figura 1. https://proceedings.science/p/193521?lang=pt-br DOI: 10.59254/sbpo-2024-193521 q j k ℓ αqj αqk Vjk Fqjk Fℓjk Vkj αjℓ αkℓ θj θk Figura 1: Localização de um nó fictício. Na Figura 1, os pontos q, j, k e ℓpertencem ao conjunto N2 N2 N2, com j e k também perten- cendo ao conjunto N1 N1 N1. Se a variável yjk = 1, um drone pode pousar no veículo terrestre para troca de bateria em qualquer ponto do segmento de reta entre j e k. A aresta destacada em vermelho na figura representa essa situação, enquanto o ponto central, destacado em branco, indica a posição do nó fictício. Observa-se que a variável Vjk define a distância entre a origem j e a posição do nó fictício. Assuma que um drone localizado no ponto q deve se deslocar para a localização do nó fictício destacado e, após a troca de bateria, parte para o nó ℓ. Sendo assim, Fqjk e Fℓjk determinam os pesos das arestas fictícias que se conectam ao nó fictício. O peso das arestas (q, j), (q, k) e (j, k) são os parâmetros de entrada αqj, αqk e αjk, respectivamente. A partir destes parâmetros e das variáveis Vjk e Fqjk, estabelecemos uma relação trigonométrica nas quais, garantem que a posição do nó fictício seja um ponto qualquer no segmento de reta j e k. Seja θj o ângulo formado entre as arestas (j, q) e (j, k). Então, pela lei dos cossenos, a relação de θj com o peso das arestas (q, j), (q, k) e (j, k) é definida pela Equação 1. cos θj = α2 qj + α2 jk −α2 qk 2αqjαjk (1) Se aplicarmos a mesma lei a um triângulo escaleno formado pelo parâmetro αqj e pelos valores das variáveis Vjk e Fqjk, tal como destacado em azul na Figura 1, chegamos a Equação (2). F 2 qjk = α2 qj + V 2 jk −2αqjVjk cos θj (2) A mesma analogia pode ser estendida ao ângulo θk formado entre as arestas (k, ℓ) e (j, k). Na ocasião, um drone deixa o nó fictício e parte em direção ao nó ℓe, desta forma, também existe uma expressão para a aresta fictícia de peso Fℓjk em termos dos parâmetros de entrada e da diferença (αjk −Vjk). Tal diferença pode ser expressa por Vkj que é a distância percorrida do ponto k até o nó fictício, tal como destacado em vermelho na Figura 1. Assim, por se tratar de um grafo não direcionado, a Equação (2) também é válida para Fℓjk. Após substituirmos a Equação (1) na Equação (2), obtemos a Equação (3), que estabelece a relação entre as variáveis Fℓjk e Vjk, sendo essencial para determinar a localização ideal dos nós fictícios. Nessa equação, d Fqjk e c Vjk representam o quadrado de Fqjk e Vjk, respectivamente, enquanto o termo Hqjk é uma constante determinada apenas por parâmetros de entrada do problema. https://proceedings.science/p/193521?lang=pt-br DOI: 10.59254/sbpo-2024-193521 d Fqjk = α2 qj + c Vjk −Vjk \u0018\u0018\u0018\u0018\u0018\u0018\u0018\u0018\u0018\u0018\u0018 :Hqjk α2 qj αjk + αjk − α2 qk αjk ! , ∀q ∈N2 N2 N2 ∀j, k ∈N1 N1 N1 (3) A variável Vjk é limitada ao intervalo [0, αjk], enquanto Fqjk é restrito a valores radiais no intervalo entre [αqj, αqk] ou [αqk, αqj]. Assim, as expressões quadráticas c Vjk = V 2 jk e d Fqjk = F 2 qjk são linearizadas utilizando série de Taylor nos pontos αjk/2 e |αqk−αqj|/2, respectivamente. Desta forma, a Equação (4) e a Equação (5) definem expressões lineares para c Vjk e d Fqjk, respectivamente. c Vjk = α2 jk 4 + αjk \u0010 Vjk −αjk 2 \u0011 (4) d Fqjk = (αqk −αqj)2 4 + (αqk −αqj) \u0012 Fqjk −(αqk −αqj) 2 \u0013 (5) Na subseção 2.3, as relações apresentadas são transformadas em restrições que, junta- mente com outras premissas, estabelecem a formulação matemática do problema. 2.3. Formulação para o problema Executar a operação de monitoramento de forma ótima corresponde a minimizar o rotea- mento do drone. No entanto, para uma melhor interpretação da qualidade das soluções, o problema foi escrito como um problema maximização, tal como expresso na Função (6). Ou seja, ao ser maximizada, define o valor dos argumentos que minimizam o roteamento do drone. max   − X i∈N2 N2 N2 X j∈N′ 2 N′ 2 N′ 2 (αij + βj)xij − X i∈N2 N2 N2 X j∈G G G Υxij   (6) O termo  corresponde ao pior planejamento de rotas, no qual, o drone percorre todas as arestas, monitora e troca de bateria a cada monitoramento. Assim,  pode ser calculado pela Equação (7).  = X i∈N2 N2 N2 X j∈N′ 2 N′ 2 N′ 2 αij + X i∈CCC βi + Υ|GGG| (7) As restrições (8-12) garantem a relação entre as variáveis Fqjk e Vjk para todas com- binações possíveis dos índices q, j e k , tal como definido na Equação (2). As restrições (8-10) determinam que a variável binária pij é ativada apenas se existir uma aresta que indique uma che- gada (xij = 1) ou uma saída (xji = 1) no nó j, para todo i, j pertencente ao conjunto N2 N2 N2. Se esta condição for satisfeita e j corresponder a um ponto de troca de bateria, j ∈N1 N1 N1, um veículo terrestre passará por j e yjk = 1. As restrições (11) e (12) asseguram que a igualdade expressa na Equação (2) é válida apenas se as variáveis pqj e yjk estiverem ativas. pij ≤xij + xji, ∀i, j ∈N2 N2 N2 (8) pij ≥xij, ∀i, j ∈N2 N2 N2 (9) pij ≥xji, ∀i, j ∈N2 N2 N2 (10) d Fqjk ≤α2 qj + c Vjk −VjkHqjk + M(2 −pqj −yjk), ∀q ∈N2 N2 N2, ∀j ∈GGG, k ∈N1 N1 N1 (11) d Fqjk ≥α2 qj + c Vjk −VjkHqjk −M(2 −pqj −yjk), ∀q ∈N2 N2 N2, ∀j ∈GGG, k ∈N1 N1 N1 (12) https://proceedings.science/p/193521?lang=pt-br DOI: 10.59254/sbpo-2024-193521 c Vjk ≤α2 jkyjk, ∀j, k ∈N1 N1 N1 (13) Vjk ≤αjkyjk, ∀j, k ∈N1 N1 N1 (14) d Fqjk ≤Θ2uqjk, ∀j ∈GGG, ∀k ∈N1 N1 N1 ∀q ∈N2 N2 N2 (15) Fqjk ≤Θuqjk, ∀j ∈GGG, ∀k ∈N1 N1 N1 ∀q ∈N2 N2 N2 (16) uqjk ≤pqj, ∀j ∈GGG, ∀k ∈N1 N1 N1 ∀q ∈N2 N2 N2, q ̸= j, j ̸= k (17) uqjk ≤yjk, ∀j ∈GGG, ∀k ∈N1 N1 N1 ∀q ∈N2 N2 N2, , q ̸= j, j ̸= k (18) uqjk ≥pqj + yjk −1, ∀j ∈GGG, ∀k ∈N1 N1 N1 ∀q ∈N2 N2 N2, , q ̸= j, j ̸= k (19) uqjk = 0, ∀j ∈GGG, ∀k ∈N1 N1 N1 ∀q ∈N2 N2 N2, q = j ou j = k (20) c Vjk = α2 jkyjk 4 + αjk \u0010 Vjk −αjkyjk 2 \u0011 , ∀j, k ∈N1 N1 N1 (21) d Fqjk = (αqk −αqj)2uqjk 4 + (αqk −αqj) \u0012 Fqjk −(αqk −αqj)uqjk 2 \u0013 , ∀q ∈N2 N2 N2 ∀j, k ∈N1 N1 N1 (22) z0j = α0jx0j, ∀j ∈N′ 2 N′ 2 N′ 2 (23) zqj = αqjxij, ∀q ∈CCC, ∀j ∈CCC (24) zqj = X k∈N1 N1 N1 Fqjk, ∀q ∈N′ 2 N′ 2 N′ 2, ∀j ∈N1 N1 N1 (25) zjq = X k∈N1 N1 N1 Fijk, ∀q ∈CCC, ∀j ∈GGG (26) Aij ≥zij −(1 −xij)Θ, ∀i, j ∈N2 N2 N2 (27) Aij ≤xijΘ, ∀i, j ∈N2 N2 N2 (28) Aij ≤zij, ∀i, j ∈N2 N2 N2 (29) X j∈N′ 2 N′ 2 N′ 2 lij − X j∈N2 N2 N2 lji = X j∈N′ 2 N′ 2 N′ 2 Aij + X j∈N′ 2 N′ 2 N′ 2 βixij, ∀i ∈CCC (30) X j∈N′ 2 N′ 2 N′ 2 lij − X j∈N2 N2 N2 lji = X j∈N′ 2 N′ 2 N′ 2 Aij + X j∈N′ 2 N′ 2 N′ 2 Υixij, ∀i ∈GGG (31) lij ≤Mxij, ∀i ∈N2 N2 N2, ∀j ∈N2 N2 N2 (32) X j∈N′ 2 N′ 2 N′ 2 bij − X j∈N2 N2 N2 bji = X j∈N2 N2 N2 Aij + X j∈N2 N2 N2 βixij, ∀i ∈CCC (33) bij = Aij, ∀i ∈N1 N1 N1, ∀j ∈N2 N2 N2 (34) bij ≤(Θ −βj)xij, ∀i ∈N2 N2 N2, ∀j ∈CCC (35) bij ≤Θxij, ∀i ∈N2 N2 N2, ∀j ∈N1 N1 N1 (36) X i∈N2 N2 N2 xij = 1, ∀j ∈CCC (37) X j∈N ′ 2 N ′ 2 N ′ 2 x0j = 1 (38) X i∈N2 N2 N2 xji = X i∈N2 N2 N2 xij, ∀j ∈GGG (39) https://proceedings.science/p/193521?lang=pt-br DOI: 10.59254/sbpo-2024-193521 X i∈N2 N2 N2 X j∈N′ 2 N′ 2 N′ 2 xij = |CCC| + X i∈N2 N2 N2 X j∈G G G xij (40) X i∈N1 N1 N1 yij ≤1, ∀j ∈N1 N1 N1 (41) X i∈N1 N1 N1 yij = X i∈N1 N1 N1 yji, ∀j ∈N1 N1 N1 (42) X j∈G G G y0j ≤1, (43) rin j ≥rin i + ρij + dij −M(1 −yij), ∀i ∈N1 N1 N1, ∀j ∈GGG (44) rin j ≤rin i + ρij + dij + M(1 −yij), ∀i ∈N1 N1 N1, ∀j ∈GGG (45) rin j ≤M X i∈N1 N1 N1 yij, ∀j ∈GGG (46) djk ≤yjkM, ∀j, k ∈GGG (47) lij ≥rin j + Vjk −M(2 −xij −yjk), ∀i ∈N2 N2 N2, ∀j ∈GGG, k ∈N1 N1 N1 (48) lij ≤rin j + djk + Vjk + M(2 −xij −yjk), ∀i ∈N2 N2 N2, ∀j ∈GGG, k ∈N1 N1 N1 (49) xqj ≤ X i∈N1 N1 N1 yij, ∀q ∈N2 N2 N2, ∀j ∈GGG (50) yij ≤ X q∈N2 N2 N2 xqj, ∀i ∈N1 N1 N1 ∀j ∈GGG (51) As restrições (13) e (14) estabelecem que as variáveis c Vjk e Vjk podem ter valores dife- rentes de zero apenas se houver movimentação do veículo terrestre na aresta (j, k). De maneira semelhante, as restrições (15) e (16) restringem os valores das variáveis d Fqjk e Fqjk ao movimento do drone e do veículo terrestre no par de arestas (q, j) e (j, k). O termo uqjk é então uma variável auxiliar, na qual, as restrições (17-20) refletem a linearização da igualdade uqjk = pqjyjk. Assim, as versões lineares das expressões quadráticas c Vjk = V 2 jk e d Fqjk = F 2 qjk, tal como descritas pelas restrições (4) e (22) são asseguradas pelas restrições restrições (14) e (22), respectivamente. A variável zqj representa o peso atribuído a cada movimentação do drone entre dois nós q e j. A restrição (23) define que a aresta que conecta o ponto de partida ao primeiro nó visitado j possui o peso α0j. As arestas (q, j) ativas, que conectam dois locais de monitoramento, q, j ∈CCC, também têm pesos associados diretamente ao conjunto de parâmetros αqj, para todo q, j ∈CCC, conforme definido pela restrição (24). Por outro lado, as restrições (25) e (26) atribuem pesos às variáveis zqj e zjq os pesos das arestas fictícias ativas de chegada e de saída em um nó fictício situado entre os pontos j e k, tal como ilustrado na Figura 1. As equações (27-29) representam restrições lineares que definem a variável Aij como o produto de zij e xij. Os valores das variáveis Aij, i, j ∈N2 N2 N2, correspondem aos pesos das arestas ativas e são utilizados para determinar o fluxo do drone. Esse fluxo é garantido por restrições baseadas nas arestas (ARC-based constraint), conforme descrito nas Equações (30-32), onde lij representa o tempo acumulado do drone ao percorrer a aresta (i, j). Nesse contexto, a (30) e a (31) acumulam o tempo de rota sempre que o drone passa por um local de monitoramento e por um local de troca de bateria, respectivamente. Já a restrição (32) assegura valores nulos para lij caso a aresta (i, j) não esteja ativa. Restrições baseadas nas arestas também são aplicadas para determinar a autonomia de https://proceedings.science/p/193521?lang=pt-br DOI: 10.59254/sbpo-2024-193521 voo do drone, levando em consideração a necessidade de recarga de bateria. Seja bij o consumo acumulado de energia na aresta (i, j). A restrição (33) define bij após o monitoramento do nó i ∈CCC. Esse consumo inclui o deslocamento, representado por Aij, e o tempo de inspeção, definido pelo parâmetro Bj. O valor de bij precisa ser atualizado sempre que um drone parte de um nó i, onde i ∈N1 N1 N1, já que os nós do conjunto N1 N1 N1 são dedicados à troca de bateria. Essa condição é assegurada pela restrição (34). Por fim, as restrições (35) e (36) limitam o voo do drone à capacidade da bateria. O roteamento do drone é estabelecido pelo conjunto de restrições (37-40). A restrição (37) garante que todos os pontos de monitoramento sejam visitados uma única vez, ao passo que a restrição (38) assegura a existência de uma única rota; restrição (39) equilibra o número de arestas de chegada e saída em cada local de troca de bateria; e a restrição (40) equilibra o número de arestas ativas em função do número de pontos de monitoramento e demandas por trocas de bateria. O roteamento do veículo terrestre é definido pelo conjunto de restrições (41-47). Enquanto a restrição (41) determina que cada ponto de suporte pode ser visitado uma única vez, a restrição (42) equilibra o número de arestas de entrada e saída nesses locais e a restrição (43) permite que apenas uma rota de suporte seja criada. O fluxo do veículo terrestre é baseado em nó (Node-based constraint), conforme definido pelas restrições (44) e (45). Assim, para cada aresta ativa (i, j), em que i pertence ao conjunto N1 e j ao conjunto G, o tempo de chegada ao nó destino j é determinado pelo tempo acumulado até o nó de origem i, adicionado ao tempo de deslocamento e ao tempo de permanência. Além disso, as restrições (46) e (47) garantem que o tempo de chegada e permanência em locais relacionados a arestas não ativadas sejam nulos. O último conjunto de restrições, (48-51), trata da sincronização entre o drone e o veículo terrestre. As restrições (49) e (50) estabelecem um intervalo de tempo no qual o drone pode pousar no veículo terrestre para troca de bateria. Em outras palavras, em um determinado segmento entre os pontos j e k, com j pertencendo ao conjunto GGG e k ao conjunto N1 N1 N1, o instante de chegada do drone deve coincidir com o período em que o veículo terrestre está posicionado em um ponto neste segmento. Por fim, a restrição (50) garante que o drone só pode visitar um determinado local se o veículo terrestre passar por ele, enquanto a restrição (51) assegura que o veículo terrestre só pode visitar um local que também é visitado pelo drone. 3. Estudo fundamentado em um centro urbano A metodologia apresentada foi testada em possíveis cenários de inundações na cidade de Belo Horizonte, em Minas Gerais (MG). Segundo Assis et al. [2023], a capital mineira é uma das metrópoles brasileiras marcadas por desafios recorrentes de enchentes devido à sua topografia e ao rápido crescimento urbano. A cidade tem adotado várias medidas para lidar com esses problemas, incluindo investimentos em sistemas de alerta precoce e planos de gestão de riscos. Neste sentido, o mapeamento das áreas de risco em conjunto com a metodologia de monitoramento aqui descrita, pode gerar uma resposta rápida e eficiente capaz de mitigar perdas humanas e materiais. A partir de mapas obtidos pela ferramenta Open Street Map NetworkX (OSMnx), criada por Boeing [2017], são construídos possíveis cenários de inundação na cidade de Belo Horizonte- MG. Os locais de inundação em cada cenário correspondem às coordenadas geográficas e formam o conjunto CCC da formulação matemática. O local de partida dos veículos alocados na tarefa é a coordenada de uma das unidades da defesa civil da cidade em investigação, definindo o conjunto OOO. Esses mapas também incluem um grafo que representa a rede de ruas e avenidas transitáveis por veículos terrestres na cidade. Assim, cada nó em GGG corresponde a um dos 32.483 nós presentes no grafo. Cada nó do conjunto GGG representa a localização mais próxima de uma área inundada acessível por veículo terrestre, obtida por funcionalidades da ferramenta OSMnx. Após a definição dos conjuntos OOO, CCC e GGG, bem como de seus derivados N1 N1 N1 e N2 N2 N2, os parâmetros de entrada da formulação matemática são estabelecidos. Tais parâmetros dependem https://proceedings.science/p/193521?lang=pt-br DOI: 10.59254/sbpo-2024-193521 principalmente do tipo de drone utilizado. Para este estudo, consideramos um único drone, modelo Autel EVO Max 4T. Trata-se de um drone profissional com uma câmera térmica apropriada para operações de busca e com capacidade de voo em condições adversas, como ventos fortes e chuvas. Este modelo de drone tem uma autonomia de voo de 40 minutos a uma velocidade média de 22 metros por segundo, o que equivale a 2.400 segundos para Θ. O peso de cada aresta αij é calculado dividindo-se a distância euclidiana entre os dois nós pela velocidade média do drone, para cada par de nós i e j no conjunto N2 N2 N2. Consideramos um veículo terrestre para a tarefa, onde o peso de cada aresta ρij, para cada par de nós i e j no conjunto N1 N1 N1, é calculado com base no tempo mínimo que o veículo terrestre leva para percorrer entre esses pontos na rede de trânsito urbano da cidade. A localização dos nós do conjunto GGG também é obtida por funcionalidades da ferramenta OSMnx e é executada em tempo polinomial. Para o tempo de monitoramento βi de cada local de inundação i, cada inspeção consome em média cinco minutos, o equivalente a um voo de 6.600 metros à velocidade estabelecida. Sob as atuais condições, aproximadamente dois minutos são necessários para trocar, verificar e preparar o drone para um novo voo, sendo Υ definido como dois minutos. 4. Resultados computacionais Para validar e testar os limites computacionais da metodologia proposta, foram realizados testes em diferentes cenários de inundações na cidade de Belo Horizonte-MG. Ao todo, foram testados 50 cenários, divididos em cinco grupos de tamanhos com |CCC| = 8, |CCC| = 10, |CCC| = 12, |CCC| = 14, e |CCC| = 16. Cada cenário foi executado utilizando uma licença acadêmica do Solver Gurobi, versão 10.0.3, com um limite de tempo de 30 minutos, em um computador equipado com processador Intel(R) Core(TM) i5-7200U CPU 2.50GHz e 16GB de RAM. |CCC| BIS Cenários 1 2 3 4 5 6 7 8 9 10 8 t(m) 78.79 85.21 84.61 85.3 83.74 80.17 75.13 85.07 81.51 75.55 GAP 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 10 t(m) 103.69 96.24 98.99 101.22 99.74 95.86 97.86 96.53 99.11 104.27 GAP 0.01 0.01 0.01 0.14 0.01 0.0 0.01 0.52 0.0 0.0 12 t(m) 116.49 119.41 113.79 115.65 120.16 116.85 118.23 118.86 115.88 110.95 GAP 0.01 0.17 0.0 0.28 0.14 0.01 0.23 0.01 0.01 0.09 14 t(m) JJ 132.82 168.5 JJ 134.75 133.81 135.08 135.59 139.36 136.23 GAP 0.13 0.0 0.26 0.16 0.18 0.39 0.32 0.42 16 t(m) JJ JJ 153.62 151.97 JJ JJ 147.01 145.2 152.94 JJ GAP 0.23 0.07 0.0 0.29 0.45 Tabela 2: Resultados obtidos A Tabela 2 apresenta os resultados obtidos, onde os cenários estão divididos em 10 colu- nas, mostrando o melhor tempo de operação encontrado e o gap. O tempo, rotulado como t(m), é expresso em minutos, e o símbolo JJ na tabela indica que não foi possível encontrar uma solução viável dentro do limite de tempo estabelecido. Nos grupos com tamanhos |CCC| = 8, |CCC| = 10 e |CCC| = 12, o solver encontrou o ótimo global ou obteve uma solução com gap próximo de zero. No caso dos cenários com tamanho |CCC| = 14, o solver não encontrou solução viável em duas das 10 instâncias dentro do limite de tempo estabelecido. Contudo, foi possível obter o ótimo global ou uma solução com gap baixo para os demais cenários deste grupo. Já no grupo com tamanho |CCC| = 16, a otimalidade foi alcançada dentro do limite de tempo estabelecido em apenas cinco dos 10 cenários. https://proceedings.science/p/193521?lang=pt-br DOI: 10.59254/sbpo-2024-193521 (a) Grupo com |CCC| = 12 - Cenário 8 (b) Grupo com |CCC| = 14 - Cenário 5 (c) Grupo com |CCC| = 16 - Cenário 4 Figura 2: Roteamento ótimo obtido de três cenários apresentados na Tabela 2 A Figura 2 mostra o roteamento ótimo obtido para três dos 50 cenários testados na cidade Belo Horizonte - MG. Os losangos marrons representam os locais de inundação, enquanto as arestas pretas indicam a rota ótima do drone para realizar a tarefa. A estrela verde marca o local de partida dos veículos, correspondendo à coordenada geográfica de uma unidade da defesa civil da cidade. Os pontos em azul marcam os locais onde o veículo terrestre deve parar para oferecer suporte. Cada um desses pontos representa uma localização na rede de trânsito da cidade próxima à coordenada do respectivo nó fictício gerado na solução. Por fim, os caminhos destacados em azul na rede de trânsito indicam o percurso que o veículo terrestre deve seguir durante a tarefa. 5. Conclusão O trabalho apresentou uma nova formulação MILP de dois níveis que integra drone e veículo terrestre em centros urbanos, especificamente em operações que utilizam drones para mo- nitorar regiões afetadas por inundações. Esta abordagem síncrona permite que os drones estendam sua capacidade de voo realizando trocas de baterias durante a operação. Ao explorar funcionalida- des de ferramentas de mapeamento, a nova proposta oferece uma forma dinâmica e flexível de gerar rotas ótimas, melhorando assim a eficiência das tarefas. Foram testados possíveis cenários de inundações na cidade de Belo Horizonte-MG. Os resultados computacionais mostram que a formulação MILP desenvolvida satisfaz as características do problema, definindo locais de suporte para o drone que não necessariamente correspondem à posições geográficas próximas aos locais de inundação. Além disso, os resultados demonstram que é possível resolver instâncias pequenas em tempo hábil. Conforme exposto, foi possível encontrar o ótimo global ou uma solução com baixo gap na maioria das instâncias testadas em um Solver exato. Também foi possível identificar os limites computacionais da formulação. Para o grupo de cenários com |CCC| = 16, o Solver não obteve solução viável dentro do tempo de 30 minutos em 50% dos testes. Diante disso, torna-se necessário explorar novas estratégias, como a adoção de Solvers que utilizam processamento paralelo, a clusterização dos locais de monitoramento para dividir o problema em instâncias menores, e o desenvolvimento de métodos heurísticos e/ou meta- heurísticos. Essas sugestões de trabalhos futuros se somam a adaptação da metodologia para outros contextos que demandem sincronismo entre veículos, ou mesmo para estabelecer sincronismo em mais de dois níveis. https://proceedings.science/p/193521?lang=pt-br DOI: 10.59254/sbpo-2024-193521 Agradecimentos Este trabalho foi realizado com o apoio da Coordenação de Aperfeiçoamento de Pessoal de Nível Superior - Brasil (CAPES) por meio do Programa de Excelência Acadêmica (PROEX)"
        },
        {
            "titulo": "EXPLORAÇÃO E OTIMIZAÇÃO DO PROBLEMA DOS MÚLTIPLOS CAIXEIROS VIAJANTES",
            "informacoes_url": "https://proceedings.science/p/193847?lang=en",
            "idioma": "português",
            "storage_key": "galoa-proceedings--sbpo-2024--193847.pdf",
            "autores": [
                {
                    "nome": "Helen Vitaline de Castro Santos",
                    "afiliacao": "Universidade Federal de Viçosa – Campus Rio Paranaíba",
                    "orcid": ""
                },
                {
                    "nome": "Laís Gonçalves Viana",
                    "afiliacao": "Universidade Federal de Viçosa – Campus Rio Paranaíba",
                    "orcid": ""
                },
                {
                    "nome": "Thiago Henrique Nogueira",
                    "afiliacao": "Universidade Federal de Viçosa – Campus Rio Paranaíba",
                    "orcid": ""
                },
                {
                    "nome": "Raiane Ribeiro Machado Gomes",
                    "afiliacao": "Universidade Federal de Viçosa – Campus Rio Paranaíba",
                    "orcid": ""
                },
                {
                    "nome": "Larissa Sousa Campos",
                    "afiliacao": "Universidade Federal de Viçosa – Campus Rio Paranaíba",
                    "orcid": ""
                }
            ],
            "data_publicacao": "",
            "resumo": "Este artigo explora o problema dos Múltiplos Caixeiros Viajantes (mTSP) através da comparação entre o modelo de otimização usando Colônia de Formigas e um projeto anterior que utilizou cinco heurísticas.",
            "keywords": [
                "Heurística",
                "Problema do Caixeiro Viajante Múltiplo",
                "Colônia de Formigas (ACO)"
            ],
            "referencias": [
                "BELL, John E.; MCMULLEN, Patrick R. Ant colony optimization techniques for the vehicle routing problem. Advanced engineering informatics, v. 18, n. 1, p. 41-48, 2004.",
                "BRAGA, Edgar Augusto Silva. Modelagem e otimização do problema do caixeiro viajante com restrições de tempo, distância e confiabilidade via algoritmos genéticos. 2007. Dissertação de Mestrado. Universidade Federal de Pernambuco.",
                "CARVALHO, M. B.; YAMAKAMI, A. Meta-heurística híbrida de sistema de colônia de formigas e algoritmo genético para o problema do caixeiro viajante. Trends in Computational and Applied Mathematics, v. 9, n. 1, p. 31-40, 2008.",
                "Colorni A, Dorigo M, Maniezzo V. Distributed Optimization by Ant Colonies. Proceedings of European Conference on Artificial Life. 1991; Paris, France. p. 134-142.",
                "CORMEN, Thomas H. et al. Algoritmos: teoria e prática. Editora Campus, v. 2, p. 296, 2002.",
                "CERQUEIRA, Fábio Ribeiro; CRAVO, Gildásio Lecchi. METAHEURÍSTICA COLÔNIA DE FORMIGAS APLICADA AO PROBLEMA DO CAIXEIRO VIAJANTE.",
                "DA CUNHA, Claudio Barbieri; DE OLIVEIRA BONASSER, Ulisses; ABRAHÃO, Fernando Teixeira Mendes. Experimentos computacionais com heurísticas de melhorias para o problema do caixeiro viajante. In: XVI Congresso da Anpet. 2002.",
                "DANTZIG, George; FULKERSON, Ray; JOHNSON, Selmer. Solution of a large-scale traveling-salesman problem. Journal of the operations research society of America, v. 2, n. 4, p. 393-410, 1954.",
                "JOHNSON, David S.; GAREY, Michael R. Computers and intractability: A guide to the theory of NP-completeness. WH Freeman, 1979.",
                "DORIGO, Marco; BIRATTARI, Mauro; STUTZLE, Thomas. Ant colony optimization. IEEE computational intelligence magazine, v. 1, n. 4, p. 28-39, 2006.",
                "GOLDBARG, Marco Cesar; LUNA, Henrique Pacca L. Otimização combinatória e programação linear: modelos e algoritmos. Elsevier, 2000.",
                "GONÇALVES, André Ricardo; BRUNETTO, Maria Angélica de Oliveira Camargo. Um novo modelo híbrido baseado em Otimização por Colônia de Formigas e Redes Neurais para identificação de indivíduos com DPOC. In: Anais do XI Congresso Brasileiro de Informática em Saúde. 2008.",
                "HELSGAUN, Keld. An effective implementation of the Lin–Kernighan traveling salesman heuristic. European journal of operational research, v. 126, n. 1, p. 106-130, 2000.",
                "KANDA, Jorge Yoshio. Sistema de meta-aprendizado para a seleção de meta-heurísticas para o problema do caixeiro viajante. In: Anais do X Simpósio Brasileiro de Sistemas de Informação. SBC, 2014. p. 651-662.",
                "KARP, Richard M. On the computational complexity of combinatorial problems. Networks, v. 5, n. 1, p. 45-68, 1975.",
                "LAPORTE, Gilbert et al. Classical and modern heuristics for the vehicle routing problem. International transactions in operational research, v. 7, n. 4‐5, p. 285-300, 2000.",
                "LIN, Shen; KERNIGHAN, Brian W. An effective heuristic algorithm for the traveling-salesman problem. Operations research, v. 21, n. 2, p. 498-516, 1973.",
                "MACAMBIRA, Ana Flávia Uzeda et al. Tópicos em otimização inteira. UFRJ, 2022.",
                "DORIGO, Marco; MANIEZZO, Vittorio; COLORNI, Alberto. Ant system: optimization by a colony of cooperating agents. IEEE transactions on systems, man, and cybernetics, part b (cybernetics), v. 26, n. 1, p. 29-41, 1996.",
                "REINELT, Gerhard. The traveling salesman: computational solutions for TSP applications. Springer, 2003.",
                "RODRIGUES, Samuel Bellido. Metaheurística Colônia de Formigas aplicada a um Problema de Roteamento de Veículos: caso da Itaipu Binacional. 2007.",
                "BEKTAS, Tolga. The multiple traveling salesman problem: an overview of formulations and solution procedures. omega, v. 34, n. 3, p. 209-219, 2006.",
                "I. Vallivaara. A team ant colony optimization algorithm for the multiple travelling salesmen problem with minmax objective. In Proceedings of the 27th IASTED International Conference on Modelling, Identification and Control, pages 387–392, Anaheim, CA, USA, 2008",
                "WHITLEY, Darrell; STARKWEATHER, Timothy; SHANER, Dan. The traveling salesman and sequence scheduling: Quality solutions using genetic edge recombination. Fort Collins: Colorado State University, Department of Computer Science, 1991."
            ],
            "artigo_completo": "EXPLORAÇÃO E OTIMIZAÇÃO DO PROBLEMA DOS MÚLTIPLOS CAIXEIROS VIAJANTES. RESUMO Este artigo explora o problema dos Múltiplos Caixeiros Viajantes (mTSP) através da comparação entre o modelo de otimização usando Colônia de Formigas e um projeto anterior que utilizou cinco heurísticas. O mTSP é uma variação do problema clássico do Caixeiro Viajante, onde n pontos devem ser visitados por um conjunto de m caixeiros, cada um apenas uma vez. Os algoritmos foram implementados em Python neste estudo, com o objetivo de identificar qual das seis metaheurísticas obteve a solução mais eficiente. PALAVRAS CHAVE. Heurística, Problema do Caixeiro Viajante Múltiplo, Colônia de Formigas (ACO). https://proceedings.science/p/193847?lang=en DOI: 10.59254/sbpo-2024-193847 1. Introdução Ter competências e habilidades para solucionar adversidades no ambiente de trabalho e na vida cotidiana é uma aptidão almejada por todos, mas esta não é uma tarefa simples. A sociedade busca inovar através de tecnologias e métodos que auxiliem na solução de obstáculos emergentes. Sendo assim, a todo momento, atribuições referentes a setores econômicos, transporte, logística, produção e entre outros, são resolvidas maximizando e minimizando os critérios concebidos. Onde são simbolizadas matematicamente por modelos de Otimização que reivindicam algoritmos e grafos em sua resolução computacional [MACAMBIRA, 2022]. Estudos de modelos de otimização aplicados à logística possibilitam a redução de custos envolvidos nesta área, além de promover uma melhoria significativa do nível de serviço, aumento da capacidade de cumprir prazos, competitividade e credibilidade das organizações [BRAGA 2007]. Segundo Cerqueira e Cravo [2006], tais estudos dizem respeito a problemas de otimização combinatória, envolvendo uma função objetivo a ser otimizada, sujeita a um conjunto de restrições. Exemplos desses problemas são o Problema do Caixeiro Viajante, o Problema da Mochila, Problema de Roteamento de Veículos e Programação de Horários. De acordo com Goldbarg e Luna [2000], o problema do Caixeiro Viajante (PCV), em inglês chamado de travelling salesman problem (TSP), é um dos problemas mais conhecidos e tradicionais da programação matemática, que lida com passeios em pontos de demanda, como cidades, postos de trabalho e depósitos. Apesar de ser facilmente compreendido, é um problema de difícil solução, já que é classificado como NP- Difíceis [KARP 1975]. O problema do Caixeiro Viajante (PCV) é reconhecido por apresentar uma elevada complexidade de solução devido ao grande número de soluções existentes em instâncias de médio e grande porte, segundo Garey e Johnson [1979]. Os autores também afirmam que um problema NP-difícil é comumente solucionado por meio de heurísticas, procedimentos estes que possibilitam a obtenção de uma ou mais soluções através de uma abordagem intuitiva que considera a estrutura específica do problema. Whitley et al. [1991] afirmam que o objetivo destes procedimentos é encontrar a melhor solução possível dentre as soluções viáveis, buscando maximizar ou minimizar uma função objetivo, enquanto satisfaz a todas as restrições estabelecidas pelo problema. O objetivo do estudo é utilizar uma heurística eficiente para o problema de mTSP e comparar seus resultados com algoritmos já existentes na literatura Sendo assim, este estudo terá como base de dados as informações do artigo publicado “Estudo Comparativo de Metaheurísticas Aplicadas ao Problema do Caixeiro Viajante Múltiplo” que envolve a mesma problemática. Sendo assim, o modelo utilizado será o Modelo de Otimização por Colônia de Formigas, para diferenciar dos demais aplicados e assim comparar os resultados das diferentes heurísticas manipuladas para a solução deste problema. Figura 1: Desenvolvimento do trabalho Fonte: autores [2023] 2. Referencial Teórico O Problema do Caixeiro Viajante Múltiplo representa vendedores que tem como propósito visitar n cidades por uma única vez, dando início em uma localização e retornando para o mesmo local de origem. Sendo assim, o objetivo do mTSP é encontrar o caminho mais curto com o menor custo, ou seja, minimizar o trajeto percorrido pelo viajante ou os custos envolvidos [DANTZIG 1954]. O mTSP é um problema NP-difícil, assim como o TSP clássico, e não existe um algoritmo conhecido que possa resolver o problema, ou seja, os métodos de solução aplicados a instâncias reais são, em geral, heurísticos, isto é, não asseguram a obtenção da solução ótima do https://proceedings.science/p/193847?lang=en DOI: 10.59254/sbpo-2024-193847 ponto de vista matemático [DA CUNHA 2002]. Sendo assim, de acordo com Helsgaun [2000] existem dois grupos de procedimentos heurísticos para solucionar o problema do caixeiro viajante múltiplo: os métodos de construção de roteiros e os métodos de melhoria de roteiros. Para o método de construção de roteiros as cidades serão alocadas gradualmente, seguindo regras de construção, em outros termos, as sequências parciais de cidades são definidas ao longo do algoritmo e, posteriormente, não são modificadas, seguindo um processo iterativo [DA CUNHA 2002]. Já o método de melhoria busca testar novas rotas refazendo conexões para melhorar o roteiro pré-estabelecido, com o intuito de diminuir a distância total percorrida [LIN e KERNIGHAN 1973]. Para a construção dos roteiros Laporte [2000] ressalta o método vizinho mais próximo e o método de inserção, já Reinelt [1994] exemplifica heurísticas baseadas em árvores de cobertura e o método do economista. Para a melhoria das rotas, Helsgaun [2000] traz a heurística de Lin e Kernighan [1973] sobre as melhorias do tipo k-opt, e Laporte [2000] aponta as metaheurísticas simulated annealing e busca tabu. Dessa forma, é entendível que existem diversas possibilidades para a resolução do problema do caixeiro viajante múltiplo. Dessa forma, a quantidade de operações necessárias para solucionar o problema e analisar todas as possibilidades é o que dita o nível de complexidade do algoritmo que será usado. Assim como no caso do PCVM, onde múltiplos caixeiros querem visitar n cidades, muitos outros problemas não podem ser solucionados através de algoritmos em tempo polinomial, sendo denominados como problemas computacionalmente intratáveis. Tais problemas são conhecidos como NP-difícil [GAREY e JOHNSON 1979]. Assim, pode-se afirmar que o PCVM também pertence à classe NP-Difícil, onde o uso de métodos exatos não se mostra uma opção viável. Neste contexto, a resolução para o PCVM proposta neste trabalho utiliza conceitos de meta-heurísticas [MESTREIA 2010]. Para Silva Drummond et al. [2000], uma excelente opção para a solução de problemas NP-Difíceis e NP-completos, na área de otimização combinatória, são as chamadas heurísticas inteligentes ou Meta-Heurísticas. Essas metodologias podem ser explicadas como sendo uma estrutura algorítmica geral, aplicável a variados problemas de otimização com poucas modificações que possam adaptá-las a um problema específico, [BRAGA 2007]. Kureuchicj, MiagKikh et al. [2001] ressaltam que a principal característica das Meta-heurísticas é a de possuírem mecanismos que buscam, em problemas de otimização, não ficar presos a ótimos locais, quando ainda estamos longe de um ótimo global. Segundo Kanda [2014], A Otimização por Colônia de Formigas (Ant Colony Optmization, ACO) está entre as principais meta-heurísticas usadas para o TSP. Ela tem alcançado resultados consistentes para problemas de otimização combinatória, recebendo esta denominação por ser baseada na maneira como colônias de formigas reais encontram rotas mais curtas até suas fontes de alimento, como mostram Dorigo et. Al. [1996]. A partir do primeiro algoritmo ACO, denominado Ant System, que obteve resultados encorajadores para o TSP, a ACO tem sido aplicada com sucesso para vários problemas NP-difíceis de otimização combinatória. Stutzle [2004] afirma que na ACO, as soluções são geradas num processo iterativo no qual agentes inteligentes, as formigas, percorrem todas as cidades de uma instância de TSP, por exemplo, escolhendo a cada iteração a próxima cidade de sua rota de maneira estocástica através da Regra de Transição de Estado (RTE). Para Rodrigues [2007], a solução para o problema tratado é um caminho de menor custo entre os estados do problema, respeitando suas restrições. A complexidade de cada formiga é tal que uma formiga sozinha poderia resolver o problema, mas, provavelmente, de forma ruim. Cormen et al. [2002], diz que as soluções de boa qualidade são obtidas somente como o resultado da cooperação global entre todos os agentes da colônia que criam soluções diferentes ao mesmo tempo. Os trabalhos relacionados mostram que o PRV ainda é um problema difícil de resolver na prática, pois os métodos existentes são muito complexos e pouco eficientes. Assim, existe uma necessidade de abordagens mais simples e mais eficazes para esse problema. Na literatura, https://proceedings.science/p/193847?lang=en DOI: 10.59254/sbpo-2024-193847 algoritmos que usam Colônia de Formigas (CF) [Dorigo et al. 1996] têm obtido bons resultados com baixo custo computacional para resolver variações do PRV [Bell; Mcmullen 2004; Tan, Zhuo e Zhang 2006; Yu, Yang e Yao 2009]. Logo, um algoritmo que usa Colônia de Formigas (CF) pode ser uma solução adequada para o PRV. Segundo Gonçalves [2008], o trabalho apresenta um modelo que usa a Otimização por Colônias de Formigas, que foi introduzida por Colorni et. al [1991]. Um dos principais desafios em usar os algoritmos ACO é a necessidade de transformar o problema em um problema de encontrar o menor caminho em grafos. Isso é necessário porque o ACO é baseado em um processo no qual um grupo de formigas procura o menor caminho entre o ninho e a fonte de comida [DORIGO 2006]. Para Carvalho [2008] diversos problemas combinatoriais são utilizados para a resolução de impasses logísticos, tais como, roteamento de veículos, Caixeiro Viajante, otimização de roteiros e entre outros. A partir disso o algoritmo ACO foi escolhido para determinar a solução ótima do PCV, sendo que os resultados obtidos serão comparados com outras heurísticas, a fim de inferir qual delas apresentará uma melhor resposta ao problema em questão. Dessa forma, esses estudos contribuíram para a formulação do modelo matemático e resolução do código para o Problema do Caixeiro Viajante. 3. Formulação Matemática do Problema Através da definição apresentada sobre o problema do caixeiro viajante múltiplo, tornou- se necessário articular o m-TSP através da formulação demonstrada por Bektas [2006]. Sendo assim, o problema pode ser descrito através de um grafo G=(V,A), na qual V={1,2,...,n} é o conjunto dos vértices que simbolizam as n cidades presentes no m-TSP e A o conjunto das arestas que representam as conexões entre os vértices. A cada aresta percorrida é associado um custo, que pode ser definido a partir de distâncias, despesas ou tempo. A representação pode ser representada da seguinte forma: cij - custo de um caixeiro viajar da cidade i ∈ V para cidade j ∈ V. Ainda, deve-se levar em consideração outras variáveis que influenciam diretamente a resolução do m-TSP, como o número de caixeiros, um conjunto para os vértices do grafo e as variáveis binárias. No qual seguem as seguintes simbologias: S: número de elementos do subconjunto dos vértices do grafo atribuídos para cada caixeiro; m: número de caixeiros viajantes; xij=1: se um caixeiro viaja da cidade i ∈ V para cidade j ∈ V; xij=0: se o caixeiro não viaja da cidade i ∈ V para cidade j ∈ V. Com todas as variáveis definidas, o modelo matemático pôde ser estruturado. Contendo a função objetivo (1), que garante a minimização da distância total percorrida por todos os caixeiros viajantes. Também, foram implementadas as restrições impostas pelo mTSP. 𝑀𝑖𝑛∑ ∑ ⬚ 𝑛  𝑗=1  𝐶𝑖𝑗 𝑋𝑖𝑗 ̇ 𝑛  𝑖=1  (1) ∑ 𝑋1𝑗 𝑛 𝑗∈𝑆 = 𝑚   (2) ∑ 𝑋𝑖1 𝑛 𝑖∈𝑆 = 𝑚   (3) https://proceedings.science/p/193847?lang=en DOI: 10.59254/sbpo-2024-193847 ∑ 𝑖𝑗 ∑𝑗∈𝑆 𝑋 𝑖∈𝑆   ≥1,    ∀ 𝑆  ⊆  ∨∖{1},  𝑆≠∅ (4) ∑ 𝑋𝑖𝑗  𝑛 𝑗=1  = 1,  𝑖= 2, … , 𝑛  (5) ∑ 𝑋𝑖𝑗  𝑛 𝑖=1  = 1,  𝑗= 2, … , 𝑛  (6) 𝑋𝑖𝑗  ∈ {0,1},  ∀ 𝑖,  𝑗∈∨ (7) A restrição 2 tem como função garantir que todos os m caixeiros saiam da cidade de origem, já a 3 certifica que os mesmos m viajantes retornem para a mesma cidade. Em outras palavras, existem m arestas vinculadas a cidade de partida que reproduzem as arestas de retorno dos caixeiros. A quarta (4) limitação imposta tem como objetivo assegurar a não formação de subconjuntos de cardinalidade S que não contenham no depósito, ou seja, os elementos serão delimitados apenas a quantidade presentes em S. Já as restrições 5, 6 e 7 correspondem às regras de atribuição presentes no m-TSP. 3.1 ACO A metaheurísticas escolhida para a resolução do problema do caixeiro viajante múltiplo foi a Colônia de Formigas (ACO). Na qual, Stutzle [2004] afirma que, as soluções são geradas num processo iterativo no qual agentes inteligentes, as formigas, percorrem todas as cidades de uma instância de TSP, por exemplo, escolhendo a cada iteração a próxima cidade de sua rota de maneira estocástica através da Regra de Transição de Estado (RTE). A RTE do Ant System é mostrada na equação a seguir: 𝑝𝑖𝑗 𝑘(𝑡) = ├0 [𝜏𝑖𝑗(𝑡)]𝛼[𝜂𝑖𝑗] 𝛽 ∑[𝜏𝑖𝑗(𝑡)]𝛼[𝜂𝑖𝑗]𝛽    , onde j é uma aresta permitida à k caso contrário Equação 1: RTE do Ant System A equação, que determina a probabilidade de um vértice i ser escolhido por uma formiga representa o vértice no qual a formiga k se encontra, e j um dos possíveis vértices para o qual ela pode se deslocar. Os vértices permitidos à formiga são aqueles ainda não visitados até a fase atual da construção da solução. Cada formiga armazena os nós já visitados em sua memória, que é denominada como lista tabu. τij (t) corresponde à quantidade de feromônio presente na aresta entre os vértices i e j no instante t. ηij corresponde à visibilidade da aresta, que ́é definida pelo valor 1/cij, onde cij é o custo de deslocamento da aresta. α e β são parâmetros que definem o peso da trilha de feromônio e da visibilidade, respectivamente, na escolha do próximo vértice pela formiga. • A ALF (regra de Atualização Local de Feromônio) A ALF (regra de Atualização Local de Feromônio) é definida pela equação 2, onde ξ é um parâmetro com o melhor valor experimentalmente calculado como ξ = ρ = 0,1. Já τ0 é outro parâmetro que é utilizado tanto na atualização local de feromônio quanto na quantidade inicial de feromônio depositada em todas as arestas no início da execução do algoritmo. O melhor valor para τ0 é calculado com base no custo de uma solução gerada aplicando o algoritmo do vizinho mais próximo à instância em análise, pode ser calculada na equação 3, onde n é o número de cidades na https://proceedings.science/p/193847?lang=en DOI: 10.59254/sbpo-2024-193847 instância e Cnn é o custo da solução obtida utilizando o algoritmo do vizinho mais próximo na instância. 𝜏𝑖𝑗=  (1 −𝜉)𝜏𝑖𝑗⬚+ 𝜉𝜏0 Equação ALF (2) 𝜏0 = 1/𝑛𝐶𝑛𝑛 Equação (3) • TACO (Team Ant Colony Optimization, Otimização por Colônia com Equipes de Formigas) O TACO (Team Ant Colony Optimization, Otimização por Colônia com Equipes de Formigas) é um algoritmo desenvolvido por [Vallivaara 2008] que adapta o ACS para instâncias de MTSP. Em vez de usar formigas individuais para gerar soluções para o TSP, o TACO utiliza equipes de formigas compostas por m elementos, onde cada formiga representa um caixeiro na construção de uma solução para o MTSP, e cada equipe tem sua própria lista tabu. No início da construção da solução, todas as formigas de todas as equipes são colocadas no depósito. Para distribuir a carga de trabalho, a formiga com a menor rota parcial, em qualquer momento da construção da solução, escolhe sua próxima cidade. Embora seja eficiente na distribuição da carga de trabalho, muitas vezes as escolhas das formigas resultam em soluções sub- ótimas. Para lidar com esse problema, a cada escolha é verificado se ceder a cidade escolhida para qualquer outra formiga da equipe resultaria em uma solução total menor, considerando também o retorno ao depósito. Se for o caso, a formiga com a menor rota parcial se move e pode fazer uma nova escolha para o próximo vértice. Matematicamente, considerando uma formiga k na posição do vértice Vk, onde Vo representa o depósito da instância, C(Vi, Vj) é o custo de deslocamento entre dois vértices quaisquer Bi e Vj, CP(k) é o custo parcial total da rota já percorrida pela formiga k, e Vj é o vértice escolhido como o próximo. O método verifica, antes da formiga se mover, se existe qualquer outra formiga l da instância em que: 𝐶(𝑉𝑙, 𝑉𝑗) + 𝐶(𝑉𝑗, 𝑉0) + 𝐶𝑃(𝑙)  < 𝐶(𝑉𝑘, 𝑉𝑗) + 𝐶(𝑉𝑗, 𝑉0) + 𝐶𝑃(𝑘)  Equação (4) Caso haja, permite-se então que a formiga l escolha, o próximo e novo vértice, se movimentando para o mesmo. No processo de otimização das instâncias do problema MSPT, é utilizada a técnica de busca local 2-opt, que consiste em trocar duas arestas na solução, sendo aplicada a todas as soluções geradas. Além disso, a busca local 3-opt é aplicada apenas à melhor solução obtida entre as N soluções geradas pelos times, com o objetivo de comutar três arestas simultaneamente. Para implementar essa abordagem, foi desenvolvido um protótipo baseado em uma variação do TACO de Vallivaara [2008], que é descrito em detalhes a seguir. Tabela 1: Pseudocódigo https://proceedings.science/p/193847?lang=en DOI: 10.59254/sbpo-2024-193847 Fonte: Autores [2023] • Inicialização As instâncias de MTSP e os parâmetros utilizados neste problema, são as entradas do algoritmo ACO. A instância é definida pela variação de contexto aos quais o problema será resolvido, sendo estes os números de caixeiros (m) e cidades, ou clientes, a serem atendidos (n). O retorno deste modelo é a melhor solução de MTSP, sendo usado apenas um único depósito, ao qual os caixeiros devem sair e retornar. O Algoritmo ACO se inicializa declarando as principais variáveis. Estas estão presentes na linha 2 e 4 onde são declarados, de acordo com as instâncias, o valor inteiro n de cidades, e m de caixeiros, onde V0 equivale ao depósito em cada ciclo do algoritmo. De forma ilustrativa, N representa o número de formigas que criam, de forma simultâneas, soluções para o problema. As soluções são criadas de forma sequencial, e quando se atinge o critério de paradas, encerra-se o ciclo. O objetivo do MTSP é estabelecido na linha 6, que neste caso é minimizar o custo total da solução. https://proceedings.science/p/193847?lang=en DOI: 10.59254/sbpo-2024-193847 Na linha 7 é construída a matriz de custos da instância. É utilizado custos previstos, a fim de melhor representar o ambiente real. É por estes e outros pormenores que a matriz assume um caráter assimétrico e todos os custos terão que ser fornecidos para sua confecção. Logo o custo de deslocamento entre dois pontos pode ser diferente dependendo do sentido. Na linha 8, é inicializada a matriz de feromônio, ocorrendo com que todas as arestas recebem a mesma quantidade deste, indicando que informações sobre as instâncias são inexistentes até o momento. Na linha 9, dá-se início aos ciclos do algoritmo, onde os mesmos são limitados pelo critério de parada. Usar diferentes critérios de parada será uma possibilidade útil em experimentos futuros, permitindo identificar qual é o mais adequado para cada algoritmo desenvolvido. • Construção das soluções Iniciam-se a construção das soluções na linha 10. Já na linha 11, times de m formigas são criados, sendo cada uma a representação de cada caixeiro, onde apenas um time constrói uma solução de cada vez. Em uma lista tabu comum são armazenadas as cidades já visitadas pelos caixeiros durante a construção da solução, onde são esvaziadas na linha 12, estabelecendo que todas as cidades ainda possuem chances de serem exploradas. Por fim, na linha 13, todas as formigas são alocadas ao depósito, de onde partirão para mais uma rota. Os movimentos são inicializados na linha 14, onde as formigas viajam de sua cidade atual para a próxima da rota. Na linha 15, pode-se notar que a formiga escolhida para movimentar é aquela que possui a rota parcial com o menor custo, sendo este método aplicado por Vallivaara [2008]. Em caso de empate, a escolha será feita de forma aleatória, selecionando a formiga que possui o menor número de identificação no protótipo. Este método é eficaz para o minmax MTSP, pois busca equilibrar o custo das rotas durante o período de escolha formiga que inicializará o movimento. Após a seleção da formiga, há a criação da lista, como mostra a linha 16, composta pelas Clsize cidades que estão em locais mais próximos da formiga selecionada. Com finalidade de restringir o espaço de busca das arestas que conferem uma melhor solução, a lista de candidatos também busca reduzir o tempo computacional. Em seguida, a linha 17 corresponde à Regra de Transição de Espaço (RTE) da ACO, ou seja, quando a formiga escolhe a próxima cidade de sua rota a ser visitada. É realizada, após a escolha da próxima cidade da formiga selecionada, uma verificação que precede a inicialização do movimento, como ressaltado na linha 18. Como as escolhas das formigas podem tender a soluções não ótimas, de acordo com o menor custo de sua rota, essa verificação torna-se imprescindível. A fim de tratar este problema, faz-se uma verificação a cada ação da formiga se, caso a cidade escolhida fosse atribuída a qualquer outra formiga, não ocasionaria em um menor deslocamento que o da formiga selecionada, levando-se em consideração também o retorno à origem (depósito). Na linha 20, a formiga que resulta no menor caminho é escolhida, mas não se move de forma obrigatória para a cidade que a formiga anterior escolheu, sendo refeita para a posição de nova formiga, a lista de candidatos. Logo, na linha 21 e 22, a RTE é executada novamente, possibilitando a escolha de uma nova cidade. Na linha 24 há a inclusão da cidade na rota da formiga que a escolheu, posteriormente a posição dessa formiga é atualizada. Há também a inclusão da cidade visitada na lista tabu, como mostra a linha 25. Desta forma a cidade não pode ser selecionada novamente durante a construção da solução atual. Já na linha 26, ocorre a atualização do feromônio. Todo esse processo, que abrange a linha 15 à linha 26, é repetido até que não haja mais cidades a serem visitadas. 4. Resultados O código do algoritmo foi testado utilizando dois computadores, sendo o primeiro, um notebook Dell Vostro, com um processador Intel Core i7-7500 CPU @ 2.90 GHz e memória ram de 16 GB. Já o segundo dispositivo consiste em um computador ASUS com um processador https://proceedings.science/p/193847?lang=en DOI: 10.59254/sbpo-2024-193847 Intel(R) Core(TM) i5-1035G1 CPU @ 1.20 GHz e uma memória RAM de 6 GB. O código foi redigido em Python e usa bibliotecas, tais como random e math para gerar números aleatórios e realizar operações matemáticas Por se tratar de um estudo comparativo com um trabalho já publicado, a obtenção dos resultados para este artigo em questão seguiu etapas similares às do artigo defrontado. Neste, foi testado metaheurísticas diferentes para a resolução do problema do caixeiro viajante. Outro aspecto importante deste estudo é que, assim como o trabalho base, as metaheurísticas foram todas executadas utilizando o mesmo tempo computacional estabelecido em He e Hao [2022]: (n/100) × 240 segundos. Dessa forma, se o critério de parada de uma metaheurísticas for alcançado antes do limite de tempo máximo, o método é reiniciado. No trabalho base, os métodos BRKGA e ILS foram os que apresentaram os melhores resultados no estudo, conforme destacado no trabalho de referência. Por outro lado, o método LNS obteve os piores resultados. Em um total de 11 instâncias avaliadas, o BRKGA alcançou um RPD igual a zero em todas as instâncias, enquanto o ILS obteve um RPD igual a zero em 7 das instâncias analisadas Para início de análise, vale ressaltar que a designação das instâncias foi feita seguindo o padrão mstp n_K. Onde n é o número de clientes e k o número de caixeiros. No total foram realizados testes em 3 instâncias, cenários diferentes, onde houve uma variação do número de caixeiros, sendo estes compreendidos em 3, 5 e 10. Vale ressaltar que os dados de entrada foram os mesmos utilizados pelo estudo defrontado, ressaltando algumas exceções. Já para o número de clientes foi fixado um valor igual a 51. Foram utilizadas 1000 interações para a metaheurísticas Colônia de Formigas (ACO). Para cada uma das 3 instâncias, executou-se 10 vezes o algoritmo. Sendo os valores obtidos para a função, apresentados na tabela 1. Os resultados foram analiticamente observados e comparados com os valores da função objetivo (FO), e os valores ótimos oriundos das funções das metaheurísticas utilizadas pelo artigo defrontado. Tabela 1: Resultados Fonte: Autores [2023] Figura 2: Gráfico de Melhoria Fonte: Autores [2023] https://proceedings.science/p/193847?lang=en DOI: 10.59254/sbpo-2024-193847 Ao analisar a tabela, pode-se dizer que os valores obtidos a partir da ACO, apresentou resultado significativamente melhor em uma das três instâncias analisadas. Essa solução corresponde à instância mstp 51_3, ou seja, 3 caixeiros viajantes atendendo a uma demanda de 51 cidades, com valor de custo minimizado igual a 436. Se a compararmos às soluções trazidas pelas melhores metaheurísticas ressaltadas pelos estudo Vieira, sendo estas o BRKGA e a ILSR. Nota- se que esta solução é a melhor obtida em todo o estudo comparativo, contemplando à ACO um lugar de destaque entre os demais métodos. Outro ponto a se analisar são os dados obtidos pela Figura 2, onde, é possível entender que a heurística ACO não é a melhor para a resolução do problema do caixeiro viajante múltiplo. Isso pode ser explicado devido à complexidade do mTSP, que apresenta um grande número de soluções a cada instância adicionada. Sendo assim, a ACO apresenta dificuldades em explorar todas as opções, dessa forma, essa metaheurísticas pode gerar resultados piores em comparação a outras heurísticas. Devido ao baixo número de instâncias e a pouca exploração de cenários variados, dificultou-se identificar um padrão de comportamento bem definido para a heurística ACO. Em termos de estudo comparativo, a ACO obteve a melhor solução para a função ótima, sendo igual a 436. Porém apresentou resultados piores que os demais métodos em cerca 85 por cento das instâncias analisadas. Deste modo, pode ser conferido ao método, um posicionamento de eficiência equivalente aos métodos BRKGA e a ILSR. 5. Conclusão Neste artigo, foi abordado o problema dos caixeiros viajantes múltiplos (mTSP), e foram comparados alguns métodos de solução baseados em metaheurísticas, com o objetivo de encontrar boas soluções para esse problema. Para realizar essa análise, um conjunto de 7 instâncias com diferentes cenários de mTSP foi testado, e os resultados mostraram que o algoritmo ACO obteve os melhores resultados, se comparados às metaheurísticas trabalhadas por Alves et. Al. [1995], sendo ela BRKGA, ILS, VNS, LNS e GRASP com instâncias menores. Embora os resultados obtidos neste estudo não tenham superado os resultados da literatura [He e Hao 2022], houve uma taxa aparentemente considerável de instâncias em que o resultado na ACO foi sorrateiramente pior que os dos métodos dos outros trabalhos. Entretanto, os resultados são úteis para entender como as metaheurísticas podem ser aplicadas para encontrar boas soluções em problemas desafiadores, como é o caso do mTSP. Além disso, esses resultados permitem avaliar como diferentes estratégias de diversificação e intensificação podem melhorar ou piorar cada técnica, dependendo do contexto. Para trabalhos futuros, é necessário planejar e aprimorar os métodos desenvolvidos, além disso, deve-se investigar novas técnicas, com o objetivo de obter soluções mais próximas ao estado da arte da literatura em relação ao mTSP. Novas melhorias podem elevar o potencial dos resultados gerando conclusões mais promissoras para o problema do caixeiro viajante múltiplo."
        },
        {
            "titulo": "UM MODELO EXATO PARA UM PROBLEMA DO ROTEAMENTO DE VEÍCULOS COM LOCKERS",
            "informacoes_url": "https://proceedings.science/p/193811?lang=pt-br",
            "idioma": "português",
            "storage_key": "galoa-proceedings--sbpo-2024--193811.pdf",
            "autores": [
                {
                    "nome": "Bruno Davi Mattos de Oliveira",
                    "afiliacao": "Programa de Pós-Graduação em Engenharia de Produção - Universidade Federal Fluminense",
                    "orcid": ""
                },
                {
                    "nome": "Marcos Roboredo",
                    "afiliacao": "Departamento de Engenharia de Produção - Universidade Federal Fluminense",
                    "orcid": ""
                },
                {
                    "nome": "Diogo Lima",
                    "afiliacao": "Departamento de Engenharia de Produção - Universidade Federal Fluminense",
                    "orcid": ""
                },
                {
                    "nome": "Artur Pessoa",
                    "afiliacao": "Departamento de Engenharia de Produção - Universidade Federal Fluminense",
                    "orcid": ""
                },
                {
                    "nome": "Eduardo Uchoa",
                    "afiliacao": "Departamento de Engenharia de Produção - Universidade Federal Fluminense",
                    "orcid": ""
                }
            ],
            "data_publicacao": "",
            "resumo": "Os Problemas de Roteamento de Veículos com Lockers (PRVL) envolvem estruturas de armazenamento de produtos localizadas estrategicamente para receber demandas de diferentes clientes. Clientes atribuídos a lockers devem se locomover até o local atribuído, gerando um custo de atribuição. O objetivo é, assim, definir rotas e atribuições de modo que todo cliente seja atendido diretamente ou atribuído a algum locker visitado, visando minimizar a soma dos custos de travessia e atribuição.",
            "keywords": [
                "Roteamento de veículos",
                "Lockers",
                "Janelas de tempo",
                "Branch-cut-and-price"
            ],
            "referencias": [
                "Boschetti, M. A. e Novellani, S. (2024). Last-mile delivery with drone and lockers. Networks, 83(2):213–235.",
                "Buzzega, G. e Novellani, S. (2023). Last mile deliveries with lockers: Formulations and algorithms. Soft Computing, 27(18):12843–12861.",
                "Costa, L., Contardo, C., e Desaulniers, G. (2019). Exact branch-price-and-cut algorithms for vehicle routing. Transportation Science, 53(4):946–985.",
                "Dantzig, G. B. e Ramser, J. H. (1959). The truck dispatching problem. Management science, 6(1):80–91.",
                "Dell’Amico, M., Montemanni, R., e Novellani, S. (2023). Pickup and delivery with lockers. Transportation Research Part C: Emerging Technologies, 148:104022.",
                "Dumas, Y., Desrosiers, J., Gelinas, E., e Solomon, M. M. (1995). An optimal algorithm for the traveling salesman problem with time windows. Operations research, 43(2):367–371.",
                "Gendreau, M., Hertz, A., Laporte, G., e Stan, M. (1998). A generalized insertion heuristic for the traveling salesman problem with time windows. Operations Research, 46(3):330–335.",
                "Grabenschweiger, J., Doerner, K. F., Hartl, R. F., e Savelsbergh, M. W. (2021). The vehicle routing problem with heterogeneous locker boxes. Central European Journal of Operations Research, 29:113–142.",
                "Jiang, L., Dhiaf, M., Dong, J., Liang, C., e Zhao, S. (2020). A traveling salesman problem with time windows for the last mile delivery in online shopping. International Journal of Production Research, 58(16):5077–5088.",
                "Pessoa, A., Sadykov, R., Uchoa, E., e Vanderbeck, F. (2020). A generic exact solver for vehicle routing and related problems. Mathematical Programming, 183:483–523.",
                "Praxedes, R., Bulhões, T., Subramanian, A., e Uchoa, E. (2024). A unified exact approach for a broad class of vehicle routing problems with simultaneous pickup and delivery. Computers & Operations Research, 162:106467.",
                "Roboredo, M., Sadykov, R., e Uchoa, E. (2023). Solving vehicle routing problems with intermediate stops using vrpsolver models. Networks, 81(3):399–416.",
                "Soares, V. C. e Roboredo, M. (2023). On the exact solution of the multi-depot open vehicle routing problem. Optimization Letters, p. 1–17.",
                "Tilk, C., Olkis, K., e Irnich, S. (2021). The last-mile vehicle routing problem with delivery options. OR Spectrum, 43(4):877–904.",
                "Vincent, F. Y., Susanto, H., Jodiawan, P., Ho, T.-W., Lin, S.-W., e Huang, Y.-T. (2022). A simulated annealing algorithm for the vehicle routing problem with parcel lockers. IEEE Access, 10:20764–20782."
            ],
            "artigo_completo": "UM MODELO EXATO PARA UM PROBLEMA DO ROTEAMENTO DE VEÍCULOS COM LOCKERS. RESUMO Os Problemas de Roteamento de Veículos com Lockers (PRVL) envolvem estruturas de armazenamento de produtos localizadas estrategicamente para receber demandas de diferentes clientes. Clientes atribuídos a lockers devem se locomover até o local atribuído, gerando um custo de atribuição. O objetivo é, assim, definir rotas e atribuições de modo que todo cliente seja aten- dido diretamente ou atribuído a algum locker visitado, visando minimizar a soma dos custos de travessia e atribuição. Este estudo examina uma variante que inclui janelas de tempo, capacidades nos veículos e nos lockers, e a limitação de uma única visita a cada locker. Para resolvermos o problema de forma exata, propomos um algoritmo de Branch-and-Cut-and-Price utilizando o fra- mework VRPSolver. Experimentos computacionais demonstram a robustez do procedimento, que supera o melhor método exato da literatura e obtém a solução ótima de diversas instâncias com até 60 clientes pela primeira vez. PALAVRAS CHAVE. Roteamento de veículos, Lockers, Janelas de tempo, Branch-cut-and- price Tópicos (Otimização Combinatória, Logística e Transportes) https://proceedings.science/p/193811?lang=pt-br DOI: 10.59254/sbpo-2024-193811 1. Introdução Desde Dantzig e Ramser [1959], os Problemas de Roteamento de Veículos (PVRs), originalmente chamados de Vehicle Routing Problems (VRPs), têm se destacado entre as aplicações práticas da Pesquisa Operacional, envolvendo vários desafios nas atividades diárias das organizações. Frequentemente, características práticas de problemas de roteamento são incorpora- das aos modelos de forma que estes abordem aspectos reais enfrentados por gerentes e tomadores de decisão. Por exemplo, problemas específicos de roteamento incluem frotas heterogêneas, janelas de tempo, seleção de hotéis e paradas para reabastecimento de veículos. Uma classe de PRVs que vem chamando a atenção de pesquisadores nos últimos anos é aquela que envolve os chamados lockers, que são estruturas especiais, localizadas estrategicamente, onde as demandas de diferentes clientes são armazenadas. Os clientes então se deslocam até o locker onde sua demanda foi armazenada para a sua retirada, o que gera um custo de atribuição. Assim, nos PRVs com lockers, deve-se definir as rotas de cada veículo, bem como decidir quais clientes são diretamente atendidos e quais são atribuídos a algum locker de modo que o custo de travessia somado ao custo de atribuição seja o menor possível. Dentre os trabalhos que focam em PRVs, destacam-se os propostos por Grabenschweiger et al. [2021], Vincent et al. [2022], Buzzega e Novellani [2023], Dell’Amico et al. [2023] e Boschetti e Novellani [2024]. Neste estudo, focamos na variante PRV com lockers proposta por Buzzega e Novellani [2023], que possui as seguintes características: a demanda de cada cliente pode ser atendida direta- mente na casa do cliente ou ser armazenada em algum locker visitado próximo ao cliente; tanto os veículos quanto os lockers possuem capacidades; e cada locker só pode ser visitado por no máximo um veículo. Os autores consideraram duas variantes, com e sem janelas de tempo nos vértices, aqui referidas respectivamente como PRVLJT e PRVL. Para resolver o problema de forma exata, Buzzega e Novellani [2023] propuseram formulações de Programação Linear Inteira Mista (PLIM). Conforme destacado por Costa et al. [2019], dentre as formas de resolver PRVs de maneira exata, destaca-se os algoritmos Branch-Cut-and-Price (BCP). Infelizmente, a implementação de um algoritmo BCP com componentes estado-da-arte para um VRP específico requer muito tempo, mesmo para uma equipe habilidosa. Para mitigar esse problema, Pessoa et al. [2020] propuse- ram o framework VRPSolver, capaz de gerar um algoritmo BCP para resolver um VRP específico baseado na modelagem fornecida pelo usuário. Um modelo VRPSolver contém uma formulação PLIM que inclui variáveis representando rotas viáveis. O conjunto de rotas viáveis é modelado por um conjunto de caminhos com restrições de recursos em um ou vários grafos direcionados. O VRPSolver resolve o modelo usando um algoritmo BCP genérico que gera variáveis de caminho dinamicamente, resolvendo os subproblemas de pricing. Estes são modelados no framework como problemas do caminho mais curto com restrições de recurso. Além da formulação PLIM e dos gra- fos direcionados, o usuário também pode definir os chamados packing sets, que permitem ao usuário ativar alguns componentes estado-da-arte para algoritmos BCP, tais como NG paths, geração de cor- tes de capacidade arredondados e de cortes de rank-1 com memória limitada, enumeração de rotas, entre outras. Algoritmos BCP gerados com auxílio do VRPSolver são competitivos ou até mesmo considerados o estado-da-arte para diversos PRVs [Roboredo et al., 2023; Soares e Roboredo, 2023; Praxedes et al., 2024]. Este trabalho propõe um algoritmo BCP exato para o PRVLJT e PRVL gerado a partir do VRPSolver. Como sua principal característica, a modelagem proposta não considera todas as possi- bilidades de atribuição no subproblema de pricing. Ao invés disso, considera-se no subproblema de pricing qual a demanda total atribuída a um locker, mas a decisão de quais clientes são efetivamente alocados é tomada no problema mestre. Para demonstrar a robustez do método proposto, apresen- tamos diversos experimentos computacionais nas 60 instâncias com até 60 clientes também usadas https://proceedings.science/p/193811?lang=pt-br DOI: 10.59254/sbpo-2024-193811 por Buzzega e Novellani [2023]. Resultados mostram que o método proposto supera a literatura, uma vez que apresenta tempo computacional menor para todas as instâncias e resolve diversas des- tas até otimalidade pela primeira vez. Apresentamos ainda o custo ótimo de todas as 60 instâncias em tempos computacionais razoáveis. 2. O Problema O PRVLJT é definido sobre um grafo não dirigido completo G = (V, E), onde o conjunto de vértices V é particionado em V = {0} ∪VC ∪VL; onde 0 indica o depósito, VC = {1, 2, ..., n} representa um conjunto de n clientes e VL = {n+1, n+2, ..., n+m} representa um conjunto de m lockers disponíveis. Cada vértice i ∈V está associado a uma janela de tempo [ai, bi]. Cada cliente i ∈VC está associado a uma demanda positiva di e, para cada aresta e ∈E, está associado um custo e a um tempo de travessia positivos, denotados por ce e te, respectivamente. Para o atendimento dos clientes, existe uma frota não limitada de veículos homogêneos, onde cada um destes está associado a uma capacidade positiva Q. Para ser atendido, cada cliente i ∈VC pode ser visitado diretamente por uma das rotas, ou pode ser atribuído a algum locker l ∈VL visitado por alguma das rotas, o que gera um custo de atribuição c′ il. Cada locker l ∈VL possui uma capacidade de atendimento, νl, e um raio de cobertura, Rl. Seja γl o conjunto de clientes que podem ser atendidos pelo locker l ∈VL. O objetivo é definir rotas que começam e terminam no depósito, bem como definir atribuições de clientes a lockers de modo a respeitar as seguintes restrições: • Todo cliente i ∈VC deve ser diretamente visitado por uma das rotas ou deve ser atribuído a algum locker l ∈Vl visitado por uma das rotas tal que c(i,l) ≤Rl. • Nenhum locker pode ser visitado mais de uma vez mesmo que por veículos diferentes. • O número de clientes atribuídos a um locker l ∈VL não excede νl. • Para cada veículo, a soma das demandas dos clientes visitados diretamente por ele com a soma das demandas dos clientes atribuídos a lockers visitados por ele não pode ultrapassar a capacidade Q. • Um vértice i ∈V só pode ser visitado dentro da sua janela de tempo [ai, bi], incluindo o depósito. Tal imposição não é considerada na versão do problema sem janelas de tempo (VRPL). As decisões de roteamento e atribuição são feitas de modo a minimizar a soma do custo total de travessia com o custo total de atribuição. Para exemplificar a situação descrita acima, considere o Exemplo Ilustrativo 1, com n = 4, m = 2, Q = 3, ν5 = ν6 = 2. Considere que os raios dos lockers são definidos de tal forma que γ5 = {1, 2} e γ6 = {2, 3}. Além disso, considere que as demandas são unitárias. Na Figura 1, onde clientes são representados por círculos e lockers por triângulos, ilustra-se uma instância com essas características e três exemplos de soluções viáveis: Sol1 = {Rotas:{(0 → 1 →2 →0), (0 →4 →3 →0)}; Atribuições:∅}, Sol2 = {Rotas:{(0 →5 →0), (0 → 4 →3 →0)}; Atribuições:{(1, 5), (2, 5)}} e Sol3 = {Rotas:{(0 →4 →0), (0 →5 → 6 →0)}; Atribuições:{(1, 5), (2, 6), (3, 6)}}. Perceba que enquanto a primeira solução não realiza atribuições e constrói duas rotas que utilizam duas unidades de capacidade. No segundo exem- plo, uma das rotas visita o locker 5 para o qual são designados os atendimentos dos clientes 1 e 2. Destaca-se que esta rota, apesar de visitar apenas um locker, também consome duas unidades de capacidade do veículo (dois clientes são atendidos). No terceiro exemplo, uma das rotas visita https://proceedings.science/p/193811?lang=pt-br DOI: 10.59254/sbpo-2024-193811 apenas o cliente 4 e retorna ao depósito enquanto a outra rota visita os dois armários e consumiu as três unidades de capacidade do veículo. Percebe-se também que é inviável atender todos os clientes com um único veículo uma vez que excederia-se a restrição de capacidade. 0 1 2 3 4 5 6 0 1 2 3 4 5 6 0 1 2 3 4 5 6 Figura 1: Ilustração do grafo para o exemplo ilustrativo. 3. Modelo VRPSolver proposto para o PRVL Um modelo VRPSolver consiste em um modelo PLIM que também inclui variáveis de caminho em um ou mais grafos direcionados definidos pelo usuário. O problema é resolvido por meio de um algoritmo genérico BCP onde as variáveis de caminho são geradas sob demanda através da resolução dos subproblemas de pricing, modelados como Problemas de Caminho Mais Curto com Restrição de Recursos (RCSPP). As Seções 3.1 e 3.2 apresentam, respectivamente, o grafo gerador de caminhos e a formulação que compõem o modelo VRPSolver proposto para o PRVLJT. 3.1. Grafo gerador de caminhos Seja G′ = (V ′, A) o grafo gerador de caminhos restritos em recursos definido para o subproblema do RCSPP, e sejam vso e vsi vértices desse grafo que representam respectivamente a fonte (source, nó inicial) e o semidouro (sink, nó final) dos caminhos. O conjunto de vértices é dado por V ′ = {vso, vsi} ∪{vi|i ∈V \\ {0}} ∪{¯vl|l ∈VL} e A = A1 ∪A2 ∪A3 ∪A4 ∪A5, onde: • A1 = {(vso, vi), (vso, vl), (vi, vsi), (¯vl, vsi), | i ∈VC, l ∈VL} • A2 = {(vi, vj), (vj, vi) | i, j ∈VC, i ̸= j} • A3 = {(vi, vl) | i ∈VC, l ∈VL} • A4 = {(¯vl, vi), | l ∈VL, i ∈V \\ vl} • A5 = {(vl, ¯vl, k) | l ∈VL, k = 1, ..., Q} A ideia por trás do grafo é que, cada rota viável do PRVLJT possa ser representada por um caminho em G′ começando em vso e terminando em vsi. Assim, estes vértices representem o depósito respectivamente no início e no fim da rota, vi, com i ∈VC representam o clientes i, e vl e ¯vl, com l ∈VL representam o locker l na entrada e na saída dos veículos, respectivamente. Assim, o conjunto de arcos de A1 representam as possíveis chegadas e saídas no depósito, os arcos A2 representam conexões entre clientes, os arcos de A3 e A4 representem respectivamente a chegada e saída nos lockers. O conjunto de arcos A5 representam conexões paralelas entre um vértice que represente a entrada em um locker l (vl) e um vértice que represente a sua saída (¯vl), que são diferenciados por um terceiro índice k, k ∈{1, ..., Q}. O objetivo é que, quando um arco (vl, ¯vl, k) https://proceedings.science/p/193811?lang=pt-br DOI: 10.59254/sbpo-2024-193811 é percorrido, isso indique que o locker está sendo visitado e uma demanda total de k vai ser atribuída no mesmo. Para se garantir que os caminhos estejam associados a rotas que respeitem a capacidade do veículo e as janelas de tempo dos vértices, são criados dois recursos 1 e 2, onde cada arco a = (i, j) ∈A esteja associado aos seguintes consumos q1 a e q2 a dos recursos 1 e 2, respectivamente, da seguinte maneira: q1 a =      dj se a = (i, vj) , i ∈V ′, j ∈VC k se a = (vl, ¯vl, k) , l ∈VL 0, caso contrário. q2 a = ( ta se a ∈A \\ A5 0 se a ∈A5 Seja p um caminho sobre o grafo G′ começando e terminando nos vértices vso e vsi, respectivamente. Seja ainda um vértice j ∈V ′ qualquer que é visitado no caminho p. Denotamos o consumo acumulado dos recursos 1 e 2 no caminho p ao visitar o vértice j como respectivamente S1 j,p e S2 j,p e definimos o seu cálculo da seguinte maneira. S1 j,p = S2 j,p = 0 quando j = vso. Para o caso de j ̸= vso, seja (i, j) o arco de incidência em j no caminho p. Para recurso 1, definimos S1 j,p = S1 i,p + q1 (i,j). Já para o recurso 2, definimos S2 j,p = max{S2 i,p + q2 (i,j), a(j)}, onde a(j) representa o início da janela de tempo do vértice no grafo original G representado pelo vértice j. Dizemos que p em G′ é viável se S1 j,p ≤Q e a(j) ≤S2 j,p ≤Q, para todo j ∈p. Para ilustração de G′, considere uma pequena instância com n = 2, m = 1, Q = 2, T = 3 ν3 = 2, γ3 = {1, 2}. Para cada aresta e = {i, j} ∈E, t{i,j} = t{j,i}, e sejam esses tempos de travessia dados por t{0,1} = t{0,2} = t{0,3} = t{1,3} = t{2,3} = 1 e t{1,2} = 2. Por fim, considere demandas unitárias para os clientes, d1 = d2 = 1. A Figura 2 apresenta o grafo gerador de caminhos restritos em recurso para esse exemplo, onde os consumos de recurso estão ilustrados nos arcos do grafo e as janelas de tempo dos vértices estão representadas em colchetes. Note que dois arcos são criados entre os vértices v3 e ¯v3, indicando que existem duas opções de alocação de demanda neste locker caso este seja utilizado. vso [0, 3] vsi [0, 3] v3 [0, 3] ¯v3 [0, 3] v1 [2, 3] v2 [1, 3] q1 = q2 = 1 q1 = q2 = 1 q1 = q2 = 1 q1 = 1; q2 = 0 q1 = 2; q2 = 0 q1 = 1; q2 = 2 q1 = 1; q2 = 2 q1 = 0; q2 = 1 q1 = 0; q2 = 1 q1 = q2 = 1 q1 = q2 = 1 q1 = 0; q2 = 1 q1 = 0; q2 = 1 q1 = 0; q2 = 1 Figura 2: Grafo gerador de caminhos restritos em recurso para o Exemplo Ilustrativo 2 - consumo https://proceedings.science/p/193811?lang=pt-br DOI: 10.59254/sbpo-2024-193811 3.2. Formulação PLIM Apresentamos agora a formulação que é utilizada pelo modelo VRPSolver proposto. Tal formulação usa as seguintes constantes: o conjunto P representa o conjunto de caminhos viáveis em G′ e, para cada locker l ∈VL, definimos Cl como o conjunto de clientes que podem ser atribuídos a l. Matematicamente, temos Cl = {j ∈VC|c(j,l) ≤Rl}. A formulação proposta considera as seguintes variáveis. Para cada e ∈E, definimos uma variável inteira xe indicando o número de vezes que a aresta e é percorrida. Para cada locker l ∈L, para cada cliente j ∈Cl, definimos a variável binária yjl indicando se o cliente j é atribuído ao locker l (yjl = 1) ou não (yjl=0).Para cada locker l ∈VL, define-se a variável binária tl indicando se o locker l é visitado (tl = 1) ou não (tl=0). Para cada locker l e cada possível valor de demanda k = 1, ..., Q, definimos a variável zk l indicando a demanda total atribuída ao locker l é igual a k (zk l = 1) ou não (zk l =0). Finalmente, para cada caminho p ∈P, definimos a variável inteira λp indicando quantas vezes a rota correspondente ao caminho p é usada na solução. Para relacionar as variáveis de caminho. A formulação proposta é apresentada no modelo (1). Min X e∈E cexe + X l∈VL X i∈Cl c′ ilyil (1a) S.a. X e∈δ({j}) xe + X l : j∈Cl 2yjl = 2 ∀j ∈VC; (1b) X e∈δ({l}) xe = 2tl ∀l ∈VL; (1c) yil ≤tl ∀l ∈VL , i ∈Cl; (1d) X j∈Cl yjl ≤νl ∀l ∈VL; (1e) Q X k=1 kzk l = X i∈Cl diyil ∀l ∈VL; (1f) xe = X p∈P   X a∈M(xe) αp a  λp ∀e ∈E; (1g) tl = X p∈P  X a∈M(tl) αp a  λp ∀l ∈VL; (1h) zk l = X p∈P  X a∈M(zl) αp a  λp ∀l ∈VL, k ∈Dl; (1i) 0 ≤ X p∈P λp ≤|VC|; (1j) xe ∈Z+ ∀e ∈E; (1k) yil ∈B ∀l ∈VL, i ∈Cl; (1l) zk l ∈B ∀l ∈VL, k ∈Dl; (1m) tl ∈B ∀l ∈VL; (1n) λp ∈Z+ ∀p ∈P. (1o) https://proceedings.science/p/193811?lang=pt-br DOI: 10.59254/sbpo-2024-193811 A função objetivo (1a) visa minimizar a soma do custo total de travessia com o custo total de atribuição. As restrições (1b) garantem que todo cliente j ∈VC deve ser atendido ou em casa ou através de alguma atribuição. Quando P e∈δ({j}) xe = 2, o cliente j está sendo atendido em casa. Já quando P l∈Lj 2yjl = 2, temos que j está sendo atendido via uma atribuição. As restrições (1c) garantem o grau de um locker l ∈VL é igual a 2 se este locker é visitado (tl = 1) ou é igual a 0 se este locker não é visitado (tl = 0). Restrições (1d) reforçam que para um cliente ser alocado a um locker, esse locker deve ser visitado. Restrições (1e) garantem que a demanda atribuída a um locker não ultrapassa a sua capacidade. Restrições (1f) asseguram que todos os lockers satisfaçam as demandas alocadas a eles. Restrições (1g), (1h) e (1i) relacionam respectivamente as variáveis x, y e z com as variáveis λ através da chamada função de mapeamento M definida da seguinte forma para as variáveis x: M(x(i,j)) =                {(vso, vj), (vj, vsi)} se i = 0, j ∈VC {(vso, vj), (¯vj, vsi)} se i = 0, j ∈VL {(vi, vj), (vj, vi)} se i, j ∈VC {(vi, vj), (¯vj, vi)} se i ∈VC, j ∈VL {(¯vi, vj), (¯vj, vi)} se i, j ∈VL Para as variáveis t e z, definimos respectivamente M(tl) = {a = (vl, ¯vl, k) | k = 1, ...Q} e M(zk l ) = {a = (vl, ¯vl, k)}. Basicamente, o valor de cada variável x, y ou z é dado pelo número de vezes que os arcos pertencentes aos seus respectivos conjuntos de mapeamentos M(x), M(y) e M(z) são usados pelos caminhos da solução. Para as variáveis y, não houve a necessidade da definição de uma função de mapeamento. Restrição (1j) apresenta um limite inferior e superior para o número de caminhos (rotas) usados na solução. As demais restrições garantem o domínio das variáveis. A Figura 3 ilustra a função de mapeamento das variáveis x, t e z no grafo gerador de caminhos onde, sobre cada arco do grafo, colocamos as variáveis para as quais este arco faz parte do conjunto de mapeamento. vso vsi v3 ¯v3 v1 v2 x01 x02 x03 z1 3, t3 z2 3, t3 x12 x12 x13 x23 x13 x23 x01 x02 x03 Figura 3: Grafo gerador de caminhos restritos em recurso para o Exemplo Ilustrativo 2 - mapeamento https://proceedings.science/p/193811?lang=pt-br DOI: 10.59254/sbpo-2024-193811 A partir do grafo gerador de caminhos e da formulação PLIM definidos anteriormente, o VRPSolver aplica um algoritmo BCP genérico. Para que componentes estado-da-arte para algorit- mos BCP sejam ativadas, é necessário definir os chamados packing sets, que são subconjuntos de vértices do grafo G′ para os quais no máximo um de seus elementos pode pertencer a no máximo um único caminho na solução ótima. Como tanto os clientes e os lockers só podem ser visitados uma única vez de acordo com a definição do problema, cada conjunto unitário {vi}, i ∈VC ∪VL e cada conjunto unitário {¯vl} são definidos como um packing set. Para mais detalhes a respeito do algoritmo BCP genérico, sugerimos a leitura de Pessoa et al. [2020]. 4. Experimentos Computacionais Nesta seção, apresentamos diversos experimentos computacionais para demonstrar a ro- bustez do modelo proposto. Todos os experimentos foram realizadas em um computador com um processador Intel Core i7-10700 com 2.90 GHz e 16 GB de memória RAM. O sistema operacional usado é o Ubuntu e o algoritmo foi implementado em Julia v1.4.2 usando o framework VRPSolver v0.4.1a (https://vrpsolver.math.u-bordeaux.fr/). Nós executamos cada uma das instâncias testadas neste trabalho de duas maneiras. Na primeira delas, nós testamos o modelo proposto sem o fornecimento de nenhum limite superior válido. Na segunda maneira, nós fornecemos o custo ótimo acrescido de 0,01 como limite superior. 4.1. Geração das instâncias Nós seguimos Buzzega e Novellani [2023] e também usamos as instâncias propostas por Jiang et al. [2020], que foram geradas através da inclusão de vértices lockers nos grafos de 40 instâncias benbchmark do problema do caixeiro viajante com janelas de tempo. Em particular, as instâncias originais são dividas em dois conjuntos: o primeiro possui janelas de tempo de amplitude 20 e foram inicialmente propostas por Dumas et al. [1995], enquanto o segundo tem janelas de tempo de amplitude 100 e foram propostas por Gendreau et al. [1998] baseadas nas instâncias propostas por Dumas et al. [1995]. Cada um destes conjuntos pode ser divididos em 4 grupos, cada um com 10 instâncias, com o mesmo número de clientes n = 20, 40, 60, 100, cada um destes possuindo uma demanda unitária (di = 1, ∀i ∈VC). O número de lockers adicionados é m = n/10. Cada instância é modificada através da inclusão de m lockers nos m primeiros vértices do seguinte conjunto de coordenadas: (25,0, 25,0), (12,5, 12,5), (37,5, 37,5), (12,5, 25,0), (37,5, 12,5), (12,5, 25,0), (25,0, 37,5), (37,5, 25,0), (25,0, 12,5), e (0, 0). O custo ce e o tempo de travessia te de cada aresta e ∈E do grafo são dados pela distância euclideana entre os pontos arrendondada para a segunda casa decimal. O custo c′ jl de atribuir um cliente j ∈VC a um locker l ∈VL é dado por c′ jl = 0.5×c(j,l). Para cada instância, para cada locker l ∈VL, tem-se Rl = 20 e νl = 5. As janelas de tempo do depósito e dos clientes são as mesmas da instância original enquanto que, para cada locker l ∈VL, tem-se [al, bl] = [a0, b0]. A capacidade de cada veículo é dada por Q = n 2 . 4.2. Comparação com a literatura Os métodos exatos propostos por Buzzega e Novellani [2023] foram testados nas instâncias descritas na Seção 4.1 considerando um tempo limite de 7200s. Para uma comparação justa, nós comparamos através do site https://www.cpubenchmark.net/ a versão single thread dos processadores utilizados neste trabalho com a do processador usado pela literatura e concluímos que o tempo limite a ser usado neste trabalho é de 5034s. A Tabela 1 mostra uma comparação com a literatura para instâncias com até 60 clientes. As instâncias estão agrupadas de acordo com a variante (PRVLJT) e de acordo com o número de clientes. Os seguintes cabeçalhos são usados para as colunas. As colunas Variante e n indicam res- pectivamente a variante e o número de clientes associados ao grupo de instâncias correspondente. A Coluna # Inst indica o número de instâncias no grupo. A Coluna Tempo Médio(s) indica o tempo médio de resolução em segundos considerando todas as instâncias do grupo. Para as instâncias não https://proceedings.science/p/193811?lang=pt-br DOI: 10.59254/sbpo-2024-193811 resolvidas, o tempo limite é usado para o cálculo da média. A Coluna #Opt representa o número de soluções comprovadamente ótimas obtidas dentro do limite de tempo. A Coluna Literatura apre- senta os resultados obtidos pelo melhor método exato proposto por Buzzega e Novellani [2023] enquanto que as Colunas Este trabalho Sem UB e Este trabalho Com UB apresenta estatística obti- das pelo modelo proposto sem e com o uso do limite superior. O uso da solução ótima como upper bound é interessante para analisarmos o tempo com- putacional do modelo para resolver o problema provando a otimalidade caso uma heurística que atingiu a melhor solução conhecida fosse utilizada. De toda forma, observando a Tabela 1, nota-se que o método proposto supera o melhor método da literatura para ambas variantes do problema mesmo quando um limite superior não é utilizado. Este Trabalho Literatura Sem UB Com UB Tempo Tempo Tempo Variante n #Inst Médio(s) #Opt Médio(s) #Opt Médio(s) #Opt 20 10 2,5 10 0,0 10 0,0 10 PRVLJT 40 10 1283,2 9 80,1 10 11,2 10 60 10 5088,2 3 2529,2 8 1716,4 9 20 10 2,0 10 2,7 10 0,3 10 PRVL 40 10 4639,4 6 144,0 10 43,0 10 60 10 6187,9 2 3557,7 7 1532,0 9 Tabela 1: Comparação com a literatura 4.3. Resultados detalhados A Tabela 2 apresenta, para cada experimento considerando o limite superior, o nome da instância correspondente (Coluna Instância) o custo ótimo (Coluna ub∗), o gap percentual da solução ótima em relação ao limite inferior do nó raiz (Coluna Gap0), e o tempo total em segundos (Coluna T(S)). Os nomes de cada instância tem o formato ”nXtwYlZ id”, onde X representao o número de clientes, Y representa a amplitude das janelas de tempo (20 ou 100), Z representa o número de lockers e id representa o índice da instância, que varia de 1 a 5. Observando a Tabela 2, vemos que o método proposto resolveu quase todas as instâncias em razoáveis tempos computacionais. A principal foi a instância n60tw100l6 2, que precisou de 16835s e 11360s para ter a comprovação da otimalidade nas variantes PRVLJT e PRVL, respecti- vamente. Tais instâncias estão associadas aos maiores gaps na raiz obtidos pelo método. 5. Conclusões e trabalhos futuros Neste artigo, propusemos um novo método exato para a um problema de roteamento de veículos com lockers com duas variantes: com e sem janelas de tempo. O método proposto é um algoritmo BCP desenvolvido com auxílio do framework VRPSolver. Aplicamos o algoritmo em 60 instâncias benchmark da literatura com até 60 clientes. Os resultados mostram que o algoritmo proposto supera o melhor método exato da literatura, sendo capaz de resolver a maioria das instâncias em razoáveis tempos computacionais. Várias instâncias foram resolvidas pela primeira vez. Apesar dos bons resultados, algumas instâncias com 60 clientes apresentaram tempos computacionais e gaps na raiz relativamente altos. Como trabalhos futuros, pretendemos estudar o poliedro do problema para identificar cor- tes capazes de melhorar ainda mais os tempos computacionais obtidos, bem como permitir que o método seja testado em instâncias maiores. Além disso, pretende-se estender o modelo proposto https://proceedings.science/p/193811?lang=pt-br DOI: 10.59254/sbpo-2024-193811 PRVLJT PRVL Instância ub∗ Gap0 T(s) ub∗ Gap0 T(s) n20tw100l2 1 227,465 0,7 0 211,725 0,1 0 n20tw100l2 2 213,245 0,1 0 208,110 0,2 0 n20tw100l2 3 277,805 0,0 0 226,280 0,0 0 n20tw100l2 4 258,295 0,1 0 235,510 0,0 0 n20tw100l2 5 266,490 1,1 0 239,240 1,4 0 n20tw20l2 1 254,620 2,3 0 225,950 2,0 0 n20tw20l2 2 229,695 0,2 0 206,300 0,2 0 n20tw20l2 3 279,575 1,3 0 251,190 2,5 2 n20tw20l2 4 234,070 0,0 0 202,360 0,0 0 n20tw20l2 5 266,815 0,5 0 217,380 0,0 0 n40tw100l4 1 320,790 2,8 10 283,160 3,3 48 n40tw100l4 2 305,700 2,9 39 271,930 0,2 0 n40tw100l4 3 280,515 1,8 8 261,365 2,8 114 n40tw100l4 4 282,210 0,3 0 262,585 1,2 14 n40tw100l4 5 288,090 1,7 6 243,995 0,0 0 n40tw20l4 1 385,930 0,2 0 307,995 2,1 11 n40tw20l4 2 334,090 1,0 1 280,130 1,7 6 n40tw20l4 3 315,025 2,4 11 282,345 4,0 95 n40tw20l4 4 281,990 0,6 1 250,770 1,0 4 n40tw20l4 5 355,765 1,2 2 276,110 2,0 9 n60tw100l6 1 351,000 3,3 3103 299,940 1,0 115 n60tw100l6 2 379,795 4,9 16835 328,855 4,8 11360 n60tw100l6 3 350,710 2,8 2939 301,160 3,0 53 n60tw100l6 4 381,250 2,9 480 327,920 2,6 759 n60tw100l6 5 356,960 2,4 119 307,525 2,6 296 n60tw20l6 1 366,475 1,3 11 317,660 3,0 280 n60tw20l6 2 429,200 1,4 90 345,230 2,7 2077 n60tw20l6 3 400,770 1,7 133 351,055 3,0 926 n60tw20l6 4 405,895 0,1 10 336,140 1,2 180 n60tw20l6 5 405,865 1,8 84 335,710 2,7 993 Tabela 2: Resultados por instância do modelo proposto quando se é fornecido o limite superior válido. para outras variantes de problemas de roteamentos de veículos que considerem a atribuição de di- versos clientes a um único local de atendimento, como é o caso da variante estudada por Tilk et al. [2021]."
        },
        {
            "titulo": "Método Heurístico e Exato para o Minimum Broadcast Center",
            "informacoes_url": "https://proceedings.science/p/193575?lang=pt-br",
            "idioma": "português",
            "storage_key": "galoa-proceedings--sbpo-2024--193575.pdf",
            "autores": [
                {
                    "nome": "Alfredo Lima",
                    "afiliacao": "Instituto de Computação, Universidade Federal Fluminense",
                    "orcid": ""
                },
                {
                    "nome": "Luiz Satoru Ochi",
                    "afiliacao": "Instituto de Computação, Universidade Federal Fluminense",
                    "orcid": ""
                },
                {
                    "nome": "Bruno Nogueira",
                    "afiliacao": "Instituto de Computação, Universidade Federal de Alagoas",
                    "orcid": ""
                },
                {
                    "nome": "Rian G. S. Pinheiro",
                    "afiliacao": "Instituto de Computação, Universidade Federal de Alagoas",
                    "orcid": ""
                }
            ],
            "data_publicacao": "",
            "resumo": "O problema do Minimum Broadcast Center (MBC), que envolve a seleção de um conjunto de nós fonte e a determinação do Minimum Broadcast Time (MBT) a partir desse conjunto.",
            "keywords": [
                "Redes",
                "Otimização Combinatória",
                "Minimum Broadcast Center"
            ],
            "referencias": [
                "Bean, J. C. (1994). Genetic algorithms and random keys for sequencing and optimization. INFORMS Journal on Computing, 6(2):154–160.",
                "Elkin, M. e Kortsarz, G. (2003). Sublogarithmic approximation for telephone multicast: Path out of jungle. Proceedings of the Annual ACM-SIAM Symposium on Discrete Algorithms, p. 76–85.",
                "Farley, A., Hedetniemi, S., Mitchell, S., e Proskurowski, A. (1979). Minimum broadcast graphs. Discrete Mathematics, 25(2):189 – 193. ISSN 0012-365X.",
                "Floyd, R. W. (1962). Algorithm 97: Shortest path. Commun. ACM, 5(6):345. ISSN 0001-0782.",
                "Gonçalves, J. e Resende, M. (2011). Biased random-key genetic algorithms for combinatorial optimization. J. Heuristics, 17:487–525.",
                "Harutyunyan, H. e Maraachlian, E. (2007). Linear algorithm for broadcasting in unicyclic graphs. Computing and Combinatorics, p. 372–382.",
                "Harutyunyan, H. A. e Li, Z. (2021). The complexity of finding a broadcast center. In Algorithmic Aspects in Information and Management: 15th International Conference, AAIM 2021, Virtual Event, December 20–22, 2021, Proceedings 15, p. 57–70. Springer.",
                "Harutyunyan, H. A. e Maraachlian, E. (2008). On broadcasting in unicyclic graphs. Journal of combinatorial optimization, 16:307–322.",
                "Hasson, Y. e Sipper, M. (2004). A novel ant algorithm for solving the minimum broadcast time problem. In Parallel Problem Solving from Nature - PPSN VIII, p. 501–510, Berlin, Heidelberg. Springer Berlin Heidelberg. ISBN 978-3-540-30217-9.",
                "Hoelting, C. J., Schoenefeld, D. A., e Wainwright, R. L. (1996). A genetic algorithm for the minimum broadcast time problem using a global precedence vector. In Proceedings of the 1996 ACM Symposium on Applied Computing, SAC ’96, p. 258–262, New York, NY, USA. Association for Computing Machinery. ISBN 0897918207.",
                "Holland, J. H. (1975). Adaptation in Natural and Artificial Systems: An Introductory Analysis with Applications to Biology, Control and Artificial Intelligence. University of Michigan Press, Ann Arbor, MI.",
                "Ivanova, M. (2019). Optimization problems in communication networks and multi-agent path finding. Bergen Open Research Archive.",
                "Jansen, K. e Müller, H. (1995). The minimum broadcast time problem for several processor networks. Theoretical Computer Science, 147(1):69 – 85. ISSN 0304-3975.",
                "Kortsarz, G. e Peleg, D. (1992). Approximation algorithms for minimum time broadcast. In Dolev, D., Galil, Z., e Rodeh, M., editors, Theory of Computing and Systems, p. 67–78, Berlin, Heidelberg. Springer Berlin Heidelberg. ISBN 978-3-540-47214-8.",
                "Lima, A., Aquino, A. L., Nogueira, B., e Pinheiro, R. G. (2024). A matheuristic approach for the minimum broadcast time problem using a biased random-key genetic algorithm. International Transactions in Operational Research, 31(1):246–273.",
                "López-Ibáñez, M., Dubois-Lacoste, J., Cáceres, L. P., Birattari, M., e Stützle, T. (2016). The irace package: Iterated racing for automatic algorithm configuration. Operations Research Perspectives, 3:43–58. ISSN 2214-7160.",
                "Resende, M. G. C. (2011). Biased random-key genetic algorithms with applications in telecommunications. TOP, 20(1):130–153.",
                "Robledo, F., Rodríguez-Bocca, P., e Romero, P. (2020). Optimal broadcast strategy in homogeneous point-to-point networks. In Machine Learning, Optimization, and Data Science, p. 448–457, Cham. Springer International Publishing. ISBN 978-3-030-64583-0.",
                "Scheuermann e Wu (1984). Heuristic algorithms for broadcasting in point-to-point computer networks. IEEE Transactions on Computers, C-33(9):804–811. ISSN 2326-3814.",
                "Slater, P. J., Cockayne, E. J., e Hedetniemi, S. T. (1981). Information dissemination in trees. SIAM Journal on Computing, 10(4):692–701.",
                "Sousa, A., Gallo, G., Gutiérrez, S., Robledo, F., Rodríguez-Bocca, P., e Romero, P. (2018). Heuristics for the minimum broadcast time. Electronic Notes in Discrete Mathematics, 69:165 – 172. ISSN 1571-0653. Joint EURO/ALIO International Conference 2018 on Applied Combinatorial Optimization (EURO/ALIO 2018).",
                "Su, Y.-H., Lin, C.-C., e Lee, D. (2010). Broadcasting in heterogeneous tree networks. In International Computing and Combinatorics Conference, p. 368–377. Springer.",
                "Wieselthier, J. E., Nguyen, G. D., e Ephremides, A. (2002). Energy-efficient broadcast and multicast trees in wireless networks. Mobile networks and applications, 7(6):481–492."
            ],
            "artigo_completo": "Método Heurístico e Exato para o Minimum Broadcast Center. RESUMO O problema do Minimum Broadcast Center (MBC), que envolve a seleção de um con- junto de nós fonte e a determinação do Minimum Broadcast Time (MBT) a partir desse conjunto. Esse problema é relevante para o design de redes em cidades inteligentes e sistemas distribuídos, especialmente com a Internet das Coisas (IoT). Foram propostos dois métodos para resolver o MBC: um modelo de Programação Linear Inteira (ILP) e uma metaheurística baseada em Algo- ritmo Genético com Chaves Aleatórias Viciadas (BRKGA). A análise comparativa entre o ILP e o BRKGA em 111 instâncias mostrou que ambos os métodos são eficientes, mas o BRKGA demons- trou maior consistência e rapidez na obtenção de soluções ótimas, especialmente em instâncias mai- ores onde o ILP teve dificuldade. Essa comparação ressalta a eficácia do BRKGA como heurística para o problema do MBC. PALAVRAS CHAVE. Redes, Otimização Combinatória, Minimum Broadcast Center. Tópicos (Otimização Combinatória. Meta-heurísticas) 1. Introdução No contexto das redes de computadores, a disseminação eficiente de dados é crucial. Di- versos estudos visam otimizar essa eficiência, incluindo o problema do MINIMUM BROADCAST TIME (MBT) [Farley et al., 1979]. O MBT consiste em um problema de disseminação (broadcast) cujo objetivo é espalhar uma mensagem o mais rapidamente possível para todos os dispositivos em uma rede de computadores. Cada dispositivo que recebe a mensagem pode transmiti-la para ou- tro dispositivo por vez. O objetivo é determinar o menor tempo necessário para que todos na rede recebam a mensagem, começando a partir de um conjunto específico de dispositivos. O MBT pode ser modelado como um grafo não direcionado G = (V, E), em que os nós são representados pelos vértices e as conexões entre eles pelas arestas (E ⊂V × V ). Os nós fontes são indicados por V0 (V0 ⊆V ). O tempo de transmissão T é discretizado em intervalos t (1 ≤t ≤T, t, T ∈N). O conjunto de vértices que possuem a mensagem no instante t é Vt (Vt−1 ⊆Vt) e as transmissões no instante t são representadas por Et (Et ⊆E). As restrições são: (i) um nó que recebeu a informação torna-se um emissor, e (ii) um nó emissor pode enviar a informação para, no máximo, um vizinho por vez. A função b(G, V0) computa o tempo mínimo de transmissão a partir dos nós V0 no grafo G. Após a definição inicial do MBT, diversas variantes foram propostas para modelar outros problemas de broadcast. Uma variante importante é o BROADCAST CENTER DECIDING (BCD) [Harutyunyan e Li, 2021]. O broadcast center BCG = {v0 | b(G, {v0}) ≤b(G, {u}), ∀u ∈V } é o conjunto de vértices que possuem o menor tempo de transmissão no grafo G. No problema BCD, dada uma instância (G, U), onde G = (V, E) é um grafo e U é um subconjunto de V , o objetivo é verificar se U é um subconjunto de BCG. Para simplificar a explicação, a definição de BCG e, consequentemente, do BCD, considera apenas um nó fonte. No entanto, essas definições podem ser estendidas para múltiplos nós fonte. Ou seja, o broadcast center para K nós fonte pode ser definido como BCK G = {V0 | b(G, V0) ≤b(G, U), ∀U ⊆V e |U| = |V0| = K}. Consequentemente, o BCD é modificado para, dada uma instância (G, U, K), em que G é um grafo, U é um subconjunto dos conjuntos de vértices, e K é a quantidade de nós fonte, o objetivo é verificar se U é um subconjunto de BCK G . Essa é a versão de decisão do problema. Até onde se sabe, este é o primeiro trabalho que considera a versão de otimização do problema. Portanto, neste artigo, a versão de otimização será denominada MINIMUM BROADCAST CENTER (MBC), em que é necessário encontrar apenas um subconjunto que pertença a BCK G . A Figura 1(a) ilustra um exemplo simples de rede com os nós V = {v1, v2, v3, v4} para demonstrar o MBC com K = 1. Nas Figuras 1(b)–1(e), são apresentadas soluções ótimas do MBT usando diferentes conjuntos de nós fonte: V0 = {v1}, V0 = {v2}, V0 = {v3} e V0 = {v4}. O valor do MBT é 3 para V0 = {v3} e V0 = {v4}, enquanto é 2 para V0 = {v1} e V0 = {v2}. Portanto, para o MBC com |V0| = 1, existem duas soluções ótimas: V0 = {v1} e V0 = {v2}. Observe que o MBC é um problema de dois estágios: (i) definir o conjunto de nós fontes (V0), e (ii) encontrar o MBT a partir desse conjunto. O interesse em estudar o problema do MINI- MUM BROADCAST CENTER (MBC) surgiu a partir de uma necessidade de otimizar o processo de atualização de dispositivos em uma rede point-to-point de um parceiro industrial. Nesta rede, os dispositivos utilizavam Bluetooth Low Energy (BLE) para comunicação interna, enquanto alguns https://proceedings.science/p/193575?lang=pt-br DOI: 10.59254/sbpo-2024-193575 v3 v4 v2 v1 ((a)) Rede v3 v4 v2 v1 1 2 2 ((b)) V0 = {v1} v3 v4 v2 v1 1 2 2 ((c)) V0 = {v2} v3 v4 v2 v1 2 1 3 ((d)) V0 = {v3} v3 v4 v2 v1 2 3 1 ((e)) V0 = {v4} Figura 1: Exemplo de rede e diagramas de transmissão para diferentes conjuntos iniciais V0. (gateways) usavam General Packet Radio Service (GPRS) para comunicação externa. O desafio era realizar a atualização do firmware de forma eficiente e confiável, considerando uma imagem de firmware de 200KB. Duas topologias do BLE foram testadas para a atualização: Point-to-Point e Mesh. Na Point-to-Point, cada dispositivo transmite uma vez por vez, garantindo uma propagação ordenada e gradual. Na Mesh, um dispositivo pode atualizar vários vizinhos ao mesmo tempo para acelerar a disseminação. No entanto, os resultados mostraram que a Point-to-Point completou a atualização em 2 minutos, enquanto a Mesh levou 4,5 horas, mesmo sendo a atualização de um único disposi- tivo. Embora a Mesh permita transmissões simultâneas, o alto consumo de largura de banda causou congestionamento e perda de pacotes, levando a atrasos, como demonstrado por Robledo et al. [2020]. A tarefa de atualizar o firmware de todos os dispositivos na rede de forma eficiente utili- zando a topologia Point-to-Point é análoga ao problema do MBT, que visa transmitir uma mensa- gem dos nós de origem para todos os outros nós no menor tempo possível, determinando também os nós mais adequados para atuarem como gateways (MBC). Redes bem projetadas devem minimi- zar o tempo de transmissão e garantir a rápida disseminação de informações, tornando essencial a identificação dos melhores centros de transmissão. Assim, resolver o problema MBC, mesmo que de forma aproximada, é fundamental para o desenvolvimento de redes de comunicação eficientes, robustas e escaláveis. Este trabalho propõe três contribuições para o MBC: (i) um modelo matemático para o MBC, (ii) um lower bound para o MBC, e (iii) uma meta-heurística Biased Random-Key Genetic Algorithm (BRKGA) para o MBC. Na Seção 2, é apresentada uma revisão bibliográfica sobre os problemas MBT e BCD. A Seção 3 traz um modelo matemático e um limite inferior para o MBC. A Seção 4 fornece uma explicação sobre o BRKGA e sua aplicação para resolver o MBC. Os resultados e comparações das propostas são discutidos na Seção 5. Por fim, a Seção 6 apresenta a conclusão e sugestões para trabalhos futuros. 2. Trabalhos Relacionados A literatura sobre o MBT é extensa, abrangendo algoritmos exatos [Scheuermann e Wu, 1984; Sousa et al., 2018; Ivanova, 2019], aproximativos [Kortsarz e Peleg, 1992; Elkin e Kortsarz, 2003], heurísticos [Scheuermann e Wu, 1984; Sousa et al., 2018], meta-heurísticos [Hoelting et al., 1996; Hasson e Sipper, 2004; Lima et al., 2024] e matheurísticos [Lima et al., 2024]. Existem também algoritmos polinomiais para casos específicos de grafos, como árvores [Slater et al., 1981] e grades completas [Jansen e M¨uller, 1995], todos com a restrição adicional de |V0| = 1. Além disso, há estudos sobre limites inferiores para o MBT [Ivanova, 2019; Lima et al., 2024]. Para o BCD, a maioria dos estudos foca em classes específicas de grafos: (i) Slater et al. [1981] desenvolveram um algoritmo polinomial para o BCD em árvores com |V0| = 1; (ii) Ha- https://proceedings.science/p/193575?lang=pt-br DOI: 10.59254/sbpo-2024-193575 rutyunyan e Maraachlian [2008] estudaram o BCD em grafos unicíclicos; (iii) Harutyunyan e Ma- raachlian [2007] exploraram redes de clusters de árvores; (iv) Su et al. [2010] apresentaram um algoritmo linear para encontrar o BCD em árvores ponderadas. Além disso, Harutyunyan e Li [2021] provaram que o BCD é NP-difícil. Como mencionado anteriormente, durante a revisão bibliográfica, não foi identificada na literatura nenhuma proposta para o BCD ou MBC aplicável a grafos arbitrários. 3. Modelo Matemático para o MINIMUM BROADCAST CENTER O modelo matemático proposto para o MBC é uma adaptação do modelo proposto por Sousa et al. [2018] para o problema MBT. Dado um grafo G = (V, E), em que V é o conjunto de vértices e E é o conjunto de arestas que representam as conexões entre os vértices, seja K a quantidade de nós fontes, com 1 ≤K ≤|V |. Considere que N(i) representa o conjunto de nós vizinhos do nó i, e Tmax seja o limite superior para o tempo em que todos os nós recebem a mensagem, sendo Tmax = |V |−K o limite trivial. As variáveis utilizadas são definidas da seguinte forma: xt ij é uma variável binária que assume o valor 1 se o nó i envia a mensagem para o nó j no tempo t, e 0 caso contrário; Si é uma variável binária que assume o valor 1 se o nó i será um nó fonte, e 0 caso contrário; e T é uma variável de decisão que representa o tempo de transmissão. A partir dessas definições, o modelo proposto é formulado a seguir: min T (1) s. a X i∈V Si = K (2) Si + X j∈N(i) Tmax X t=1 xt ji = 1 ∀i ∈V (3) X j∈N(i) xt ij ≤1 ∀i ∈V, ∀t ∈{1, . . . , Tmax} (4) xt ij ≤Si + t−1 X τ=1 X l∈N(i)\\{j} xτ li ∀(i, j) ∈E, ∀t ∈{1, · · · , Tmax} (5) Tmax X t=1 t · xt ij ≤T ∀(i, j) ∈E (6) T ∈N (7) xt ij ∈{0, 1} ∀(i, j) ∈E, ∀t ∈{1, . . . , Tmax} (8) Si ∈{0, 1} ∀i ∈V (9) A Equação (1) apresenta a função objetivo, que é minimizar o valor de T. A Restrição (2) garante que o número total de nós fonte selecionados seja igual a K. As Restrições (3) asseguram que cada nó será um nó fonte ou receberá a mensagem de um nó vizinho em algum instante t. As Restrições (4) impõem que cada nó envie no máximo uma mensagem aos vizinhos em cada t. As Restrições (5) estabelecem que o nó só pode transmitir se recebeu a mensagem anteriormente ou se é nó fonte. As Restrições (6) condicionam que o valor de T deve ser maior ou igual ao tempo de qualquer transmissão. A Restrição (7) define o domínio de T. E por fim, as Restrições (8) e (9) definem o domínio de cada variável xt ij e Si, respectivamente. 3.1. Lower bound para o MINIMUM BROADCAST CENTER Diferentemente do problema MBT, no qual os nós fontes são fixados, permitindo a utilização de lower bounds para definir algumas variáveis xt ij como 0 [Lima et al., 2024; Sousa et al., 2018], isso não é possível para o MBC, pois qualquer nó pode ser um nó fonte. https://proceedings.science/p/193575?lang=pt-br DOI: 10.59254/sbpo-2024-193575 Para o exemplo na Figura 2, um grafo P8, o MBC com K = 1 é 4, e BC1 P8 = {v4, v5}. A maior distância a partir de qualquer v ∈BC1 P8 é 4, o que coincide com o valor do MBC. Assim, é possível utilizar o algoritmo de Floyd-Warshall [Floyd, 1962] como um lower bound baseado na distância entre os vértices, uma ideia semelhante à descrita em Lima et al. [2024] para o MBT. No entanto, para K > 1, esse lower bound não funciona. Por exemplo, para K = 2, o MBC de P8 é 2, onde BC2 P8 = {{v2, v7}, {v2, v6}, {v3, v6}, {v3, v7}}. No entanto, ainda é viável empregar o lower bound para o MBT proposto por Ivanova [2019] para o MBC: ⌈log2 |V | K ⌉≤T ≤|V | −K. Ou seja, ⌈log2 |V | K ⌉≤T pode ser adicionado como uma restrição ao modelo. v1 v2 v3 v4 v5 v6 v7 v8 Figura 2: Grafo P8. 4. Algoritmo Genético com Chaves Aleatórias Viciadas O BRKGA, desenvolvido por Gonçalves e Resende [2011], é uma versão avançada dos algoritmos genéticos, originalmente propostos por Holland [1975]. Os algoritmos genéticos são técnicas bioinspiradas que utilizam conceitos como hereditariedade, mutação, seleção natural e recombinação. No BRKGA, os cromossomos são representados por vetores de chaves aleatórias com valores reais no intervalo [0, 1) [Bean, 1994]. Ele divide a população em duas subpopulações – elite e não-elite – para preservar as melhores soluções e promover a diversidade genética. Durante o crossover, cada gene do descendente é escolhido aleatoriamente de um dos pais, com maior probabilidade de herdar características do indivíduo da elite, favorecendo a propagação de boas características. Uma proporção fixa da nova geração é composta por indivíduos mutantes, mantendo a diversidade genética e evitando a convergência prematura. Essas características garantem um equilíbrio entre a exploração e a exploração do espaço de soluções. A Figura 3 ilustra o processo de evolução da população utilizando o BRKGA. Nesse exemplo, são apresentados a cópia da população de elite, a introdução de indivíduos mutantes e o processo de crossover com enviesamento. Figura 3: Processo de evolução da população do BRKGA O BRKGA possui parâmetros configuráveis, como o tamanho da população, a proporção https://proceedings.science/p/193575?lang=pt-br DOI: 10.59254/sbpo-2024-193575 de indivíduos elite, a proporção de mutantes e a probabilidade de herança dos genes durante o crossover. Esses parâmetros permitem ajustar o algoritmo para diferentes problemas, tornando necessário um processo de ajuste fino. 4.1. BRKGA para o MBC Este trabalho visa resolver o problema MBC usando o BRKGA. Primeiro, será detalhada a técnica para melhorar o cálculo do MBT descrita por Slater et al. [1981] e Lima et al. [2024]. O algoritmo de Slater et al. [1981], chamado de SCHA, computa o MBT de grafos do tipo floresta de forma polinomial. Lima et al. [2024] mostraram que a adição do SCHA como método de refinamento é eficaz. Portanto, será utilizado o algoritmo SCHA, que tem um custo computacional de O(|V | · log |V |) no pior caso. Para mais detalhes sobre esse algoritmo, consulte os trabalhos de Slater et al. [1981] e Lima et al. [2024]. O BRKGA para o MBC foi desenvolvido utilizando a API de Resende [2011], sendo ne- cessária apenas a implementação do procedimento de decodificação. O processo de decodificação e avaliação do indivíduo é descrito no pseudocódigo do Algoritmo 1. O Algoritmo 1 possui dois níveis de decisão: (i) definição do conjunto de nós fontes (|V0| = K) e (ii) cálculo do tempo de transmissão a partir de V0. A entrada do algoritmo é composta por um grafo G = (V, E), a quantidade de nós fontes K, e um vetor de cromossomos Cr, em que Cr tem tamanho |V |. Cada Cri determina a prioridade do vértice vi. Os K vértices de maior prioridade formam o conjunto V0 (linhas 2–10). Para selecionar as arestas da solução, é escolhido sempre um vértice que possui a informação para transmiti-la a um que ainda não a possui, seguindo a filosofia: o primeiro que recebe é o primeiro que envia. A lista Order indica a ordem de transmissão, construída inicialmente com os nós fontes e ordenada pelos valores dos alelos dos nós fontes (linhas 2–10). O conjunto EF , inicialmente vazio, representa as arestas da solução, e o conjunto Transmitters indica os vértices que já possuem a informação, inicialmente preenchido com os vértices de V0 (linhas 13–26). Um processo iterativo é então iniciado e continua até que todos os vértices tenham a informação (linhas 13–26). Em cada iteração, percorre-se cada vértice v na lista Order (linha 15), selecionando um vizinho u de v que ainda não tenha a informação, com a maior prioridade baseada nos alelos (linhas 16–21). A aresta (v, u) é adicionada ao conjunto EF (linha 19). No final de cada iteração, os vértices que receberam a informação são adicionados à lista Order, mantendo a filosofia de transmissão (linhas 23–25). Após o término do processo iterativo, o conjunto EF enumera todas as arestas da floresta F = (V, EF ). A partir dessa floresta e dos nós fontes V0, o MBT é computado utilizando o algoritmo SCHA (linha 27). Caso alguma solução encontre o valor igual ao do lower bound, o BRKGA inter- rompe o processo de evolução da população, pois encontrou uma solução ótima. A decodificação tem custo computacional de O(|V | · |E|) no pior caso. 5. Experimentos e Resultados Nesta seção são apresentados os experimentos computacionais conduzidos para avaliar a eficácia das propostas de ILP e BRKGA. Todos os experimentos foram realizados em um Intel Core i7-8565U com 1,80 GHz, 8 GB de RAM, rodando Ubuntu 18.04.1. Os algoritmos heurísticos foram codificados em C++ e compilados com g++ 7.5 e a flag ‘-O3‘. O framework BRKGA C++ desenvolvido por Resende [2011] foi utilizado para implementar o BRKGA. O solver IBM CPLEX 12.9 foi utilizado para resolver o modelo ILP. Por fim, para ajustar os parâmetros do algoritmo BRKGA, foi adotada a ferramenta Irace [López-Ibáñez et al., 2016]. As melhores configurações de parâmetros identificadas pelo experimento de ajuste foram: (i) o número de indivíduos em cada população p = max(100, |V |), (ii) a porcentagem de indivíduos elite em cada população pe = 0.18, (iii) a porcentagem de mutantes introduzidos em cada geração https://proceedings.science/p/193575?lang=pt-br DOI: 10.59254/sbpo-2024-193575 Algoritmo 1: Decodificador Input : Grafo: G = (V, E), Quantidade de nós fontes: K, Cromossomos: Cr Output: Tempo de transmissão: time, Nós fontes: V0, 1 DecoderMBC(G, K, Cr) 2 V0 ←∅ // Conjunto que representa os nós fontes 3 Order ←InitList() // Inicializa a lista Order 4 for each v ∈Sort(V, Cr) do // Ordenação em ordem crescente do valor do alelo 5 V0 ←AppendItem(V0,v) 6 Order ←PushBack(Order,v) 7 if |V0| = K then 8 break 9 end 10 end 11 EF ←∅ // Inicialização do conjunto de arestas da solução 12 Transmitters ←V0 // Conjunto inicial de Transmitters 13 while Transmitters ̸= V do 14 NewTransmitters ←InitList() // Lista dos novos transmissores 15 for each v ∈Order do 16 u ←argmin(Cr[u]) u∈N(v)\\Transmitters // Seleciona o vizinho com maior prioridade que não é um transmissor 17 if u ̸= ∅then 18 NewTransmitters ←PushBack(NewTransmitters, u) // Adicionar o melhor vértice em NewTransmitters 19 EF ←AppendItem(EF , {(v, u)}) // Adiciona a aresta em EF 20 Transmitters ←AppendItem(Transmitters, v) // Atualiza o conjunto Transmitters 21 end 22 end 23 for each v ∈NewTransmitters do 24 Order ←PushBack(Order,v) // Atualiza a lista Order 25 end 26 end 27 time ←SCHA-Forest((V, EF ), V0) // Computa o MBT utilizando o algoritmo SCHA 28 return time, V0 na população pm = 0.15, (iv) a probabilidade de que um descendente herde o alelo de seu parente elite ρe = 0.76, e (v) o número de populações independentes K = 1. Foi utilizado um limite de tempo de 3600 segundos (1 hora) para o CPLEX resolver o modelo ILP proposto neste trabalho. Para avaliar o desempenho médio do BRKGA, foram realizadas 10 execuções em cada instância, com diferentes sementes aleatórias para cada execução. O limite https://proceedings.science/p/193575?lang=pt-br DOI: 10.59254/sbpo-2024-193575 de tempo para essas execuções foi estabelecido em 60 segundos. 5.1. Instâncias Os métodos foram testados em um total de 111 instâncias. Essas instâncias estão dis- poníveis em Lima et al. [2024] e foram utilizadas para comparar diversos trabalhos da literatura para o MBT. Esta lista inclui: • Grafos de Harary (16 instâncias): Um grafo de Harary, denotado por Hk,n, é um grafo k-conexo com n vértices que possui o menor número possível de arestas. • Instâncias sintéticas baseadas na Árvore Binomial (36 instâncias): Seja a instância G = (V, E) definida pela união de uma árvore binomial Bk = (VB, EB) e um grafo aleatório Gr = (Vr, Er), onde V = VB = Vr e E = EB ∪Er. A árvore binomial Bk é definida recursivamente como: (i) B0 é um grafo trivial, (ii) Bk é construída a partir de duas árvores binomiais Bk−1 anexando uma delas como o filho mais à direita (ou à esquerda) da raiz da outra. Uma árvore Bk contém 2k vértices e possui a propriedade de que o MBC é igual a k se K = 1, e k −1 se K = 2. • Network Data Repository1 (59 instâncias): Essas instâncias são baseadas em redes de mundo pequeno conectadas com 100 ou 1000 vértices. 5.2. Experimentos A Tabela 1 compara a metaheurística BRKGA com o modelo ILP. Para resolver o ILP, em todas as instâncias, foi utilizada a técnica de warm start a partir de uma solução do BRKGA. A tabela apresenta os resultados considerando um nó fonte (K = 1) e dois nós fontes (K = 2). Para o BRKGA, a tabela mostra: ‘Melhor’, que indica o menor valor de MBC encontrado em 10 execuções; ‘Média’, que indica a média dos valores de MBC em 10 execuções; e ‘Tempo’, que indica o tempo médio necessário para encontrar a melhor solução em segundos, calculado a partir das 10 execuções. Para o ILP, a tabela mostra: ‘MBC’, que indica o valor de MBC, e ‘Tempo’, que indica o tempo de execução em segundos. Um asterisco (*) indica que o ILP provou a otimalidade da solução; caso contrário, o ‘GAP’ indica o quão próximo a solução atual está da solução ótima em porcentagem. Para as instâncias Grafos de Harary, ambas as técnicas mostraram eficiência semelhante em termos de qualidade de solução. No entanto, o ILP exigiu um tempo considerável para encontrar as soluções e, em um caso específico, apresentou um ’GAP’ de 68%. Neste conjunto de instâncias, também vale ressaltar que somente a variação do K mudou significativamente o valor de MBC em algumas instâncias. Para as instâncias Sintéticas baseadas na Árvore Binomial, o BRKGA encontrou 26 soluções ótimas para K = 1 e 28 soluções ótimas para K = 2. O ILP encontrou todas as soluções ótimas para instâncias com até 128 vértices, tanto para K = 1 quanto para K = 2, mas teve dificuldade para encontrar soluções viáveis para instâncias com 1024 vértices. Para as instâncias da Network Repository, ambos os métodos enfrentaram maior dificul- dade. O ILP apresentou soluções de melhor qualidade para instâncias com 100 vértices, tanto para K = 1 quanto para K = 2. No entanto, para instâncias com 1000 vértices, o ILP não conseguiu provar a otimalidade em nenhuma instância, enquanto o BRKGA foi mais consistente em termos de qualidade. 1http://www.networkrepository.com https://proceedings.science/p/193575?lang=pt-br DOI: 10.59254/sbpo-2024-193575 Tabela 1: Comparação do BRKGA e ILP em todas as instâncias. Instância K = 1 K = 2 BRKGA ILP BRKGA ILP MBC Média Tempo MBC (GAP) Tempo MBC Média Tempo MBC (GAP) Tempo Grafos de Harary H10,30 5 5.0 < 0.01 5* 0.01 4 4.0 < 0.01 4* 0.03 H11,50 6 6.0 < 0.01 6* 0.02 5 5.0 < 0.01 5* 0.01 H20,50 6 6.0 < 0.01 6* 0.04 5 5.0 < 0.01 5* 0.03 H21,50 6 6.0 < 0.01 6* 0.04 5 5.0 < 0.01 5* 0.04 H2,100 50 50.0 < 0.01 50* 153.0 25 25.0 < 0.01 25 ( 68.0 ) 3600.0 H2,17 9 9.0 < 0.01 9* 0.44 5 5.0 < 0.01 5* 0.08 H2,30 15 15.0 < 0.01 15* 1.21 8 8.0 < 0.01 8* 48.96 H2,50 25 25.0 < 0.01 25* 3.32 13 13.0 < 0.01 13* 437.19 H3,17 5 5.0 < 0.01 5* < 0.01 4 4.0 < 0.01 4* < 0.01 H3,30 9 9.0 < 0.01 9* 0.77 5 5.0 < 0.01 5* 0.56 H3,50 14 14.0 < 0.01 14* 3.76 8 8.0 < 0.01 8* 940.87 H5,17 5 5.0 < 0.01 5* < 0.01 4 4.0 < 0.01 4* < 0.01 H6,17 5 5.0 < 0.01 5* < 0.01 4 4.0 < 0.01 4* < 0.01 H7,17 5 5.0 < 0.01 5* < 0.01 4 4.0 < 0.01 4* < 0.01 H8,30 5 5.0 0.03 5* 0.01 4 4.0 < 0.01 4* < 0.01 H9,30 5 5.0 < 0.01 5* 0.01 4 4.0 < 0.01 4* 0.01 Instâncias sintéticas baseadas na Árvore Binomial B5 ∪RG32,0.05 5 5.0 0.92 5* < 0.01 4 4.0 2.27 4* < 0.01 B5 ∪RG32,0.075 5 5.0 5.07 5* < 0.01 4 4.0 1.75 4* < 0.01 B5 ∪RG32,0.1 5 5.0 0.1 5* < 0.01 4 4.0 0.1 4* 0.01 B5 ∪RG32,0.15 5 5.0 0.13 5* < 0.01 4 4.0 0.08 4* 0.01 B5 ∪RG32,0.2 5 5.0 < 0.01 5* 0.01 4 4.0 < 0.01 4* 0.01 B5 ∪RG32,0.25 5 5.0 < 0.01 5* 0.01 4 4.0 < 0.01 4* 0.01 B6 ∪RG64,0.05 7 7.0 60.0 6* 4.38 6 6.0 60.0 5* 121.25 B6 ∪RG64,0.075 7 7.0 60.0 6* 3256.42 6 6.0 60.0 5* 238.63 B6 ∪RG64,0.1 6 6.0 11.07 6* 0.01 5 5.0 11.48 5* 0.02 B6 ∪RG64,0.15 6 6.0 0.05 6* 0.02 5 5.0 0.09 5* 0.03 B6 ∪RG64,0.2 6 6.0 < 0.01 6* 0.03 5 5.0 0.01 5* 0.05 B6 ∪RG64,0.25 6 6.0 < 0.01 6* 0.05 5 5.0 < 0.01 5* 0.06 B7 ∪RG128,0.05 8 8.0 < 0.01 8 ( 12.0 ) 3600.0 7 7.0 60.0 6* 392.79 B7 ∪RG128,0.075 8 8.0 60.0 7* 290.74 6 6.9 56.96 6* 194.69 B7 ∪RG128,0.1 7 7.0 4.09 7* 0.09 6 6.0 8.62 6* 0.11 B7 ∪RG128,0.15 7 7.0 0.08 7* 0.16 6 6.0 0.16 6* 0.2 B7 ∪RG128,0.2 7 7.0 0.01 7* 0.25 6 6.0 0.02 6* 0.33 B7 ∪RG128,0.25 7 7.0 < 0.01 7* 0.35 6 6.0 < 0.01 6* 0.46 B8 ∪RG256,0.05 9 9.0 < 0.01 9 ( 11.0 ) 3600 8 8.0 < 0.01 8 ( 88.0 ) 3600 B8 ∪RG256,0.075 8 8.9 54.4 9 ( 89.0 ) 3600 7 7.8 53.13 8 ( 88.0 ) 3600 B8 ∪RG256,0.1 8 8.2 24.74 9 ( 89.0 ) 3600 7 7.0 28.19 7* 0.51 B8 ∪RG256,0.15 8 8.0 0.25 8* 1.45 7 7.0 0.22 7* 1.13 B8 ∪RG256,0.2 8 8.0 0.02 8* 2.33 7 7.0 0.02 7* 1.83 B8 ∪RG256,0.25 8 8.0 0.01 8* 4.1 7 7.0 0.01 7* 2.76 B9 ∪RG512,0.05 10 10.0 < 0.01 10 ( 90.0 ) 3600 9 9.0 < 0.01 9 ( 89.0 ) 3600 B9 ∪RG512,0.075 10 10.0 < 0.01 10 ( 90.0 ) 3600 9 9.0 < 0.01 9 ( 89.0 ) 3600 B9 ∪RG512,0.1 9 9.6 51.82 9* 16.84 8 8.7 49.86 8* 5.31 B9 ∪RG512,0.15 9 9.0 0.87 9* 36.87 8 8.0 0.99 8* 36.54 B9 ∪RG512,0.2 9 9.0 0.08 - 3600 8 8.0 0.09 8* 160.26 B9 ∪RG512,0.25 9 9.0 0.02 - 3600 8 8.0 0.02 - 3600 B10 ∪RG1024,0.05 11 11.0 0.01 11 ( 91.0 ) 3600 10 10.0 0.01 10 ( 90.0 ) 3600 B10 ∪RG1024,0.075 11 11.0 0.01 - 3600 10 10.0 0.01 - 3600 B10 ∪RG1024,0.1 11 11.0 0.01 - 3600 9 9.9 57.7 - 3600 B10 ∪RG1024,0.15 10 10.0 2.77 - 3600 9 9.0 2.92 - 3600 B10 ∪RG1024,0.2 10 10.0 0.32 - 3600 9 9.0 0.33 - 3600 B10 ∪RG1024,0.25 10 10.0 0.09 - 3600 9 9.0 0.09 - 3600 Network Repository Continua na próxima página https://proceedings.science/p/193575?lang=pt-br DOI: 10.59254/sbpo-2024-193575 Tabela 1 – continuação da página anterior Instância K = 1 K = 2 BRKGA ILP BRKGA ILP Melhor Média Tempo MBC (GAP) Tempo Melhor Média Tempo MBC (GAP) Tempo SW-100-3-0d1-trial1 35 35.0 < 0.01 35* 86.58 18 18.0 0.03 18 ( 66.0 ) 3600 SW-100-3-0d2-trial1 21 21.0 < 0.01 21* 5.72 16 16.0 0.01 16 ( 62.0 ) 3600.0 SW-100-3-0d2-trial3 25 25.0 < 0.01 25* 9.13 19 19.0 < 0.01 19 ( 65.0 ) 3600.0 SW-100-4-0d1-trial1 8 8.0 3.41 8* 8.21 7 7.0 0.08 7 ( 14.00 ) 3600.0 SW-100-4-0d1-trial2 8 8.0 4.41 8* 20.69 7 7.0 60.0 6* 52.07 SW-100-4-0d1-trial3 8 8.6 42.96 8* 33.14 7 7.0 0.11 7 ( 14.00 ) 3600.0 SW-100-4-0d2-trial1 8 8.0 60.0 7* 15.48 7 7.0 60.0 6* 18.33 SW-100-4-0d2-trial2 8 8.0 0.04 8* 492.69 7 7.0 60.0 6* 160.25 SW-100-4-0d2-trial3 8 8.0 0.01 8* 579.89 7 7.0 60.0 6* 251.12 SW-100-4-0d3-trial1 8 8.0 60.0 7* 49.5 7 7.0 60.0 6* 7.33 SW-100-4-0d3-trial2 8 8.0 60.0 7* 850.53 7 7.0 60.0 6* 21.28 SW-100-4-0d3-trial3 8 8.0 60.0 7* 27.1 7 7.0 60.0 6* 23.33 SW-100-5-0d1-trial1 9 9.0 60.0 8* 4.81 7 7.0 0.03 7 ( 14.00 ) 3600.0 SW-100-5-0d1-trial2 9 9.0 0.01 9* 1042.15 7 7.0 0.69 7 ( 14.00 ) 3600.0 SW-100-5-0d1-trial3 9 9.0 60.0 8* 47.93 7 7.0 2.26 7 ( 14.00 ) 3600.0 SW-100-5-0d2-trial1 8 8.0 0.08 8* 57.74 7 7.0 0.01 7 ( 14.00 ) 3600.0 SW-100-5-0d2-trial2 8 8.0 0.02 8* 146.87 7 7.0 60.0 6* 238.55 SW-100-5-0d2-trial3 8 8.0 0.02 8* 800.17 7 7.0 60.0 6* 1318.86 SW-100-5-0d3-trial1 8 8.0 60.0 7* 539.46 7 7.0 60.0 6* 51.11 SW-100-5-0d3-trial2 8 8.0 60.0 7* 214.58 7 7.0 60.0 6* 19.63 SW-100-5-0d3-trial3 8 8.0 60.0 7* 42.49 7 7.0 60.0 6* 48.14 SW-100-6-0d1-trial1 8 8.0 60.0 7* 26.87 6 6.8 49.81 6* 23.14 SW-100-6-0d1-trial2 8 8.0 60.0 7* 19.49 6 6.9 55.36 6* 0.01 SW-100-6-0d1-trial3 8 8.0 60.0 7* 2125.69 6 6.7 46.77 6* 144.46 SW-100-6-0d2-trial1 7 7.9 56.92 7* 21.08 6 6.0 8.31 6* 0.01 SW-100-6-0d2-trial2 7 7.0 0.75 7* 0.02 6 6.0 0.71 6* 0.01 SW-100-6-0d2-trial3 7 7.0 3.88 7* 0.02 6 6.0 0.69 6* 0.01 SW-100-6-0d3-trial1 7 7.0 0.38 7* 0.02 6 6.0 0.11 6* 0.01 SW-100-6-0d3-trial2 7 7.0 0.21 7* 0.02 6 6.0 0.07 6* 0.01 SW-100-6-0d3-trial3 7 7.0 0.27 7* 0.02 6 6.0 0.07 6* 0.01 SW-1000-3-0d2-trial1 69 69.0 0.45 69 ( 86.0 ) 3600 61 61.0 1.78 61 ( 85.0 ) 3600 SW-1000-3-0d2-trial2 69 69.0 0.34 69 ( 86.0 ) 3600 63 63.0 3.04 63 ( 86.0 ) 3600 SW-1000-3-0d3-trial2 47 47.0 0.28 47 ( 78.0 ) 3600 42 42.0 5.92 42 ( 79.0 ) 3600 SW-1000-4-0d1-trial1 15 15.6 44.22 15 ( 33.0 ) 3600 14 14.0 1.52 14 ( 93.0 ) 3600 SW-1000-4-0d1-trial2 15 15.0 0.73 15 ( 93.0 ) 3600 13 13.8 53.56 13 ( 92.0 ) 3600 SW-1000-4-0d1-trial3 15 15.0 3.61 15 ( 33.0 ) 3600 13 13.4 41.08 14 ( 93.0 ) 3600 SW-1000-4-0d2-trial1 13 13.9 54.8 14 ( 93.0 ) 3600 12 12.0 8.82 12 ( 92.0 ) 3600 SW-1000-4-0d2-trial2 13 13.0 3.66 13 ( 92.0 ) 3600 12 12.0 1.5 12 ( 92.0 ) 3600 SW-1000-4-0d2-trial3 13 13.0 2.78 13 ( 92.0 ) 3600 12 12.0 0.69 12 ( 92.0 ) 3600 SW-1000-4-0d3-trial1 13 13.0 0.02 13 ( 92.0 ) 3600 12 12.0 0.01 12 ( 92.0 ) 3600 SW-1000-4-0d3-trial3 13 13.0 0.01 13 ( 92.0 ) 3600 12 12.0 0.01 12 ( 92.0 ) 3600 SW-1000-5-0d1-trial1 15 15.0 21.42 15 ( 33.0 ) 3600 14 14.0 2.36 14 ( 93.0 ) 3600 SW-1000-5-0d1-trial2 15 15.0 1.41 15 ( 93.0 ) 3600 13 13.1 20.09 13 ( 92.0 ) 3600 SW-1000-5-0d1-trial3 15 15.0 0.93 15 ( 93.0 ) 3600 13 13.5 42.74 14 ( 93.0 ) 3600 SW-1000-5-0d2-trial1 14 14.0 0.03 14 ( 93.0 ) 3600 12 12.0 13.25 12 ( 92.0 ) 3600 SW-1000-5-0d2-trial2 13 13.0 21.01 13 ( 92.0 ) 3600 12 12.0 3.72 12 ( 92.0 ) 3600 SW-1000-5-0d2-trial3 13 13.0 3.86 13 ( 92.0 ) 3600 12 12.0 2.24 12 ( 92.0 ) 3600 SW-1000-5-0d3-trial1 13 13.0 0.02 13 ( 92.0 ) 3600 12 12.0 0.01 12 ( 92.0 ) 3600 SW-1000-5-0d3-trial2 13 13.0 0.02 13 ( 92.0 ) 3600 12 12.0 0.01 12 ( 92.0 ) 3600 SW-1000-5-0d3-trial3 13 13.0 0.02 13 ( 92.0 ) 3600 12 12.0 0.02 12 ( 92.0 ) 3600 SW-1000-6-0d1-trial1 13 13.0 0.85 13 ( 92.0 ) 3600 12 12.0 0.07 12 ( 92.0 ) 3600 SW-1000-6-0d1-trial2 13 13.0 0.05 13 ( 92.0 ) 3600 12 12.0 0.03 12 ( 25.0 ) 3600 SW-1000-6-0d1-trial3 13 13.0 0.13 13 ( 92.0 ) 3600 12 12.0 0.04 12 ( 92.0 ) 3600 SW-1000-6-0d2-trial1 12 12.0 0.03 12 ( 92.0 ) 3600 11 11.0 0.01 11 ( 91.0 ) 3600 SW-1000-6-0d2-trial2 12 12.0 0.02 12 ( 92.0 ) 3600 11 11.0 0.01 11 ( 91.0 ) 3600 SW-1000-6-0d2-trial3 12 12.0 0.02 12 ( 92.0 ) 3600 11 11.0 0.01 11 ( 91.0 ) 3600 SW-1000-6-0d3-trial1 11 11.9 56.84 11 ( 91.0 ) 3600 10 10.7 49.91 11 ( 91.0 ) 3600 SW-1000-6-0d3-trial2 11 11.9 57.61 12 ( 92.0 ) 3600 10 10.7 48.84 11 ( 91.0 ) 3600 SW-1000-6-0d3-trial3 11 11.9 55.29 12 ( 92.0 ) 3600 10 10.3 37.25 10 ( 90.0 ) 3600 Continua na próxima página https://proceedings.science/p/193575?lang=pt-br DOI: 10.59254/sbpo-2024-193575 Tabela 1 – continuação da página anterior Instância K = 1 K = 2 BRKGA ILP BRKGA ILP Melhor Média Tempo MBC (GAP) Tempo Melhor Média Tempo MBC (GAP) Tempo # Melhor solução 96 99 96 100 6. Conclusão Este trabalho apresenta diversas contribuições para o MINIMUM BROADCAST CENTER (MBC): um modelo de Programação Linear Inteira (ILP), uma metaheurística utilizando Algoritmo Genético com Chaves Aleatórias Viciadas (BRKGA) e um lower bound. Além disso, destaca a relevância do estudo sobre o MBC em redes de computadores, especialmente no contexto do projeto de redes para cidades inteligentes que utilizam sistemas distribuídos e a Internet das Coisas (IoT). O MBC envolve a definição de um conjunto de nós fontes e, a partir desse conjunto, a determinação do MINIMUM BROADCAST TIME (MBT). A análise comparativa entre o BRKGA e o ILP em 111 instâncias demonstrou que o BRKGA encontrou soluções equiparáveis às do ILP em diversas instâncias, indicando sua eficácia como heurística para resolver o problema. O desempenho consistente do BRKGA foi evidenciado pelo fato de que o valor da melhor solução encontrada foi igual à média das melhores soluções, destacando a consistência em seu desempenho. Em trabalhos futuros, pretende-se realizar estudos sobre outras variantes ou problemas correlacionados aos problemas MBC e MBT: (i) MBC com arestas/vértices ponderados, (ii) estudos de lower bound para o MBC, (iii) o problema Minimum Multicast Time [Wieselthier et al., 2002], (iv) entre outros."
        },
        {
            "titulo": "Cortes do tipo capacidade para o Problema de Cobertura Multi-Veículo",
            "informacoes_url": "https://proceedings.science/p/193775?lang=pt-br",
            "idioma": "pt-br",
            "storage_key": "galoa-proceedings--sbpo-2024--193775.pdf",
            "autores": [
                {
                    "nome": "Bruno Davi Mattos de Oliveira",
                    "afiliacao": "Universidade Federal Fluminense",
                    "orcid": null
                },
                {
                    "nome": "Artur Alves Pessoa",
                    "afiliacao": "Universidade Federal Fluminense",
                    "orcid": null
                },
                {
                    "nome": "Marcos Costa Roboredo",
                    "afiliacao": "Universidade Federal Fluminense",
                    "orcid": null
                }
            ],
            "data_publicacao": null,
            "resumo": "O Problema do Roteamento Multi-Veículos com Cobertura (m-CTP) envolve um depósito e três subconjuntos distintos que representam clientes, facilidades obrigatórias e facilidades opcionais. Cada cliente está vinculado a um subconjunto específico de facilidades opcionais que definem seu conjunto de cobertura. O objetivo é determinar um conjunto de rotas com custo mínimo que satisfazem as seguintes restrições: cada rota começa e termina no depósito; cada facilidade obrigatória é visitada exatamente uma vez em uma única rota; cada rota visita não mais do que p facilidades e tem um custo máximo de q; para cada cliente, pelo menos uma facilidade opcional de seu conjunto de cobertura deve ser visitada por uma das rotas. Neste artigo, apresentamos uma nova família de cortes tipo capacidade e relatamos várias experiências que comprovam a eficácia do algoritmo e cortes propostos.",
            "keywords": [
                "Problema de Cobertura Multi-Veículo",
                "Branch-and-cut-and-price",
                "Desigualdades"
            ],
            "referencias": [
                "Achterberg, T., Koch, T., e Martin, A. (2005). Branching rules revisited. Operations Research Letters, 33(1):42–54.",
                "Allahyari, S., Salari, M., e Vigo, D. (2015). A hybrid metaheuristic algorithm for the multi-depot covering tour vehicle routing problem. European Journal of Operational Research, 242(3):756–768. ISSN 0377-2217. URL https://www.sciencedirect.com/science/article/pii/S0377221714008704.",
                "Baldacci, R., Mingozzi, A., e Roberti, R. (2011). New route relaxation and pricing strategies for the vehicle routing problem. Operations Research, 59(5):1269–1283.",
                "Ben Mohamed, I., Klibi, W., Sadykov, R., Şen, H., e Vanderbeck, F. (2023). The two-echelon stochastic multi-period capacitated location-routing problem. European Journal of Operational Research, 306(2):645–667.",
                "Bulhões, T., Sadykov, R., Subramanian, A., e Uchoa, E. (2020). On the exact solution of a large class of parallel machine scheduling problems. Journal of Scheduling, 23.",
                "Contardo, C. e Martinelli, R. (2014). A new exact algorithm for the multi-depot vehicle routing problem under capacity and route length constraints. Discrete Optimization, 12.",
                "Gendreau, M., Laporte, G., e Semet, F. (1997). The covering tour problem. Operations Research, 45(4):568–576.",
                "Glize, E., Roberti, R., Jozefowiez, N., e Ngueveu, S. U. (2020). Exact methods for mono-objective and bi-objective multi-vehicle covering tour problems. European Journal of Operational Research, 3:812–824.",
                "Ha, M. H., Bostel, N., Langevin, A., e Rousseau, L. M. (2013). An exact algorithm and a metaheuristic for the multi-vehicle covering tour problem with a constraint on the number of vertices. European Journal of Operational Research, 226:211–220.",
                "Hachicha, M., Hodgson, M. J., Laporte, G., e Semet, F. (2000). Heuristics for the multi-vehicle covering tour problem. Computers & Operations Research, 27:29–42.",
                "Kammoun, M., Derbel, H., Ratli, M., e Jarboui, B. (2015). A variable neighborhood search for solving the multi-vehicle covering tour problem. Electronic Notes in Discrete Mathematics, 47:285–292.",
                "Lopes, R., Souza, V. A., e da Cunha, A. S. (2013). A branch-and-price algorithm for the multi-vehicle covering tour problem. Electronic Notes in Discrete Mathematics, 44:61–66.",
                "Margolis, J. T., Song, Y., e Mason, S. J. (2021). A multi-vehicle covering tour problem with speed optimization. Networks, 79:119–142.",
                "Naji-Azimi, Z., Renaud, J., Ruiz, A., e Salari, M. (2012). A covering tour approach to the location of satellite distribution centers to supply humanitarian aid. European Journal of Operational Research, 222:596–605.",
                "Pecin, D., Pessoa, A., Poggi, M., e Uchoa, E. (2016). Improved branch-cut-and-price for capacitated vehicle routing. Mathematical Programming Computation, 9.",
                "Pessoa, A., Sadykov, R., Uchoa, E., e Vanderbeck, F. (2020). A generic exact solver for vehicle routing and related problems. Mathematical Programming, 183:483–523.",
                "Pessoa, A., Sadykov, R., Uchoa, E., e Vanderbeck, F. (2018). Automation and combination of linear-programming based stabilization techniques in column generation. INFORMS Journal on Computing, 30.",
                "Pham, T. A., Hà, M. H., e Nguyen, X. H. (2017). Solving the multi-vehicle multi-covering tour problem. Computers & Operations Research, 88:258–278.",
                "Righini, G. e Salani, M. (2006). Symmetry helps: Bounded bi-directional dynamic programming for the elementary shortest path problem with resource constraints. Discrete Optimization, 3(3):255–273.",
                "Roboredo, M., Sadykov, R., e Uchoa, E. (2023). Solving vehicle routing problems with intermediate stops using vrpsolver models. Networks, 81(3):399–416.",
                "Sadykov, R., Uchoa, E., e Pessoa, A. (2021). A bucket graph–based labeling algorithm with application to vehicle routing. Transportation Science, 55(1):4–28.",
                "Soares, V. C. e Roboredo, M. (2023). On the exact solution of the multi-depot open vehicle routing problem. Optim Lett.",
                "Uchoa, E., Pecin, D., Pessoa, A., Poggi, M., Vidal, T., e Subramanian, A. (2017). New benchmark instances for the capacitated vehicle routing problem. European Journal of Operational Research, 257(3):845–858."
            ],
            "artigo_completo": "Cortes do tipo capacidade para o Problema de Cobertura Multi-Veículo. RESUMO O Problema do Roteamento Multi-Veículos com Cobertura (m-CTP) envolve um depósito e três subconjuntos distintos que representam clientes, facilidades obrigatórias e facilidades opcio- nais. Cada cliente está vinculado a um subconjunto específico de facilidades opcionais que definem seu conjunto de cobertura. O objetivo é determinar um conjunto de rotas com custo mínimo que satisfaçam as seguintes restrições: cada rota começa e termina no depósito; cada facilidade obri- gatória é visitada exatamente uma vez em uma única rota; cada rota visita não mais do que p facilidades e tem um custo máximo de q; para cada cliente, pelo menos uma facilidade opcional de seu conjunto de cobertura deve ser visitada por uma das rotas. Neste artigo, apresentamos uma nova família de cortes tipo capacidade e relatamos várias experiências que comprovam a eficácia do algoritmo e cortes propostos. PALAVRAS CHAVE. Problema de Cobertura Multi-veículo, Branch-and-cut-and-price, De- sigualdades. https://proceedings.science/p/193775?lang=pt-br DOI: 10.59254/sbpo-2024-193775 1. Introdução O m-CTP foi proposto por Hachicha et al. [2000] e é formalmente definido da seguinte maneira. Seja G = (V, E) um grafo completo e não direcionado. O conjunto de nós é V = 0∪M ∪ O∪C, onde 0 representa o depósito, M = 1, ..., m representa o conjunto de instalações obrigatórias, O = m + 1, ...m + o representa o conjunto de instalações opcionais e C = m + o + 1, ..., m + o + c representa o conjunto de clientes. Cada aresta e ∈E é associada a um custo de viagem ce. Cada cliente j ∈C está associado a um conjunto de cobertura ϕ(j) ⊆O. O objetivo do m-CTP é projetar um conjunto de rotas finitas com custo total de viagem mínimo satisfazendo as seguintes restrições: cada rota deve começar e terminar no depósito; cada instalação obrigatória i ∈M é visitada exata- mente uma vez em todas as rotas; para cada cliente j ∈C, há pelo menos uma instalação opcional i ∈ϕ(j) que é visitada por uma das rotas; cada rota visita no máximo p instalações; o custo máximo de cada rota é q. Para os casos específicos do m-CTP com q = +∞ou p = +∞, os referimos, respectivamente, como m-CTP-p e m-CTP-q. Ao longo deste trabalho, podemos usar o termo m- CTP para denotar as instâncias do problema onde ambos os tipos de restrições estão presentes, o que deve ficar claro a partir do contexto. Para ilustrar o m-CTP, apresentamos uma instância simplificada com M = {1}, O = {2, 3, 4}, C = {5, 6}, p = 2, q = +∞, ϕ(5) = {3, 4} e ϕ(6) = {2}. Omitimos os custos de viagem. A Figura 1 mostra um exemplo de uma solução viável para a instância proposta, onde os nós marcados em amarelo, vermelho, verde e azul representam, respectivamente, o depósito, a instalação obrigatória, as instalações opcionais e os clientes. Em torno de cada cliente, deline- amos uma circunferência vermelha tracejada. As instalações opcionais dentro da circunferência representam o conjunto de cobertura do cliente. 0 3 4 2 1 5 6 Figura 1: Exemplo de uma solução para uma instância do m-CTP. O PCMV foi inicialmente proposto por Hachicha et al. [2000], que também introduziu heurísticas para sua resolução. Ao longo do tempo, outros algoritmos foram apresentados por di- versos autores, como Naji-Azimi et al. [2012], Lopes et al. [2013], Ha et al. [2013], Kammoun et al. [2015], Glize et al. [2020]. Além da versão clássica do PCMV, a literatura também aborda algumas variantes, como a variante com múltiplos depósitos, proposta por Allahyari et al. [2015], a variante em que os clientes devem ser atendidos mais de uma vez, mencionada em Pham et al. [2017], e a variante com otimização de velocidade, discutida por Margolis et al. [2021]. Para o m-CTP-p o melhor algoritmo exato é o proposto por Glize et al. [2020], onde foi desenvolvido um algoritmo branch-and-cut-price (BCP) capaz de resolver instâncias com até |V | = 200. No entanto, algumas instâncias não foram resolvidas até a otimalidade ou exigiram um tempo considerável para serem solucionadas por ambos os métodos. Já para o m-CTP, não há nenhum método exato na literatura, apenas métodos heurísticos, como a proposta por Pham et al. [2017]. https://proceedings.science/p/193775?lang=pt-br DOI: 10.59254/sbpo-2024-193775 2. Modelo BCP Nesta seção, apresentamos o modelo BCP para o m-CTP. Um modelo BCP é composto por uma formulação MIP onde as variáveis são chamadas de variáveis originais, e um subproblema que define um conjunto adicional de variáveis (ou colunas), cada uma associada a uma solução do subproblema. As variáveis originais na formulação MIP são então requeridas a ser uma combinação linear das colunas, fortalecendo ainda mais a relaxação linear da formulação MIP. No caso do m- CTP, o subproblema é um Problema do Caminho Mais Curto com Restrição de Recurso (RCSPP), e cada variável original conta o número de vezes que uma aresta de G é percorrida por uma solução. Para definir o subproblema RCSP, mostramos como traduzir G em um grafo direcionado G′ que é usado como entrada para o solucionador RCSP. Chamamos isso de grafo gerador de caminho. Para empregar técnicas avançadas que melhoram o desempenho do BCP, também definimos conjuntos de embalagem, que são subconjuntos de vértices de G′ que podem ser usados no máximo uma vez em uma solução completa. 2.1. Grafo gerador de caminho Seja G′ = (V ′, A′) um grafo direcionado tal que V ′ = v0, v1, . . . , v|M|+|O| e A′ = (vi, vj), (vj, vi)|i, j ∈V ′, i < j. Seja ρ um caminho que começa e termina no nó v0 tal que este nó não seja visitado no meio do caminho. O caminho ρ está associado a dois números não negativos S1 ρ e S2 ρ que representam o consumo acumulado de dois recursos. S1 ρ e S2 ρ são calculados da seguinte forma. Quando ρ começa, S1 ρ = S2 ρ = 0. Sempre que uma aresta (vi, vj) ∈A′ é percorrida, os valores de S1 ρ e S2 ρ são aumentados da seguinte forma: Se i = 0 ou j = 0, o consumo de S1 ρ é acrescido em 0, 5. Caso contrário, é acrescido em 1, 0. Para S2 ρ, seu consumo é acrescido em c(i,j). Dizemos que o caminho ρ é restrito por recursos se S1 ρ ≤p e S2 ρ ≤q. A Figura 2 ilustra o grafo gerador de caminhos para o exemplo simplificado proposto, onde marcamos em amarelo, verde e vermelho o depósito, as facilidades opcionais e obrigatórias, respectivamente. Em cada aresta, denotamos por s1 e s2 o aumento no valor de S1 ρ e S2 ρ, respectivamente. v0 v1 v2 v3 v4 s1 = 0.5, s2 = c(0,1) s1 = 0.5, s2 = c(0,2) s1 = 0.5, s2 = c(0,3) s1 = 0.5, s2 = c(0,4) s1 = 1, s2 = c(1,2) s1 = 1, s2 = c(1,3) s1 = 1, s2 = c(1,4) s1 = 1, s2 = c(2,3) s1 = 1, s2 = c(2,4) s1 = 1, s2 = c(3,4) Figura 2: Grafo gerador de caminho para o exemplo dado. 2.2. Fomulação Mestre Nesta seção, introduzimos uma formulação MIP que considera variáveis de caminho sobre G′ definido anteriormente. A ideia por trás da formulação proposta é que cada rota que visita no https://proceedings.science/p/193775?lang=pt-br DOI: 10.59254/sbpo-2024-193775 máximo p facilidades e com um custo total menor ou igual a q está associada a uma variável de caminho em G′. Especificamente, a formulação usa uma variável inteira xe para cada e ∈E′′, onde E′′ = e = (i, j) ∈E|i, j ∈0 ∪M ∪O. Cada variável xe indica quantas vezes a aresta e é usada na solução. Seja P o conjunto de caminhos restritos por recursos sobre o grafo G′. Para cada ρ ∈P, a formulação considera uma variável inteira λρ para indicar o número de vezes que o caminho ρ é usado na solução. Além das variáveis, a formulação usa os seguintes conjuntos: o conjunto δ(S) = (i, j) ∈E′′|(i ∈S ∧j /∈S) ∨(i /∈S ∧j ∈S), para um dado S ⊆0 ∪M ∪O; a constante ha ρ indica o número de vezes que uma aresta a ∈A′ é usada no caminho ρ ∈P; o conjunto M(e) = (vi, vj), (vj, vi), para cada e = (i, j) ∈E′′. A formulação segue. Min X e∈E′′ cexe (1a) s.t. X e∈δ({i}) xe = 2, i ∈M; (1b) X e∈δ({i}) xe ≤2, i ∈O; (1c) X e∈δ(ϕ(j)) xe ≥2, j ∈C; (1d) xe = X ρ∈P X a∈M(e) ha ρλρ, e ∈E′′; (1e) 1 ≤ X ρ∈P λρ ≤|M| + |O|; (1f) xe ∈Z, ∀e ∈E′′; (1g) λρ ≥0, ρ ∈P (1h) A função objetivo (1a) minimiza o custo total das rotas. As restrições (1b) garantem que cada nó obrigatório seja visitado exatamente uma vez. As restrições (1c) garantem que cada nó opcional seja visitado no máximo uma vez. As restrições (1d) garantem que haja pelo menos um nó visitado em ϕ(j), para cada cliente j ∈C. As restrições (1e) garantem a relação entre as variáveis λ e x. Para um dado e = (i, j) ∈E′′, o valor de xe é dado pelo número de vezes que as arestas em M(e) são percorridas considerando todos os caminhos da solução ótima. As restrições (1f) garantem que a solução tenha pelo menos 1 caminho e no máximo |M| + |O|. Como permitimos que os caminhos não elementares sejam soluções do RCSPP, é possível encontrar uma solução inteira para as variáveis x, mas uma solução fracionária para as variáveis λ, onde o grau de uma instalação opcional i ∈O é igual a 1, ou seja, existe e∗∈δ(i) tal que P e∈δ(i) xe = xe∗= 1. Para evitar ter que fazer branch nas variáveis λ, inserimos a seguinte restrição sob demanda, por inspeção: xe∗≤P e∈δ(i)\\e∗xe. 2.3. Packing Sets Nesta seção, definimos os packing sets que podem ser explorados por solucionadores BCP para ativar recursos avançados. Seja SV ⊂2V ′\\v0 uma coleção de subconjuntos mutuamente disjuntos de V ′ \\ v0. Dizemos que os conjuntos em SV são packing sets se houver pelo menos uma solução ótima para a formulação (1), satisfazendo as seguintes restrições: https://proceedings.science/p/193775?lang=pt-br DOI: 10.59254/sbpo-2024-193775 X ρ∈P X v∈S hρ v ! λρ ≤1, S ∈SV , (2) onde hρ v indica quantas vezes o nó v aparece no caminho ρ. Em outras palavras, para cada conjunto de agrupamento S ∈SV , no máximo um nó neste conjunto pode ser percorrido por um caminho e ele pode ocorrer no máximo uma vez. Em nosso modelo, definimos um conjunto de agrupamento diferente vi para cada i ∈M ∪O uma vez que cada facilidade é visitada no máximo uma vez. Para detalhes sobre como os elementos do estado-da-arte de BCP para roteamento podem ser ativados com base nos packing sets fornecidos, consulte Pessoa et al. [2020]. 3. Uma nova família de cortes para o m-CTP Nesta seção, introduzimos um conjunto de desigualdades válidas para o m-CTP. Essas desigualdades podem ser vistas como uma generalização das seguintes restrições propostas por Gendreau et al. [1997] para uma versão do m-CTP que considera apenas uma única rota: X e∈δ(S) xe ≥2, ∀S ⊆M ∪O: S ∩M ̸= ∅ou ϕ(j) ⊆S, para algum j ∈C (3) As restrições (3) garantem que um determinado conjunto S ⊆M ∪O deve ser visitado por pelo menos um veículo (que entra e sai de S) quando há uma instalação obrigatória em S, ou quando todas as instalações do conjunto de cobertura de um determinado cliente estão em S. Note que, se tivermos S = ϕ(j), j ∈C, obtemos as restrições (1d). O conjunto proposto de desigualdades válidas visa identificar casos em que o número de veículos que devem visitar um determinado subconjunto S de instalações é maior que um. Para isso, utilizados do limite p no número de instalações que podem ser visitadas por cada veículo. Se pudermos provar que pelo menos α instalações de S devem ser visitadas em qualquer solução viável, então o número de veículos que entram (e saem) de S deve ser pelo menos ⌈α/p⌉. Nas desigualdades propostas, α é calculado como o número de instalações obrigatórias em S mais o valor objetivo ótimo para uma relaxação linear de um Problema de Cobertura de Conjuntos com uma função objetivo modificada que minimiza o número de instalações opcionais de S que são visitadas. Esse método leva à seguinte desigualdade: X e∈δ(S) xe ≥2K(S), ∀S ⊆M ∪O, (4) onde, K(S) =    |S ∩M| + min ξ∈R|O| +    X i∈S∩O ξi | X i:i∈ϕ(j) ξi ≥1, ∀j ∈C     /p   . A partir de agora, nos referiremos à desigualdade (4) como um Corte de Capacidade de Cobertura (CCC). Para ilustrar a desigualdade, considere uma instância do m-CTP com p = 2. Para esta instância, tomamos S = i1, i2, i3, onde i1 ∈M, i2, i3 ∈O e existem dois clientes j1, j2 ∈C tal que ϕ(j1) = i2 e ϕ(j2) = i3. A Figura 3 ilustra a instância e o conjunto S. A Proposição 1 demonstra que o CCC é válido para o m-CTP. https://proceedings.science/p/193775?lang=pt-br DOI: 10.59254/sbpo-2024-193775 i1 S i2 j1 i3 j2 S xe xe xe xe Figura 3: Uma ilustração dos cortes propostos. Proposição 1. O CCC é válido para o m-CTP. Demonstração. Seja S ⊆M ∪O. Primeiro, provamos que pelo menos |S ∩M| + z∗instalações em S devem ser visitadas em qualquer solução viável do m-CTP, onde z∗= min ξ∈R|O| +    X i∈S∩O ξi | X i:i∈ϕ(j) ξi ≥1, ∀j ∈C    . De fato, pela definição do m-CTP, todas as |S ∩M| instalações obrigatórias em S devem ser visitadas. Em relação às instalações opcionais em S, z∗representa um limite inferior para o número mínimo de instalações opcionais visitadas em S em qualquer solução viável. Portanto, nenhuma solução do m-CTP pode visitar menos de |S∩M|+z∗instalações em S. Agora, seja x uma solução viável para (1). Como nenhuma rota pode visitar mais do que p instalações, o número total de vezes que a solução percorre uma aresta de δ(S) deve ser pelo menos 2⌈(|S ∩M| + z∗)/p⌉. Assim, (4) deve ser satisfeita por x. 3.1. Algoritmo de separação Nossa abordagem para encontrar os CCC violados envolve resolver um problema de separação. Para cada valor fixo de K(S), modelamos este problema como um MIP. Aqui, S ⊆ M ∪O é buscado de forma a minimizar o lado esquerdo da desigualdade (4), com a restrição de que K(S) seja maior ou igual a k, onde k varia de 1 a kmax. O valor máximo de k, denotado como kmax, é obtido quando S contém todos os nós obrigatórios e opcionais (M ∪O). Esta abordagem nos permite explorar diferentes configurações de S, buscando identificar as violações dos CCC. Para cada i pertencente a M ∪O, introduzimos uma variável binária zi, que indica se i pertence a S (zi = 1) ou não (zi = 0). Além disso, para cada e ∈E′′, onde E′′ é o conjunto de arestas do grafo G′, introduzimos uma variável binária re que indica se e pertence à fronteira de S (re = 1) ou não (re = 0). Essas variáveis são cruciais para a formulação do problema e ajudam a definir as condições de validade dos cortes CCC. A partir dessas variáveis de primeiro nível, formulamos o problema de separação, bus- cando determinar o conjunto S que satisfaz as condições impostas e viola a desigualdade (4). https://proceedings.science/p/193775?lang=pt-br DOI: 10.59254/sbpo-2024-193775 Isso nos permite identificar eficientemente os cortes violados e, assim, fortalecer o modelo de otimização. Min X e∈E′′ ¯xere (5a) s.t. re ≥zi −zj, e = (i, j) ∈E′′ (5b) re ≥zj −zi, e = (i, j) ∈E′′ (5c) z0 = 0 (5d) X i∈M zi + min z′∈R|O| +    X i∈O ziξi | X i∈ϕ(j) ξi ≥1, ∀j ∈C   ≥(k −1)p + ϵ (5e) re ∈{0, 1}, e ∈E′′ (5f) zi ∈{0, 1}, i ∈M ∪O, (5g) onde ϵ é um número pequeno que ainda é suficientemente grande para garantir que o lado esquerdo de (5e) seja estritamente maior que (k −1)p, apesar de erros numéricos. A função objetivo (5a) visa minimizar o lado esquerdo de (4). As restrições (5b) e (5c) garantem a relação entre as variáveis r e z. A restrição (5d) garante que o depósito não está em S. A restrição (5e) garante que K(S) ≥k. Para ver isso, observe que ela assegura que  X i∈M zi + min z′∈R|O| +    X i∈O ziξi | X i∈ϕ(j) ξi ≥1, ∀j ∈C     /p > (k −1). (6) Como (5) não pode ser otimizada em sua forma atual, obtemos uma formulação equiva- lente substituindo o problema de otimização que aparece na Restrição (5e) por seu dual. Para isso, para cada j ∈C, seja yj a variável dual associada à restrição P i∈ϕ(j) z′ i ≥1. A formulação segue. Min (5a) (7a) s.t. (5b), (5c), (5d), (5f), (5g) (7b) X i∈M zi +                Max X j∈C yj s.t. X j∈C|i∈ϕ(j) yj ≤zi, i ∈O yj ≥0, j ∈C                ≥(k −1)p + ϵ, (7c) que é equivalente a: https://proceedings.science/p/193775?lang=pt-br DOI: 10.59254/sbpo-2024-193775 Min (5a) (8a) s.t. (5b), (5c), (5d), (5f), (5g) (8b) X i∈M zi + X j∈C yj ≥(k −1)p + ϵ (8c) X j∈σ(i) yj ≤zi, i ∈O (8d) yj ≥0 j ∈C. (8e) Nós utilizamos (8) para encontrar CCC violados, para k = 1, . . . , kmax. 4. Resultados Computacionais Nesta seção, compartilhamos os resultados obtidos pelo nosso modelo em três conjuntos distintos de instâncias. Os dois primeiros conjuntos são os mesmos utilizados por Glize et al. [2020] e Pham et al. [2017] para investigar o m-CTP-p e o m-CTP, respectivamente. O terceiro conjunto é uma contribuição original deste trabalho, inspirado no conjunto de instâncias de CVRP proposto por Uchoa et al. [2017] e abrangendo até 393 instalações. Todas as instâncias utilizadas nos experimentos estão disponíveis para acesso público no repositório online https://github. com/brunomattos1/m-ctp_instances. Optamos por resolver o modelo utilizando o framework VRPSolver, desenvolvido por Pessoa et al. [2020] com o intuito de simplificar a implementação de algoritmos BCP eficientes para problemas de roteamento de veículos e outros problemas relacionados. Escolhemos o framework VRPSolver para implementar o algoritmo BCP devido às suas características de ponta, tais como um algoritmo de rotulação bidirecional Righini e Salani [2006] no conceito de baldes, proposto por Sadykov et al. [2021], para resolver o subproblema de precificação, relaxamento de rota ng Baldacci et al. [2011], cortes de Chvátal-Gomory de classificação-1 com memória limitada, Pecin et al. [2016], enumeração de rotas, Contardo e Martinelli [2014], ramificação forte, Achterberg et al. [2005], técnica automática de estabilização dual, Pessoa et al. [2018]. Além disso, destacamos o sucesso comprovado do VRPSolver em várias variantes de VRP e de escalonamento, conforme demonstrado em Roboredo et al. [2023], Soares e Roboredo [2023], Ben Mohamed et al. [2023], Bulhões et al. [2020] e Pessoa et al. [2020]. Todos os testes foram realizados em um processador Intel(R) Core(TM) i7-10700 CPU@ 2.90GHz. O sistema operacional utilizado foi o Ubuntu e o algoritmo foi implementado em Julia uti- lizando o framework VRPSolver v0.4.1a (https://vrpsolver.math.u-bordeaux.fr/). O CPLEX 12.10 foi utilizado para resolver formulações LP e MIP. As tabelas apresentadas neste ar- tigo contêm apenas estatísticas médias. Dados detalhados para cada instância testada são fornecidos em um material suplementar online. 4.1. Resultados para Glize et al. [2020] e Pham et al. [2017] A Tabela 1 apresenta os indicadores de desempenho do nosso método sobre instâncias da literatura, e uma comparação entre as duas versões do algoritmo BCP proposto (com e sem CCC) e o melhor método exato da literatura para o m-CTP-p proposto por Glize et al. [2020]. Para as instâncias de m-CTP e m-CTP-p, nosso método utiliza como limites superiores iniciais os valores de solução encontrados pelas heurísticas propostas por Pham et al. [2017] e Kammoun et al. [2015], respectivamente. Em relação à comparação entre nosso algoritmo e o proposto por Glize et al. [2020], destacamos dois pontos. Primeiro, cada tempo de execução relatado pela literatura foi dividido por 1,5. Esse fator é a razão entre os scores do processador utilizado por nós e pela https://proceedings.science/p/193775?lang=pt-br DOI: 10.59254/sbpo-2024-193775 literatura obtidos em www.cpubenchmark.net, para um único thread. O segundo ponto é que a literatura considerou um limite de tempo de 7200s. Por esse motivo, definimos um limite de tempo de 4800s (7200/1.5) para experimentos sobre instâncias de m-CTP-p. Para as demais instâncias, definimos um limite de tempo de 7200s. Para cada problema (m-CTP ou m-CTP-p), indicamos a categoria das instâncias (Coluna Categoria) e o número de instâncias na categoria correspondente (Coluna #Inst.). Além disso, para cada metodologia comparada, apresentamos o número de soluções ótimas comprovadas dentro do limite de tempo (Coluna #Opt) e o tempo total médio consumido em segundos (Coluna T(s)). BCP proposto Glize et al. [2020] Sem CCC Com CCC Problema Categoria #Inst #Opt T(s) #Opt T(s) #Opt T(s) m-CTP-p |V ′| = 100, |M| = 0 32 32 4.2 32 1.7 32 1.9 m-CTP-p |V ′| = 100, |M| > 0 32 31 ≥151.3 32 55.1 32 2.1 m-CTP-p |V ′| = 200 32 27 ≥966.3 32 132.5 32 6.1 m-CTP |V ′| = 100, |M| = 0 64 - - 64 3.8 64 14.0 m-CTP |V ′| = 100, |M| > 0 64 - - 64 1.7 64 2.0 m-CTP |V ′| = 200 64 - - 63 206.1 63 128.1 Tabela 1: Resultado nas instância da literatura. A análise da Tabela 1 revela uma notável superioridade do nosso novo algoritmo BCP em relação ao método proposto por Glize et al. [2020] em todas as categorias avaliadas, tanto em termos de tempo de execução quanto no número de instâncias resolvidas de forma ótima. Uma observação significativa é que todas as instâncias de m-CTP-p foram resolvidas de forma ótima, mesmo na ausência do uso dos cortes CCC. Destaca-se que cinco instâncias de m-CTP-p foram solucionadas de forma ótima pela primeira vez neste estudo: A2-20-100-100-6, A2-20-100-100-8, B2-1-100-100-8, B2-20-100-100-6 e B2-20-100-100-8, com custos de solução ótima de, respecti- vamente, 20966, 18415, 13137, 25960 e 22082. A aplicação dos cortes CCC resultou em uma melhoria significativa no desempenho do nosso algoritmo, levando a ganhos de mais de uma ordem de magnitude. Quanto às instâncias de m-CTP, ambas as versões do nosso algoritmo alcançaram a solução ótima para 195 das 196 instâncias. É interessante observar que a vantagem obtida com a aplicação dos cortes foi mais expressiva para a categoria de instâncias de maior porte. A Tabela 2 fornece uma visão da redução do gap pela introdução de diferentes tipos de cortes em instâncias grandes da literatura, onde o número de vértices é de 200. Cada entrada na tabela representa a diferença percentual entre a melhor solução conhecida e o limite inferior obtido pela geração de colunas pura no nó raiz (Coluna Gap GC). Esta diferença percentual diminui quando aplicamos os cortes da literatura (3) na relaxação da geração de colunas (Coluna Cortes Lit.), indicando uma redução significativa na diferença de otimalidade. A introdução adicional dos CCC amplifica essa redução, como demonstrado na Coluna Cortes CCC. Além disso, a aplicação dos cortes de Chvátal-Gomory Rank-1, fornecidos pelo framework VRPSolver, resulta em uma redução adicional na diferença de otimalidade, conforme apresentado na Coluna Cortes R1C. Esses resultados destacam a importância dos cortes na melhoria da qualidade das soluções obtidas, mostrando como diferentes tipos de cortes podem trabalhar em conjunto para reduzir a lacuna entre o melhor valor conhecido e o limite inferior. Tal redução é essencial para aproximar os resultados obtidos do valor ótimo e demonstra a eficácia dos cortes na resolução de problemas de https://proceedings.science/p/193775?lang=pt-br DOI: 10.59254/sbpo-2024-193775 m-CTP-p m-CTP(q = 500) m-CTP(q = 250) GC Cortes GC Cortes GC Cortes Instância Gap Lit. CCC Rank-1 Gap Lit. CCC Rank-1 Gap Lit. CCC Rank-1 A2-1-100-100-4 4.22 0.20 77.8 100.00 3.25 0.00 100.00 - 6.80 0.35 39.61 16.73 A2-1-100-100-5 2.14 15.07 100.00 - 1.86 11.58 100.00 - 0.40 2.33 100.00 - A2-1-100-100-6 6.69 2.39 100.00 - 5.47 4.20 83.62 100.00 3.63 0.54 89.13 100.00 A2-1-100-100-8 6.50 4.57 65.60 100.00 8.32 0.24 26.21 15.13 7.71 0.26 25.82 9.89 A2-20-100-100-4 1.82 0.00 38.84 56.08 1.80 0.21 36.74 60.07 1.91 0.79 44.25 41.28 A2-20-100-100-5 4.15 1.13 48.28 89.74 3.39 0.63 62.44 82.77 3.49 2.56 65.21 100.00 A2-20-100-100-6 4.33 1.76 54.99 100.00 3.42 1.39 74.26 100.00 5.67 1.96 39.85 78.70 A2-20-100-100-8 7.06 1.92 46.12 85.59 5.07 1.07 63.82 86.57 8.46 0.98 38.49 89.67 B2-1-100-100-4 3.49 0.78 21.66 71.94 4.94 0.65 10.04 26.70 4.70 0.80 17.84 34.03 B2-1-100-100-5 2.15 2.05 100.00 - 4.51 1.36 25.58 59.89 5.44 1.33 14.04 41.96 B2-1-100-100-6 4.24 0.79 44.16 75.64 4.86 0.82 37.57 36.06 7.19 0.54 23.26 38.68 B2-1-100-100-8 5.36 1.99 25.51 100.00 6.18 0.49 45.97 81.90 17.16 0.15 2.36 17.84 B2-20-100-100-4 1.35 3.27 100.00 - 1.35 3.49 100.00 - 1.35 3.49 82.84 100.00 B2-20-100-100-5 2.97 0.92 30.72 78.67 2.95 0.81 33.60 73.56 2.95 1.04 31.35 79.97 B2-20-100-100-6 3.01 0.64 39.82 50.32 3.04 1.90 46.84 78.88 3.03 1.65 39.84 45.38 B2-20-100-100-8 4.85 1.68 31.05 100.00 4.83 2.06 33.52 100.00 4.49 1.61 32.21 60.82 Average 4.02 2.44 57.78 83.99 4.08 1.93 55.01 69.34 5.27 1.27 42.88 56.99 Tabela 2: Comparação na redução dos gaps. https://proceedings.science/p/193775?lang=pt-br DOI: 10.59254/sbpo-2024-193775 otimização. 5. Conclusão Neste trabalho, abordamos o m-CTP, uma variante dos Problemas de Roteamento de Veículos onde as rotas são responsáveis por visitar facilidades para atender clientes dentro de uma rede dada. Nesse cenário, as rotas são limitadas tanto pelo número de facilidades que podem vi- sitar quanto pelo custo total incorrido. Nosso foco foi desenvolver uma família de cortes robustos visando dois aspectos fundamentais do problema: cobertura de facilidades e capacidade do veículo. Além de um algoritmo para separá-los. Para avaliar a eficácia de nosso método e cortes propostos, conduzimos experimentos computacionais extensos divididos em duas fases. Inicialmente, aplicamos nosso modelo, tanto com quanto sem os cortes propostos, a uma coleção de 288 instâncias de referência da literatura. Os resultados indicaram que nosso método resolveu de forma ótima quase todas as instâncias, com ape- nas uma exceção. Além disso, comparamos nosso algoritmo com o melhor método existente, adap- tado para a variante do problema onde as limitações das rotas são baseadas apenas no número de facilidades visitadas. Impressionantemente, nossa abordagem superou o método existente mesmo sem a incorporação dos cortes propostos."
        },
        {
            "titulo": "Uma nova abordagem para o problema integrado de corte de estoque e sequenciamento de padrões",
            "informacoes_url": "https://proceedings.science/p/193724?lang=pt-br",
            "idioma": "pt",
            "storage_key": "galoa-proceedings--sbpo-2024--193724.pdf",
            "autores": [
                {
                    "nome": "Gabriel Gazzinelli Guimarães",
                    "afiliacao": "Instituto de Matemática, Estatística e Computação Científica (IMECC), Universidade Estadual de Campinas (UNICAMP)",
                    "orcid": ""
                },
                {
                    "nome": "Kelly Cristina Poldi",
                    "afiliacao": "Instituto de Matemática, Estatística e Computação Científica (IMECC), Universidade Estadual de Campinas (UNICAMP)",
                    "orcid": ""
                }
            ],
            "data_publicacao": "2022",
            "resumo": "Propomos uma nova abordagem para o Problema Integrado de Corte Unidimensional (CSP - Cutting Stock Problem) e o Problema de Minimização de Pilhas Abertas (MOSP - Minimization of Open Stacks), na qual o desperdício de material e o número de pilhas abertas são minimizados simultaneamente.",
            "keywords": [
                "Problema de corte de estoque",
                "Otimização biobjetivo",
                "Pilhas abertas"
            ],
            "referencias": [
                "Arbib, C., Marinelli, F., e Ventura, P. (2016). One-dimensional cutting stock with a limited number of open stacks: bounds and solutions from a new integer linear programming model. International Transactions in Operational Research, 23:47–63.",
                "Guimarães, G. G. e Poldi, K. C. (2023). Mathematical models for the cutting stock with limited open stacks problem. RAIRO-Operations Research, 57(4):2067–2085.",
                "Yanasse, H. H. e Senne, E. L. F. (2010). The minimization of open stacks problem: A review of some properties and their use in pre-processing operations. European Journal of Operational Research, 203:559–567."
            ],
            "artigo_completo": "Uma nova abordagem para o problema integrado de corte de estoque e sequenciamento de padrões. RESUMO Propomos uma nova abordagem para o Problema Integrado de Corte Unidimensional (CSP - Cutting Stock Problem) e o Problema de Minimização de Pilhas Abertas (MOSP - Mi- nimization of Open Stacks), na qual o desperdício de material e o número de pilhas abertas são minimizados simultaneamente. Nos referimos a essa extensão do CSP como o Problema de Corte com Pilhas Abertas (CSP-OS - Cutting Stock Problem with Open Stacks). Para resolver o CSP-OS, propomos três abordagens baseadas nos métodos de ε-restrição e soma ponderada. Desenvolvemos uma abordagem exata para resolver o Problema de Corte Unidimensional com um número Limi- tado de Pilhas Abertas (CS-LOSP - Cutting Stock with a Limited number of Open Stacks Problem), dividindo-o em subproblemas resolvidos via um solver de Programação Linear Inteira e propomos uma formulação que não requer conhecimento prévio dos padrões de corte viáveis. Realizamos tes- tes computacionais para verificar a qualidade das abordagens propostas e comparar seu desempenho com a formulação atual estado da arte da literatura. PALAVRAS CHAVE. Problema de corte de estoque. Otimização biobjetivo. Pilhas abertas. *Apoios CNPq e FAPESP 2022/05803-3 https://proceedings.science/p/193724?lang=pt-br 1. Introdução O Problema de Corte de Estoque Unidimensional (1D-CSP) é um problema NP-difícil com grande aplicação prática em diversos setores industriais. O objetivo é determinar a melhor forma de cortar um conjunto de objetos em itens de menores comprimentos para satisfazer a de- manda e otimizar a redução de desperdício de material. Um padrão de corte é a forma específica como um objeto é cortado. Uma solução para o CSP compreende um conjunto de padrões de corte P e o número de vezes que cada padrão de corte deve ser executado para atender a demanda. Con- sideramos o caso clássico do 1D-CSP em que todos os objetos têm o mesmo comprimento L, e a função objetivo é a minimização do número de objetos utilizados. Na prática, durante o processo de cortar os objetos em itens, esses itens, ao serem pro- duzidos, são colocados em pilhas; cada tipo de item é colocado em uma pilha diferente. Quando não houver mais padrões de corte contendo um tipo de item, a pilha desse tipo de item pode ser fe- chada; caso contrário, a pilha é considerada aberta. O Problema da Minimização de Pilhas Abertas (MOSP) visa determinar a ordem dos padrões de corte para minimizar o número máximo de pilhas abertas. Na literatura, CSP e MOSP são frequentemente resolvidos de forma independente. O CSP é resolvido primeiro e, em seguida, os padrões de corte são sequenciados para minimizar o número máximo de pilhas abertas. Como apontado em Arbib et al. [2016] e Guimarães e Poldi [2023], há desvantagens em resolver CSP e MOSP separadamente. A qualidade da solução do MOSP está relacionada ao conjunto de padrões de corte, e diferentes conjuntos podem resultar em diferentes resultados para o MOSP. Assim, resolver os problemas de forma independente pode não otimizar ambos os objetivos simultaneamente. Além disso, em aplicações reais, um limite predefinido pode limitar o número máximo de pilhas abertas simultaneamente, tornando inviável a solução do CSP. Uma abordagem alternativa é resolver o CSP com a restrição de que o número máximo de pilhas abertas não pode exceder um limite predefinido, conhecido como Problema de Corte com um número Limitado de Pilhas Abertas (CS-LOSP). A abordagem do CS-LOSP pode não ser ideal dependendo dos objetivos. Por exemplo, duas soluções que usam a mesma quantidade de material e respeitam a restrição quanto ao número máximo de pilhas abertas são consideradas idênticas em termos de optimalidade. Como afirmado em Yanasse e Senne [2010], há interesse em encontrar soluções que minimizem o número máximo de pilhas abertas em aplicações reais. Além disso, é impossível determinar antecipadamente o im- pacto que a restrição no número de pilhas terá sobre o número de objetos necessários para atender à demanda. Portanto, a integração do CSP e do MOSP pode ser melhor representada se considerar- mos um problema biobjetivo, minimizando simultaneamente o material desperdiçado e o número máximo de pilhas abertas. Assim, garantimos que a solução represente fielmente os objetivos dos dois problemas. Nesta pesquisa, propomos três abordagens para resolver o CSP-OS; essas abordagens de- pendem da solução de vários CS-LOSPs. Assim, também propomos uma abordagem para resolver o CS-LOSP unidimensional. A abordagem é baseada em uma formulação que, ao contrário dos principais modelos propostos na literatura, não requer conhecimento prévio dos padrões de corte e o número de variáveis e restrições é proporcional ao comprimento dos itens. Por outro lado, o número de variáveis e restrições, assim como o número de soluções simétricas, aumenta conforme a demanda exigida para os itens. Para avaliar a qualidade das abordagens propostas, realizamos expe- rimentos computacionais em um conjunto clássico de instâncias de CSP da literatura e um conjunto de instâncias geradas aleatoriamente propostas neste artigo. A solução obtida a partir da abordagem proposta para o CS-LOSP é comparada ao modelo para o CS-LOSP unidimensional proposto em Arbib et al. [2016], os resultados dos experimentos computacionais mostram que a metodologia de https://proceedings.science/p/193724?lang=pt-br solução desenvolvida neste trabalho apresenta resultados promissores para instâncias onde o com- primento dos tipos de itens é pequeno. Além disso, avaliamos a eficiência das três abordagens em encontrar a fronteira de Pareto para os dois conjuntos de instâncias. 2. Abordagem proposta para o CS-LOSP Modelos tradicionais para resolver o CS-LOSP unidimensional exigem a geração ante- cipada de todos os padrões de corte viáveis. Quando os itens são pequenos ou há muitos tipos diferentes, o número de padrões pode se tornar excessivamente grande. Propomos uma abordagem que não exige conhecimento prévio dos padrões de corte, sendo o número de variáveis e restrições proporcional ao comprimento dos itens, baseada no conceito de track proposto em Arbib et al. [2016]. Considerando C como o número máximo de pilhas abertas simultaneamente, tih como o elemento de T na linha i e coluna h; P como um conjunto de padrões de corte; α(j) como o j-ésimo padrão de corte em P e α(j) i como a quantidade de itens do tipo i obtida pelo j-ésimo padrão de corte em P. Uma track viável T é uma matriz matriz 0-1 com M linhas não nulas tal que: • Para j < k, i ≤M, se tij = tik = 1, então tih = 1 para todo j < h < k. Esta propriedade é conhecida como a Propriedade dos Uns Consecutivos (C1P). • ω(T) ≤C. Além disso, dizemos que P é suportado por T se para qualquer α(j) ∈P, existir uma coluna h em T tal que α(j) i > 0 =⇒tih > 0, i = 1, . . . , M. Em Arbib et al. [2016], é demonstrado que um conjunto de padrões de corte tem uma sequência tal que o número máximo de pilhas abertas é menor ou igual a C se, e somente se, este conjunto é suportado por uma track viável. Com base nisso, o CS-LOSP unidimensional pode ser reformulado como o problema de determinar um conjunto de padrões de corte P que atenda à demanda de itens, minimizando o desperdício de material e sendo suportado por uma track viável. Ademais, Arbib et al. [2016] mostra que uma track viável não-dominada tem H = M −C + 1 colunas. Nossa abordagem gera gradualmente as possíveis tracks viáveis e, para cada track T, de- termina a solução do CSP sujeita à restrição de que todos os padrões de corte são suportados por T. Chamamos isso de CSP modificado. A abordagem termina quando a melhor solução encontrada é igual a um limite inferior para o CS-LOSP ou todas as tracks são avaliadas. Para encontrar uma solução ótima para o CSP modificado, propomos um ILP que não requer conhecimento prévio dos padrões de corte, com o tamanho da formulação crescendo em função do comprimento dos itens. 3. Abordagens propostas para o CSP-OS Para resolver o CSP-OS, desenvolvemos três abordagens. A primeira baseia-se no método ε-restrição, a segunda no método das somas ponderadas e a terceira resulta da combinação dos dois métodos. Essencialmente, as abordagens consistem em decompor o problema biobjetivo em vários CS-LOSPs, de forma a obter diversas soluções eficientes para o problema. 4. Resultados dos experimentos computacionais Consideramos dois conjuntos de instâncias: um gerado pelo CUTGEN1, com 18 classes de 100 instâncias, e outro com cinco classes de instâncias geradas aleatoriamente. Os conjuntos variam em comprimento e demanda dos itens. Estes conjuntos foram escolhidos para destacar os pontos fortes e fracos do modelo proposto, que tem dificuldades em instâncias com compri- mento pequeno dos itens. Os dados aleatórios estão disponíveis em https://github.com/ ggazzinelli/1D-CS-LOSP. https://proceedings.science/p/193724?lang=pt-br Em relação ao CS-LOSP, avaliamos a abordagem proposta em termos de qualidade das soluções e tempo de execução, comparando-a com o modelo proposto em Arbib et al. [2016]. Para a maioria das instâncias, a formulação proposta em Arbib et al. [2016] apresentou os melhores resultados. A principal desvantagem do modelo proposto em Arbib et al. [2016] é o número exponencial de variáveis. Assim, para instâncias em que o comprimento do item é pequeno, a formulação tem dificuldades em encontrar soluções ótimas em um tempo razoável. Destacamos que, embora a abordagem proposta para o CS-LOSP seja mais adequada para lidar com instâncias com demanda mais baixa, tal abordagem foi capaz de lidar com instâncias com valores de demanda razoáveis, desde que o comprimento dos tipos de itens fosse pequeno. Assim, concluímos que, mesmo que o uso da abordagem proposta seja restrito a casos específicos, a abordagem é uma alternativa viável ao modelo proposto em Arbib et al. [2016]. Em relação ao CSP-OS, os resultados obtidos confirmam a natureza conflitante dos obje- tivos. De forma geral, notamos que para restrições fortes no número máximo de pilhas abertas, a quantidade de material consumida para satisfazer a demanda dos tipos de itens é significativamente maior. No entanto, é importante ressaltar que o trade-off é limitado para valores relativamente bai- xos na restrição referente ao número máximo de pilhas abertas simultaneamente. Desta forma, a partir de certo ponto, soluções com um maior número de pilhas abertas não consomem menos ob- jetos. A Figura 1 apresenta a fronteira de Pareto para a quinta instância da primeira classe gerada aleatoriamente e a décima instância da segunda classe gerada pelo gerador CUTGEN1. Figura 1: Fronteira de Pareto obtida pelas abordagens propostas. Aplicando as abordagens propostas, foi possível obter a fronteira de Pareto para 59 das 65 instâncias consideradas nos experimentos computacionais. Desta forma, concluímos que os métodos propostos são eficientes em resolver o problema biobjetivo. 5. Agradecimentos Os autores agradecem o apoio financeiro de CNPq e FAPESP 2022/05803-3."
        },
        {
            "titulo": "MODELO EXATO PARA O PROBLEMA DA GRADE DE HORÁRIO ESCOLAR CONSIDERANDO CUSTO PEDAGÓGICO E PREFERÊNCIAS DOCENTES: REALIDADE DOS INSTITUTOS FEDERAIS",
            "informacoes_url": "https://proceedings.science/p/193641?lang=pt-br",
            "idioma": "pt",
            "storage_key": "galoa-proceedings--sbpo-2024--193641.pdf",
            "autores": [
                {
                    "nome": "Filipe Eringer Garruth",
                    "afiliacao": "Instituto Federal do Espírito Santo - Serra",
                    "orcid": ""
                },
                {
                    "nome": "Leandro Colombi Resendo",
                    "afiliacao": "Instituto Federal do Espírito Santo - Serra",
                    "orcid": ""
                }
            ],
            "data_publicacao": "",
            "resumo": "Neste estudo, apresentamos uma formulação de Programação Linear Inteira (PLI) para resolver o problema de agendamento de horários escolares nos institutos federais de ensino, onde professores lecionam tanto no ensino médio quanto no superior.",
            "keywords": [
                "Programação Linear Inteira",
                "Alocação de grade de horários",
                "restrições pedagógicas"
            ],
            "referencias": [
                "Amaral, P. e Pais, T. C. (2016). Compromise ratio with weighting functions in a tabu search multi-criteria approach to examination timetabling. Computers & Operations Research, 72:160–174.",
                "Babaei, H., Karimpour, J., e Hadidi, A. (2015). A survey of approaches for university course timetabling problem. Computers & Industrial Engineering, 86:43–59. ISSN 0360-8352.",
                "Bettinelli, A., Cacchiani, V., Roberti, R., e Toth, P. (2015). An overview of curriculum-based course timetabling. Top, 23:313–349.",
                "Carter, M. W., Laporte, G., e Lee, S. Y. (1996). Examination timetabling: Algorithmic strategies and applications. Journal of the operational research society, 47:373–383.",
                "Ceschia, S., Di Gaspero, L., e Schaerf, A. (2023). Educational timetabling: Problems, benchmarks, and state-of-the-art results. European Journal of Operational Research, 308(1):1–18.",
                "Chen, M. C., Goh, S. L., Sabar, N. R., Kendall, G., et al. (2021). A survey of university course timetabling problem: perspectives, trends and opportunities. IEEE Access, 9:106515–106529.",
                "Daskalaki, S., Birbas, T., e Housos, E. (2004). An integer programming formulation for a case study in university timetabling. European journal of operational research, 153(1):117–135.",
                "Feizi-Derakhshi, M.-R., Babaei, H., e Heidarzadeh, J. (2012). A survey of approaches for university course timetabling problem. In Proceedings of 8th international symposium on intelligent and manufacturing systems, Sakarya University Department of Industrial Engineering, Adrasan, Antalya, Turkey, p. 307–321.",
                "Fonseca, G. H., Santos, H. G., Carrano, E. G., e Stidsen, T. J. (2017). Integer programming techniques for educational timetabling. European Journal of Operational Research, 262(1):28–39. ISSN 0377-2217.",
                "Kristiansen, S., Sørensen, M., e Stidsen, T. R. (2015). Integer programming for the generalized high school timetabling problem. Journal of Scheduling, 18:377–392.",
                "Leite, N., Melício, F., e Rosa, A. C. (2019). A fast simulated annealing algorithm for the examination timetabling problem. Expert systems with applications, 122:137–151.",
                "Schaerf, A. (1999). A survey of automated timetabling. Artificial intelligence review, 13:87–127.",
                "Tan, J. S., Goh, S. L., Kendall, G., e Sabar, N. R. (2021). A survey of the state-of-the-art of optimisation methodologies in school timetabling problems. Expert Systems with Applications, 165:113943.",
                "Tassopoulos, I. X., Iliopoulou, C. A., e Beligiannis, G. N. (2020). Solving the greek school timetabling problem by a mixed integer programming model. Journal of the Operational Research Society, 71(1):117–132.",
                "Yusop, N. (2022). A systematic literature review: Optimization timetable in education to support work-life balance (wlb). Journal of Computing Research and Innovation, 7(2):316–326.",
                "Zhang, D., Liu, Y., MHallah, R., e Leung, S. C. (2010). A simulated annealing with a new neighbourhood structure based algorithm for high school timetabling problems. European Journal of Operational Research, 203(3):550–558. ISSN 0377-2217."
            ],
            "artigo_completo": "MODELO EXATO PARA O PROBLEMA DA GRADE DE HOR ÁRIO ESCOLAR CONSIDERANDO CUSTO PEDAG ÓGICO E PREFER ÊNCIAS DOCENTES: REALIDADE DOS INSTITUTOS FEDERAIS. RESUMO Neste estudo, apresentamos uma formulação de Programação Linear Inteira (PLI) para resolver o problema de agendamento de horários escolares nos institutos federais de ensino, onde professores lecionam tanto no ensino médio quanto no superior. A principal contribuição desse trabalho é a introdução do conceito de Custo Pedagógico, que incorpora restrições pedagógicas à função objetivo. A abordagem também considera preferências dos docentes, como evitar aulas em certos dias ou horários. Além disso, propomos um tratamento específico para aulas geminadas, utilizando restrições lógicas. As funções de Custo Pedagógico e Custo Docente permitiram incluir preferências de horários específicas. A solução proposta otimiza o atendimento das solicitações pedagógicas, dos docentes e dos alunos. Apesar do grande número de restrições que pode tornar o problema infactível. A formulação proposta é flexível, permitindo a inclusão de novas regras para atender a diferentes cenários e necessidades. PALAVRAS CHAVE. Programação Linear Inteira, Alocação de grade de horários, restrições pedagógicas. Tópicos: PM – Programação Matemática; AdP&ED – PO na Administração Pública e Educação https://proceedings.science/p/193641?lang=pt-br DOI: 10.59254/sbpo-2024-193641 1. Introdução A alocação eficiente de recursos é uma tarefa importante em diversos setores de instituições públicas e privadas, desde a programação de aulas em escolas e universidades, o planejamento de horários de transporte público e a gestão de tarefas em ambientes empresariais [Bettinelli et al., 2015]. Uma área de pesquisa com aplicação nesse contexto é o que se convencionou chamar de Timetabling Problem, ou problema da grade de horários. De acordo com [Zhang et al., 2010], o Ti- metabling Problem é um problema de otimização complexo que envolve a distribuição de recursos limitados, como salas, professores, veículos ou máquinas, a um conjunto de atividades, conside- rando diversas restrições dependendo do cenário investigado. A tarefa de alocar recursos de maneira eficiente enfrenta obstáculos decorrentes das restrições impostas pelo ambiente e pelas preferências das partes envolvidas. Estas restrições desempenham um papel fundamental na modelagem do problema, pois determinam as limitações que o cenário deve atender. Segundo [Yusop, 2022], em instituições educacionais, horários bem planejados podem melhorar a experiência dos alunos e a produtividade dos professores. Na literatura acadêmica é possível encontrar vários trabalhos tratando do problema de grade de horário escolar. Comumente, tais trabalhos tratam da alocação de pessoas (tipicamente professores e alunos) e recursos (salas de aula e laboratórios) aos horários de aula disponíveis da semana, nos ambientes de escolas de ensino médio ou graduação [Ceschia et al., 2023]. Na taxonomia encontrada para o problema, existem três classes distintas para o problema da grade de horário: ensino médio (high-school), graduação (University Course) e agendamento de prova (University Examination) [Ceschia et al., 2023; Chen et al., 2021; Babaei et al., 2015; Tan et al., 2021]. Porém, no Brasil, a rede dos Institutos Federais trabalha com um cenário onde se tem ensino médio, técnico, graduação, cursos de curta duração (FIC - Formação Inicial Continuada) e pós-graduação compartilhando professores, salas e horários, sendo esse ambiente pouco explorado na literatura. Nesse trabalho, usaremos como estudo de caso o cenário do Campus Cachoeiro de Itape- mirim do Instituto Federal do Espírito Santo. O campus possui todas as modalidades de ensino pre- conizadas pelos Institutos Federais. Porém, por se tratar dos cursos mais críticos para a construção do horário, consideraremos apenas o ensino médio integral, com aulas nos turnos matutino e ves- pertino, os cursos técnicos, no turno noturno, e a graduação, nos três turnos. O foco principal deste trabalho reside no desenvolvimento de um modelo de Programação Linear Inteira (PLI) voltado para resolver o problema de alocação de horários. Na construção do horário, além das restrições físicas, devem ser consideradas as solicitações pessoais dos professores. Essas solicitações são fundamentais para o bem-estar dos profissionais. Tais restrições podem ser encontradas na literatura e podem ser tratadas como restrições hard, quando são obrigatórias, ou como restrições soft, quando o professor gostaria que fossem atendidas [Feizi-Derakhshi et al., 2012]. Nesse trabalho, trataremos dessas restrições como soft. Além disso, na graduação, é comum o agrupamento de aulas; assim, uma das contribuições deste trabalho é a forma como tratamos as restrições de aulas geminadas. Diferente dos trabalhos encontrados na literatura [Daskalaki et al., 2004], aqui propomos um conjunto de restrições lógicas linearizáveis para tratar esse tipo de restrição. Por fim, outra contribuição, inspirada no agendamento de horários de provas [Amaral e Pais, 2016], é a proposição de um conjunto de restrições chamadas de Custo Pedagógico, que devem ser otimizadas. 2. Revisão de literatura A programação de horários educacionais, em essência, envolve a alocação de encontros entre professores e alunos em dias, horários e salas de aula. Apesar da aparente simplicidade desse processo, é preciso destacar que cada instituição possui suas próprias regras, convenções e particu- laridades, o que torna cada problema específico praticamente único [Ceschia et al., 2023]. https://proceedings.science/p/193641?lang=pt-br DOI: 10.59254/sbpo-2024-193641 De acordo com [Schaerf, 1999], existem três classificações para o Educational Timeta- bling Problem. São elas: Highschool Timetabling (HTT): que tem como restrições básicas evitar que os professores tenham aula com duas turmas ao mesmo tempo e que dois professores não este- jam na mesma turma ao mesmo tempo; Course Timetabling (CTT): comumente busca minimizar a sobreposição de aulas de cursos de graduação que compartilham estudantes em comum; Examina- tion Timetabling (ETT): busca evitar a sobreposição de exames de cursos que possuem estudantes em comum, distribuindo os exames para os estudantes o máximo possível. Uma formulação ma- temática clássica na literatura para o HTT é apresentada por [Schaerf, 1999]. Esta formulação é classificada como complexa pelo autor e considera três tipos de elementos: tempos, recursos (alu- nos, turmas, professores e salas) e eventos. O modelo inclui 15 tipos de restrições, abrangendo desde a distribuição de aulas/palestras ao longo da semana até os tempos ociosos dos alunos, pre- ferências e indisponibilidades. Cada restrição pode ser categorizada como forte (obrigatória) ou fraca (não obrigatória). Para o CTT padrão, o survey de [Ceschia et al., 2023] apresenta um modelo onde um conjunto de eventos, períodos e salas são fornecidos. Além disso, um conjunto de dias é definido e cada período é um intervalo de tempo pertencente a um dia. Algumas características das salas também são consideradas, como o número de assentos. A função objetivo dessa formulação penaliza situações em que um estudante está comparecendo a um evento no último período de um dia, comparecendo a três (ou mais) eventos em intervalos de tempo consecutivos no mesmo dia, ou comparecendo a apenas um evento em um dia. A versão clássica do ETT, proposta por [Carter et al., 1996], considera como restrição apenas os conflitos entre exames que envolvem estudantes em comum. Salas de aula ou locais de aplicação não são considerados nesse problema. O objetivo dessa formulação é maximizar a distância entre exames que possuam estudantes em comum. Destacamos que, neste trabalho, foi usada parte dessa ideia para definir o Custo Pedagógico do horário. 2.1. Métodos de solução encontrados A seguir, apresentamos alguns trabalhos encontrados na literatura, classificando-os pelos métodos de solução adotados para cada tipo de problema. Métodos Exatos O trabalho de [Kristiansen et al., 2015] apresentou o primeiro método exato para instâncias de elaboração de horários escolares do ensino médio no formato XHSTT (XML High School Time- Tabling, que é um formato de arquivo XML utilizado para representar problemas de horários de escolares). Neste trabalho, conseguiram produzir duas novas soluções ótimas e comprovar a oti- malidade de quatro soluções previamente conhecidas. Para as instâncias não resolvidas de forma ótima, obtiveram melhorias em nove instâncias investigadas. Em [Fonseca et al., 2017], os autores aprimoraram o trabalho de [Kristiansen et al., 2015], corrigindo algumas desproporcionalidades e propondo uma formulação estendida baseada em fluxo. Como resultado, a relaxação linear da formulação foi melhorada, resultando em uma redução média de 32% nas lacunas de aulas dos pro- fessores. No trabalho de [Tassopoulos et al., 2020], foi desenvolvido um modelo de Programação Linear Inteira Mista (PLIM) para lidar com os desafios de planejamento de horários em escolas gregas. A aplicação desse modelo foi realizada por meio das ferramentas Gurobi e CPLEX. Duas abordagens metodológicas distintas foram adotadas na formulação do problema. A primeira adotou um modelo “monolítico”, que incorporava todas as restrições, tanto as fortes quanto as fracas. A segunda estratégia desmembrou o problema em seis subproblemas distintos. Os resultados compu- tacionais evidenciaram que o segundo método se revelou eficiente na obtenção de soluções ótimas, ao passo que o primeiro método não alcançou resultados satisfatórios. Métodos Heurísticos https://proceedings.science/p/193641?lang=pt-br DOI: 10.59254/sbpo-2024-193641 O trabalho de [Babaei et al., 2015] afirma que as abordagens baseadas em métodos exa- tos não apresentam boa eficiência na resolução do CTT. Por outro lado, a exploração do espaço de soluções é mais eficiente ao aplicar métodos metaheurísticos e técnicas inteligentes na análise desse tipo de problema. Mesmo assim, não se pode considerar uma abordagem metaheurística como o melhor método para resolver o problema CTT, uma vez que os conjuntos de dados utilizados são diversos e a forma de aplicar esse tipo de método difere. Em [Leite et al., 2019], é proposto um algoritmo baseado em coloração de grafos para iniciar a solução e a metaheurística Simulated Anne- aling (SA) para otimizá-la. No trabalho foram testados dois algoritmos de otimização. O primeiro é o SA original, enquanto o segundo, denominado FastSA, baseia-se no SA, mas emprega um critério de aceitação modificado que fixa o exame selecionado assim que o número de movimentos aceitos do exame no vizinho anterior é zero. 3. Características do Cenário e Modelo Proposto A construção da grade de horários passa pelo atendimento a restrições que podem ser classificadas em duas categorias: Restrições Fortes e Restrições Fracas. As Restrições Fortes (hard) são aquelas que garantem que uma solução seja viável. Em termos práticos, as restrições fortes são geralmente relacionadas a requisitos essenciais que não podem ser comprometidos de forma alguma. Destacamos como restrições fortes as restrições físicas e algumas restrições pedagógicas. Por exemplo, na graduação, as aulas costumam ser geminadas, com dois ou três tempos, e a violação dessa regra inviabiliza as aulas de laboratório. As Restrições Fracas (soft) são importantes, mas permitem alguma flexibilidade. Elas podem ser violadas em circunstâncias específicas. Essas restrições serão associadas à função obje- tivo do modelo proposto neste trabalho. Além das preferências de horário dos professores, o Custo Pedagógico também foi considerado uma restrição fraca. Esse custo se inspira nos critérios esta- belecidos por [Amaral e Pais, 2016] para o agendamento de exames, adaptados para o problema em questão. Assim, o modelo buscará minimizar a ocorrência de algumas situações consideradas pedagogicamente indesejáveis, por exemplo: uma disciplina não deve ser alocada sempre no último (ou no primeiro) horário; e deve ser evitada aula da mesma disciplina em dois dias seguidos. O modelo apresentado aqui considera as características do campus investigado, mas reflete a realidade da maioria dos Institutos Federais no Brasil. Os elementos básicos do modelo são: • Professor: Neste contexto, levamos em conta apenas o número de aulas que cada profes- sor ministra para cada turma, sem considerar as especificidades das disciplinas. Sendo um conjunto de 82 professores, representados por P = {P1, P2, P3, ..., P82}. • Dia da Semana: Abrangendo de segunda a sexta-feira. • Turma: Refere-se a cada grupo de alunos matriculados em um período, série ou módulo específico de um curso. As 43 turmas são representadas por T = {T1, T2, T3, ..., T43}. • Horário: Refere-se a cada intervalo de tempo disponível para a alocação de uma aula durante o dia. Esses tempos são divididos em três períodos: matutino (tempos de 1 a 6), vespertino (de 7 a 12) e noturno (de 13 a 16). Na Tabela 1 apresentamos as notações, parâmetros e variáveis do modelo posto. Restrições básicas A Expressão 1 garante que em cada horário de uma turma, apenas um professor será alocado: https://proceedings.science/p/193641?lang=pt-br DOI: 10.59254/sbpo-2024-193641 Tabela 1: Estrutura básica do modelo proposto Notações Descrição Conjuntos P Conjunto de professores, onde p ∈P = {P1, P2, P3, ..., P82} D Conjunto de dias da semana, onde d ∈D = {1, 2, 3, 4, 5} T Conjunto de turmas onde os professores deverão ministrar aulas, com t ∈T = {T1, T2, T3, ..., T43} H Conjunto de horários disponíveis em cada dia, onde h ∈H = {1, 2, 3, 4, ..., 16} PT[p, t] Matriz com o número de aulas de cada professor em cada turma, com p ∈P e t ∈T Var. de decisão xp,t d,h Variável binária que indica se o professor p está alocado na turma t no dia d no horário h CustoP p,t d Variável inteira que define o Custo Pedagógico a ser minimizado na função objetivo CustoDp,t Variável inteira que define o Custo Docente a ser minimizado na função objetivo X p∈P xp,t d,h ≤1; ∀d ∈D, ∀h ∈H, ∀t ∈T. (1) A Inequação 2 garante que cada professor pode estar alocado, no máximo, a uma turma em cada horário e em cada dia: X t∈T xp,t d,h ≤1; ∀d ∈D, ∀h ∈H, ∀p ∈P. (2) A Equação 3 determina o número de aulas atribuídas a cada professor em cada turma, com base em uma matriz representada por PT[p, t]: X d∈D,h∈H xp,t d,h = PT[p, t]; ∀p ∈P, ∀t ∈T. (3) A Equação 4 é aplicada para delimitar a alocação das aulas em horários específicos. Neste modelo, esse tipo de restrição foi utilizado para designar adequadamente o turno de cada turma. Na restrição apresentada abaixo, o modelo assegura que as aulas das turmas de 1 a 4 sejam programadas para o período da manhã, isto é, nos intervalos de tempo de 1 a 6: X p∈P xp,t d,h = 0; ∀t ∈{1...4}, ∀h ∈{7...16}, ∀d ∈D. (4) Para impor restrições a outras turmas e turnos, basta substituir o conjunto que representa as turmas e o conjunto que representa as aulas que a turma não pode estar alocada. 3.1. Restrições para aulas geminadas Devido à necessidade de alguns cursos, neste modelo consideramos a alocação de aulas consecutivas. Um professor com duas aulas em uma turma pode escolher ministrá-las em dois intervalos de tempo consecutivos. O mesmo se aplica a um professor com três aulas: ele pode optar por uma aula de dois tempos consecutivos e uma aula avulsa em outro dia ou uma aula de 3 tempos. Se um professor tiver quatro aulas em uma turma, pode escolher entre dar duas aulas consecutivas de dois tempos em dias diferentes ou uma aula de dois tempos em um dia e outras duas aulas isoladas em dias distintos. Nesse contexto, o professor deve indicar a necessidade do agrupamento de aulas na sua disciplina. O modelo é capaz de acomodar pedidos de aulas consecutivas de dois e três tempos. Foram aplicadas restrições lógicas para resolver essa demanda específica, e o conjunto https://proceedings.science/p/193641?lang=pt-br DOI: 10.59254/sbpo-2024-193641 dessas restrições é explicado a seguir. A Tabela 2 apresenta os novos elementos (parâmetros e variáveis) que devem ser inseridos no modelo para tratar essas demandas. Tabela 2: Estrutura para o tratamento de aulas geminadas Notações Descrição Matrizes G2[p, t] Matriz que indica se o professor p possui aula geminada de dois tempos na turma t. G22[p, t] Matriz que indica se o professor p possui duas aulas geminadas de dois tempos na turma t. G3[p, t] Matriz que indica se o professor p possui aula geminada de três tempos na turma t. Var. de Decisão y2p,t d Variável binária que indica se o professor p tem aula geminada de dois tempos na turma t no dia d. y2ap,t d , y2bp,t d Variáveis binárias que indicam se o professor p possui duas aulas geminada de dois tempos, sendo uma variável para cada aula na turma t no dia d. y3p,t d Variável binária que indica se o professor p possui uma aula geminada de três tempos na turma t no dia d. Uma Aula Geminada com Dois Tempos A Restrição 5 assegura que a aula geminada ocorra em apenas um dia, enquanto a Restrição 6 garante que o modelo aloque as aulas de forma consecutiva, resultando em uma seção de aula ge- minada de dois tempos. X d∈D y2p,t d = 1; ∀p ∈P, ∀t ∈T : G2[p, t] = 1. (5) Se (y2p,t d = 1) então \u0000(xp,t d,1 = 1 e xp,t d,2 = 1) ou ((xp,t d,2 = 1 e xp,t d,3 = 1) ou ... ou (xp,t d,15 = 1 e xp,t d,16 = 1) \u0001 ; ∀d ∈D, ∀p ∈P, ∀t ∈T : G2[p, t] = 1. (6) Duas Aulas Geminadas com Dois Tempos Para representar essa demanda, foi desenvolvida a matriz G22[p, t], onde o valor 1 é atribuído quando o professor p possui duas aulas geminadas de dois tempos na turma t. Para dife- renciar os dias em que cada seção de aula geminada de dois tempos ocorre, foram introduzidas as variáveis y2ap,t d e y2bp,t d , que assumem o valor 1 quando o professor p tem uma aula geminada de dois tempos na turma t no dia d, conforme indicado pelas Equações 7 e 8. X d∈D y2ap,t d = 1; ∀p ∈P, ∀t ∈T : G22[p, t] = 1. (7) X d∈D y2bp,t d = 1; ∀p ∈P, ∀t ∈T : G22[p, t] = 1. (8) A Restrição 9 garante que as seções de aulas geminadas de dois tempos aconteçam em dias distintos, enquanto a Restrição 10 realiza a alocação das aulas de forma consecutiva. y2ap,t d + y2bp,t d ≤1; ∀p ∈P, ∀t ∈T : G22[p, t] = 1. (9) https://proceedings.science/p/193641?lang=pt-br DOI: 10.59254/sbpo-2024-193641 Se (y2ap,t d = 1) ou (y2bp,t d = 1) então \u0000(xp,t d,1 = 1 e xp,t d,2 = 1) ou ((xp,t d,2 = 1 e xp,t d,3 = 1) ou ... ou (xp,t d,15 = 1 e xp,t d,16 = 1) \u0001 ; ∀d ∈D, ∀p ∈P, ∀t ∈T : G22[p, t] = 1. (10) Uma Aula Geminada com Dois Tempos e uma Aula Geminada com Três Tempos A matriz G3[p, t] segue a mesma lógica das matrizes mencionadas anteriormente, indi- cando ao modelo se o professor p possui uma aula geminada de três tempos na turma t. Da mesma forma, a variável y3p,t d é definida como 1 quando o professor p tem uma aula geminada de três tem- pos na turma t no dia d, conforme apresentado na Equação 11. A Restrição 12 garante a alocação consecutiva das aulas. X d∈D y3p,t d = 1; ∀p ∈P, ∀t ∈T : G3[p, t] = 1. (11) Se (y3p,t d = 1) então \u0000(xp,t d,1 = 1 e xp,t d,2 = 1 e xp,t d,3 = 1) ou ((xp,t d,2 = 1 e xp,t d,3 = 1 e xp,t d,4 = 1) ou ... ou (xp,t d,14 = 1 e xp,t d,15 = 1 e xp,t d,16 = 1) \u0001 ; ∀d ∈D, ∀p ∈P, ∀t ∈T : G3[p, t] = 1. (12) Se um professor possuir cinco ou mais aulas em uma turma específica e optar por ministrar uma aula geminada de três tempos em um dia e outra de dois tempos em outro dia, a Restrição 13 garante que apenas uma aula geminada seja agendada em um único dia. y2p,t d + y3p,t d ≤1; ∀p ∈P, ∀t ∈T, ∀d ∈D : G2[p, t] = 1 ∧G3[p, t] = 1. (13) 3.2. Restrições para o Custo Pedagógico (CP) O modelo proposto tem como objetivo organizar a grade de horários levando em consideração as diretrizes pedagógicas da instituição. Para garantir isso, são aplicadas penalidades às situações pedagogicamente indesejáveis no horário. Chamaremos estas situações de Custo Pedagógico (CP). Assim, a função objetivo tentará minimizar a ocorrência dessas situações, otimizando o Custo Pe- dagógico. No modelo proposto, foram incorporadas duas dessas situações, onde serão definidas as variáveis CustoP1p,t d e CustoP2p,t d . Essa divisão permite atribuir custo a cada uma das restrições independentemente. CP1: Mais de uma aula de um professor para a mesma turma no mesmo dia A Expressão 14 foi formulada para evitar a ocorrência de duas ou mais aulas ministradas pelo mesmo professor para a mesma turma no mesmo dia. Essa restrição foi considerada para os professores que não optaram por ministrar aulas geminadas. Inicialmente, foi atribuída uma penalidade de valor 3 para essa situação. Se X h∈H xp,t d,h ≥2 ! então CustoP1p,t d = 3; ∀d ∈D, ∀t ∈T, ∀p ∈P : G2[p, t] = 0 ∧G22[p, t] = 0. (14) https://proceedings.science/p/193641?lang=pt-br DOI: 10.59254/sbpo-2024-193641 Analogamente, a Expressão 15 trata da situação em que o professor possui aulas gemi- nadas com 3 tempos. No entanto, esta restrição permite a alocação de até duas aulas do mesmo professor para a mesma turma no mesmo dia sem penalidades, evitando que o modelo penalize todas as aulas geminadas de dois tempos já definidas anteriormente. Se X h∈H xp,t d,h ≥3 ! então CustoP1p,t d = 3; ∀d ∈D, ∀t ∈T, ∀p ∈P : G3[p, t] = 0. (15) CP2: Aulas de um mesmo professor para a mesma turma em dias seguidos A Expressão 16 foi elaborada para evitar a atribuição de aulas do mesmo professor para a mesma turma em dias consecutivos. Nesse contexto, uma penalidade de valor 1 foi atribuída inicialmente, dado que essa restrição é considerada menos importante em comparação à anterior. Se X h∈H xp,t d−1,h ≥1 ! e X h∈H xp,t d,h ≥1 ! então CustoP2p,t d = 1; ∀d ∈{2..5}, ∀t ∈T, ∀p ∈P. (16) 3.3. Restrições para as Preferências dos Docentes (PD) Na função objetivo proposta, também consideramos as preferências dos professores, bus- cando atendê-las sempre que possível. Assim como as restrições de Custo Pedagógico, foram de- finidas outras quatro variáveis, uma para cada situação abordada, sendo CustoD1p,t, CustoD2p,t, CustoD3p,t e CustoD4p,t. PD1: Evitar que um professor lecione o último horário de um dia e o primeiro do dia seguinte. A Restrição 17 foi estabelecida para prevenir a ocorrência de aulas ministradas pelo mesmo professor no último horário de um dia e o primeiro horário do dia seguinte, respeitando um período de descanso do docente. Uma penalidade de valor 3 foi atribuída para essa situação. Se X h∈H xp,t d,16 ≥1 ! e X h∈H xp,t d+1,1 ≥1 ! então CustoD1p,t = 3; ∀d ∈{1..4}, ∀t ∈T, ∀p ∈P (17) PD2: Quando o professor não pode dar aula no final da manhã e início da tarde Para ilustrar a capacidade do modelo em atender às preferências dos professores, tomamos como exemplo uma restrição pessoal de um conjunto de docentes. Nesse caso específico, os profes- sores não podem ser designados para o último horário da manhã (h = 6) ou para o primeiro horário da tarde (h = 7). Essa condição está modelada na Restrição 18, para um conjunto de professores k∗. Para essa solicitação, foi atribuída uma penalidade de valor 1. Se X d∈D xk∗,t d,6 ≥1 ! ou X d∈D xk∗,t d,7 ≥1 ! então CustoDk∗,t = 1; ∀t ∈T. (18) PD3: Quando o professor não pode dar aula nos dois primeiros horários do dia https://proceedings.science/p/193641?lang=pt-br DOI: 10.59254/sbpo-2024-193641 Outra situação que surge no campus é a restrição de que o professor k∗não pode ser designado para os dois primeiros horários do dia. Essa condição está modelada na Restrição 19. Se X h∈{1,2} xk∗,t d,h ≥1 ! então CustoDk∗,t = 1; ∀t ∈T, ∀d ∈D. (19) PD4: Quando o professor não dá aulas em dias específicos Um exemplo clássico no problema de alocação de horários surge quando um professor, ou grupo de professores, opta por não ministrar aulas em um dia específico da semana. Para lidar com essa preferência, elaboramos a Restrição 20. Tomamos como exemplo um conjunto de professores k∗que não deseja lecionar em um dia específico (d∗). Se X h∈H xk∗,t d∗,h ≥1 ! então CustoDk∗,t = 1; ∀t ∈T. (20) 3.4. Função objetivo Como mencionado, a função objetivo do modelo visa minimizar as penalidades associ- adas a certas situações que definimos como Custo Pedagógico e Preferência Docente. O modelo apresentado aqui inclui duas restrições de Custo Pedagógico e quatro restrições de Preferência Do- cente. Para evitar sobreposição de custos foi definida uma variável para cada situação que deve ser minimizada. A função objetivo do modelo é apresentada na Expressão 21. minimize X d∈D X t∈T X p∈P CustoP1p,t d + X d∈D X t∈T X p∈P CustoP2p,t d + X t∈T X p∈P CustoD1p,t + X t∈T X p∈P CustoD2p,t+ (21) X t∈T X p∈P CustoD3p,t + X t∈T X p∈P CustoD4p,t; 4. Resultados O modelo proposto na Seção 3 foi implementado utilizando o software IBM ILOG CPLEX 20.1.0. Destacamos que as expressões lógicas na apresentação do modelo foram implementadas como estão descritas e foram linearizadas pelo Cplex. As instâncias foram executadas em um com- putador equipado com 20GB de memória RAM e um processador Intel Core i7 com 2.80 GHz. O sistema operacional em uso foi o Microsoft Windows 11. Para um benchmark de comparação do tempo computacional e resultados alcançados, implementamos o modelo utilizando uma função objetivo simples, cujo propósito era apenas orga- nizar a grade de horários conforme as restrições, sem a consideração de minimização dos custos pedagógicos e preferências dos docentes. Essa função objetivo está definida na Expressão 22. Note que o resultado na somatória é o número total de aulas da grade de horário, sendo esse um valor constante. Assim, a tarefa do modelo seria apenas criar uma grade de horário factível. Com essa função objetivo, o modelo alcançou um resultado viável em 30 minutos. maximize X p∈P X t∈T X d∈D X h∈H xp,t d,h; (22) Para o restante dos experimentos, estabelecemos um limite de processamento de 60 mi- nutos, sendo apresentado o Gap caso o modelo não encontre a solução ótima dentro desse tempo. https://proceedings.science/p/193641?lang=pt-br DOI: 10.59254/sbpo-2024-193641 A Tabela 3 apresenta os resultados dos experimentos realizados, considerando a função objetivo descrita na Expressão 21. Os experimentos tiveram o objetivo de avaliar os resultados considerando variações dos pesos da função objetivo e transformando elementos da função objetivo em restrições. Em cada experimento, na linha ’Custo’, é apresentado o peso dado a cada parcela da Função Ob- jetivo; na linha ’Quantidade (gerada)’, é indicado o número de fatores gerados para cada custo associado, pedagógico ou docente; na linha ’Não atendidas’, mostra a quantidade de solicitações de cada parcela que não foi atendida. Adicionalmente, o ’custo hard’ significa que a parcela correspon- dente da função objetivo foi transformada em restrição e deve ser atendida obrigatoriamente. Para exemplificar, no Experimento Exp01, a solução ótima foi obtida em 3050 segundos. Para o fator da função objetivo CP1 (Mais de uma aula de um professor para a mesma turma no mesmo dia), foram geradas 33910 parcelas, das quais apenas 49 não foram atendidas. Adicionalmente, nota-se que todos os outros elementos da função objetivo, seja CP ou PD, tiveram suas demandas 100% atendidas. No experimento denominado Exp02, ajustamos o valor do custo de CP1 para tentar priori- zar sua resolução, visto que, no experimento anterior, CP1 foi a única restrição que apresentou casos de não atendimento. Como resultado, observamos uma leve redução na quantidade de restrições não atendidas em CP1. No entanto, também houve um pequeno aumento nas restrições não atendidas em CP2 e PD4, conforme evidenciado na linha correspondente ao Exp02 na Tabela 3. Esse experi- mento foi interrompido com 1 hora de processamento e obteve uma Gap de 4,34%, sendo esse um valor considerado baixo. No Experimento Exp03 os custos dos fatores foram configurados com 1, dando mesmo nível de prioridade para todas das demandas pedagógicas se docentes. Observamos que o modelo encontrou a solução ótima em menos tempo do que nos experimentos anteriores, resultando em uma leve redução na quantidade de restrições não atendidas em CP1 e um pequeno aumento na quanti- dade não atendida em CP2 e PD4 em comparação com o Exp01. Os resultados deste experimento estão detalhados na linha correspondente ao Exp03 na Tabela 3. No Exp04, modificamos os fatores CP1 e CP2 para torná-los obrigatórios, isto é, esses fo- ram transformados em restrições. Como nos experimentos anteriores sempre houve fatores CP1 ou CP2 não atendidos, como esperado, a solução nesse caso foi infactível. Por outro lado, no Exp05, transformando as restrições de Preferências Docentes (PD) para serem obrigatórias, enquanto deixa- mos as restrições de Custo Pedagógico (CP) com custo 1, a solução obtida foi equivalente à solução encontrada no Exp01, porém com aproximadamente metade do tempo computacional. Os experimentos realizados mostram que transformar solicitações de preferências em restrições pode tornar o modelo infactível. No caso de instâncias com muitas solicitações, como nas instâncias apresentadas, ficaria inviável identificar o conjunto de restrições que esta tornando infactível. Assim, a estratégia de custo pedagógica e preferência docente se apresentou promissora para maximizar o atendimento dessas solicitações, mantendo a factibilidade da instância. 5. Conclusão Neste artigo, propomos uma formulação de Programação Linear Inteira (PLI) para resol- ver o problema de agendamento de horários escolares em um campus da rede de institutos federais de ensino. Uma das principais características dessa rede de ensino, para a construção da grade de horário, é o fato dos professores atuarem no ensino médio e superior. A principal contribuição desse trabalho consiste na introdução do conceito de Custo Pe- dagógico. A ideia da proposta consistem em transformar restrições que são comumente solicita- das pela equipe pedagógica, em parte da função objetivo. Assim, tais restrições seriam atendi- das sempre que possível. Usando a mesma estratégia, também tratamos alguns exemplos de pre- ferências docentes, como solicitações pessoais para evitar aulas em dias ou horários específicos. https://proceedings.science/p/193641?lang=pt-br DOI: 10.59254/sbpo-2024-193641 Tabela 3: Resultados dos experimentos Tempo(s) Gap Parâmetros da F.O. CP1 CP2 PD1 PD2 PD3 PD4 Exp01 3050 - Custo 1 3 3 2 2 1 Quantidade (gerada) 33910 14104 14104 129 215 430 Não atendidas 49 0 0 0 0 0 Exp02 3600 4.34% Custo 4 3 3 2 2 1 Quantidade (gerada) 33910 14104 14104 129 215 430 Não atendidas 44 3 0 0 0 2 Exp03 2174 - Custo 1 1 1 1 1 1 Quantidade (gerada) 33910 14104 14104 129 215 430 Não atendidas 46 2 0 0 0 1 Exp04 inviável - Custo hard hard 1 1 1 1 Quantidade (gerada) 33910 14104 14104 129 215 430 Não atendidas - - - - - - Exp05 1823 - Custo 1 1 hard hard hard hard Quantidade (gerada) 33910 14104 14104 129 215 430 Não atendidas 49 0 - - - - Além dessa estratégia para tratar solicitações, destacamos como outra contribuição desse trabalho o tratamento proposto para as aulas geminadas. Aqui foram usadas restrições lógicas para tratar diferentes situações de aulas geminadas. As funções de Custo Pedagógico e Custo Docente possibilitam a inclusão de preferências específicas quanto aos horários de aula e dias. Por exemplo, excluindo as solicitações de aulas geminadas, atribuíram-se custos para evitar que um professor tivesse mais de uma aula na mesma turma. Outra configuração que evitamos, demandada pelos alunos, foi que um professor desse aula na mesma turma em dias seguidos. Diferente dos custos pedagógicos e solicitações dos docen- tes, as aulas geminadas foram tratadas como restrições impositivas, pois a violação dessas pode comprometer a viabilidade das aulas, como, por exemplo, em situações de aulas de laboratório. Dados as características do estudo de caso, considerando o grande número de profes- sores, turmas e diversidade de cursos, os resultados numéricos demonstram que as solicitações pedagógicas e docentes podem gerar milhares de restrições. A combinação dessas restrições, em muitos casos torna o problema infactível, sendo inviável encontrar a combinação exata de restrições que leva a essa infactibilidade de solução. Assim, a solução proposta conseguiu gerar uma grade de horário maximizando o atendimento das solicitações da equipe pedagógica, docentes e alunos. O problema da grade de horário escolar possui infindáveis variações de solicitações pe- dagógica e docentes. Aqui apresentamos algumas situações e uma estratégia de modelagem para maximizar o atendimento dessas solicitações. Porém, a generalização da formulação proposta fle- xibiliza a inserção de novas regras para atender diferentes cenários e demandas. 6. Agradecimento Os autores agradecem a FAPES/UnAC (Nº FAPES 1228/2022 P 2022-CD0RQ, Nº SIA- FEM 2022-CD0RQ) pelo apoio financeiro dado por meio do Sistema UniversidaES."
        },
        {
            "titulo": "UMA ABORDAGEM HEURÍSTICA PARA UM PROBLEMA MULTI-OBJETIVO DE SEQUENCIAMENTO EM MÁQUINAS PARALELAS COM CONSIDERAÇÕES AMBIENTAIS",
            "informacoes_url": "https://proceedings.science/p/193733?lang=pt-br",
            "idioma": "pt-br",
            "storage_key": "galoa-proceedings--sbpo-2024--193733.pdf",
            "autores": [
                {
                    "nome": "Clarissa Maria Rodrigues de Oliveira",
                    "afiliacao": "Universidade Federal de Pernambuco, Departamento de Engenharia de Produção",
                    "orcid": null
                },
                {
                    "nome": "Matheus Lopes Bittencourt",
                    "afiliacao": "Universidade Federal de Pernambuco, Departamento de Engenharia de Produção",
                    "orcid": null
                },
                {
                    "nome": "Raphael Kramer",
                    "afiliacao": "Universidade Federal de Pernambuco, Departamento de Engenharia de Produção",
                    "orcid": null
                }
            ],
            "data_publicacao": null,
            "resumo": "Este artigo aborda um problema multi-objetivo de sequenciamento em máquinas paralelas com foco em eficiência energética, visando minimizar o makespan e o consumo de energia, considerando tarifas que variam ao longo do dia, política comumente conhecida como Time-of-use (TOU).",
            "keywords": [
                "Sequenciamento de Produção",
                "Sequenciamento Verde",
                "Otimização Bi-Objetivo",
                "Consumo Energético",
                "Heurísticas",
                "OC - Otimização Combinatória",
                "MH - Metaheurísticas"
            ],
            "referencias": [
                "Afzalirad, M. e Shafipour, M. (2018). Design of an efficient genetic algorithm for resource-constrained unrelated parallel machine scheduling problem with machine eligibility restrictions. Journal of Intelligent Manufacturing, 29(2):423–437.",
                "Anghinolfi, D., Paolucci, M., e Ronco, R. (2021). A bi-objective heuristic approach for green identical parallel machine scheduling. European Journal of Operational Research, 289(2):416–434.",
                "Antoniadis, A., Garg, N., Kumar, G., e Kumar, N. (2020). Parallel machine scheduling to minimize energy consumption. In Proceedings of the fourteenth annual ACM-SIAM symposium on discrete algorithms, p. 2758–2769. SIAM.",
                "Bérubé, J.-F., Gendreau, M., e Potvin, J.-Y. (2009). An exact formula not shown-constraint method for bi-objective combinatorial optimization problems: Application to the traveling salesman problem with profits. European Journal of Operational Research, 194(1):39–50.",
                "Che, A., Zhang, S., e Wu, X. (2017). Energy-conscious unrelated parallel machine scheduling under time-of-use electricity tariffs. Journal of Cleaner Production, 156:688–697. ISSN 0959-6526. URL https://www.sciencedirect.com/science/article/pii/S0959652617307175.",
                "Lust, T. e Teghem, J. (2010). Two-phase pareto local search for the biobjective traveling salesman problem. Journal of Heuristics, 16(3):475–510.",
                "Pinedo, M. L. (2016). Scheduling: Theory, Algorithms, and Systems. Springer Publishing Company, Incorporated, 5 edition.",
                "Wang, L. e Qi, Y. (2023). Scheduling an energy-aware parallel machine system with deteriorating and learning effects considering multiple optimization objectives and stochastic processing time. CMES-Computer Modeling in Engineering & Sciences, 135(1):325–339.",
                "Wang, S., Wang, X., Yu, J., Ma, S., e Liu, M. (2018). Bi-objective identical parallel machine scheduling to minimize total energy consumption and makespan. Journal of Cleaner Production, 193:424–440.",
                "Wu, X., Guo, P., Wang, Y., e Wang, Y. (2022). Decomposition approaches for parallel machine scheduling of step-deteriorating jobs to minimize total tardiness and energy consumption. Complex & Intelligent Systems, p. 1–16.",
                "Wu, X. e Che, A. (2019). A memetic differential evolution algorithm for energy-efficient parallel machine scheduling. Omega, 82:155–165.",
                "Xue, Y., Rui, Z., Yu, X., Sang, X., e Liu, W. (2019). Estimation of distribution evolution memetic algorithm for the unrelated parallel-machine green scheduling problem. Memetic Computing, 11:423–437.",
                "Yin, Y., Wang, Y., Cheng, T., Liu, W., e Li, J. (2017). Parallel-machine scheduling of deteriorating jobs with potential machine disruptions. Omega, 69:17–28."
            ],
            "artigo_completo": "UMA ABORDAGEM HEURÍSTICA PARA UM PROBLEMA MULTI-OBJETIVO DE SEQUENCIAMENTO EM M ÁQUINAS PARALELAS COM CONSIDERAÇ ÕES AMBIENTAIS. RESUMO Este artigo aborda um problema multi-objetivo de sequenciamento em máquinas para- lelas com foco em eficiência energética, visando minimizar o makespan e o consumo de energia, considerando tarifas que variam ao longo do dia, política comumente conhecida como Time-of-use (TOU). Propomos uma heurística que combina uma proposta recente com a meta-heurística Busca Local de Pareto de Duas Fases, integrando estratégias específicas para este desafio. Avaliamos a qualidade das soluções usando indicadores de desempenho como Hipervolume, Pureza e Dr, que mensuram a qualidade da fronteira de soluções. A comparação dos algoritmos foi realizada com o Teste de Wilcoxon, evidenciando a superioridade da abordagem proposta neste trabalho em relação à anterior em todas as medidas de performance, para instâncias pequenas e grandes. Esta pesquisa amplia o conhecimento científico e fomenta a aplicação prática em sistemas de manufatura, visando a otimização dos recursos e a redução dos impactos ambientais. PALAVRAS CHAVE. Sequenciamento de Produção. Sequenciamento Verde. Otimização Bi-Objetivo. Consumo Energético. Heurísticas. OC – Otimização Combinatória; MH – Metaheurísticas. https://proceedings.science/p/193733?lang=pt-br DOI: 10.59254/sbpo-2024-193733 1. Introdução Um dos problemas mais estudados na otimização combinatória é o sequenciamento da produção, que visa determinar a ordem ideal das atividades [Afzalirad e Shafipour, 2018]. Os ambientes de manufatura, como máquina única, máquinas paralelas, flow shop, job shop e open shop, influenciam o sequenciamento adequado [Pinedo, 2016]. O problema de sequenciamento em máquinas paralelas, comum em diversas indústrias (e.g., usinagem e soldagem [Wang et al., 2018] e indústria química [Wu et al., 2022]), busca otimizar medidas de desempenho como o atraso ponderado de entrega e o makespan [Pinedo, 2016]. Além disso, a programação da produção pode incorporar questões ambientais para reduzir custos e impactos, considerando indicadores como emissões de carbono [Xue et al., 2019] e con- sumo total de energia. A última pode ser avaliada por meio de uma política de tarifação de energia por horário de uso (Time-of-use, TOU), simulando a situação prática do mercado de eletricidade de períodos de pico, vale e normal [Che et al., 2017], pelo ajuste de níveis de velocidade das máquinas, de forma a regular o consumo de energia e o tempo de processamento das tarefas [Wu e Che, 2019] e pela decisão sobre os diferentes estados das máquinas, como em processamento, desligada e oci- osa, com atribuição de diferentes níveis de consumo energético para cada estado [Antoniadis et al., 2020]. As medidas de desempenho operacionais, em geral, são conflitantes com os objetivos ambi- entais. Visto isso, a literatura recente utiliza modelagens matemáticas multiobjetivo para encontrar soluções ótimas que equilibram eficiência operacional e sustentabilidade ambiental [Wang e Qi, 2023]. O Problema de sequenciamento em máquinas paralelas com considerações ambientais (PSMPCA) é uma extensão do Problema de sequenciamento em máquinas paralelas (PSMP), o qual é classificado como NP-difícil, i.e., a resolução desse tipo de problema demanda um tempo de processamento computacional não polinomial para auferir a solução ótima [Yin et al., 2017]. Visto isso, métodos heurísticos são comumente empregados para resolvê-lo. Essa pesquisa apresenta como objetivo geral propor um algoritmo heurístico para resolver um PSMPCA multi-objetivo. 2. Descrição do problema O modelo selecionado para estudo foi proposto inicialmente por Wang et al. [2018] e estudado em Anghinolfi et al. [2021], no qual envolve o sequenciamento verde a medida que busca a minimização do custo total energético, chamado de TEC, e do makespan. O problema consiste em sequenciar N tarefas independentes em M máquinas paralelas idênticas. Todas as tarefas estão disponíveis para processamento no tempo 0 (i.e., no início do hori- zonte de tempo), e cada máquina pode processar apenas uma tarefa por vez. Seja J = {1, . . . , N} o conjunto de tarefas a serem processadas, e H = {1, . . . , M} um conjunto de máquinas. Para cada tarefa j ∈J, o tempo de processamento pj é idêntico para todas as máquinas. As tarefas devem ser sequenciadas em um horizonte de tempo que consiste em um conjunto T = {1, . . . , K} de intervalos de tempo. As tarefas não podem ser interrompidas, i.e., cada tarefa j deve ser processada em um conjunto Sj de pj intervalos de tempo consecutivos em uma única máquina h ∈H. Devido aos custos variáveis de energia na abordagem TOU, os intervalos de tempo em T são organizados em grupos, onde cada grupo engloba uma série de intervalos de tempo que compartilham o mesmo preço de energia. Ou seja, um determinado preço da energia ct é atribuído a cada intervalo de tempo t ∈T. Cada máquina h ∈H está associada a uma taxa fixa de consumo de energia eh, e o custo do consumo de energia associado ao processamento da tarefa j na máquina h é eh P t∈Sj ct. O tempo de conclusão Cj de uma tarefa j é o tempo final do último intervalo de tempo designado para a tarefa. Além disso, o Cmax de um sequenciamento é o tempo de término do último j ∈J, ou seja, Cmax = max{Cj : j ∈J}. O valor do TEC está associado ao sequenciamento de- finido como P h∈H eh P j∈Jh P k∈Sj ck, onde Jh é o conjunto de tarefas sequenciadas na máquina https://proceedings.science/p/193733?lang=pt-br DOI: 10.59254/sbpo-2024-193733 h. Dessa forma, as variáveis desse problema são: Xjht ∈{0, 1}, j ∈J, h ∈H, t ∈T, que assume valor 1 se a tarefa j for processada na máquina h começando no início do intervalo de tempo t, e 0 caso contrário; Cj ≥0, j ∈J, referente ao tempo de conclusão da tarefa j; Cmax ≥0; e TEC ≥0. Diante disso, este problema pode ser formulado da seguinte maneira: Min Cmax (1) Min TEC (2) sujeito a TEC = X h∈H eh X j∈J k−pj+1 X t=1 Xjht   t+pj−1 X i=t ci  , (3) X h∈H K−pj+1 X t=1 Xjht = 1, ∀j ∈J, (4) X j∈J t X i=max{0,t−pj+1} Xjhi ≤1, ∀t ∈T, h ∈H, (5) Cj = X h∈H K−pj+1 X t=1 (t −pj + 1) Xjht, ∀j ∈J, (6) Cmax ≥Cj, ∀j ∈J, (7) Cmax ≤K, (8) Cmax ≥0, TEC ≥0, Cj ≥0, ∀j ∈J, (9) Xjht ∈{0, 1}, ∀j ∈J, h ∈H, t ∈T. (10) As Expressões (1) e (2) representam as funções objetivos a serem minimizadas, sendo elas Cmax e o TEC, respectivamente. A Equação (3) define o cálculo do TEC. As Restrições (4) impõem que cada tarefa seja atribuída a uma única máquina, garantindo que o processamento de qualquer tarefa comece em um único intervalo de tempo em uma única máquina. O conjunto de Restrições (5) garantem que no máximo uma única tarefa seja processada em cada intervalo de tempo em cada máquina. As Restrições (6) fornecem os horários de conclusão das tarefas, impondo implicitamente a não preempção. As Inequações (7) definem o Cmax, enquanto que a Inequação (8), impõe que o Cmax não deva exceder o horizonte temporal disponível (observe que, devido a Equação (8), o problema pode não ser solucionável se K não for suficientemente grande). Finalmente, as Restrições (9) e (10) definem os domínios das variáveis. O modelo abordado é definido como um Problema de Otimização Multiobjetivo (POM). Conforme Xue et al. [2019], um POM pode ser formalmente descrito da seguinte maneira: consi- derando um problema de minimização, para uma dada solução x ∈B, i.e., x é um vetor de decisão pertencente ao espaço de soluções viáveis B, deseja-se minimizar f(x) = f1(x), f2(x), . . . , fq(x), sendo f1, f2, . . . , fq objetivos conflitantes. Diante disso, uma solução viável a domina a solução viável b (com notação a ≻b), se fl(a) ≤fl(b) para todo l ∈{1, 2, . . . , q} e se fl(a) < fl(b) para pelo menos uma função objetivo l ∈{1, 2, . . . , q}. De acordo com Bérubé et al. [2009], alguns conceitos importantes são apresentados: Definição 2.1 (Solução eficiente e Conjunto eficiente) Diz-se que uma solução x ∈B é (Pareto) eficiente se não existe uma outra solução x ′ ∈B de tal modo que x ′ ≻x. E conjunto eficiente agrupa todas as soluções ditas eficientes, isto é, A = {x ∈B : x é eficiente em B}. https://proceedings.science/p/193733?lang=pt-br DOI: 10.59254/sbpo-2024-193733 Definição 2.2 (Fronteira de Pareto) Agrupa as imagens do conjunto A no espaço dos objetivos, ou seja, P = {fl(x) ∀l ∈{1, 2, ..., q} : x ∈A}. Definição 2.3 (Ponto Ideal e Ponto de Nadir) Para um problema bi-objetivo, o ponto ideal pI = (fI 1 , fI 2 ), no qual, fI 1 = min{f1(x)} e fI 2 = min{f2(x)}, x ∈A. E o ponto de Nadir é entendido como pN = (fN 1 , fN 2 ), no qual, fN 1 = {f1(x) : f2(x) = fI 2 } e fN 2 = {f2(x) : f1(x) = fI 1 }, x ∈A. O conjunto de soluções encontradas pelos métodos de otimização multi-objetivo podem ser comparados conforme métricas de performance. Para esse trabalho, os indicadores de perfor- mance considerados são: (a) Pureza: Mede a quantidade de soluções que têm os mesmos valores de TEC e Cmax quando comparadas a uma fronteira de referência. Os valores de Pureza variam de 0 a 1, com valores mais altos indicando uma fronteira de melhor qualidade; (b) Dr: Calcula a distância euclidiana entre os pontos do método avaliado e uma fronteira de referência. Valores menores de Dr são desejáveis, indicando soluções mais próximas da fronteira ideal; (c) Hipervolume: Avalia a aproximação e dispersão das soluções em relação a um ponto de referência, que é o Ponto de Nadir da união de todas as fronteiras obtidas. Um maior Hipervolume indica soluções menos dispersas e mais próximas da fronteira de referência. Nesse trabalho, a fronteira de referência foi definida por meio de um algoritmo restrição- ϵ exato para pequenas instâncias ou pela união das soluções encontradas por todos os métodos, removendo as soluções dominadas, para grandes instâncias. 3. Algoritmos implementados A heurística de sequenciamento apresentada a seguir foi desenvolvida por Anghinolfi et al. [2021]. Testes computacionais revelaram que essa abordagem supera significativamente ou- tras alternativas comparadas, como as abordagens evolutivas multi-objetivo NSGA-III e MOEA/D. Esse algoritmo é definido como Sequenciamento Guloso Dividido (SGS) e combina uma heurística construtiva gulosa aleatória que considera a alocação preemptiva de tarefas, buscando aproveitar períodos de menor custo energético, com uma heurística de refinamento (ES) que busca melhorar o TEC sem comprometer o Cmax por meio de trocas de blocos. Para facilitar a compreensão, algumas definições de Anghinolfi et al. [2021] são necessárias. Definição 3.1 (Unidades de tempo adjacentes e consecutivas) Duas unidades de tempo k e k+1 na mesma máquina são consideradas adjacentes, e duas unidades de tempo k e k + t na mesma máquina são consideradas como unidades de tempo consecutivas, se todas as unidades de tempo de k + 1 até k + t −1 forem utilizadas para processar tarefas, ou seja, não estiverem livres. As unidades de tempo são consideradas livres se não estiverem sendo processadas tarefas nelas. Uma localização l que contém as unidades de tempo F ⊆T em uma máquina h ∈H é denotada como l = (h, F). O custo energético dessa localização, ECl, é dado por eh P t∈F ct. Definição 3.2 (Localização livre e Localização dividida) Uma localização livre para uma tarefa j é uma localização (h, F) que agrupa apenas unidades de tempo adjacentes e/ou consecutivas livres da máquina h, de modo que |F| = pj. E uma localização dividida é uma localização que inclui pelo menos duas unidades de tempo livres consecutivas. Uma localização atribuída para uma tarefa j na máquina h é representada como (h, Aj), onde Aj é o conjunto de unidades de tempo adjacentes atribuídas à tarefa j e |Aj| = pj. Observe que o horário de início de uma tarefa j, sj, é igual a mint∈Aj{t}. https://proceedings.science/p/193733?lang=pt-br DOI: 10.59254/sbpo-2024-193733 Definição 3.3 (Sequenciamento Viável) Um sequenciamento viável S = {(h, Aj), j ∈J : h ∈ H, Aj ⊆T} é um conjunto de atribuições de tarefas a localizações não divididas, de modo que (h, Aj) e (h, Aj′), Aj ∩Aj′ = ∅. O exemplo da Figura 1a) mostra duas tarefas, j e j′, com tempos de processamento pj = 3 e pj′ = 2, respectivamente. Essas tarefas são atribuídas a localizações com pares de unidades de tempo adjacentes, formadas pela localização l = (h, Ij), onde Ij = {3, 4, 5} e (h, I′ j), onde Ij′ = {9, 10}, enquanto que j′′, com tempo de processamento pj′′ = 2, é atribuída a uma localização com um par de unidades de tempo consecutivas, chamada de localização dividida, l = (h, Ij′′), onde Ij′′ = {8, 11}. Se uma tarefa j é atribuída a uma localização dividida, diz-se que j é agendada dividida em l. Se pelo menos uma tarefa é agendada dividida em l, temos um sequenciamento dividido, que é o equivalente a um sequenciamento com preempção. Definição 3.4 (Sequenciamento Dividido) Um sequenciamento dividido S = {(h, Ij), j ∈J : h ∈H, Ij ⊆T} é um conjunto de localizações atribuídas e localizações divididas atribuídas de tal forma que, para toda localização (h, Ii) e (h, Ij) atribuídas às tarefas i, j ∈J, Ii ∩Ij = ∅, se i ̸= j. Um sequenciamento viável apresenta apenas locais atribuídos às tarefas com unidades de tempo adjacentes na mesma máquina e satisfaz a condição de não sobreposição para tarefas atribuídas à mesma máquina, ou seja, não pode haver intervalos de tempo comuns. Visto isso, um sequenciamento dividido S′ pode ser convertido em um sequenciamento viável S (com tarefas atribuídas a localizações com unidades de tempo adjacentes apenas) sem alterar os valores de TEC e makespan. Portanto, pode-se afirmar que um sequenciamento dividido S′ é equivalente a S, se Cmax(S′) = Cmax(S) e TEC(S′) = TEC(S). j 1 2 j j 3 4 5 6 7 8 9 10 11 12 j\" j' t 5 5 2 2 2 6 5 5 2 2 2 6 ct h h j' a) b) j\" j j j j\" j\" j' j' Figura 1: Exemplo de conversão de um sequenciamento dividido em um viável. O sequenciamento dividido pode ser convertido em um viável sem alterar os valores de TEC e Cmax, uma vez que não altera os períodos de tempo utilizados para processar tarefas. Na Figura 1a), apresenta-se um sequenciamento com a atribuição das tarefas j e j′ à máquina h em localizações (h, {3, 4, 5}) e (h, {9, 10}), com custo energético ECIj = 6 e ECIj′ = 4, assumindo eh = 1, respectivamente. A tarefa j′′ é atribuída à mesma máquina na localização dividida (h, {8, 11}), com ECIj′′ = 7. Portanto, temos um sequenciamento dividido com TEC = 17 e Cmax = 11, o qual pode ser convertido em um sequenciamento viável equivalente, conforme mostrado na Figura 1b), com a atribuição das tarefas j, j′ e j′′ aos respectivos locais (h, {3, 4, 5}), (h, {10, 11}) e (h, {8, 9}), que apresentam apenas unidades de tempo adjacentes. A heurística construtiva é chamada de Heurística Gananciosa Dividida (SGH), apresen- tada no Algoritmo 1, e constrói uma solução inicial minimizando o TEC dentro de um horizonte de tempo definido. O processo envolve definir localizações livres e divididas nas máquinas. Tarefas são alocadas em localizações, e sequenciamentos divididos são convertidos em sequenciamentos viáveis, que não alteram os valores de TEC e Cmax. https://proceedings.science/p/193733?lang=pt-br DOI: 10.59254/sbpo-2024-193733 Algoritmo 1: Heurística gananciosa dividida(J, H, T) 1 S ←{Sh, h ∈H}, Sh = ∅, h ∈H; 2 Construir uma lista ˆP dos elementos de PJ e os ordenar de forma não-crescente; 3 Para todo p ∈PJ, construir uma lista Fp ←{j ∈J : pj = p}; 4 for p ∈ˆP do 5 for h ∈H do 6 Construir uma lista Lph com as localizações alternativas na máquina h para alguma tarefa j, no qual, pj = p; 7 end 8 for j ∈Fp do 9 if Lph = ∅∀h ∈H then 10 return “Não existe solução viável” 11 end 12 else 13 Selecionar aleatoriamente a localização ˆl = (ˆh, Î) dentre as localizações de menor custo energético provenientes de ∪h∈HLph; 14 Designar a localização ˆl para a tarefa j e adicionar ˆl em Sˆh; 15 Remover de Lpˆh qualquer localização (ˆh, I) no qual I ∩Î ̸= ∅; 16 Construir as novas localizações divididas (ˆh, I′), com |I′| = p e inserir em Lpˆh; 17 end 18 end 19 end 20 if O sequenciamento S construído é dividido then 21 Converter sequenciamento(S); 22 end 23 return S Com base no Algoritmo 1, a construção de uma solução inicial começa com a criação de uma lista ˆP dos tempos de processamento distintos p ∈PJ das tarefas j ∈J, ordenados de forma não-crescente (Linha 2). Em seguida, é construída uma lista de listas F, onde Fp armazena as tarefas j ∈J com o tempo de processamento p (Linha 3). Para cada tempo de processamento distinto p ∈ˆP, as tarefas correspondentes são alocadas em localizações livres (possivelmente divididas) visando obter o menor custo energético (Linhas 4 a 19). Esse procedimento começa com a construção de uma lista Lph das localizações livres e livres divididas disponíveis para alocar uma tarefa com tempo de processamento p para cada máquina h ∈H (Linhas 5 a 7). As localizações livres (e divididas) são construídas ao longo dos intervalos de tempo, iterando uma unidade até alcançar Kmax, i.e., o maior período do horizonte de tempo. Uma fila é definida e, se a unidade de tempo t é considerada livre, ela é enfileirada até que se alcance uma capacidade de p unidades, indicando que uma nova localização (possivelmente dividida) foi encontrada. O custo energético desse local pode ser definido pelo custo do local anterior retirando o custo da unidade de tempo mais antiga da fila e acrescentando a unidade de tempo mais atual da fila à nova localização. Para cada tarefa j com tempo de processamento p (ou seja, j ∈Fp), uma localização ˆl dentre as de menor custo energético, considerando todas as máquinas, é selecionada aleatoriamente (Linha 13). Essa seleção uniforme aleatória foi definida em Anghinolfi et al. [2021], pois obser- varam que a escolha aleatória produziu melhores resultados de TEC em comparação com uma escolha determinística que prioriza a alocação das tarefas nos primeiros períodos de tempo. https://proceedings.science/p/193733?lang=pt-br DOI: 10.59254/sbpo-2024-193733 Em seguida, a localização selecionada ˆl = (ˆh, Î) é designada para a tarefa j e adicionada ao sequenciamento da máquina ˆh (Linha 13). Posteriormente, nas Linhas 15 e 16, a lista Lpˆh é atualizada removendo as localizações l′ ∈Lpˆh onde I′ ∩Î ̸= ∅e adicionando as novas localizações divididas que surgem da designação de j para ˆl. Se não houver localização livre em qualquer uma das máquinas para alocar uma tarefa, isso indica um problema sem solução viável, uma vez que Kmax é muito restrito para sequenciar todas as tarefas (Linhas 9 a 11). O algoritmo Converter sequenciamento é usado para ajustar sequenciamentos di- vididos em viáveis, garantindo que as tarefas sejam alocadas a unidades de tempo adjacentes sem sobreposição. A solução obtida pela heurística construtiva SGH pode ser aprimorada por meio de uma busca baseada em trocas, conhecida como ES. Para uma compreensão mais profunda dessa abordagem, são necessárias as seguintes definições. Definição 3.5 (Sequência de Períodos Trocáveis - EPS) Um bloco EPS é um subconjunto E de intervalos de tempo adjacentes em uma máquina específica h dentro de um cronograma viável S. Em um EPS, se uma unidade de tempo é utilizada para processar uma tarefa j, então todas as unidades de tempo atribuídas à tarefa j devem estar contidas em E. Na Figura 2 o subconjunto E1 = {1, 2, 3} na máquina h não pode ser considerado um EPS, uma vez que a unidade de tempo 3 é utilizada para executar parte da tarefa 1, porém E1 não contém todos os períodos utilizados para processar a tarefa 1, ou seja, os períodos 4 e 5 não estão contidos em E1. Nesse caso, possíveis EPS’s de tamanho 3 seriam E2, que abrange todos os períodos utilizados para processar a tarefa 1, e E3 e E4, que englobam todos os períodos usados para processar a tarefa 2. 1 1 2 1 1 3 4 5 6 7 8 9 10 t h 2 2 3 E1 E3 E2 E4 Figura 2: Exemplo para identificar uma EPS. Definição 3.6 (Troca de EPS) Uma troca entre dois EPS’s E e E′, pertencentes às máquinas h e h′, respectivamente, tal que |E| = |E′| e E ∩E′ = ∅se h = h′, é um procedimento que permite o sequenciamento das tarefas atribuídas às unidades de tempo em E, na máquina h, para as unidades de tempo em E′, na máquina h′, e vice-versa, sem alterar a ordem de atribuição das tarefas dentro das unidades de tempo de E e E′. Definição 3.7 (Rearranjo de EPS) Um rearranjo de um EPS E em um sequenciamento viável S é um procedimento que reatribui o conjunto de tarefas sequenciadas em E, denotado por JE(S), em localizações com períodos de tempo adjacentes. A Figura 3 exemplifica uma troca e rearranjo de EPS. Na Figura 3a), temos um sequenci- amento viável S de 5 tarefas. Nesta ilustração, o EPS E = {8, 9, 10} na máquina h é trocado com o EPS E′ = {2, 3, 4} na máquina h′, resultando no sequenciamento em 3b). Em seguida, o rearranjo em E é realizado, resultando no novo sequenciamento em 3c). Esse rearranjo tem como objetivo atribuir as tarefas envolvidas na troca nos períodos de tempo de menor custo energético. Ainda, conforme ilustrado nas Figuras 2 e 3, é possível notar que nem todas as unidades de tempo em um EPS são atribuídas às tarefas. Nesse caso, podemos distinguir um EPS-J de um EPS-I. https://proceedings.science/p/193733?lang=pt-br DOI: 10.59254/sbpo-2024-193733 1 1 2 1 1 1 3 4 5 6 7 8 9 10 3 3 t h 4 5 2 2 2 h' 3 a) E' E Troca b) 1 1 2 1 1 1 3 4 5 6 7 8 9 10 4 t h 3 3 2 2 2 h' 5 E' E 3 Rearranjo c) 1 1 2 1 1 1 3 4 5 6 7 8 9 10 4 t h 3 3 2 2 2 h' 5 E' E 3 Figura 3: Exemplo para identificar troca e rearranjo. Definição 3.8 (Sequência de Períodos Trocáveis - J (EPS-J)) Um EPS-J é um EPS que contém uma única tarefa, sem nenhuma unidade de tempo ociosa. Definição 3.9 (Sequência de Períodos Trocáveis - I (EPS-I)) Um EPS-I é um EPS que contém no mínimo uma unidade de tempo ociosa. Diante disso, a troca de blocos só pode ocorrer entre um EPS-J e um EPS-I que possuem a mesma cardinalidade de E. Durante esse procedimento, todas as tarefas contidas no EPS-J são atribuídas ao EPS-I, enquanto as tarefas contidas no EPS-I são rearranjadas no EPS-J, caso existam. Esse procedimento combinado de troca e rearranjo é denominado “movimento”. No caso da Figura 3a), o EPS E = {8, 9, 10} na máquina h é caracterizado como um EPS-J e o EPS E′ = {2, 3, 4} na máquina h′ é um EPS-I, ambos com cardinalidade igual a 3. O pseudocódigo da busca local pode ser visto no Algoritmo 2. Este procedimento busca refinar a solução utilizando uma política de primeira melhoria, reduzindo o TEC sem aumentar o makespan. Inicialmente todos blocos denominados de EPS-J e EPS-I para cada tempo de proces- samento p ∈ˆP são criados e armazenados em blocos epsi e blocos epsj, respectivamente. O EPS-J de cada tarefa i ∈Fp com tempo de processamento p é formado pelo subconjunto de T, EJ = {sj, sj + 1, . . . , sj + pj −1}, na máquina hJ, onde sj é o tempo de início da tarefa j. A identificação de um conjunto EPS-I, formado por p unidades de tempo adjacentes, EI = {s, s + 1, . . . , s + p −1} na máquina hI é feita de tal modo que o primeiro período do subconjunto EI, s, seja um tempo de início de uma tarefa j ∈J ou um período ocioso, e o último período de EI, s + p −1, deve ser um tempo de conclusão de uma tarefa j ∈J ou um período ocioso. No entanto, caso s seja um tempo de início e s + p −1 seja um tempo de conclusão, deve existir pelo menos uma unidade de tempo livre entre eles. Os subconjuntos de T formados por períodos adjacentes são testados de 1 até Kmax, iterando de uma em uma unidade até completar um subconjunto de períodos de tempo de tamanho p, para cada máquina. Para cada tempo de processamento distinto (Linha 4) e para cada EPS-J de blocos epsj (Linha 5) e EPS-I de blocos epsi (Linha 6) de cardinalidade igual a p, i.e., |EPS Jp| = |EPS Ip| = p, a função Viabilidade (Linha 7) verifica se, no melhor caso de movimentação, o TEC pro- veniente desta (novo tec) é melhor que o TEC original do sequenciamento S, se sim, temos que uma atribuição de verdade para a variável viabilidade, c.c., falso. O cálculo do novo tec é realizado retirando do TEC de S o custo do EPS Jp e do EPS Ip e somando o custo da ocupação de todas as unidades de tempo pertencentes ao EPS Ip e do custo da quantidade de unidades de tempo ocupadas no EPS Ip das tarifas de menor custo do EPS Jp (menor custo) nas suas respectivas máquinas. https://proceedings.science/p/193733?lang=pt-br DOI: 10.59254/sbpo-2024-193733 Algoritmo 2: Busca local(J, H, M, S, ˆP) 1 Criar os blocos EPS-I e EPS-J ∀p ∈ˆP e armazenar em blocos epsi e blocos epsj, respectivamente; 2 while melhoria = verdade do 3 melhoria ←falso; 4 for p ∈ˆP do 5 for EPS jp ∈blocos epsj do 6 for EPS ip ∈blocos epsi do 7 viabilidade, novo tec, menor custo ←Viabilidade(EPS jp, EPS ip); 8 if viabilidade = verdade then 9 θ ←Movimento(novo tec, menor custo); 10 if θ < TEC(S) then 11 Atualizar o Sequenciamento S; 12 Atualizar os blocos EPS-I e EPS-J ∀p ∈ˆP e armazenar em blocos epsi e blocos epsj, respectivamente; 13 melhoria ←verdade; 14 Retornar para a linha 5; 15 end 16 end 17 end 18 end 19 end 20 end 21 return S Se o novo tec for menor que o TEC de S, i.e., viabilidade = verdade então realizamos o movimento entre ambos. A função Movimento (Linha 9) realiza a troca e o rearranjo das tarefas de EPS Ip nos períodos e máquina de EPS Jp e o cálculo do novo TEC proveniente dessa movimentação, θ, é definido pela redução de menor custo de novo tec e pela adição do real custo de ocupação das tarefas de EPS Ip nos períodos de EPS Jp. Em seguida, se θ for menor que o TEC de S (Linha 10), o novo sequenciamento e seus respectivos valores de TEC e makespan são atualizados (Linha 11), e blocos epsi e blocos epsj são atualizados para todo p ∈ˆP (Linha 12). Após isso, o procedimento retorna para a Linha 5. Assim, a heurística de refinamento adota uma política de “primeira melhoria”, repetindo esse processo até que não seja mais possível realizar nenhuma troca de EPS que melhore a solução. Para resolver o problema de forma bi-objetiva e obter a fronteira aproximada de Pareto, utiliza-se o método de Restrição-ϵ aproximado. Este método envolve iterar através de diferentes horizontes de tempo ˆK, que variam de Kmax até Kmin. O valor de Kmax representa o maior período do horizonte de tempo, enquanto Kmin = max{⌊P j∈J pj/M⌋, maxj∈J{pj}}. Para cada horizonte de tempo ˆK, aplica-se a heurística SGH para construir um sequenciamento viável de N tarefas em M máquinas. Em seguida, utiliza-se a heurística de refinamento ES para encontrar um ótimo local, e a solução resultante é adicionada à fronteira aproximada de Pareto F ′. A cada iteração, ˆK é reduzido em uma unidade, repetindo o procedimento até que o horizonte de tempo se torne tão pequeno que não seja mais possível encontrar um sequenciamento viável. Por fim, reporta-se F ′ sem incluir as soluções dominadas. 3.1. Abordagens propostas A meta-heurística, denominada de Busca Local de Pareto de Duas fases (2PPLS), é pro- posta por Lust e Teghem [2010] e utiliza algoritmos aproximativos nas duas fases do método. Estas fases são: (1) Buscar um conjunto aproximado de boas soluções eficientes suportadas, empregando um algoritmo aproximativo com um único objetivo (mono-objetivo), resultante da agregação li- https://proceedings.science/p/193733?lang=pt-br DOI: 10.59254/sbpo-2024-193733 near dos múltiplos objetivos do POM inicial; (2) Buscar um conjunto de soluções eficientes não- suportadas aproximadas, obtidas pela aplicação de um procedimento de busca em vizinhança, a partir da fronteira gerada na primeira fase. No contexto deste trabalho, nos inspiramos nessa meta-heurística aplicando a proposta de Anghinolfi et al. [2021] na primeira fase, com algumas estratégias para melhorar as soluções, e aplicamos na segunda fase uma busca em vizinhança adaptada ao problema de modo a explorar estrategicamente mais soluções no espaço de soluções viáveis. Uma dessas estratégias mencionadas envolve a definição de EPS-K. Definição 3.10 (Sequência de Períodos Trocáveis - K (EPS-K)) Um EPS-K é um EPS que contém uma ou mais tarefas, sem nenhuma unidade de tempo ociosa. No algoritmo de busca local (1ª fase do 2PPLS) e na busca em vizinhança (2ª fase) considera-se movimentações entre EPS-K e EPS-I. Um subconjunto E é identificado como um EPS-K que pode conter uma ou mais tarefas se o primeiro elemento do subconjunto E é o tempo de início de uma tarefa j ∈J, se o último elemento de E é o tempo de conclusão de uma tarefa j′ ∈J, e se todas as unidades de tempo do subconjunto E são ocupadas, ou seja, são utilizadas para processar tarefas. A consideração dessa estratégia permite uma maior possibilidade de trocas entre blocos, permitindo explorar mais o espaço de soluções. Outra estratégia aplicada consiste na troca da política de refinamento, de “primeira me- lhoria” para “melhor melhoria”. Nesse caso, todas as possíveis trocas de EPS-I e EPS-K para cada tempo de processamento distinto p ∈ˆP, são testadas, e o movimento escolhido é aquele que resulta na melhor melhoria. Esse processo é repetido até alcançar um ótimo local. Por fim, na segunda fase do 2PPLS, a busca por vizinhos x′ de uma solução x é conduzida por meio do refinamento que envolve movimentos entre EPS’s no sequenciamento de x. No entanto, adaptamos essa busca para permitir trocas que resultam em um aumento no valor de Cmax(x) em θ unidades, desde que haja uma melhoria no valor de TEC. Esse processo segue uma política de “primeira melhoria”, onde os movimentos são realizados até que não seja possível encontrar um TEC menor sem piorar o Cmax de x′, indicando a convergência para um ótimo local dentro dessa estrutura de vizinhança. A busca na vizinhança considera incrementos graduais de piora (de 1 unidade) no valor de Cmax(x), começando de 0 (para refinar a solução corrente) e avançando até a diferença entre o menor Cmax de uma solução q da fronteira aproximada Fe que seja maior que o Cmax da solução corrente x, e o próprio Cmax da solução corrente x, i.e., max piora = min{Cmax(q) : q ∈ Fe, Cmax(q) > Cmax(x)} −Cmax(x). Portanto, novas soluções vizinhas x′ podem ser exploradas por meio de movimentos de blocos no sequenciamento da solução x que permitem uma piora do Cmax(x) em θ ∈{0, 1, . . . , max piora−1, max piora} desde que TEC(x′) < TEC(x). Ainda, caso uma solução vizinha x′ de ótimo local encontrada for dominada por alguma outra solução da fronteira aproximada de Pareto Fe a busca dos vizinhos da solução corrente x para e a próxima solução de F ′ passa a ser a corrente. 4. Resultados computacionais As instâncias de teste propostas por Wang et al. [2018] são classificadas em pequena e grande escala. As instâncias pequenas possuem entre 6 e 25 tarefas, 3 a 7 máquinas paralelas, e 50 a 80 intervalos de tempo disponíveis por máquina. As instâncias grandes, por sua vez, incluem de 30 a 200 tarefas, 8 a 25 máquinas paralelas, e 100 a 300 intervalos de tempo. Em ambas as escalas, são considerados os tempos de processamento das tarefas, os custos de consumo energético das máquinas e as tarifas associadas aos intervalos de tempo disponíveis. https://proceedings.science/p/193733?lang=pt-br DOI: 10.59254/sbpo-2024-193733 Nas primeiras analisamos os indicadores de performance para a fronteira obtida por um algoritmo exato baseado em restrição-ϵ (coluna “MIP”), para a Abordagem 1, proposta por Anghi- nolfi et al. [2021] e a Abordagem 2, proposta nesse trabalho, e na segunda analisamos apenas os dois últimos. A comparação entre as abordagens foi analisada por meio de testes estatísticos de Wil- coxon. Um valor da estatistica de teste p-valor menor que 0,05 indica uma diferença significativa entre as abordagens. Tabela 1: Resultados dos indicadores de performance para Instâncias Pequenas e Grandes Indicadores de Performance Métricas Instâncias Pequenas Instâncias Grandes MIP Abord. 1 Abord. 2 Abord. 1 Abord. 2 Hipervolume Média 0,7552 0,7534 0,7541 0,8314 0,8325 Mediana 0,7650 0,7585 0,7614 0,8487 0,8508 GAP - 0,2371% 0,1523% - -0,1321% p-valor - 0,0008 6,56E-07 Pureza Média 1,0000 0,8384 0,8902 0,5569 0,7265 Mediana 1,0000 0,9034 0,9296 0,4844 0,7413 GAP - 16,157% 10,978% - -30,451% p-valor - 0,0017 1,77E-05 Dr Média 0,0000 0,0021 0,0015 0,0034 0,0015 Mediana 0,0000 0,0007 0,0004 0,0025 0,0009 GAP - - - - -121,70% p-valor - 0,0042 3,98E-06 Tempo CPU 25,0351 0,3904 0,9659 90,8097 241,2196 p-valor - 1,86E-09 1,86E-09 Na Tabela 1, observamos que a Abordagem 2 supera significativamente a Abordagem 1 em todas as métricas de desempenho, tanto para instâncias pequenas quanto grandes. Nas instâncias pequenas, a Abordagem 2 se distancia da “MIP” em média em 0,15% e 10,98% para o Hipervolume e Pureza, respectivamente, enquanto a 1 se distancia mais, com 0,24% e 16,16%, nessa ordem. Nas instâncias grandes, essas diferenças são ainda mais notáveis, com a média da Abordagem 2 supe- rando a Abordagem 1 em 0,13%, 30,45% e 121,22% para Hipervolume, Pureza e Dr, respectiva- mente. No entanto, em termos de tempo computacional, a Abordagem 2 requer 2,47 e 2,66 vezes mais tempo que a Abordagem 1 para instâncias pequenas e grandes, respectivamente. Apesar disso, as estratégias implementadas, como o uso de EPS-K, a política de “melhor melhoria” e a busca em vizinhança, são cruciais para aprimorar as fronteiras. 5. Conclusão Neste estudo, apresentamos uma heurística para resolver um problema de sequenciamento de máquinas paralelas considerando questões ambientais em um contexto bi-objetivo. Nosso obje- tivo é minimizar simultaneamente o makespan, e o consumo total de energia. Avaliamos a eficácia da nossa abordagem em comparação com a proposta de Anghinolfi et al. [2021] através de indi- cadores de desempenho que medem a qualidade da fronteira de Pareto. Os resultados dos testes computacionais mostram que nossa heurística supera significativamente a proposta anterior em to- das as medidas de desempenho, em instâncias de pequeno e grande porte. Nosso trabalho promete contribuir na redução dos impactos ambientais e na competitivi- dade das indústrias, além de contribuir para o avanço da comunidade acadêmica. Visto isso, dada a crescente relevância do agendamento de eficiência energética, futuras pesquisas explorarão diver- sas estratégias nesse sentido. Além disso, planejamos aprimorar nossa proposta desenvolvendo uma busca em vizinhança mais eficiente e reduzindo o tempo computacional do algoritmo. https://proceedings.science/p/193733?lang=pt-br DOI: 10.59254/sbpo-2024-193733 6. Agradecimento O presente trabalho foi realizado com apoio do Conselho Nacional de Desenvolvimento Científico e Tecnológico (CNPq), 404807/2021-6; e da Coordenação de Aperfeiçoamento de Pes- soal de Nível Superior (CAPES), Código de Financiamento 001."
        },
        {
            "titulo": "CONSTRUÇÃO ITERATIVA DE ROTAS COM CAPTAÇÃO DE PONTOS EM SISTEMAS DE COBERTURA GEOGRÁFICA",
            "informacoes_url": "https://proceedings.science/p/193461?lang=pt-br",
            "idioma": "Português",
            "storage_key": "galoa-proceedings--sbpo-2024--193461.pdf",
            "autores": [
                {
                    "nome": "Márcio André Araújo Gonçalves",
                    "afiliacao": "Universidade Federal do Rio de Janeiro (UFRJ) - Programa de Engenharia de Produção",
                    "orcid": ""
                },
                {
                    "nome": "Virgílio José Martins Ferreira Filho",
                    "afiliacao": "Universidade Federal do Rio de Janeiro (UFRJ) - Programa de Engenharia de Produção",
                    "orcid": ""
                }
            ],
            "data_publicacao": "",
            "resumo": "Este artigo apresenta um modelo iterativo para geração de rotas a partir da seleção de pontos iniciais, usando a abordagem do Problema do Caixeiro Viajante, de forma a garantir a cobertura de uma área geográfica, com a captura de pontos pelas rotas, em função de um raio de cobertura.",
            "keywords": [
                "Problema do Caixeiro Viajante",
                "Problema de Cobertura",
                "Varredura"
            ],
            "referencias": [
                "Abreu, G. M. (2007). A Amazônia Azul: o mar que nos pertence. Cadernos de Estudos Estratégicos, n. 6, p. 17-66.",
                "Bellingham, J. (2001). Autonomous underwater vehicles (AUVs). Sea, v. 7, n. 915, p. 980. DOI: 10.1006/rwos.2001.0303.",
                "BRASIL. Lei nº 8.617, de 4 de janeiro de 1993. Dispõe sobre o mar territorial, a zona contígua, a zona econômica exclusiva e a Plataforma Continental brasileiros, e dá outras providências. Disponível em: <http://www.planalto.gov.br/ccivil_03/Leis/L8617.htm>. Acesso em: 03 mai. 2024.",
                "BRASIL. Decreto nº 5.129, de 6 de julho de 2004. Dispõe sobre a Patrulha Naval e dá Outras Providências. Brasília, 2004a. Disponível em: <http://www.planalto.gov.br/ccivil_03/_ato2004-2006/2004/decreto/d5129.htm>. Acesso em: 03 mai. 2024.",
                "Dantzig, G., Fulkerson, R., Johnson, S. (1954). Solution of a large-scale traveling-salesman problem. Journal of the operations research society of America, v. 2, n. 4, p. 393-410.",
                "Galvão, A. C. F. et al. (2008). Mar e Ambientes Costeiros. Centro de Gestão e Estudos Estratégicos, Brasília/DF. Disponível em: <https://repositorio.mcti.gov.br/bitstream/mctic/5320/1/2007_mar_e_ambientes_costeiros.pdf>. Acesso em: 22 mai. 2024.",
                "Gonçalves, F. B. (2021). Guerra de minas. Revista Passadiço, v. 34, n. 41, p. 80-80.",
                "Kilhian, K. (2013). Web page. https://www.obaricentrodamente.com/2013/06/distancia-de-um-ponto-uma-reta.html/. Acessado: 2024-05-16.",
                "Lawler, E. L., Lenstra, J. K., Rinnooy Kan, A. H. G., Shmoys, D. B. (1985). The Traveling Salesman Problem: A Guided Tour of Combinatorial Optimization. Wiley.",
                "Rodrigues, M. B. de A. et al. (2021). Estratégia Eficiente com Alta Disponibilidade para Provisionamento Dinâmico de Pontos de Acesso em Redes sem Fio de Grande Escala. In: Anais Estendidos do XI Simpósio Brasileiro de Engenharia de Sistemas Computacionais. SBC, p. 110-115.",
                "Sousa, J. V. N. (2018). Características gerais dos veículos autônomos submarinos. Revista Marítima Brasileira, v. 138, n. 01/04, p. 137-150. https://proceedings.science/p/193461?lang=pt-br DOI: 10.59254/sbpo-2024-193461"
            ],
            "artigo_completo": "CONSTRUÇÃO ITERATIVA DE ROTAS COM CAPTAÇÃO DE PONTOS EM SISTEMAS DE COBERTURA GEOGRÁFICA. RESUMO Este artigo apresenta um modelo iterativo para geração de rotas a partir da seleção de pontos iniciais, usando a abordagem do Problema do Caixeiro Viajante, de forma a garantir a cobertura de uma área geográfica, com a captura de pontos pelas rotas, em função de um raio de cobertura. Tal modelo consiste em determinar rotas em áreas geográficas onde não existem pontos a serem visitados, sendo necessário, dessa forma, a geração desses pontos, denominados waypoints, para que o modelo apresente uma rota ótima a ser realizada. O trabalho apresenta uma metodologia inovadora para otimização de varreduras marítimas, com aplicação em atividades de exploração do leito submarino, levantamentos batimétricos, localização de objetos submersos e na identificação de possíveis ameaças submarinas, contribuindo para segurança da navegação marítima. PALAVRAS CHAVE. Problema do caixeiro viajante, Problema de Cobertura, Varredura. Tópicos: (OC) Otimização Combinatória, (PM) Programação Matemática, (D&SP) – PO em Defesa e Segurança Pública. https://proceedings.science/p/193461?lang=pt-br DOI: 10.59254/sbpo-2024-193461 1. Introdução O território marítimo brasileiro, conhecido como Amazônia Azul, abrange uma área de cerca de 4,5 milhões de quilômetros quadrados, equivalente a mais da metade da área do Brasil continental. De acordo com a COMISSÃO INTERMINISTERIAL PARA OS RECURSOS DO MAR (CIRM), um estudo sobre o limite exterior da Plataforma Continental Brasileira foi encaminhado à Organização das Nações Unidas (ONU), visando a ampliação da Amazônia Azul, totalizando 5,7 milhões de km² de área marítima. Essa região possui uma grande importância estratégica, econômica e ambiental para o país, pois nela se encontram recursos naturais, energéticos e biológicos de alto valor [Abreu 2007]. Conforme a LEI Nº 8.617, DE 4 DE JANEIRO DE 1993, que dispõe sobre o mar territorial e a zona econômica exclusiva e a Plataforma Continental brasileiros, a exploração e a conservação desses recursos exigem uma atuação efetiva do Estado brasileiro, que deve garantir a soberania nacional e a sustentabilidade da Zona Econômica Exclusiva (ZEE), onde o Brasil tem direitos exclusivos sobre as atividades econômicas realizadas no mar. Para garantir a proteção e o uso racional da Amazônia Azul, o Brasil precisa contar com uma presença naval efetiva e permanente nas suas águas jurisdicionais. De acordo com o DECRETO Nº 5.129, DE 6 DE JULHO DE 2004, que dispõe sobre a patrulha naval, o patrulhamento naval é um instrumento indispensável para a vigilância contínua e a resposta rápida a eventuais ameaças nas águas jurisdicionais brasileiras. Essa atividade não só reforça a segurança nacional, mas também contribui para a conservação dos ecossistemas marinhos, ao detectar e neutralizar ameaças subaquáticas, como poluição, pesca ilegal e mineração clandestina. Nesse sentido, o desenvolvimento tecnológico traz soluções inovadoras para os desafios subaquáticos, como os Veículos Autônomos Subaquáticos (Autonomous Underwater Vehicles - AUVs), que são capazes de realizar missões militares, comerciais e científicas sem intervenção humana [Souza 2018]. Tal categoria de veículos contribuirá, sobremaneira, para o desenvolvimento de diversas aplicações marítimas. O uso de veículos autônomos subaquáticos (AUVs) representa uma abordagem inovadora, permitindo a cobertura eficiente de áreas remotas e de difícil acesso. Segundo um estudo de [Bellingham 2001], os AUVs têm a capacidade de realizar missões de varredura de forma autônoma, coletando dados valiosos e reduzindo a dependência de embarcações tripuladas. 2. Descrição do Problema A condução eficiente de operações de varredura submarina é crucial para a segurança e estabilidade de áreas marítimas estratégicas. Essas atividades, realizadas por meio de equipamentos especializados, seguem rotas predefinidas com base em doutrinas específicas. No entanto, um desafio significativo emerge na falta de precisão no controle da distância percorrida durante essas missões, prejudicando a assertividade na cobertura das áreas demarcadas. A ausência de mecanismos precisos para avaliar o percentual de varredura dentro das coordenadas geográficas designadas agrava a complexidade operacional. A falta de dados confiáveis compromete a eficácia global das missões, deixando áreas críticas suscetíveis a possíveis ameaças não detectadas. Esse dilema também impacta a capacidade de análise pós- missão, impedindo uma compreensão abrangente do desempenho e dificultando melhorias contínuas nas estratégias de varredura. Diante desse cenário desafiador, a oportunidade de melhoria reside no desenvolvimento de um sistema avançado de monitoramento e avaliação. A integração de tecnologias de rastreamento preciso da distância percorrida e análise detalhada do percentual de varredura em áreas demarcadas é essencial. A consecução desse domínio não apenas aprimorará a eficácia das operações de varredura submarina, mas também abrirá caminho para o aumento sustentável no número de missões, impulsionado por dados confiáveis e uma compreensão mais profunda das operações. Este trabalho propõe o uso de um método interativo em que se calcula a cobertura a partir da rota obtida para utilização do equipamento de varredura, considerando um aumento sucessivo https://proceedings.science/p/193461?lang=pt-br DOI: 10.59254/sbpo-2024-193461 na seleção de pontos visitados, ou waypoints, até o atingimento do nível mínimo de cobertura definido. Para garantir a eficiência das rotas, as mesmas são obtidas via solução de um problema do caixeiro viajante. Como fator de diferenciação dos modelos encontrados na literatura, o modelo proposto aborda o conceito de captura de pontos dentro de uma área geográfica, sendo composto por captura de pontos fixo, a partir do posicionamento estratégico dos meios navais dispostos na área, como também pela captura de pontos pelas rotas definidas no modelo de roteamento, desde que dentro do raio definido pelo equipamento de detecção, garantindo, assim, um determinado patamar de atendimento ao serviço de varredura da área. 3. Referencial Teórico 3.1. Atividade de Varredura Submarina A varredura submarina, uma atividade metodicamente conduzida, representa um campo essencial para diversas aplicações marítimas. Além de sua participação crucial em operações de busca e salvamento, a varredura submarina desempenha um papel fundamental na exploração de recursos marinhos e na vigilância submarina. A literatura destaca a relevância dessas operações para a segurança marítima e a importância de aprimorar constantemente as técnicas e tecnologias associadas. No contexto da exploração de recursos naturais, a varredura submarina desempenha um papel crucial na identificação e mapeamento de depósitos minerais no fundo do mar. De acordo com [Galvão et al. 2008], a capacidade de detectar e avaliar os recursos submarinos permite a gestão sustentável desses recursos, contribuindo para o desenvolvimento econômico e a preservação ambiental. A localização de objetos submersos, como destroços de embarcações, é outra aplicação vital da varredura submarina. A atividade é essencial em operações de busca e salvamento, onde a rapidez e precisão são fundamentais. Estudos como o de [Rodrigues et al. 2021] enfatizam a necessidade de técnicas avançadas para otimizar a cobertura de áreas extensas, possibilitando, em casos de emergências, uma resposta bem mais eficientes. No âmbito da segurança marítima, a varredura submarina desempenha um papel preventivo e estratégico. A identificação de possíveis ameaças submersas, como minas navais, é crucial para garantir a segurança de rotas marítimas. [Gonçalves 2021] destaca a importância dos navios varredores, e novas tecnologias como os veículos autônomos, equipados com tecnologias avançadas de sonar na detecção precoce de ameaças, contribuindo para a defesa eficaz de áreas estratégicas. 3.2. Cobertura de Área Geográfica O presente trabalho apresenta um modelo de cobertura de área geográfica, delimitada por pontos fornecidos de latitude x longitude, onde não existem pontos a serem definidos como “waypoints” para solução do problema do caixeiro viajante. Ou seja, trata-se de cobrir uma área marítima “limpa” (Figura 1), onde qualquer elemento que nela se encontre, passa a ser considerado restrição à navegação ou simplesmente, um obstáculo a ser evitado. Figura 1 – Delimitação de uma área geográfica. https://proceedings.science/p/193461?lang=pt-br DOI: 10.59254/sbpo-2024-193461 Fonte: Elaborado pelo Autor 3.3. Problema do Caixeiro Viajante (PCV) O Problema do Caixeiro Viajante (Traveling Salesman Problem - TSP) destaca-se como um dos problemas mais proeminentes e estudados em otimização combinatória. Sua formulação clássica consiste em encontrar o caminho mais curto que visita cada ponto em um conjunto exatamente uma vez, retornando ao ponto de origem. Essa problemática, apesar de sua aparente simplicidade, tem implicações significativas no roteamento de veículos, desencadeando uma vasta gama de estudos e pesquisas na busca por soluções eficientes. O TSP é intrinsecamente ligado à otimização de rotas de veículos, onde a busca pelo caminho mais curto tem implicações diretas na redução de custos operacionais e no aumento da eficiência logística. [Lawler et al. 1985] ressaltam que a resolução eficiente do TSP é fundamental para a tomada de decisões estratégicas no roteamento, impactando diretamente a economia de recursos e a satisfação do cliente. A complexidade computacional do TSP, classificado como um problema NP-completo, desafia os pesquisadores a desenvolverem algoritmos eficientes para encontrar soluções ótimas ou aproximadas. Diversas abordagens, como a heurística do vizinho mais próximo e algoritmos genéticos, têm sido exploradas para enfrentar essa complexidade e encontrar soluções viáveis em tempo hábil. Dado um grafo G = (N, M) onde N = {1, ..., n} é um conjunto de vértices ou localidades de uma rede e M = {1, ..., m} um conjunto de arestas ou estradas que ligam as localidades da rede, o problema consiste em definir a rota de menor custo que ligue todas as localidades, considerando que o caixeiro motorista do veículo visite cada localidade uma única vez. A cada aresta (i, j) Є M está associado um custo, cij, que representa o custo do deslocamento da localidade i para a j, e uma variável binária xij, que representa a utilização da aresta (i, j) pelo caixeiro e terá valor 1 se a aresta (i, j) é utilizada e 0, caso contrário. Com base nestas informações, tem-se o modelo matemático clássico do TSP, proposto por [Dantzig et al. 1954]. Minimizar: ∑ i∈N ∑ j∈∋} cij xij (1) Sujeito a: ∑ j∈∋} xij=1i=1,….,n (2) ∑ i∈Nj} xij=1 j=1,….,n (3) ∑ i∈S ∑ j∈Si } xij≤|S|−1∀S ⊂N ,S≠0 (4) xij∈{0,1}i , j=1,…,n,i ≠j (5) A função objetivo expressa na equação (1) realiza o cálculo do custo do percurso do caixeiro. As restrições (2) e (3) garantem que toda localidade da rede, o caixeiro chega apenas uma vez na localidade e sai apenas uma vez da localidade. A restrição (4) assegura a formação de uma única rota que visita todas as localidades da rede uma única vez. O Problema do Caixeiro Viajante continua a ser uma pedra angular na otimização de rotas de veículos, desafiando a comunidade científica a desenvolver abordagens inovadoras e adaptáveis às demandas emergentes da logística moderna. https://proceedings.science/p/193461?lang=pt-br DOI: 10.59254/sbpo-2024-193461 4. Metodologia A metodologia proposta neste trabalho visa aprimorar a realização da atividade de varredura, estabelecendo uma abordagem estruturada para a delimitação da área geográfica, e a seleção eficiente de pontos de interesse a serem utilizados no processo de roteamento. Inicialmente, foram empregadas duas abordagens distintas para a seleção dos pontos iniciais à área geográfica delimitada. 4.1. Atribuição de Pontos Iniciais à Área Geográfica Na primeira abordagem, os pontos iniciais são atribuídos de forma aleatória dentro dessa área. Esse método proporciona uma distribuição diversificada de pontos iniciais, garantindo uma cobertura abrangente da região em questão (Figura 2). Na segunda abordagem, a área é subdividida em uma grade com espaçamento igualmente distribuído entre os pontos iniciais. Essa estratégia busca otimizar a eficiência na varredura, assegurando uma cobertura sistemática e completa da região (Figura 3). Figura 2 – Distribuição de pontos aleatórios. Figura 3 – Distribuição de pontos equidistantes. Fonte: Elaborado pelo Autor Fonte: Elaborado pelo Autor 4.2. A Processo de Captura de Pontos O presente trabalho utiliza o conceito de distância do ponto a reta como forma de identificar pontos que estejam a uma distância d de qualquer segmento de reta r gerado pelo roteamento. Tal conceito pode ser mais bem visualizado pela Figura 4, onde, dada a equação geral da reta r :axo+byo+çe o ponto P (xo , yo), temos:  a é o coeficiente angular da reta ou a inclinação da reta;  b o coeficiente linear da reta ou o sentido da reta (crescente ou decrescente);  c é o termo constante ou a distância vertical da reta em relação à origem; e  (xo , yo) são as coordenadas do ponto P. Como processo de captura de pontos pelas rotas definidas como solução do modelo de PCV, os pontos selecionados como waypoints e os pontos captados pelas rotas, são desconsiderados da próxima rodada de escolhas, quando do não atingimento do percentual de cobertura mínimo. Figura 4 – Representação gráfica e formulação distância do ponto a reta. https://proceedings.science/p/193461?lang=pt-br DOI: 10.59254/sbpo-2024-193461 Fonte: [Kilhian 2013] A aplicação desta fórmula permite a identificação de pontos que estão a uma distância específica de uma reta, formando uma região similar a uma “faixa” ou “corredor” em torno da reta. Esta região é delimitada por duas retas paralelas à reta original da solução do roteamento, cada uma distante d de ambos os lados, conforme mostra a Figura 5. Figura 5 – Captura de pontos pela reta considerando distância d. Fonte: Elaborado pelo Autor 5. O Método Iterativo de Roteamento com Cobertura de Área Geográfica O roteamento iterativo, proposto no trabalho, trabalha com a seleção de pontos de forma gradativa, onde se espera o retorno de uma rota e o cálculo da cobertura de pontos iniciais, para, a partir de então, uma nova seleção de “waypoint”, dentro dos pontos iniciais do modelo, desconsiderando os pontos já captados pelas rotas anteriores, e assim sucessivamente, até o atingimento do percentual de cobertura mínimo definido (Figura 6). A cada iteração, o modelo recalcula a rota utilizando o modelo do PCV, apresentado no item 3.3 deste trabalho, em função de uma nova configuração geográfica dos pontos selecionados (Figura 7). Figura 6 – Fluxograma do modelo de Roteamento Iterativo. Fonte: Elaborado pelo Autor Figura 7 – Modelo de Rotas Iterativas com Pontos Aleatórios (Seleção de Pontos) https://proceedings.science/p/193461?lang=pt-br DOI: 10.59254/sbpo-2024-193461 Pontos Escolha do Ponto Rota com Captura p = 1 p = 2 p = 3 . . . . . . . . . p = 15 Fonte: Elaborado pelo Autor https://proceedings.science/p/193461?lang=pt-br DOI: 10.59254/sbpo-2024-193461 Um aspecto observado no modelo exposto neste trabalho diz respeito à complexidade computacional a ser encontrada, visto que dependendo da área a ser explorada, e do raio de cobertura do equipamento a ser utilizado, o número de “waypoints” a serem escolhidos para cobertura da área aumentará significativamente, o que tornará o problema exponencialmente mais complexo. 6. Resultados Computacionais Para avaliação do modelo, foram realizadas 9 análises com parâmetros variando raio de cobertura e percentual de cobertura mínima a ser atingido (Tabela 1). Foi implementado utilizando o auxílio da linguagem Python®, utilizando o solver Gurobi Optimizer version 9.5.2 build v9.5.2rc0, para resolução do modelo matemático do PCV, e executados em equipado com processador 11th Gen Intel(R) Core(TM) i5-1135G7 @ 2.40GHz 2.42 GHz, 8 GB de memória RAM, sob o sistema operacional Microsoft Windows 10 de 64 Bits. Tabela 1 – Parâmetros simulação Raio de cobertura % Cobertura mínimo 15, 20 e 25 75, 85, 95 Fonte: Elaborado pelo Autor Os resultados apresentados, referem-se ao cenário com pontos equidistantes: Figura 8 – Resultados raio de cobertura (R15) Cobertura Captação de Pontos Rota (Mapa) 75% 85% https://proceedings.science/p/193461?lang=pt-br DOI: 10.59254/sbpo-2024-193461 95% Fonte: Elaborado pelo Autor Figura 9 – Resultados raio de cobertura (R20) Cobertura Captação de Pontos Rota (Mapa) 75% 85% 95% Fonte: Elaborado pelo Autor https://proceedings.science/p/193461?lang=pt-br DOI: 10.59254/sbpo-2024-193461 Figura 10 – Resultados raio de cobertura (R25) Cobertura Captação de Pontos Rota (Mapa) 75% 85% 95% Fonte: Elaborado pelo Autor Com base nos resultados, pode-se avaliar comparativamente o impacto no incremento de unidades de raio de cobertura, conforme apresentado na Tabela 2: Tabela 2 – Análise comparativa dos incrementos nos resultados por unidade de parâmetro Parâmetros Cobertura 75% Cobertura 85% Cobertura 95% R15 R20 R25 R15 R20 R25 R15 R20 R25 Nº Pontos 49 26 16 60 43 22 92 63 33 Tempo Computacional (s) 166,6 30,3 11,5 479,8 94,6 54,9 1911 678,1 146,2 Distância Acumulada (km) 1,9 1,4 1,2 2,05 1,89 1,36 2,68 2,21 1,76 Fonte: Elaborado pelo Autor https://proceedings.science/p/193461?lang=pt-br DOI: 10.59254/sbpo-2024-193461 Figura 11 – Visualização dos resultados em mapas Cobertura 75% 85% 95% R15 R20 R25 Fonte: Elaborado pelo Autor 7. Conclusão Em operações de varredura submarina, a eficiência da operação pode garantir o êxito nas atividades de busca e salvamento, bem como da agilidade no que tange a tempos de respostas em incidentes hídricos. Através dos resultados, percebeu-se que qualquer incremento na unidade de medida dos raios de cobertura, bem como na variação no nível de cobertura mínimo exigido, há uma variação considerável no número de pontos a serem utilizados no roteamento para efetuar a cobertura total da região em estudo, o que impulsiona uma elevação na complexidade do modelo. Um dos grandes desafios em utilizar o modelo proposto é o tempo computacional para resolução do problema, em alguns casos, dependendo do tamanho do raio de cobertura em relação a área a ser explorada, não será simples chegar à solução ótima em um curto espaço de tempo. Por isso para trabalhos futuros, pretende-se utilizar heurísticas clássicas para a resolução do problema do caixeiro viajante com números elevados de pontos, como por exemplo, a Heurística do Vizinho mais Próximo (Nearest Neighbor Heuristic) e a Heurística GRASP https://proceedings.science/p/193461?lang=pt-br DOI: 10.59254/sbpo-2024-193461 aplicada ao modelo de PCV. Por fim, pretende-se realizar tal estudo em outras regiões delimitadas."
        },
        {
            "titulo": "Uma abordagem ILS-BanditVND para o Team Orienteering Problem",
            "informacoes_url": "https://proceedings.science/p/193342?lang=en",
            "idioma": "português",
            "storage_key": "galoa-proceedings--sbpo-2024--193342.pdf",
            "autores": [
                {
                    "nome": "Jéssica Richards Nascimento",
                    "afiliacao": "Universidade Federal do Rio de Janeiro - UFRJ",
                    "orcid": null
                },
                {
                    "nome": "Pedro Henrique González",
                    "afiliacao": "Universidade Federal do Rio de Janeiro - UFRJ",
                    "orcid": null
                }
            ],
            "data_publicacao": null,
            "resumo": "Esse trabalho aborda o problema de orientação de times da classe problemas NP-difíceis. Para solução do problema, foi utilizada a metaheurística Iterated Local Search (ILS) com Variable Neighbourhood Descent (VND). No ILS-VND, a escolha da sequência de estruturas de vizinhanças a ser explorada impacta diretamente o resultado.",
            "keywords": [
                "Variable Neighborhood Descent",
                "Multi-Armed Bandits",
                "Team Orienteering Problem"
            ],
            "referencias": [
                "Bianchessi N., Mansini R., e Speranza M. (2018). A branch-and-cut algorithm for the team orienteering problem. International Transactions in Operational Research, 25:627–.",
                "Butt S. E. e Cavalier T. M. (1994). A heuristic for the multiple tour maximum collection problem. Computers Operations Research, 21(1):101–111. ISSN 0305-0548. URL https://www.sciencedirect.com/science/article/pii/0305054894900655.",
                "Chao I.-M., Golden B. L., e Wasil E. A. (1996). The team orienteering problem. European Journal of Operational Research, 88(3):464–474. URL https://EconPapers.repec.org/RePEc:eee:ejores:v:88:y:1996:i:3:p:464-474.",
                "Croes G. A. (1958). A method for solving traveling-salesman problems. Operations Research, 6(6):791–812. ISSN 0030364X, 15265463. URL http://www.jstor.org/stable/167074.",
                "Dang D.-C., Guibadj R., e Moukrim A. (2013). An effective pso-inspired algorithm for the team orienteering problem. European Journal of Operational Research, 229:332–344.",
                "Gintner V. e Kliewer N. (2005). Solving large multiple-depot multiple-vehicle-type bus scheduling problems in practice. Operations Research-Spektrum, 27:507–523.",
                "Golden B., Levy L., e Vohra R. (1987). The orienteering problem. Nav Res Logist, 34:307–318.",
                "Hammami F., Rekik M., e Coelho L. C. (2020). A hybrid adaptive large neighborhood search heuristic for the team orienteering problem. Computers Operations Research, 123:105034. ISSN 0305-0548). URL https://www.sciencedirect.com/science/article/pii/S0305054820301519.",
                "Hansen P., Mladenovic N., e Moreno-Pérez J. (2010). Variable neighbourhood search: Methods and applications. 4OR, 175:367–407.",
                "Lourenço H., Martin O., e Stützle T. (2001). A beginner’s introduction to iterated local search. p. 1–11.",
                "Lü Z., Hao J.-K., e Glover F. (2011). Neighborhood analysis: A case study on curriculum-based course timetabling. J. Heuristics, 17:97–118.",
                "Macedo E. A. A. G. e Senne E. L. F. (2023). Hybrid approach to solve the team orienteering problem. In Anais do Simpósio Brasileiro de Pesquisa Operacional., Campinas. Galoá.",
                "Mladenović N. e Hansen P. (1997). Variable neighborhood search. Computers Operations Research, 24(11):1097–1100. ISSN 0305-0548. URL https://www.sciencedirect.com/science/article/pii/S0305054897000312.",
                "Oliveira J. P. F. (2021). Iterated local search aplicado ao problema de roteamento de veículos com coleta e entrega simultânea, janela de tempo e frota heterogênea. Master’s thesis, Universidade Federal de Ouro Preto – UFOP.",
                "Slivkins A. (2024). Introduction to multi-armed bandits.",
                "Slivkins A. et al. (2019). Introduction to multi-armed bandits. Foundations and Trends in Machine Learning, 12(1-2):1–286.",
                "Subramanian A., Penna P., Ochi L., e Souza M. (2013). Um Algoritmo Heurístico Baseado em Iterated Local Search para Problemas de Roteamento de Veículos, p. 165–180. ISBN 9788564619104.",
                "Wu Q., Hao J.-K., e Glover F. (2012). Multi-neighborhood tabu search for the maximum weight clique problem. Annals of Operations Research, 196.",
                "Şevkli M. e Aydin M. (2006). Variable neighbourhood search for job shop scheduling problems. JSW, 1:34–39."
            ],
            "artigo_completo": "Uma abordagem ILS-BanditVND para o Team Orienteering Problem. RESUMO Esse trabalho aborda o problema de orientação de times da classe problemas NP-difícil. Para solução do problema, foi utilizada a metaheurística Iterated Local Search (ILS) com Variable Neighbourhood Descent (VND). No ILS-VND, a escolha da sequência de estruturas de vizinhanças a ser explorada impacta diretamente o resultado. Devido a isso, o Random VND e o Multi-Armed Bandit foram escolhidos para tomar decisões mais acertadas a respeito da ordem exploração. O objetivo do trabalho é verificar se essas variações com VND são boas alternativas. Dentre os re- sultados obtidos, ao escolher uma sequência inicial ruim tanto o Bandit quanto o RVND superam os resultados do VND. O Bandit em comparação ao RVND apresenta uma mediana superior em 63% dos casos testados e, em 56% dos casos, seus resultados piores foram maiores que os piores resultados obtidos com o RVND. PALAVRAS CHAVE. Variable Neighborhood Descent, Multi-Armed Bandits, Team Orien- teering Problem. Tópicos: OC – Otimização Combinatória, IC – Inteligência Computacional https://proceedings.science/p/193342?lang=en DOI: 10.59254/sbpo-2024-193342 1. Introdução O problema de orientação de times, em inglês Team Orienteering Problem (TOP), formal- izado no trabalho de Chao et al. [1996], dois anos após de ser introduzido inicialmente no trabalho de Butt e Cavalier [1994] com o nome de Multiple Tour Maximum Collection Problem (MTMCP). é um problema derivado do problema de orientação proposto por Golden et al. [1987]. A orientação é um esporte em que o participante recebe uma búlsula e um mapa. O objetivo desse esporte é conseguir coletar o melhor conjunto de recompensas possível num período limitado de tempo. Neste esporte o indivíduo tem o ponto de largada e chegada fixos e outros pontos disponíveis que têm uma recompensa única e uma vez visitados não é mais possível coletar novamente sua recompensa. O problema de orientação é um problem NP-difícil, o que faz com que o TOP também seja NP-difícil [Butt e Cavalier [1994]]. O trabalho de Macedo e Senne [2023] explora uma nova maneira de resolver esse prob- lema, usando o Iterated Local Search (ILS) [Lourenço et al. [2001]] com Variable Neighborhood Descent(VND) , cujo objetivo é gerar uma solução satisfatória para ser a solução inicial do algo- ritmo Fix-and-Optimize (F&O) [Gintner e Kliewer [2005]]. O ILS utilizado em Macedo e Senne [2023] só faz experimentos com o VND, o objetivo deste trabalho é analisar possíveis impactos no resultado final ao variar o VND por Random-VND (RVND) [Mladenovi´c e Hansen [1997]], e utilizando o Bandit [Slivkins [2024]] para escolher automaticamente uma ordem de estrutura de vizinhança para o VND. O trabalho de L¨u et al. [2011] procura entender a influência de cada estrutura de vizinhança na busca local e propõe Multiple Neighbourhood Search (U-VND). No U-VND uma única vizinhança é obtida como da união de múltiplas estruturas de vizinhança predefinidas. Wu et al. [2012] utiliza também essas múltiplas estruturas de vizinhança na busca TABU. Já em [S¸evkli e Aydin [2006]], são analisadas variantes sequenciais de estruturas de vizinhança para resolver o problema do caixeiro viajante. O restante deste artigo está organizado da seguinte maneira: a Seção 2 contém a formulação matemática do algoritmo, a Seção 3 apresenta a metodologia utilizada, na Seção 4 os resultados obtidos são analisados e a Seção 5 é a conclusão e trabalhos futuros. 2. Formulação Matemática A modelagem escolhida segue a definição proposta em Bianchessi et al. [2018], ou seja, este trabalho modela o problema como um grafo direcionado completo G = (V, A), onde A = {(i, j)|i ̸= n + 1; j ̸= 0; i ̸= j; i, j ∈V } é o conjunto de arcos e V = N ∪{0, n + 1} é o conjunto de nós a serem percorridos (N) união com o nós de origem e destino {0, n + 1}. Os n pontos possíveis para visitação estão contidos no conjunto N, onde N = {1, ..., n}. Cada nó i ∈V , possui um respectivo prêmio pi, com p0 = pn+1 = 0. A cada arco (i, j) ∈A um tempo não negativo tij é associado. No TOP, um time com K integrantes tem como objetivo con- seguir a maior pontuação possível. Cada caminho percorrido precisa começar no nó 0 e terminar no nó n + 1 respeitando um tempo pré-definido máximo, Tmax e cada prêmio pi só pode ser recolhido uma única vez. Baseando-se no fluxo de entradas e saídas de dois índices, a formulção tem as variáveis binárias xij, (i, j) ∈A, yi ∈N, onde yi = 1, se o arco (i, j) é percorrido e o nó i é visitado. As variáveis contínuas zij ∈A\\{0, n + 1}, representam o tempo de chegada no vértice j vindo do vértice i. Para cada i ∈N, seja δ+(i) = {(i, j) ∈A|j ̸= i, j ∈N} e δ−(i) = {(j, i) ∈A|i ̸= j, j ∈N}, o conjunto de arcos saindo e entrando no vértice i. A modelagem: https://proceedings.science/p/193342?lang=en DOI: 10.59254/sbpo-2024-193342 Max(− X i∈N piyi) X j∈N x0j = K X i∈N xi,n+1 = K X (j,i)∈δ−(i) xji = yi, ∀i ∈N X (i,j)∈δ+(i) xij = yi, ∀i ∈N z0j = t0jx0j, ∀j ∈N X (i,j)∈δ+(i) zij − X (j,i)∈δ−(i) zji = X (i,j)∈δ+(i) tijxij, ∀i ∈N zij ≤(Tmax −tj,n+1)xij, ∀(i, j) ∈A\\{(0, n + 1)} zij ≥(t0i + tij)xij, ∀(i, j) ∈A\\{(0, n + 1)} yi ∈{0, 1}, ∀i ∈N xij ∈{0, 1}, ∀(i, j) ∈A t0,0 = tn+1,n+1 = 0 (1) (2) (3) (4) (5) (6) (7) (8) (9) (10) (11) (12) A função objetivo (1) maximiza a soma dos prêmios coletados. As Restrições (2) e (3) garante que existam exatamente K caminhos que saem do ponto inicial e K caminhos que chegam ao ponto final. As famílias de restrições (4) e (5) forçam que exista uma única entrada e uma única saída para todos os nós visitados. A família de restrições (6) limita o fluxo originado no ponto inicial, a família de restrições (7) representa a conservação do fluxo; a família de restrições (8) limita o tempo de cada caminho; já a família de restrições (9) impõe um limite inferior para os valores das variáveis z, com o objetivo de restringir o número de valores viáveis que essas variáveis poderiam assumir. E as famílias de restrições (10) e (11) se referem ao domínio das variáveis, e a Restrição (12) define o tempo de viagem no ponto de saída e no ponto de chegada. 3. Metodologia O algoritmo utilizado é baseado no trabalho de Macedo e Senne [2023], que constrói a solução em três fases; a primeira é denominada construtivo enquanto que as duas seguintes são chamadas de otimização. Na primeira fase uma solução viável para o problema é construída. Na segunda e terceira fases o resultado obtido nas respectivas etapas anteriores é utilizado como ponto inicial, a fim de melhorar a solução encontrada. O algoritmo apresentado no trabalho deles, foi reproduzido da maneira mais fiel possível a fim de se verificar como diferentes meta-heurísticas poderiam influenciar no resultado final. O restante desta seção é dividido nas seguintes subseções: a Subseção 3.1 descreve como a solução inicial é construída; a Subseção 3.2 cita as estruturas de vizinhanças utilizadas; e, por fim, a Subseção 3.3 descreve o algoritmo ILS + VND e suas variações. 3.1. Construção Apesar do artigo de Macedo e Senne [2023] citar diferentes maneiras de construir a solução inicial para o problema, nos resultados finais analisam apenas a maneira mais vantajosa. Para fins de comparação, este trabalho adota o mesmo critério. A fase de construção da solução começa pelo pré-processamento proposto por Chao et al. [1996]. Nele, uma elipse de eixo máximo Tmax com pontos focais sendo os pontos de partida e chegada é construída. Todos os pontos fora desta elipse são eliminados. O objetivo desta restrição é descartar automaticamente candidatos que ultrapassariam o tempo máximo permitido para o per- curso. https://proceedings.science/p/193342?lang=en DOI: 10.59254/sbpo-2024-193342 Após esta eliminação de pontos os K caminhos são inicializados. A inicalização acontece escolhendo-se pontos de dentro da elipse. Estes pontos são organizados em uma lista, do mais distante ao menos distante do ponto inicial. Os K caminhos recebem o ponto inicial e o ponto final. Após isso os pontos de dentro da elipse são selecionados baseando-se na métrica proposta por Subramanian et al. [2013]: z1 = ti,ω + tω,j −ti,j z3 = z1 −γ(t0,ω + tω,0), γ ∈[0, 1] (13) (14) A equação 13 representa a melhor economia de inserção do vértice ω entre dois pontos ao se considerar todas as rotas. Na equação 14, ao valor encontrado em 13 é subtraído a distância de ida e volta do ponto ω ao ponto inicial. Escolher a equação 14 permite com que pontos mais distantes do início possam ser incluídos na solução inicial, contribuindo para sua diversificação. Os pontos continuam a ser inseridos até que não se possa mais fazê-lo. O procedimento completo é descrito em pseudocódigo no Algoritmo 1. Algorithm 1: Construtiva Melhor Economia 1 Data: G(V, A), γ, K, n, Tmax, t, N 2 begin 3 path ←∅; 4 time ←∅; 5 for i in {1..K} do 6 path ←[V0, Vn+1]; 7 time ←t0,n+1 ; 8 end 9 for i in N do 10 z3 ←Tmax; 11 best ←∅; 12 for j in {1...K} do 13 for m in {0...len(path[j])-1} do 14 p1 ←path[j][m]; 15 p2 ←path[j][m + 1]; 16 t ←tp1,i + ti,p2 −tp1,p2; 17 z = t −γ(t0,i + ti,0); 18 if t + time[j] < Tmax and z3 > z then 19 z3 = z; 20 best ←[j, m + 1, t]; 21 end 22 end 23 end 24 if best ̸= ∅then 25 j, m, t ←best; 26 path[j].insert(m, i); 27 time[j] ←time[j] + t; 28 end 29 end 30 return path, time 31 end 3.2. Estruturas de Vizinhança As estruturas de vizinhança utilizadas neste trabalho foram: Inserção, Permutação, 2-OPT e Substituição. O critério de aceite para inserir e substituir é a melhora da função objetivo. Já o https://proceedings.science/p/193342?lang=en DOI: 10.59254/sbpo-2024-193342 critério para as funções de permutação e 2-opt [Croes [1958]] são baseados na melhora do tempo do caminho, se um tempo menor for encontrado a solução é atualizada. As Subseções 3.2.1, 3.2.2, 3.2.3 e 3.2.3 explicam como foram feitas as estrutura de vizinhança da inserção, substituição, permutação e 2opt respectivamente. 3.2.1. Inserção Na busca local de inserção verifica-se dentre todos os nós não visitados e todas as posições possíveis de inserção o valor de z3, calculado pela equação 14 . O vértice escolhido é o que possui o melhor custo-benefício, ou seja, o menor valor de z3 dentre todas as opções [Macedo e Senne [2023]]. A Figura 1 mostra uma inserção do vértice com recompensa 12 no caminho original, 1b, aumentando a recompensa para 128. (a) Solução atual (b) Solução após inserir o vértice com recompensa 12 Figure 1: Inserção 3.2.2. Substituição A substituição é calculada de uma maneira similar a inserção. Nela são verificadas den- tre as posições ocupadas pelos vértices presentes nos caminhos, qual o par posição+vértice-não- visitado é mais vantajoso, segundo o melhor valor de z3. Em todos os casos o novo vértice só será aceito caso o tempo máximo seja respeitado. A Figura 2b mostra o vértice visitado de valor 32 em um dos caminhos sendo trocado pelo vértice não visitado de valor 52, aumentando a recompensa do time. (a) Solução atual (b) Solução após a substituição do vértice 32 pelo 52 Figure 2: Substituição https://proceedings.science/p/193342?lang=en DOI: 10.59254/sbpo-2024-193342 3.2.3. Permutação Na permutação o algoritmo procura trocar dois vértices de caminhos distintos. O objetivo é que ao trocar esses vértices o tempo total de cada caminho seja reduzido [Chao et al. [1996]]. Na Figura 3a, temos dois caminhos com as seguintes ordens de recompensa; {0, 22, 12, 40, 0}, {0, 52, 22, 0}, nesta permutação os vértices de recompensa 12 e 22 são escolhidos para serem trocados, resultando na seguintes sequências: {0, 22, 22, 40, 0}, {0,52,12,0}, representados na Figura 3b. (a) Solução atual (b) Solução após troca de vértices Figure 3: Permutação 3.2.4. 2opt Para tentar uma redução de tempo dentro de cada caminho o algoritmo 2-opt [Croes [1958]] é aplicado. O objetivo é que ao diminuir o tempo do caminho, na próxima iteração será possível adicionar novos pontos. Como mostra a Figura 4a, que antes de aplicar o algoritmo possui um tempo maior que após a aplicação do 2opt resulta na solução da Figura 4b. (a) Solução atual (b) Solução após 2opt Figure 4: 2opt 3.3. Busca Local Nesta seção serão apresentadas algumas variações de buscas locais utilizadas no trabalho. A Seção 3.3.1 apresenta o VND, a Seção 3.3.2, explica a variação do VND com sorteio de sequência de estruturas de vizinhança aleatória e a Seção 3.3.3 explica como o algoritmo de Multi-Armed Bandit foi utilizado para escolher a ordem de vinhança. https://proceedings.science/p/193342?lang=en DOI: 10.59254/sbpo-2024-193342 3.3.1. Variable Neighbourhood Descent O VND é uma heurística para resolver problemas de otimização combinatória e otimização global. Esta heurística utiliza trocas determinísticas de vizinhança na busca local para melhorar a solução [Hansen et al. [2010]]. Utilizando as estruturas de vizinhança apresentadas na Seção 3.2, uma sequência possível seria: Inserção-Permutação-Subtituição-2opt. Existe a possibilidade desta não ser a melhor ordem para uma determinada instância [S¸evkli e Aydin [2006]]. Por esta razão este trabalho testa algumas variações do VND, com o objetivo de automatizar a escolha desta ordem. A hipótese inicial do trabalho é que existem ordens de estruturas de vizinhança melhores que outras e, consequentemente, existem piores. Pode-se ter o azar de escolher uma ordem ruim para a busca local. Como o RVND sorteia aleatoriamente essas ordens, é esperado que sua performance seja melhor que as piores sequências, mas seja pior que as melhores. Para o Bandit-VND é esperado uma performance melhor que o RVND, já que parte das escolhas é feita com a melhor ação. 3.3.2. Random-VND No Random-VND a cada execução da busca local, a ordem das estruturas de vizinhança é embaralhada [Oliveira [2021]]. Nas estruturas de vizinhança Inserção e Substituição a busca local escolhe o primeiro aprimorante, enquanto na de Permutação e 2opt é a primeira melhora. 3.3.3. Bandit-VND O Bandit-VND utiliza o Multi-Armed Bandits para escolher a ordem de vizinhanças da busca local. O algoritmo Multi-Armed Bandits possui K possíveis ações, que são as armas, e T iterações. Em cada iteração o algoritmo escolhe uma ação e coleta uma recompensa. A recompensa é obtida a partir de uma distribuição Identicamente Independente, fixada, que depende somente da escolha da ação, mas é desconhecida para o algoritmo [Slivkins et al. [2019]]. Como o algoritmo só tem informação depois da escolha de cada ação, ele precisa de duas fases; uma de exploração, escolhendo ações e coletando as respectivas recompensas, e outra de extrapolação que escolhe a ação baseando-se nas informações coletadas anteriormente. Isso faz com que exista um tradeoff no algoritmo, o quanto de T deve-se gastar na exploração para que uma boa escolha possa ser feita na extrapolação. Para este trabalho a recompensa escolhida é 1, caso a sequência obtenha sucesso, e 0, caso contrário. No stochastic bandit, utilizado no trabalho, a fase de exploração utiliza uma porcentagem de T para coletar recompensas. Na fase extrapolação a escolha da ação é baseada na ação que obteve a melhor recompensa média na fase de exploração, com desempate arbitrário. 3.4. Iterated Local Search - VND A segunda fase do algoritmo proposto por Macedo e Senne [2023] é composta pelo ILS- BuscaLocal, Algorithm 2. Neste trabalho, a Busca Local são as variações do VND. Aqui o algoritmo começa na solução viável obtida com o construtivo. O ILS se baseia em uma melhora e em uma perturbação. Na etapa da perturbação o algoritmo sorteia aleatoriamente um vértice visitado e tenta retirá-lo. Retirar um vértice pode causar uma inviabilidade na solução, por isso uma operação de 2-opt é realizada logo em seguida para reduzir o tempo do caminho. Após essa etapa é verificado se a solução é viável e, caso não seja, um novo vértice é sorteado. Os vértices continuam a ser sorteados até que se encontre um que não cause inviabilidade na solução, ou que todos tenham sido sorteados. https://proceedings.science/p/193342?lang=en DOI: 10.59254/sbpo-2024-193342 Algorithm 2: ILS-BuscaLocal 1 begin 2 s* ←Solução Inicial 3 while Max Iter do 4 s’ ←perturbação de s* 5 s” ←BuscaLocal(s′) 6 if f(s”) > f(s*) then 7 s* ←s” 8 end 9 end 10 return s* 11 end 4. Experimentos Computacionais Esta seção apresenta os resultados experimentais obtidos. Ela está organizada em duas subseções. A Seção 4.1 apresenta detalhes dos hiper-parâmetros e as instâncias utilizadas para os experimentos, enquanto que a Seção 4.2 apresenta e analisa os resultados obtidos. Os experimentos foram implementados na linguem de programação Python versão no Sistema Operacional Linux, usando a versão 3.8. Os experimentos foram executados dez vezes para cada instância em um Intel(R) Core(TM) i5-8265U de frequência de 1.60GHz com 4GB RAM. 4.1. Instâncias e Configurações dos Algoritmos As instâncias utilizadas neste trabalho foram descritas por Dang et al. [2013] e disponibi- lizadas por Hammami et al. [2020]. Foram realizadas 10 repetições para cada instância. O número de iterações escolhido foi 104. O γ escolhido da Equação 14, foi fixado em 0.1. O percentual para a fase de exploração do Bandit foi fixado em 70%. A fim de comparar como seriam os resultados caso uma escolha ruim de sequência de vizinhanças fosse feita. Para cada par {instânciaj, permutaçãoi} foram realizadas 5 repetições, com 102 iterações. A partir desses resultados foi obtida uma média relacionada ao par. Para cada instância os experimentos utilizaram a permutação que teve seu resultado médio pior. 4.2. Resultados Computacionais Nesta seção os resultados obtidos a partir de cada algoritmo são comparados. Para fazer essa análise, foi utilizada a métrica de distância dada pela Equação (15), onde xvnd ∈{ILS+VND, ILS+RVND, ILS+BVND} e o otimo é o melhor valor encontrado, que foi retirado da literatura. Como os dados não são normalmente distribuídos, o teste de hipótese utilizado foi o Wilcoxon Signed Rank Test. m = 1 −xvnd otimo (15) Os resultados obtidos no teste de hipóteses são apresentados na Tabela 1. A primeira coluna contém as hipóteses e a segunda coluna os seus p-valores. Na hipótese nula, H0 é assumido que não há diferença entre os valores obtidos a partir de dois algoritmos diferentes, e a hipótese alternativa, H1, é assumido que os valores da métrica em um dos algoritmos é maior no outro. Como está a métrica usada é a distância até o melhor valor, aceitar a hipótese H1, significa que o algoritmo é pior que o outro, já que ele está mais distante do ótimo. A partir da Tabela 1 conclue-se que o Bandit e o RVND são preferíveis ao VND, já que no VND pode ser escolhido uma estrutura de vizinhanças ruim, o que não acontece para o Bandit ou RVND. Na Tabela 2, é possível observar que a mediana do Bandit supera em 60% a mediana do https://proceedings.science/p/193342?lang=en DOI: 10.59254/sbpo-2024-193342 RVND, que pode ser justificado devido a aleatoriedade do RVND, causando resultados melhores, mas também piores, como os obtidos em 56% das instâncias. Havendo um ajuste na porcentagem de iterações utilizada na fase de exploração do Bandit, os resultados podem ser melhorados. A última tabela, a Tabela 3, apresenta as médias e desvio padrão da pontuação obtida em cada um dos algoritmos. O campo Instância, indica a instância utilizada no experimento. No campo V Avg(Std), V é o VND com uma sequência de estrutura de vizinhança ruim, no campo B Avg(Std), B é Bandit e no campo R Avg(Std), R é o RVND. O Avg(Std), é a respectiva média e desvio padrão da pontuação obtida e o Avg Time, o tempo médio de execução. Table 1: Testes de Hipótese Hipótese p-valor H0: µ−vnd = µrvnd H1: µ−vnd > µrvnd 0.002 H0: µ−vnd = µbandit H1: µ−vnd > µbandit 0.002 H0: µ−vnd = µ+vnd H1: µ−vnd > µ+vnd 0.002 Table 2: Resultados Algoritmo 1 Algoritmo 2 Best Alg1 ≥Alg2 Worst Alg1 ≥Alg2 Median Alg1 ≥Alg2 ILS-Bandit ILS-VND 0.86 0.98 0.93 IlS-Bandit ILS-RVND 0.51 0.56 0.63 ILS-RVND ILS-VND 0.84 0.97 0.91 5. Conclusão e trabalhos futuros Este trabalho apresentou uma análise comparativa entre os algoritmos ILS com Busca Lo- cal. As buscas locais exploradas foram o VND, RVND e Bandit VND. Foi abordado também como cada um desses algoritmos é construído, o que inclui a heurística construtiva para gerar soluções iniciais e a perturbação utilizada para gerar soluções vizinhas. Os experimentos computacionais mostraram que é vantajoso optar pelo uso do Ban- dit VND ou RVND, ao VND já que não é necessário escolher uma sequência de estruturas de vizinhanças. Em particular o Bandit VND possui a mediana dos resultados melhor em 63% das instâncias, se comparado ao RVND e em 56% das instâncias o pior resultado tem valor maior com- parado ao pior resultado obtido com o RVND. Para trabalhos futuros, no Bandit seria verificado o quanto a porcentagem utilizada na fase de exploração influencia os resultados, e propor um algoritmo de aprendizado mais eficiente, como o Q-Learning, para aprender qual seria uma boa ordem de estruturas de vizinhança dado uma instância qualquer. Agradecimentos Os autores agradecem o UFRJ (23079.227622/2023-70), CNPq (307663/2021-3) , FAPERJ (307663/2021-3), e CAPES(88887.948034/2024-00) pelo financiamento parcial desta pesquisa. https://proceedings.science/p/193342?lang=en DOI: 10.59254/sbpo-2024-193342 Instância VND Av(Std) Tmp Avg VND RVND Avg(Std) Tmp Avg RVND B-VND Avg(Std) Tmp Avg B-VND eil101b m3 770(49) 107.11 829(15) 33.57 829(10) 46.94 cmt101c m3 1152(66) 159.84 1207(42) 36.27 1203(40) 55.39 eil101c m3 1096(28) 219.12 1138(20) 38.94 1122(25) 58.18 gil262a m4 2511(237) 232.1 2946(51) 103.09 2952(31) 148.51 bier127 gen2 m4 4526(296) 239.87 4799(57) 52.35 4830(62) 76.97 pr264 gen1 m4 94(6) 240.56 102(6) 78.06 103(1) 95.54 kroB200 gen3 m3 2293(162) 412.31 2722(80) 184.53 2688(86) 159.71 gil262 gen1 m4 68(3) 373.99 75(1) 209.03 75(1) 198.14 bier127 gen1 m3 92(6) 420.65 97(1) 60.03 98(1) 83.8 kroA150 gen2 m2 3533(198) 508.21 3882(58) 100.1 3784(108) 95.12 rat195 gen2 m2 4000(309) 886.6 4375(108) 147.59 4405(94) 150.03 eil101c m2 1165(38) 648.07 1175(26) 46.15 1184(17) 63.93 cmt200b m3 1655(80) 668.04 1756(51) 125.48 1769(19) 193.09 cmt151c m3 1673(59) 693.23 1712(22) 81.19 1730(23) 112.24 kroB200 gen3 m2 3362(332) 1005.28 3692(317) 191.58 3792(167) 169.09 pr264 gen3 m3 2368(103) 993.43 2370(86) 279.88 2442(113) 274.9 pr264 gen2 m3 5347(471) 988.93 5800(198) 349.27 5820(249) 279.73 pr299 gen1 m4 69(5) 360.0 80(1) 210.16 80(1) 191.63 gil262b m3 5891(289) 1093.9 6319(211) 202.86 6358(183) 286.76 bier127 gen3 m2 2316(206) 1080.4 2505(133) 1046.74 2489(136) 107.99 cmt151b m3 1164(65) 310.24 1238(22) 68.9 1230(22) 98.99 pr264 gen2 m4 4733(262) 257.62 5223(250) 79.26 5202(253) 77.47 gr229 gen2 m4 10995(86) 2220.3 10872(160) 231.64 10922(99) 224.88 bier127 gen3 m4 1889(242) 209.95 2155(59) 56.21 2153(43) 77.59 gil262b m2 6239(273) 2931.38 6600(150) 238.52 6636(255) 335.21 gr229 gen3 m4 7029(370) 2267.23 6980(191) 229.96 7057(181) 227.88 rat195 gen3 m3 2092(219) 351.79 2362(52) 132.39 2361(35) 131.04 gil262 gen2 m2 5835(500) 2467.26 6052(228) 346.59 5993(112) 320.89 pr299 gen1 m3 96(3) 893.63 103(1) 337.1 101(2) 297.45 rd400 gen3 m4 7758(282) 2018.42 8294(405) 810.09 8373(316) 814.98 bier127 gen3 m3 2039(129) 386.82 2330(140) 59.59 2257(114) 83.98 gil262 gen3 m4 1995(253) 342.63 2396(38) 258.96 2395(49) 205.06 rd400 gen1 m4 172(9) 2206.05 189(6) 812.95 188(5) 865.42 lin318 gen3 m2 5955(453) 4702.23 6167(430) 552.46 6295(262) 520.82 rd400 gen3 m3 8909(301) 3889.42 9587(362) 883.58 9007(486) 860.1 kroB200 gen2 m2 4537(477) 1162.7 5162(304) 194.45 5235(342) 178.02 gil262 gen1 m3 82(7) 608.8 93(2) 373.14 92(2) 242.58 gil262 gen3 m2 5115(370) 2184.13 5843(156) 312.89 5712(203) 300.5 bier127 gen2 m3 4750(235) 462.9 4909(60) 60.03 4904(41) 84.66 pr299 gen3 m4 1872(112) 350.49 2144(37) 192.74 2157(31) 196.31 kroB200 gen1 m2 82(8) 1067.32 98(4) 184.34 98(5) 173.46 rd400 gen2 m4 9354(380) 2267.95 9683(271) 931.06 9590(330) 819.63 kroB200 gen2 m4 4066(172) 286.46 4598(40) 150.49 4624(152) 152.82 cmt200c m2 2480(50) 4935.52 2516(29) 189.42 2536(26) 248.26 bier127 gen1 m2 98(3) 1369.97 99(1) 77.84 99(1) 108.45 lin318 gen2 m3 5574(666) 1322.11 6990(260) 430.73 6784(198) 409.49 pr136 gen1 m2 49(5) 271.22 60(1) 77.51 59(1) 76.81 gr229 gen2 m3 11109(17) 4707.04 11086(19) 297.4 11110(15) 290.22 gr229 gen3 m3 7392(180) 5340.69 7378(77) 302.1 7378(60) 291.58 gil262 gen2 m3 4451(340) 642.45 4935(114) 255.19 4961(102) 255.88 gil262c m3 8591(405) 2773.26 9076(270) 250.59 9170(327) 338.24 pr299 gen3 m3 2971(165) 844.12 3215(63) 313.01 3189(47) 310.12 kroA200 gen1 m4 66(5) 268.16 78(1) 150.32 78(1) 136.93 rd400 gen2 m3 9719(143) 4067.22 10122(205) 860.27 10332(260) 908.74 lin318 gen1 m3 111(11) 1331.09 136(7) 419.87 133(8) 413.82 pr299 gen3 m2 3999(481) 2313.44 4816(256) 378.36 4721(283) 369.41 cmt200c m3 2370(73) 1658.06 2462(62) 149.53 2484(36) 203.71 gil262a m2 3122(137) 590.76 3542(200) 124.99 3473(146) 177.06 pr299 gen1 m2 100(18) 2216.88 125(4) 478.89 122(6) 392.86 pr299 gen2 m4 3659(284) 391.77 4165(76) 241.81 4157(74) 195.08 cmt200b m2 1740(60) 1886.17 1824(26) 145.29 1840(51) 200.26 gr229 gen1 m4 215(5) 2458.01 214(2) 230.07 214(1) 225.0 pr136 gen2 m2 2681(397) 277.36 3190(128) 76.21 3244(68) 77.02 cmt151c m4 1591(53) 334.21 1696(30) 73.46 1693(28) 101.91 rd400 gen2 m2 9896(307) 7707.93 10245(190) 968.1 10230(199) 1019.66 gil262c m4 8162(333) 1216.53 8772(139) 224.25 8854(295) 300.06 cmt200c m4 2357(52) 787.63 2417(48) 131.19 2467(40) 178.29 ts225 gen2 m2 4483(552) 1196.99 5137(182) 197.72 5012(165) 186.86 kroA150 gen3 m3 2077(198) 200.09 2506(61) 85.08 2527(58) 84.08 bier127 gen2 m2 4907(192) 1268.95 5074(92) 374.09 5016(51) 109.28 pr299 gen2 m3 4901(279) 901.05 5258(87) 336.3 5320(79) 302.45 cmt200b m4 1576(105) 394.26 1723(40) 116.61 1711(40) 164.69 rd400 gen1 m3 175(8) 3136.84 194(6) 886.98 197(4) 863.15 lin318 gen3 m4 2935(229) 768.91 3351(229) 371.6 3342(230) 357.53 gil262b m4 5406(288) 627.79 5760(202) 181.32 5970(97) 249.45 pr264 gen2 m2 6308(305) 2114.66 6430(16) 434.7 6416(42) 360.19 lin318 gen1 m2 141(10) 3699.29 153(6) 526.44 154(7) 504.39 cmt151c m2 1701(51) 1370.26 1768(41) 100.69 1735(24) 135.81 gil262c m2 9014(270) 4450.37 9408(171) 322.49 9539(171) 447.43 lin318 gen2 m2 7079(470) 2608.0 7874(368) 630.36 7923(233) 527.98 rd400 gen3 m2 9436(572) 5667.35 9868(402) 952.44 9780(274) 989.63 rd400 gen1 m2 183(3) 5569.09 199(2) 970.97 200(2) 954.75 https://proceedings.science/p/193342?lang=en DOI: 10.59254/sbpo-2024-193342"
        },
        {
            "titulo": "Um modelo de programaçao inteira para o coloraçao Grundy Conexo",
            "informacoes_url": "https://proceedings.science/p/193407?lang=en",
            "idioma": "português",
            "storage_key": "galoa-proceedings--sbpo-2024--193407.pdf",
            "autores": [
                {
                    "nome": "Fabio Carlos Sousa Dias",
                    "afiliacao": "Curso de Ciência da Computação, Universidade Federal do Ceará"
                },
                {
                    "nome": "Wladimir Araújo Tavares",
                    "afiliacao": "Curso de Ciência da Computação, Universidade Federal do Ceará"
                },
                {
                    "nome": "Davi Gomes Florêncio",
                    "afiliacao": "Curso de Ciência da Computação, Universidade Federal do Ceará"
                }
            ],
            "data_publicacao": "2024",
            "resumo": "Uma ordenaçao dos vértices conexa de um grafo G = (V, E) é uma ordenaçao v1 < v2 < ... < vn de V tal que vi possui pelo menos um vizinho em {v1, ..., vi−1} para todo i ∈{2, ..., n}. Uma coloraçao Grundy conexa é uma coloraçao gulosa aplicada em uma ordenaçao de vértices conexa.",
            "keywords": [
                "Otimização Combinatória",
                "Coloraçao de Grundy Conexo",
                "Programaçao Matemática",
                "Teoria e Algoritmos em Grafos"
            ],
            "referencias": [
                "Babel, L. e Tinhofer, G. (1989). Connected sequential colorings: the smallest partiallyhard-to-color graph.Institut für Mathematik und Informatik, Technische UniversitätMünchen.",
                "Benevides, F., Campos, V., Dourado, M., Griffiths, S., Morris, R., Sampaio, L., e Silva,A. (2014). Connected greedy colourings. In LATIN 2014: Theoretical Informatics: 11thLatin American Symposium, Montevideo, Uruguay, March 31–April 4, 2014. Proceedings11, p. 433–441. Springer.",
                "Brélaz, D. (1979). New methods to color the vertices of a graph. Communications of theACM, 22(4):251–256.",
                "Carvalho, M. (2023). Application of biased random-key genetic algorithm and formulationsfor the Grundy coloring problem and the connected Grundy coloring problem. Master’sthesis, Universidade Federal da Bahia.",
                "Carvalho, M., Melo, R., Santos, M. C., Toso, R. F., e Resende, M. G. C. (2023). Formulaçõesde programação inteira para o problema da coloração de Grundy. Anais SBPO 2024.",
                "Chow, F. C. e Hennessy, J. L. (1990). The priority-based coloring approach to registerallocation. ACM Transactions on Programming Languages and Systems (TOPLAS), 12(4):501–536.",
                "Christen, C. A. e Selkow, S. M. (1979). Some perfect coloring properties of graphs. Journalof Combinatorial Theory, Series B, 27(1):49–59.",
                "Gamst, A. (1986). Some lower bounds for a class of frequency assignment problems. IEEEtransactions on vehicular technology, 35(1):8–14.",
                "Garey, M. R. e Johnson, D. S. (1979). Computers and intractability, volume 174. FreemanSan Francisco.",
                "Goyal, N. e Vishwanathan, S. (1997). NP-completeness of undirected Grundy numberingand related problems. Manuscript, Bombay.",
                "Grundy, P. M. (1939). Mathematics and games. Eureka, 2:6–9.",
                "Havet, F. e Sampaio, L. (2013).On the Grundy and b-chromatic numbers of a graph.Algorithmica, 65(4):885–899.",
                "Leighton, F. T. (1979). A graph coloring algorithm for large scheduling problems. Journalof research of the national bureau of standards, 84(6):489.",
                "Matula, D. W. e Beck, L. L. (1983). Smallest-last ordering and clustering and graph coloringalgorithms. Journal of the ACM (JACM), 30(3):417–427.",
                "Rodrigues, E. N. H. D. (2020). Coloração k-imprópria gulosa. Disponível em: http://www.repositorio.ufc.br/handle/riufc/50955. Acesso em: 14 fev. 2022.",
                "Welsh, D. J. e Powell, M. B. (1967). An upper bound for the chromatic number of a graphand its application to timetabling problems. The Computer Journal, 10(1):85–86.",
                "Zaker, M. (2005). Grundy chromatic number of the complement of bipartite graphs. Austra-las. J Comb., 31:325–330.",
                "Zaker, M. (2006). Results on the Grundy chromatic number of graphs. Discrete mathematics,306(23):3166–3173."
            ],
            "artigo_completo": "Um modelo de programação inteira para o problema da coloração Grundy Conexo. RESUMO Uma ordenação dos vértices conexa de um grafo G = (V, E) é uma ordenação v1 < v2 < . . . < vn de V tal que vi possui pelo menos um vizinho em {v1, . . . , vi−1} para todo i ∈{2, . . . , n}. Uma coloração Grundy conexa é uma coloração gulosa aplicada em uma ordenação de vértices conexa. O número Grundy conexo de G, denotado por Γc(G), é o maior k tal que G admite uma k-coloração Grundy conexa. O parâmetro Γc(G) fornece um limite de pior caso para a abordagem de coloração gulosa aplicada em uma ordenação de vértices conexa. Neste trabalho, revisitamos a formulação de programação inteira proposta por [Carvalho, 2023], propondo um fortalecimento da restrição relacionada com a conexidade da coloração. Em seguida, propomos duas novas formulações padrão para o número Grundy conexo, e conduzimos experimentos computacionais comparando-as com a formulação de representantes apresentada em [Carvalho, 2023]. PALAVRAS CHAVE. Otimização Combinatória. Coloração de Grundy Co- nexo. Programação Matemática. Teoria e Algoritmos em Grafos https://proceedings.science/p/193407?lang=en DOI: 10.59254/sbpo-2024-193407 1. Introdução Dado um grafo não direcionado G = (V, E), uma k-coloração de vértices C de G é uma partição de V em k conjuntos independentes: C = {V1, V2, . . . , Vk}. O número cromático de G, denotado por χ(G) é o número mínimo de conjuntos independentes em uma coloração de G. O Problema da Coloração de Vértices (PCV) é o problema de determinar o número cromático de G. O PCV é um clássico problema NP-difícil [Garey e Johnson, 1979] na área de teoria dos grafos com diversas aplicações: escalonamento [Leighton, 1979], alocação de registradores [Chow e Hennessy, 1990], atribuição de frequência [Gamst, 1986] e muito outros. A importância prática e a complexidade computacional do PCV levaram o desen- volvimento de métodos heurísticos para determinar soluções sub-ótimas em tempo polino- mial para o problema. Entre essas heurísticas podemos destacar a heurística de coloração gulosa. Dado uma ordem dos vértices (v1, v2, . . . , vn), para cada vértice vi atribuímos a menor cor não utilizada entre os vértices já coloridos na vizinhança vi. Chamaremos de coloração gulosa, a coloração obtida pela heurística de coloração gulosa. Uma característica interessante da heurística gulosa é que existe uma ordem dos vértices em que a coloração gulosa é ótima, ou seja, encontra o número cromático. Na literatura, podemos encontrar vários critérios para obtenção de ordenação dos vértices para a heurística de coloração gulosa. [Welsh e Powell, 1967] consideraram o critério desconhecido largest-first. O método baseia-se na observação que os vértices com grau baixo são mais flexíveis para a escolha da cor, então eles podem ser atrasados para a coloração. [Matula e Beck, 1983] consideraram o critério conhecido como smallest-last. Nesse critério, o último vértice a ser colorido deve ser o de menor grau. O penúltimo vértice colorido deve ser o vértice de menor grau no grafo desconsiderando o último vértice. [Brélaz, 1979] constrói uma ordem dinâmica dos vértices escolhendo iterativamente o vértice com o maior grau de saturação conhecida por DSATUR. [Babel e Tinhofer, 1989] sugere a utilização de uma ordem dos vértices conectada para a heurística de coloração gulosa. Uma ordem de vértice é conectada se todo vértices vi, i ≥2 tem pelo menos um vizinho vj, com j < i. Observe que cada critério de ordenação dos vértices admite várias implementações possíveis. Isso acaba adicionando uma camada de complexidade no problema de avaliação dos critérios de ordenação. Com relação a heurística de coloração gulosa, podemos propor a seguinte pergunta: quão ruim a heurística gulosa pode ser, independente da ordem do vértices escolhida? Para responder essa pergunta, definiremos o número cromático de Grundy. Uma coloração obtida pelo algoritmo de coloração gulosa é chamada de coloração Grundy. O número cromático de Grundy, denotado por Γ(G), representa o maior k tal que G admite uma k-coloração de grundy. O número cromático de Grundy indica o pior caso do algoritmo de coloração gulosa aplicada considerando uma ordem dos vértices qualquer. O número Grundy foi primeiramente estudado por Grundy em 1939 no contexto de grafos orientados na análise de jogos combinatários [Grundy, 1939]. Em 1979, o problema foi formalmente apresentado em [Christen e Selkow, 1979]. Uma pergunta importante que pode ser feita é: a diferença entre a melhor e a pior coloração é pequena? [Benevides et al., 2014] explica que essa diferença pode ser arbitrariamente grande, mesmo para árvores. Por exemplo, em árvores binomias de ordem k, denotada por Bk, temos que χ(G)(Bk) = 2 e Γ(Bk) = k. Por outro lado, o número Grundy pode ser computado em tempo polinomial para árvores e k-árvores parciais. No entanto, o problema de otimização associado número de https://proceedings.science/p/193407?lang=en DOI: 10.59254/sbpo-2024-193407 Grundy é NP-Díficil para grafos em geral [Goyal e Vishwanathan, 1997] e permanece NP- Díficil para várias classes de grafos como grafos bipartidos [Havet e Sampaio, 2013] e grafos complementos de grafos bipartidos [Zaker, 2005, 2006]. Uma importante variante da coloração Grundy é a coloração Grundy conexa. Uma coloração Grundy conexa é uma coloração Grundy obtida por uma ordem conexa de vértices. O número de Grundy conexo, denotado Γc(G), é o maior k tal que G admite uma k- coloração Grundy conexa. Note que o número de Grundy conexo representa o pior caso da heurística de coloração gulosa considerando ordem conexas. [Benevides et al., 2014] aponta que Γc(G)−χ(G) pode ser arbitrariamente grande. Além disso, existem grafos que admitem uma coloração conexa com χ(G)-cores. Contudo, o menor número de cores obtido por uma ordem conexa, denotado por χc(G), é limitado por χ(G) + 1. [Carvalho, 2023] propõe duas formulações de programação inteira baseada na for- mulação padrão e de representantes, uma heurística de coloração gulosa conexa chamada CMinDF (connected minimum-degree first) e um algoritmo genético de chaves aleatórias enviesadas para o número de Grundy conexo. Neste trabalho, apresentamos um modelo de programação inteira para o número de Grundy conexo. Além disso, apresentamos uma heurística para obtenção de uma ordem conexa. Por fim, apresentamos os resultados computacionais. 2. Preliminares Um grafo G é um par ordenado (V, E) composto por um conjunto finito V , cujos elementos são denominados vértices, e por um conjunto E ⊆{{u, v} : u, v ∈V, u ̸= v}, cujos elementos são denominados arestas. Para todo grafo G, denotamos por V (G) e E(G), respectivamente, os conjuntos de vértices e arestas de G. ∆(G) é o valor do grau máximo de G. N(v) = {u ∈V : {v, u} ∈E} é a vizinhança aberta do vértice v em G. Abaixo apresentamos algumas definições usadas no trabalho: • S é um conjunto independente de G se somente se ∀u, v ∈S, {u, v} ̸∈E(G). • Uma k-coloração própria de G é uma partição de V em conjuntos independentes S = {V1, V2, . . . , Vk}. • Dada uma k-coloração, um vértice v ∈Vi é chamado um vértice Grundy se v é adjacente a pelo menos um vértice em cada classe de cor Vj para todo j < i. • Uma k-coloração Grundy é uma k-coloração em que todos os vértices de todas as classes são Grundy. • O número de Grundy, Γ(G), é o maior número de cores em uma coloração em que todos os vértices são vértices grundy. • Uma ordem de vértice (v1, v2, . . . , vn) é conectada se para todo i ≥2, vi possui um vizinho vj para j < i. • Uma k-coloração Grundy conexa é uma k-coloração Grundy obtida por uma or- dem de vértices conexa. • O número de grundy conexo, Γc(G), é o maior k tal que existe uma k-coloração grundy conexa. https://proceedings.science/p/193407?lang=en DOI: 10.59254/sbpo-2024-193407 3. Heurística Gulosa Número de Grundy Conexo Nesta seção, apresentaremos a heurística CMINDegree apresentada em [Carvalho, 2023]. Em seguida, propomos a heurística CMINDegreeMinPath adicionando um critério de desempate para a heurísitica anterior. Logo depois, apresentamos a versão estendida de ambas heurísticas. Heurística CMINDegree: A ideia dessa heurística é começar a colorir os vértices mais flexíveis primeiro (menor grau no grafo induzido pelos vértices ainda não escolhidos). O Algoritmo 1 mostra uma implementação da heurística CMinDegree. Neste algoritmo, utilizamos uma fila de prioridade mínima para escolher os vértices que serão adicionados no vetor S. Observe que um vértice só é adicionado na fila de prioridade se ele possui pelo menos um vértice em S. Este fato garante que estamos construindo uma sequência conexa dos vértices. Durante a execução da heurística, a ordem de coloração dos vértices é armazenada em S. No final do Algoritmo, utilizamos a heurística de coloração gulosa para obter um limite inferior para Γc(G). Algoritmo 1: Heurística CMinDegree 1 Function CMINDegree(G,v): 2 Seja Q um fila de prioridade mínima. 3 Seja S um vetor de tamanho |V | 4 Seja deg um vetor de tamanho |V | 5 para v ∈V (G) faça 6 deg[v] ←|N(v)| 7 insere( Q, (deg[v], v) ) 8 enquanto Q ̸= ∅faça 9 (d, v) ←extract min(Q) 10 se v ̸∈S então 11 insert(S, v) 12 para u ∈N(v) faça 13 se u ̸∈S então 14 deg[u] ←deg[u] −1 15 insere( Q, (deg[u], u) ) 16 retorne ColoracaoGulosa(G, S) Heurística CMINDegreeMinPath: Nesta heurística, propomos que, em caso de empate entre os vértices de menor grau, seja escolhido aquele que possui o caminho mais curto até o vértice inicial. Essa nova heurística pode ser obtida com algumas mudanças na heurística apresentada anteriormente. Heurística CMinDegree Estendida e CMinDegreeMinPath: A versão estendida da heurística CMinDegree e CMinDegreeMinPath pode ser obtida iniciando a heurística CMinDegree e CMinDegreeMinPath, respectivamente, com cada vértice v ∈V . 3.1. Resultados Computacionais Nesta seção apresentamos os resultados computacionais das heurísticas desenvol- vidas neste trabalho. Para isso, geramos grafos de maneira aleatória com quantidade de vértices n = 50 e densidade d ∈{0.5, 0.8}. Foram gerados 1000 grafos para cada densidade, totalizando 2000 grafos. Na Tabela 1 mostra a comparação entre a heurística CMinDegree e a CMinDegre- eMinPath. Na primeira coluna temos a densidade dos grafos. Nas duas próximas colunas temos em quantas instâncias a heurística CMinDegree foi melhor e o total de cores geradas. Nas duas próximas colunas são as mesmas, mas agora para a heurística CMinDegreeMin- Path. Nas instâncias de densidade alta, a heurística CMinDegreeMinPath foi melhor em 81 instâncias. Dessas, em média ela gerou uma coloração com 1.62 cores a mais em https://proceedings.science/p/193407?lang=en DOI: 10.59254/sbpo-2024-193407 comparação a heurística CMinDegree. Já nas instâncias de densidade baixa, a CMinDegre- eMinPath foi melhor em 24 instâncias e, em média ela gerou uma coloração com 1.83 cores a mais. No total, a CMinDegreeMinPath foi melhor em 105 instâncias. CMinDegree CMinDegreeMinPath d Vitórias Total cores Vitórias Total cores 0.5 667 14114 691 14158 0.8 690 23175 771 23307 Tabela 1: Tabela de comparação entre as heurísticas CMinDegree e CMinDegreeMinPath A Tabela 2 apresenta uma comparação entre as heurísticas CMinDegree Esten- dida e CMinDegreeMinPath Estendida. Nas instâncias de densidade alta, a heurística CMinDegreeMinPath Estendida foi melhor em 141 instâncias. Dessas, em média ela gerou uma coloração com 1.07 cores a mais em comparação a heurística CMinDegree. Já nas instâncias de densidade baixa, a CMinDegreeMinPath foi melhor em 127 instâncias e, em média ela gerou uma coloração com 1.12 cores a mais. No total, a CMinDegreeMinPath foi melhor em 268 instâncias. CMinDegree CMinDegreeMinPath Estendida d Vitórias Total cores Vitórias Total cores 0.5 721 16029 848 16171 0.8 712 25503 853 25654 Tabela 2: Tabela de comparação entre as heurísticas CMinDegree Estendida e CMinDegreeMinPath Estendida 4. Modelo de Programação Inteira Nesta seção, apresentaremos os modelos de programação inteira existente na li- teratura para o problema e o modelo proposto nesse trabalho. Também fazemos uma demostração que toda solução viável desses modelos é uma coloração grundy conexa. 4.1. Modelo Padrão Carvalho Em [Carvalho, 2023], os autores apresentam dois modelos de programação inteira, ambas baseadas nas formulações do problema de coloração de vértices (PCV). A primeira é baseada na formulação padrão e a segunda na formulação do representante. A formulação padrão para o número grundy conexo possui os seguintes conjuntos de variáveis. Seja T = {1, 2, . . . , n} representando a ordem em que os vértices são coloridos, K = {1, 2, . . . , ∆(G) + 1} as cores disponíveis para um vértices. Considere as seguintes variáveis de decisão para o problema grundy conexo: zvkt = ( 1, se o vértice v ∈V recebe a cor k ∈K no tempo t ∈T para k ≤t. 0, caso contrário wk = ( 1, se a cor k ∈K é usada 0, caso contrário A Figura 1 apresenta ss restrições do modelo padrão para o número conexo de grundy. A função objetivo do modelo é maximizar o número de cores usada. A restrição (4.1.2) garante que os vértices adjacentes não recebem a mesma cor. A restrição (4.1.3) garante que cada vértice recebe exatamente uma cor em um algum tempo. A restrição (4.1.4) determina que wk só pode ser usada se algum vértice v ∈V em algum tempo t ∈T usar a cor k. A restrição (4.1.5) garante a propriedade grundy. A restrição (4.1.6) estabelece que um único vértice recebe uma cor em cada tempo t. A restrição (4.1.7) garante que uma coloração conectada. https://proceedings.science/p/193407?lang=en DOI: 10.59254/sbpo-2024-193407 max X v∈K wk (4.1.1) X t ∈T t ≥k zukt + X t ∈T t ≥k zvkt ≤wk ∀k ∈K, {u, v} ∈E (4.1.2) X t∈T X k∈K zvkt = 1 ∀v ∈V (4.1.3) wk ≤ X v∈V X t∈T zvkt ∀k ∈K (4.1.4) X t′≥k′ zvk′t′ ≤ X u ∈N(v) X k≤t′≤t zukt′ ∀v ∈V, k, k′ ∈K t ∈T \\ {1} com k < k′ (4.1.5) X v∈V X k∈K zvkt = 1 ∀t ∈T (4.1.6) X k∈K zvkt ≤ X u∈N(v) X t′<t X k∈K zukt′ ∀v ∈V, t ∈T \\ {1} (4.1.7) wk ∈{0, 1} ∀k ∈K (4.1.8) zvkt ∈{0, 1} ∀v ∈V, t ∈T, k ∈K (4.1.9) Figura 1: Modelo padrão para o número de grundy conexo Dada uma solução viável (z′, w′) do modelo acima podemos encontrar subconjuntos de V1, . . . , Vk subconjuntos de V tal que Vi = {v|zv,i,t = 1, ∃t ∈T} Além disso, podemos obter a ordem inicial (u1, u2, . . . , un) que os vértices são coloridos da seguinte maneira: ui = v, se zv,k,i = 1, para algumk ∈K (1) Proposição 1. Dada uma solução viável (z′, w′) da formulação acima. Seja V1, . . . , VK obtida a partir de uma solução viável (z′, w′). Então V1, . . . , VK tem a propriedade grundy. Prova Suponha por absurdo que existe um v ∈Vi que é colorido no tempo t ≥i tal que não existe nenhum vizinho de v ∈Vj para algum j < i. Sem perda de generalidade, seja Vm o primeiro subconjunto livre de vizinhos de v. Tome k = m, k′ = i, t = i, temos que X u∈N(v) X m≤t′≤t zumt′ = 0. Pela restrição 4.1.5, temos que P t′≥i zvit′ ≤0. Dessa maneira, temos que zvit′ = 0 para t′ ≥i. Absurdo com o fato zvit = 1 para t = i. Proposição 2. Dada uma solução viável (z′, w′) da formulação acima. Seja u1, . . . , un uma sequência dos vértices obtida a partir de uma solução viável (z′, w′). Então u1, . . . , un é uma sequência de vértices conectada. Prova Suponha por absurdo que existe ui com i ≥2 tal que ui não tem nenhum vizinho no conjunto {u1, . . . , ui−1}. Tome t = i e v = ui, temos que P u∈N(v) P t′<i P k∈K zukt′ = 0. Isso implica que P k∈K zvki ≤0. Concluímos que zvki = 0 para todo k ∈K. Absurdo com o fato que o vértice v é colorido no tempo t. https://proceedings.science/p/193407?lang=en DOI: 10.59254/sbpo-2024-193407 4.2. Fortalecendo a formulação padrão Nesta subseção, propomos uma maneira de fortalecer a formulação padrão adicio- nando algumas desigualdades válidas. Nós definimos a (v, k, t)-desigualdade da seguinte maneira: t X k′=k+1 t X t′=k′ zvk′t′ ≤ X u∈N(v) t−1 X t′=k zukt′ ∀v ∈V, k ∈K t ∈T \\ {1}, k < t Proposição 3. Se a restrição (4.1.5) é válida então (v, k, t)-desigualdade. Prova Seja V1, V2, . . . , Vk obtida a partir de uma solução viável (x′, z′). Vamos mostrar que a propriedade grundy é garantida pela (v, k, t)-desigualdade. Suponha por absurdo que V1, V2, . . . , Vk não tem a propriedade grundy, ou seja, existe um v ∈Vi colorido no tempo t > i tal que v não possui nenhum vizinho em algum Vj para algum j < i. Seja Vm o primeiro subconjunto de V sem vizinho de v. Logo, P u ∈N(v) P k≤t′≤t zukt′ = 0. Logo, P k′>k P t′≥k′ zvk′t′ ≤0. Isso implica que zvit = 0. 5. Novas Formulações Padrão para o Número Grundy Conexo Apresentaremos as duas novas formulações em três partes: restrições relaciona- das com a coloração, restrições relacionadas com a propriedade grundy e as restrições que garantem a conectividade. 5.1. Variáveis de decisão As duas novas formulações utilizam as seguintes variáveis: xvç = ( 1, se o vértice v recebe a cor c 0, caso contrário zc = ( 1, se a cor c é usada 0, caso contrário yvcp = ( 1, se o vértice v ∈V recebe a cor c ∈C no tempo p ∈P para c ≤p 0, caso contrário 5.2. Restrições de coloração As restrições relacionadas com a coloração utilizadas nos dois modelos são tomadas emprestadas do modelo de prograação inteira para o problema de coloração de vértices (PCV) apresentado a seguir: min X c∈C zc (2) s.a. X c∈C xvç = 1 ∀v ∈V (3) xvç + xuç ≤zc ∀{u, v} ∈E, ∀c ∈C (4) zc ≤ X v∈V xvç ∀c ∈C (5) zc ≤zc−1 ∀c ∈{2, . . . , |C|} (6) xvç ∈{0, 1} ∀v ∈V (G), ∀c ∈C (7) zc ∈{0, 1} ∀c ∈C (8) https://proceedings.science/p/193407?lang=en DOI: 10.59254/sbpo-2024-193407 A restrição (3) garante que cada vértice só pode receber uma cor. A restrição (4) garante que a coloração obtida será uma coloração própria. A restrição (5) garante que uma cor k só pode ser usada se algum vértice v recebeu a cor k. A restrição (6) assegura que as primeiras cores serão usadas. 5.3. Restrições da propriedade Grundy Em [Rodrigues, 2020], o conjunto de restrições que garante a propriedade grundy é apresentada abaixo: xvç ≥1 − c−1 X d=1 xv,d − X u∈N(v) xuç ∀v ∈V (G), ∀c ∈C (9) Já em [Carvalho et al., 2023], o conjunto de restrições que garante a propriedade grundy é apresentada abaixo: xvç′ ≤ X u∈N(v) xuç ∀v ∈V (G), ∀c, c′ ∈C se c < c′ (10) 5.4. Restrições relacionadas com a conectividade Note que a propriedade da ordem dos vértices conexa é parcialmente assegurada pela propriedade grundy. Em toda coloração grundy, os vértices que receberam cores dife- rente 1 já satisfaz a restrição de conectividade, já que esses vértices não receberam a cor 1 por que já tinha um vizinho colorido previamente com a cor 1 . Logo, as restrições para garantir a conectividade da coloração precisam ser apenas checadas nos vértices coloridos com a cor 1, exceto do vértice colorido com a cor 1 na primeira posição. Podemos apli- car essa ideia na formulação padrão de Carvalho, onde podemos substituir o conjunto de restrição (4.7) pelas restrições abaixo: zv1t ≤ X u∈N(v) X t′<t X k∈K zukt′ ∀v ∈V, t ∈T \\ {1} (11) Abaixo apresentamos as demais restrições da nossa formulação do grundy conexo. São restrições que fazem a relação entre a variável x e a variável y, a propriedade de grundy e que garantem a conectividade dos vértices de cor 1 nas posições diferente da primeira. min X c∈C zc (12) s.a. 3, 4, 5, 6, 7, 8 (13) 9 ou 10 (14) xvç ≤ n X p=c yvcp ≤xvç ∀v ∈V, ∀c ∈C (15) X ∀v∈V p X c=1 yvcp = 1 ∀p ∈P \\ {1} (16) min(p,|K|) X c=1 max(1, (c −1))yvcp ≤ X ∀u∈N(v) p−1 X p′=1 min(p′,|K|) X c=1 yucp′ ∀v ∈V, ∀p ∈P \\ {1} (17) min(p,|K|) X c′=2 p X p′=c′ yvc′p′ ≤ X ∀u∈N(v) p−1 X p′=1 yu1p′ ∀v ∈V, ∀p ∈P \\ {1} (18) yvç,p ∈{0, 1} (19) https://proceedings.science/p/193407?lang=en DOI: 10.59254/sbpo-2024-193407 A restrição (15) garante que se um vértice receber uma cor çentão ele irá ser alocado em uma única posição válida c ≤p ≤n. A restrição (16) garante que em cada posição p teremos um único vértice alocado. A restrição (17) garante que se um vértice for alocada em uma posição p > 1 com uma cor 2 ≤c ≤p, então c −1 vizinhos desse vértice devem ser alocados em posições menores com que p. Com a restrição (4), temos a garantia que será com uma cor diferente de c. Essa restrição garante a conectividade dos vértices coloridos com cor > 1. A restrição (18) garante a conectividade dos vértices coloridos com a cor 1 nas posições p > 1. Ela garante que se nenhum vizinho do vértice v for colorido com a cor 1 nas posições [1, p −1], então v deve ser colorido com a cor 1 na posição p. 6. Resultados Computacionais Nesta seção, são descritos os experimentos computacionais realizados nesse tra- balho.Todos os experimentos foram implementados na linguagem de programação Python e executados em um computador com um processador Intel Xeon E5-2620 v2, 32GB de memória RAM, 2.10GHz, e sistema operacional Linux 64 bits. Utilizamos o pacote NetworkX para manipulação de grafos e redes complexas. A documentação da biblioteca, com exem- plos detalhados, está disponível em: https://networkx.org/. Para resolver os modelos de PLI, utilizamos o solver matemático Gurobi. Todas as formulações foram executadas com um limite de tempo de 3600 segundos (1 hora) e limitação de memória de 8GB. Utilizamos os mesmos grafos de [Carvalho et al., 2023]1, que são grafos aleatórios gerados com densidades d de arestas de 0.4, 0.6 e 0.8. Para cada densidade, foram gerados 5 grafos com tamanhos n ∈15, 20, 25, 30 vértices, totalizando 60 grafos. 6.1. Formulação Padrão Carvalho versus Padrão Carvalho Modificada A primeira comparação envolve a formulação padrão de Carvalho e sua versão mo- dificada apresentada na Seção 4.2. Das 60 instâncias, a formulação padrão de Carvalho não encontrou nenhuma solução ótima, enquanto a versão modificada encontrou uma solução ótima para n = 15 e d = 0.4. Nas demais instâncias, ambas pararam devido ao limite de tempo. Das 59 instâncias em que nenhuma das formulações encontrou o ótimo, a versão modificada encontrou a melhor solução viável em 47 casos, enquanto a versão padrão obteve a melhor solução em 38 casos. Concluímos que o fortalecimento da formulação padrão de Carvalho foi eficaz. 6.2. Formulação de Representantes versus Formulações Propostas Agora, comparamos as duas versões das formulações propostas apresentadas na Seção 5. Compararemos as três formulações restantes: Representante, Proposta1 e Pro- posta2. Na Tabela 3, apresentamos o resultado geral para as instâncias de tamanho n = 15, onde a primeira coluna mostra a densidade d, e as colunas seguintes apresentam o tempo em segundos (t(s)) e o valor da função objetiva (obj). Das instâncias analisadas, apenas uma vez a formulação Proposta1 não encontrou a solução ótima (destacado em vermelho). Observamos que, nas instâncias de densidade baixa (d = 0.4) e média (d = 0.6), as formulações propostas são melhores, encontrando a solução ótima em tempos cerca de 80% e 9% menores que a formulação Representante. Contudo, para instâncias de densidade alta (d = 0.8), a formulação Representante se mostrou superior, encontrando soluções ótimas em tempos significativamente menores comparado às formulações propostas. Comportamento semelhante ocorre para as instâncias de tamanho n = 20, con- forme mostrado na Tabela 4. A partir das instâncias de densidade d = 0.6, a formulação Representante se mostra superior, encontrando a solução ótima para todas essas instâncias, 1https://github.com/mateuscsilva/grundycoloring https://proceedings.science/p/193407?lang=en DOI: 10.59254/sbpo-2024-193407 Representante Proposta1 Proposta2 d t(s) obj t(s) obj t(s) obj 258.9 7 44.6 7 21.0 7 256.6 7 26.1 7 54.5 7 307.6 5 15.1 5 23.3 5 169.1 7 143.5 7 119.6 7 0.4 274.6 7 32.7 7 42.2 7 média 253.36 52.40 52.12 267.3 9 540.4 9 292.1 9 286.7 9 429.9 9 186.6 9 24.4 9 493.3 9 277.5 9 418.4 8 88.3 8 67.4 8 0.6 12.6 9 294.9 9 103.2 9 média 201.88 369.36 185.36 2.1 11 3148.5 11 580.2 11 2.7 12 1358.0 12 559.3 12 2.9 11 588.4 11 186.8 11 3.8 10 3600.5 10 314.3 10 0.8 3.9 10 1108.8 10 1384.7 10 média 3.08 1960.84 605.06 Tabela 3: Resultado para instâncias com n = 15. enquanto as formulações propostas pararam devido ao limite de tempo. Destaque para as instâncias de densidade d = 0.8, onde a formulação Representante encontra soluções ótimas em tempos muito rápidos. Já na Tabela 5, temos um resumo com as quantidades de ótimos encontrados pelas três formulações por tamanho e densidade. Em geral, a formulação do representante se mostra superior, encontrando a solução ótima em 35 das 60 instâncias. Por essa tabela, podemos observar que o comportamento observado nas instâncias de tamanho 15 e 20 continua a ocorrer nas de tamanho 25 e 30, onde a representante encontra as soluções ótimas em praticamente todas as instancias de densidade alta. Para finalizar, das instâncias que as três formulações não garantiram a solução ótima (21 instâncias), comparamos as soluções viáveis encontradas. A formulação do re- presentante encontrou a melhor solução em 3, a Proposta1 13 e a Proposta2 em 16 das 21 instâncias. Além disso, das instâncias que cada uma não garantiu a solução ótima, em 4/25 a Representante não encontrou uma solução viável, a Proposta em 6/44 e Proposta2 0/42. Destacamos que nenhuma formulação parou devido a falta de memória. 7. Conclusão e Trabalho Futuro Neste trabalho estudamos o Problema de Coloração de Grundy conexo, onde apre- sentamos duas novas formulações de programação inteira além de um fortalecimento de uma formulação existente da literatura. Realizamos a comparação computacional das for- mulações usando instâncias de testes gerados de maneira aleatória disponíveis. Podemos concluir que a formulação do representante, estado da arte da literatura, se mostra em geral superior, mas nas instâncias de densidade baixa e média e tamanho baixo, nossas formulações se mostraram superiores. Quando comparamos as duas formulações propostas nesse trabalho, a formulação usando a restrição que garante a propriedade de Grundy de [Rodrigues, 2020] se mostra superior que a formulação que usa a propriedade de Grundy de [Carvalho et al., 2023]. Encontrando mais soluções ótimas com média de tempo menor. Além de encontrar sempre soluções viáveis nas instâncias que parou devido ao limite de tempo e com qualidade superior. Como trabalho futuro, queremos pesquisar como podemos fortalecer as formulações nas instâncias de densidade maiores. Além de realizar um estudo com instâncias menores https://proceedings.science/p/193407?lang=en DOI: 10.59254/sbpo-2024-193407 Representante Proposta1 Proposta2 d t(s) obj t(s) obj t(s) obj 0.4 3571.8 9 3600.4 9 3600.5 9 0.4 3605.7 9 3600.5 9 3586.1 9 0.4 3606.0 8 3600.7 8 872.8 8 0.4 3605.8 8 1164.9 8 670.1 8 0.4 3605.4 9 2845.0 10 3600.5 10 média 3598.9 2962.3 2466.0 0.6 1367.6 11 3600.7 11 3600.6 11 0.6 915.6 11 3600.6 11 3600.6 11 0.6 2041.7 11 3600.7 11 3600.7 11 0.6 3432.5 11 3600.6 10 3600.6 10 0.6 346.8 12 3600.7 12 3600.7 12 média 1620.84 3600.66 3600.64 0.8 9.7 13 3601.0 13 3601.0 13 0.8 74.5 13 3600.9 13 3600.8 13 0.8 47.6 13 3600.9 13 3600.9 13 0.8 15.1 13 3601.0 13 3601.0 13 0.8 12.8 14 3600.8 14 3601.0 14 média 31.94 3600.92 3600.94 Tabela 4: Resultado para instâncias com n = 20. n d Representante Proposta1 Proposta2 15 0.4 5 5 5 0.6 5 5 5 0.8 5 4 5 20 0.4 1 2 3 0.6 5 0 0 0.8 5 0 0 25 0.4 0 0 0 0.6 0 0 0 0.8 5 0 0 30 0.4 0 0 0 0.6 0 0 0 0.8 4 0 0 soma 35 16 18 Tabela 5: Quantidade de Instâncias que tiveram sua otimalidade provada. para avaliarmos o fortalecimento da formulação de Carvalho."
        },
        {
            "titulo": "MODELO DE PROGRAMAÇÃO LINEAR PARA O DIMENSIONAMENTO DE UMA ESTAÇÃO DE RECARGA DE VEÍCULOS ELÉTRICOS DE COMUNIDADES REMOTAS",
            "informacoes_url": "https://proceedings.science/p/193809?lang=pt-br",
            "idioma": "pt-br",
            "storage_key": "galoa-proceedings--sbpo-2024--193809.pdf",
            "autores": [
                {
                    "nome": "Dayara Pereira Basso",
                    "afiliacao": "Faculdade de Engenharia de Ilha Solteira – FEIS, UNESP",
                    "orcid": ""
                },
                {
                    "nome": "John Fredy Franco Baquero",
                    "afiliacao": "Faculdade de Engenharia de Ilha Solteira – FEIS, UNESP",
                    "orcid": ""
                }
            ],
            "data_publicacao": "",
            "resumo": "Veículos elétricos (VEs) estão cada vez mais sendo adotados para realizar entrega de mercadorias, manutenções técnicas e visitas médicas; entretanto, seu emprego é escasso em comunidades remotas devido à autonomia limitada da bateria para percorrer grandes distâncias, sendo necessário constantes visitas às estações de recarga.",
            "keywords": [
                "Comunidades Remotas",
                "Estação De Recarga de Veículos Elétricos",
                "Modelo De Programação Linear Inteira Mista"
            ],
            "referencias": [
                "Almouhanna, A., Quintero-Araujo, C. L., Panadero, J., Juan, A. A., Khosravi, B., & Ouelhadj, D. (2020). The location routing problem using electric vehicles with constrained distance. Computers & Operations Research, 115, 104864. https://doi.org/10.1016/j.cor.2019.104864",
                "Aziz Baig, M. J., Iqbal, M. T., Jamil, M., & Khan, J. (2021). Design and analysis of an isolated DC-microgrid for a remote community in Pakistan. 2021 IEEE 12th Annual Ubiquitous Computing, Electronics & Mobile Communication Conference (UEMCON), 0712–0716. https://doi.org/10.1109/UEMCON53757.2021.9666665",
                "Cerna, F. V., Pourakbari-Kasmaei, M., Contreras, J., & Gallego, L. A. (2019). Optimal selection of navigation modes of HEVs considering CO2 emissions reduction. IEEE Transactions on Vehicular Technology, 68(3), 2196–2206. https://doi.org/10.1109/TVT.2019.2894383",
                "Chae, S. H., Kim, G. H., Choi, Y.-J., & Kim, E.-H. (2020). Design of isolated microgrid system considering controllable EV charging demand. Sustainability, 12(22), 9746.",
                "Martinez, N., Tabares, A., & Franco, J. F. (2021). Generation of alternative battery allocation proposals in distribution systems by the optimization of different economic metrics within a mathematical model. Energies, 14(6), 1726. https://doi.org/10.3390/en14061726",
                "Napoli, G., Polimeni, A., Micari, S., Andaloro, L., & Antonucci, V. (2020). Optimal allocation of electric vehicle charging stations in a highway network: Part 1. Methodology and test application. Journal of Energy Storage, 27, 101102. https://doi.org/10.1016/j.est.2019.101102",
                "NeoSolar. (n.d.). Placa Solar Fotovoltaica 460W Monocristalina",
                "Rehman, W. ur, Bo, R., Mehdipourpicha, H., & Kimball, J. W. (2022). Sizing battery energy storage and PV system in an extreme fast charging station considering uncertainties and battery degradation. Applied Energy, 313, 118745. https://doi.org/10.1016/j.apenergy.2022.118745",
                "Shaaban, M. F., Mohamed, S., Ismail, M., Qaraqe, K. A., & Serpedin, E. (2019). Joint planning of smart EV charging stations and DGs in eco-friendly remote hybrid microgrids. IEEE Transactions on Smart Grid, 10(5), 5819–5830. https://doi.org/10.1109/TSG.2019.2891900",
                "Tabares, A., Martinez, N., Ginez, L., Resende, J. F., Brito, N., & Franco, J. F. (2020). Optimal capacity sizing for the integration of a battery and photovoltaic microgrid to supply auxiliary services in substations under a contingency. Energies, 13(22), 6037. https://doi.org/10.3390/en13226037",
                "Wang, Y., Kazemi, M., Nojavan, S., & Jermsittiparsert, K. (2020). Robust design of off-grid solar-powered charging station for hydrogen and electric vehicles via robust optimization approach. International Journal of Hydrogen Energy, 45(38), 18995–19006. https://doi.org/10.1016/j.ijhydene.2020.05.098",
                "Wu, Y., Wang, Z., Huangfu, Y., Ravey, A., Chrenko, D., & Gao, F. (2022). Hierarchical operation of electric vehicle charging station in smart grid integration applications — An overview. International Journal of Electrical Power & Energy Systems, 139, 108005. https://doi.org/10.1016/J.IJEPES.2022.108005",
                "Zainab, F., Naz, K., Mehmood, K. K., Bukhari, S. B. A., Wadood, A., Khalid, H. A., & Park, H. (2023). An optimal joint planning of DGs and electric vehicle charging stations in grid‐connected and islanded microgrids. IET Renewable Power Generation, 17(7), 1623–1634. https://doi.org/10.1049/rpg2.12686",
                "Zhang, L., Liu, Z., Yu, L., Fang, K., Yao, B., & Yu, B. (2022). Routing optimization of shared autonomous electric vehicles under uncertain travel time and uncertain service time. Transportation Research Part E: Logistics and Transportation Review, 157, 102548. https://doi.org/10.1016/j.tre.2021.102548"
            ],
            "artigo_completo": "MODELO DE PROGRAMAÇÃO LINEAR PARA O DIMENSIONAMENTO DE UMA ESTAÇÃO DE RECARGA DE VEÍCULOS ELÉTRICOS DE COMUNIDADES REMOTAS. RESUMO Veículos elétricos (VEs) estão cada vez mais sendo adotados para realizar entrega de mercadorias, manutenções técnicas e visitas médicas; entretanto, seu emprego é escasso em comunidades remotas devido à autonomia limitada da bateria para percorrer grandes distâncias, sendo necessário constantes visitas às estações de recarga. Deste modo, é imprescindível que se definam estratégias de dimensionamento de estações de recarga de VEs que possam ser implantadas em comunidades remotas. Assim, este trabalho propõe o desenvolvimento de um modelo de Programação Linear Inteira Mista para o dimensionamento de uma estação de recarga autônoma em comunidades remotas alimentada por energia renovável e baterias. O método foi testado em uma comunidade remota com 15 pontos, sendo 13 clientes, a estação de recarga e o depósito. Os resultados do teste realizado incluem a rota ótima do VE e o dimensionamento da estação de recarga, demonstrando um bom desempenho para encontrar a solução. PALAVRAS CHAVE. Comunidades Remotas. Estação De Recarga de Veículos Elétricos. Modelo De Programação Linear Inteira Mista. Tópicos: PM – Programação Matemática L&T – Logística e Transportes https://proceedings.science/p/193809?lang=pt-br DOI: 10.59254/sbpo-2024-193809 A. Conjuntos 𝐶 Conjunto de clientes 𝑄 Conjunto de estação de recarga 𝐷 Conjunto de depósitos 𝐻 Conjunto de horas do dia 𝑁 Conjunto de pontos {𝐶∪𝐷∪𝑄} 𝑆 Conjunto de cenários B. Índices ℎ Índice de hora 𝑖 Índice de origem 𝑗 Índice de destino 𝑠 Índice do cenário C. Parâmetros 𝛼 Coeficiente de valor presente para o custo operacional do veículo elétrico 𝛿 Consumo de energia por distância 𝜙 Taxa de juros 𝜆 Penalização para o tempo de operação do veículo elétrico 𝜂𝑐, 𝜂𝑑 Eficiência de carga e descarga das baterias 𝜂𝐶𝐻, 𝜂𝑑𝐸 Eficiência de carga e descarga do veículo elétrico 𝜋𝑠 Probabilidade de cada cenário 𝑠 𝜏̅ Tempo máximo de funcionamento do veículo elétrico 𝜏𝑚á𝑥 𝐶𝐻, 𝜏𝑚í𝑛 𝐶𝐻 Tempo máximo e mínimo de carga do veículo elétrico 𝜔 Porcentagem da bateria no início e final do dia 𝑐𝑏 Custo de instalação de uma unidade de bateria 𝑐𝑑 Custo de viajar cada unidade de distância 𝑐𝑝 Custo de instalação de uma unidade de painel fotovoltaico 𝑑𝑖𝑗 Distância entre os pontos 𝑖 e 𝑗 𝐸𝐵𝐴𝑇,𝑛𝑜𝑚 Energia nominal da bateria 𝐹 Fator de forma 𝐺ℎ𝑠 Irradiação solar em ℎ no cenário 𝑠 ℎ𝑠𝑎𝑖𝑑𝑎 Horário de saída do depósito 𝐼𝑠𝑐 Corrente de curto-circuito 𝐼𝑚𝑝𝑝𝑡 Corrente no ponto de máxima potência 𝐼ℎ𝑠 Corrente na célula fotovoltaica em ℎ no cenário 𝑠 𝐾𝑖, 𝐾𝑣 Coeficiente de temperatura para corrente e tensão 𝑛 Número de pontos 𝑁𝑜𝑐𝑡 Temperatura nominal de funcionamento do painel 𝑁𝑎𝑛𝑜𝑠 Número de anos de vida útil da bateria do veículo elétrico 𝑁𝑑𝑖𝑎𝑠 Número de dias úteis do ano 𝑃𝐵𝐴𝑇,𝑛𝑜𝑚 Potência nominal de cada bateria 𝑃 𝑐𝑎𝑟𝑔𝑎 Potência máxima de carga do veículo elétrico 𝑃ℎ𝑠 𝑃𝑉 Potência fotovoltaica máxima produzida pelos painéis em ℎ no cenário 𝑠 𝑆𝑂𝐶0 Estado de carga inicial do veículo elétrico 𝑆𝑂𝐶𝑚𝑎𝑥, 𝑆𝑂𝐶𝑚𝑖𝑛, Estado de carga máximo e mínimo do veículo elétrico 𝑇𝑎 Temperatura ambiente 𝑇ℎ𝑠 Temperatura na célula fotovoltaica em ℎ no cenário 𝑠 𝑉ℎ𝑠 Tensão na célula fotovoltaica em ℎ no cenário 𝑠 𝑣𝑐𝑡𝑒 Velocidade constante do veículo elétrico 𝑉𝑜𝑐 Tensão de circuito aberto 𝑉𝑚𝑝𝑝𝑡 Tensão no ponto de máxima potência https://proceedings.science/p/193809?lang=pt-br DOI: 10.59254/sbpo-2024-193809 D. Variáveis 𝛽ℎ Variável binária que armazena o horário de chegada do veículo na estação de recarga 𝛾ℎ𝑠 Variável binária para armazenar quantas horas o veículo recarregou 𝛥𝑖𝑗 Variável contínua para linearização do cálculo do estado de carga do veículo 𝜏𝑠𝐶𝐻 Tempo de carga do veículo elétrico no cenário 𝑠 𝐸ℎ𝑠 𝐵𝐴𝑇 Energia da bateria em ℎ no cenário 𝑠 𝑃ℎ𝑠 𝐵𝐴𝑇,𝑐 Potência de carga da bateria em ℎ no cenário 𝑠 𝑃ℎ𝑠 𝐵𝐴𝑇,𝑑 Potência de descarga da bateria em ℎ no cenário 𝑠 𝑃ℎ𝑠 𝑐𝑎𝑟𝑔𝑎 Potência de carga do veículo elétrico no 𝑠 𝑆𝑂𝐶𝑖 Estado de carga de saída do veículo elétrico de 𝑖 𝑆𝑂𝐶𝑗 𝑎 Estado de carga de chegada do veículo elétrico em 𝑗 𝑡𝑖𝑗 𝑎𝑢𝑥 Variável inteira auxiliar para armazenar o tempo de percurso entre 𝑖𝑗 𝑡𝑗 𝑛 Tempo de chegada do VE em 𝑗 𝑈𝑖 Variável inteira auxiliar para eliminar sub rotas 𝑥𝑖𝑗 Variável binária do estado do arco 𝑖𝑗: 1 se é percorrido e 0 em caso contrário 𝑦 Variável inteira do número de baterias para instalação Z Variável inteira do número de painéis para instalação 1. Introdução As emissões de poluentes produzidas pelo setor de transporte representam cerca de 25% do valor total depositado na atmosfera e agravam significativamente a crise climática [Napoli et al., 2020; Rehman et al., 2022]. Visando mitigar estes impactos, os veículos elétricos (VEs) surgiram como alternativa aos veículos movidos a combustíveis fósseis e têm sido empregados tanto na mobilidade urbana quanto em empresas de transporte, principalmente devido aos seus benefícios econômicos e ambientais. Todavia, deve-se ressaltar que existem alguns desafios associados ao emprego dos VEs, como a autonomia da bateria, que pode ser insuficiente para atender clientes afastados dos centros de distribuição dos VEs e a necessidade constante de visitas às estações de recarga, dificultando a adoção desta alternativa mais limpa [Zhang et al., 2022]. Essas adversidades são ainda mais desafiadoras no contexto de comunidades remotas, que estão caracterizadas por um fornecimento eletricidade instável e estão distantes de centros urbanos; consequentemente, o acesso à eletricidade para carregar as baterias dos VEs é incerta e a operação destes serviços é limitado nessas regiões. Em vista disso, uma maneira de sanar os desafios de atendimento destas regiões mais afastadas e promover o uso de veículos de forma sustentável é o aproveitamento de recursos naturais, tal como a energia solar, para carregar os VEs que atendem essa região [Aziz Baig et al., 2021]. Nesse contexto, é imprescindível que se definam estratégias de planejamento de estações de recarga possibilitando o emprego de VEs na realização de serviços em comunidades remotas [Shaaban et al., 2019; Wu et al., 2022]. Assim, alguns trabalhos vêm sendo desenvolvidos na área de planejamento e dimensionamento de estações de recarga para operar em modo autônomo, podendo ser conferido em Chae et al. [2020]; Shaaban et al. [2019]; Wang et al. [2020]; e Zainab [2023]. Geralmente são empregadas modelagens estocásticas para lidar com incertezas e o problema modelado com programação linear e não linear. Os métodos de solução variam entre meta-heurísticas e solvers comerciais. Muitos trabalhos da literatura têm sido desenvolvidos nesta linha, porém, sem dar enfoque a estações de recarga operando em modo autônomo para serem alocadas em comunidades remotas. Além disso, há uma lacuna em relação a métodos que determinem o dimensionamento da estação de recarga levando em consideração o problema de roteamento do VE. Dessa forma, este trabalho propõe um modelo de Programação Linear Inteira Mista (PLIM) para dimensionar uma estação de recarga de VEs com geração fotovoltaica e baterias a ser alocada em uma comunidade remota, com a determinação da rota do veículo elétrico como parte da solução do problema. O modelo PLIM é desenvolvido na linguagem de programação AMPL e https://proceedings.science/p/193809?lang=pt-br DOI: 10.59254/sbpo-2024-193809 resolvido com o CPLEX. O restante deste artigo é organizado da seguinte forma: a formulação matemática do modelo PLIM é apresentada na Seção 2, enquanto a Seção 3 exibe os resultados e discussões acerca do teste realizado e por fim a Seção 4, que conclui as discussões deste trabalho. 2. Formulação Matemática Nesta seção, as expressões matemáticas utilizadas no modelo de PLIM implementado são apresentadas e discutidas. Primeiramente se apresenta a função objetivo e as variáveis de decisão que compõem o problema, em seguida são apresentadas as restrições operacionais do VE e o dimensionamento da estação de recarga, e por último, é explicado brevemente como a energia fotovoltaica foi caracterizada através de cenários de irradiação solar. 2.1. Função objetivo A função objetivo de minimização é apresentada em (1). Esta função é composta por três termos, sendo o primeiro o custo de investimento e o segundo e terceiro termos o custo de operação. O primeiro termo contém a quantidade de baterias 𝑦 e seu custo 𝑐𝑏, e a quantidade de painéis 𝑧 seu custo 𝑐𝑝. O segundo termo da função objetivo está relacionado a operação do VE. Este termo é composto por um custo fixo associado ao uso do VE 𝑐𝑑 (com motoristas e percurso de rota diária), o número de dias no ano a se percorrer esta rota, 𝑁𝑑𝑖𝑎𝑠; uma taxa para trazer este valor de custo operacional futuro a um valor presente representado por 𝛼 (onde 𝛼= 1 −(1 + 𝜙)−𝑁𝑎𝑛𝑜𝑠𝜙 ⁄ , sendo 𝑁𝑎𝑛𝑜𝑠 a vida útil da bateria do VE e 𝜙 a taxa de juros) e a soma de quilômetros percorridos por dia, relacionado com variável binária de arcos ativos 𝑥𝑖𝑗. O terceiro e último termo é definido para penalizar o tempo total de operação do VE, com um peso definido como 𝜆, sendo esse fator multiplicado pela contribuição de cada cenário de irradiação 𝑠, uma vez que o tempo de recarga do VE, 𝜏𝑠𝐶𝐻, depende da energia fotovoltaica disponível. min 𝑦𝑐𝑏+ 𝑧𝑐𝑝+ 𝑁𝑑𝑖𝑎𝑠𝑐𝑑𝛼∑∑𝑑𝑖𝑗𝑥𝑖𝑗 𝑗∈𝑁 𝑖∈𝑁 + 𝜆∑𝜋𝑠 𝑠∈𝑆 (𝜏𝑠𝐶𝐻+ ∑∑𝑑𝑖𝑗𝑥𝑖𝑗 𝑣𝑚á𝑥 𝑗∈𝑁 𝑖∈𝑁 ) (1) A seguir serão apresentadas as restrições que modelam o problema de estudo e as variáveis de decisão, como as de definição da rota, 𝑥𝑖𝑗, do tempo de recarga 𝜏𝑠𝐶𝐻 e da estação de recarga: do número de baterias 𝑦 e de painéis 𝑧. 2.2. Restrições operacionais de veículos elétricos O clássico problema de roteamento de VEs baseia-se no princípio de que um veículo deve servir um conjunto específico de clientes enquanto satisfaz as limitações da sua bateria. Portanto, um veículo deve visitar todos os clientes de um conjunto 𝐶 e a estação de recarga apenas uma vez, conforme restringido pela equação (2), onde 𝑥𝑖𝑗 representa a variável binária do arco percorrido entre 𝑖 e 𝑗, que tem valor 1 quando o arco está ativo e 0 caso contrário. As restrições (3) e (4) delimitam que o VE deve sair e retornar ao depósito, isto é, o ponto inicial e último da rota são ambos o depósito. As restrições (5) e (6) correspondem às restrições de conectividade e não duplicação dos arcos, respectivamente. Por fim, a expressão (7) garante que não há sub rotas, onde 𝑛 é o número de nós existentes e 𝑈𝑖 é uma variável inteira auxiliar. Estas restrições vêm do problema clássico de roteamento e foram baseadas do trabalho de Almouhanna et al. [2020]. ∑ 𝑥𝑖𝑗= 1, ∀ 𝑗∈{𝐶∪𝑄} 𝑖∈𝑁 (2) ∑ 𝑥𝑖𝑗= 1, ∀ 𝑖∈𝐷 𝑗 ∈ {𝐶 ∪ 𝑄} (3) ∑ 𝑥𝑗𝑖= 1, ∀ 𝑖∈𝐷 𝑗∈ {𝐶 ∪ 𝑄} (4) ∑ 𝑥𝑖𝑗− 𝑗 ∈ 𝑁 ∑𝑥𝑗𝑖 𝑗 ∈ 𝑁 = 0, ∀ 𝑖∈𝑁 (5) 𝑥𝑖𝑗+ 𝑥𝑗𝑖≤1, ∀ 𝑖, 𝑗∈𝑁 (6) https://proceedings.science/p/193809?lang=pt-br DOI: 10.59254/sbpo-2024-193809 𝑈𝑖−𝑈𝑗+ (𝑛−1)𝑥𝑖𝑗≤𝑛−2, ∀ 𝑖, 𝑗∈{𝐶 ∪𝑄} (7) O estado de carga das baterias dos VEs deve ser modelado para que seja suficiente para servir todos os clientes. Portanto, o estado de carga de partida do VE em 𝑖 é definido como a variável 𝑆𝑂𝐶𝑖 e o estado de carga de chegada a 𝑗 como a variável 𝑆𝑂𝐶𝑗 𝑎. A equação (8) define o estado de carga do VE ao sair do depósito como o estado de carga inicial, enquanto (9) e (10) garantem que as variáveis do estado de carga estão dentro dos limites máximo e mínimo. Para os clientes, o estado de carga de saída e chegada é o mesmo, pois não há carga ou descarga da bateria, conforme (11); porém, para a estação de recarga, o estado de carga de saída será igual ao estado de carga em que chegou à estação mais quanto foi carregado (12). A potência que vai determinar o quanto o VE foi carregado, 𝑃ℎ𝑠 𝑐𝑎𝑟𝑔𝑎, vai depender de cada cenário 𝑠 e deve ser menor ou igual a potência nominal de recarga do VE, 𝑃 𝑐𝑎𝑟𝑔𝑎 pela quantidade de horas em que ficou na estação de recarga. A quantidade de horas que o VE carrega na estação é representado pela variável binária 𝛾ℎ𝑠, que tem valores igual a 1 na posição do índice ℎ, em que representa a hora aproximada que está na estação, conforme (13). 𝑆𝑂𝐶𝑖= 𝑆𝑂𝐶0, ∀ 𝑖∈𝐷 (8) 𝑆𝑂𝐶𝑚í𝑛≤𝑆𝑂𝐶𝑗≤𝑆𝑂𝐶𝑚á𝑥, ∀ 𝑗∈{𝐶∪𝑄} (9) 𝑆𝑂𝐶𝑚í𝑛≤𝑆𝑂𝐶𝑗 𝑎≤𝑆𝑂𝐶𝑚á𝑥, ∀ 𝑗∈𝑁 (10) 𝑆𝑂𝐶𝑗= 𝑆𝑂𝐶𝑗 𝑎, ∀ 𝑗∈𝐶 (11) 𝑆𝑂𝐶𝑗= 𝑆𝑂𝐶𝑗 𝑎+ ∑𝑃ℎ𝑠 𝑐𝑎𝑟𝑔𝑎 ℎ∈𝐻 𝜂𝐶𝐻, ∀ 𝑗∈𝑄, 𝑠∈𝑆 (12) 𝑃ℎ𝑠 𝑐𝑎𝑟𝑔𝑎≤𝑃 𝑐𝑎𝑟𝑔𝑎𝛾ℎ𝑠, ∀ ℎ∈𝐻, 𝑠∈𝑆 (13) O estado de carga de chegada do VE em 𝑗, 𝑆𝑂𝐶 𝑗 𝑎, é definido como o estado de carga de partida de 𝑖 menos a carga despendida até atingir 𝑗 (14). Porém, esta equação não é linear devido à multiplicação de uma variável binária (𝑥𝑖𝑗) por uma variável contínua (𝑆𝑂𝐶𝑖).As expressões (15)– (17) correspondem à linearização de (14) e foram baseadas no trabalho de Cerna et al. [2019]. 𝑆𝑂𝐶𝑗 𝑎= ∑𝑆𝑂𝐶𝑖𝑥𝑖𝑗 𝑖∈𝑁 −∑𝑥𝑖𝑗𝛿𝑑𝑖𝑗 𝜂𝑑𝐸 𝑖∈𝑁 , ∀ 𝑗∈𝑁 (14) 𝑆𝑂𝐶𝑗 𝑎= ∑Δ𝑖𝑗 𝑖∈ 𝑁 −∑𝑥𝑖𝑗𝛿𝑑𝑖𝑗 𝜂𝑑𝐸 𝑖∈𝑁 , ∀ 𝑗∈𝑁 (15) 0 ≤∆𝑖𝑗≤𝑆𝑂𝐶𝑚á𝑥𝑥𝑖𝑗, ∀ 𝑖, 𝑗∈𝑁 (16) 0 ≤𝑆𝑂𝐶𝑖−∆𝑖𝑗≤𝑆𝑂𝐶𝑚á𝑥(1 −𝑥𝑖𝑗), ∀ 𝑖, 𝑗∈𝑁 (17) O tempo e horário de percurso do VE devem ser formulados para ser determinado a hora em que o veículo chega na estação e se terá energia fotovoltaica disponível. Dessa forma, de acordo com a restrição (18), assume-se um horário para saída do depósito. O horário de chegada em cada é acumulado conforme os clientes são visitados, então as equações (19) e (20) calculam o tempo de chegada em 𝑗, 𝑡𝑗 𝑛, a partir do tempo de percurso entre o arco 𝑖𝑗, 𝑡𝑖𝑗 𝑎𝑢𝑥. A restrição (21) limita que o tempo de percurso entre o arco 𝑖𝑗 não deve ser maior que o tempo máximo de operação do VE, 𝜏. Algo similar é definido em (22), no qual o horário de chegada ao nó mais o tempo de recarga do VE não deve ultrapassar 𝜏. Além disso, o tempo de recarga do VE, 𝜏𝑠𝐶𝐻, não deve ultrapassar os limites mínimo e máximo (23). 𝑡𝑖 𝑛= ℎ𝑠𝑎í𝑑𝑎, ∀ 𝑖∈𝐷 (18) 𝑡𝑗 𝑛= ∑𝑡𝑖𝑗 𝑎𝑢𝑥, ∀ 𝑗∈{𝐶∪𝑄} 𝑖∈𝑁 (19) https://proceedings.science/p/193809?lang=pt-br DOI: 10.59254/sbpo-2024-193809 0 ≤𝑡𝑖 𝑛+ 𝑑𝑖𝑗 𝑣𝑚á𝑥𝑥𝑖𝑗−𝑡𝑖𝑗 𝑎𝑢𝑥≤𝜏(1 −𝑥𝑖𝑗), ∀ 𝑖∈𝑁, 𝑗∈{𝐶∪𝑄} (20) 𝑡𝑖𝑗 𝑎𝑢𝑥≤𝜏𝑥𝑖𝑗, ∀ 𝑖∈𝑁, 𝑗∈{𝐶∪𝑄} (21) 𝑡𝑖 𝑛+ 𝜏𝑠𝐶𝐻≤ 𝜏, ∀ 𝑖∈𝑁, 𝑗∈{𝐶∪𝑄} (22) 𝜏𝑚𝑖𝑛 𝐶𝐻≤𝜏𝑠𝐶𝐻≤𝜏𝑚𝑎𝑥 𝐶𝐻, ∀ 𝑠∈𝑆 (23) Para relacionar o tempo de recarga do VE com a hora em que chega à estação de recarga as equações de (24)–(29) são formuladas. A variável binária 𝛽ℎ armazena na posição ℎ a hora aproximada em que chega na estação de recarga, representada por (24). Dessa forma, como o horário de chegada na estação é apenas um, a equação (25) limita que a soma de 𝛽ℎ seja igual a 1.Outra variável binária 𝛾ℎ𝑠 armazena quantas horas em que ficou carregando na estação de acordo com a hora aproximada em que chegou (𝛽ℎ), logo, a restrição (26) obriga que 𝛾ℎ𝑠 receba valor somente depois do horário de chegada do VE na estação. Assim, as horas de recarga são calculadas para um intervalo horário aproximado com as restrições (27) e (28); sendo que estas horas não devem ultrapassar o tempo máximo de recarga, conforme define (29). ∑ℎ𝛽ℎ ℎ∈𝐻 ≤𝑡𝑗 𝑛+ 1 ∑ℎ𝛽ℎ+ 1 ℎ∈𝐻 , ∀ 𝑗∈𝑄 (24) ∑𝛽ℎ ℎ∈𝐻 = 1 (25) 𝛾ℎ𝑠≤ ∑𝛽𝑘 𝑘∈𝐻, 𝑘≤ℎ , ∀ ℎ∈𝐻, 𝑠∈𝑆 (26) ℎ⋅𝛾ℎ𝑠≤𝑡𝑗 𝑛+ 𝜏𝑠𝐶𝐻, ∀ ℎ∈𝐻, 𝑠∈𝑆, 𝑗∈𝑄 (27) ∑𝛾ℎ𝑠 ℎ∈𝐻 ≤ 𝜏𝑠𝐶𝐻+ 1 ≤∑𝛾ℎ𝑠 ℎ∈𝐻 + 1, ∀ 𝑠∈𝑆 (28) ∑𝛾ℎ𝑠 ℎ∈𝐻 ≤𝜏𝑚𝑎𝑥 𝐶𝐻, ∀ 𝑠∈𝑆 (29) 2.3. Restrições da estação de recarga Enquanto as variáveis operacionais, como aquelas que modelam a potência e a energia das baterias e painéis, dependem dos cenários de irradiação solar, as variáveis de planejamento da estação de recarga são independentes dos cenários. As restrições (30) e (31) garantem que as potências de carga e descarga das baterias, 𝑃ℎ𝑠 𝐵𝐴𝑇,𝑑 e 𝑃ℎ𝑠 𝐵𝐴𝑇,𝑐, respectivamente, estão limitadas pelos pelo valor nominal 𝑃𝐵𝐴𝑇,𝑛𝑜𝑚 e a variável de decisão de instalação da bateria 𝑦. A restrição (32) limita que as potências de carga e descarga das baterias seja limitado ao nominal durante o intervalo de hora ℎ. A equação (33) impõe os limites de valor superior e inferior do estado de carga da bateria. Em (34) se calcula a energia das baterias 𝐸ℎ𝑠 𝐵𝐴𝑇para o estado inicial (ℎ= 1) com base nas eficiências de carga e descarga 𝜂𝑐 e 𝜂𝑑 respectivamente, além de ser considerado um parâmetro 𝜔 que representa a porcentagem em que a bateria se encontra no início do dia e deve terminar o dia com a mesma porcentagem. Na restrição (35) este cálculo é feito para quando não se trata do estado inicial da bateria. Por fim, em (36), a restrição obriga que a energia da bateria no último horário do dia deve ser igual ao estado de energia em que começou o dia. Vale a pena notar que os intervalos de tempo ℎ são definidos como uma hora. 0 ≤𝑃ℎ𝑠 𝐵𝐴𝑇,𝑑≤𝑃𝐵𝐴𝑇,𝑛𝑜𝑚𝑦, ∀ ℎ∈𝐻, 𝑠∈𝑆 (30) 0 ≤𝑃ℎ𝑠 𝐵𝐴𝑇,𝑐≤𝑃𝐵𝐴𝑇,𝑛𝑜𝑚𝑦, ∀ ℎ∈𝐻, 𝑠∈𝑆 (31) 𝑃ℎ𝑠 𝐵𝐴𝑇,𝑐+ 𝑃ℎ𝑠 𝐵𝐴𝑇,𝑑≤𝑃̅𝐵𝐴𝑇,𝑛𝑜𝑚𝑦, ∀ ℎ∈𝐻, 𝑠∈𝑆 (32) https://proceedings.science/p/193809?lang=pt-br DOI: 10.59254/sbpo-2024-193809 0 ≤𝐸ℎ𝑠 𝐵𝐴𝑇≤𝐸𝐵𝐴𝑇,𝑛𝑜𝑚𝑦, ∀ ℎ∈𝐻, 𝑠∈𝑆 (33) 𝐸ℎ𝑠 𝐵𝐴𝑇−𝜔𝐸𝐵𝐴𝑇,𝑛𝑜𝑚𝑦= 𝜂𝑐𝑃ℎ𝑠 𝐵𝐴𝑇,𝑐−𝑃ℎ𝑠 𝐵𝐴𝑇,𝑑 𝜂𝑑 , ∀ ℎ∈𝐻: ℎ= 1, 𝑠∈𝑆 (34) 𝐸ℎ𝑠 𝐵𝐴𝑇−𝐸 ℎ−1,𝑠 𝐵𝐴𝑇 = 𝜂𝑐𝑃ℎ𝑠 𝐵𝐴𝑇,𝑐−𝑃ℎ𝑠 𝐵𝐴𝑇,𝑑 𝜂𝑏 𝑑 , ∀ ℎ∈𝐻, 𝑠∈𝑆 (35) 𝐸ℎ𝑠 𝐵𝐴𝑇≥𝜔𝐸𝐵𝐴𝑇,𝑛𝑜𝑚𝑦, ∀ 𝑠∈𝑆, ℎ∈𝐻: ℎ= 24 (36) O balanço de potência da estação de recarga é apresentado em (37), onde o lado esquerdo inclui a energia disponível para consumo (geração), enquanto o lado direito representa o consumo de energia (demanda). A geração é definida pelo número de painéis a ser instalado 𝑧 e a potência máxima que cada painel pode produzir, 𝑃ℎ𝑠 𝑃𝑉. A demanda é composta pela estação de recarga 𝑃ℎ𝑠 𝑐𝑎𝑟𝑔𝑎e a carga da bateria 𝑃ℎ𝑠 𝐵𝐴𝑇,𝑐. Por fim, uma restrição adicional de energia mínima necessária para a estação de recarga é apresentada em (38). Esta restrição define que a energia disponível no VE – o estado de carga inicial menos o mínimo – somado a energia disponível ao longo do dia na estação de recarga deve ser igual ou superior a energia que o veículo precisa para percorrer todos os clientes, a estação de recarga e retornar ao depósito. 𝑧𝑃ℎ𝑠 𝑃𝑉+ 𝑃ℎ𝑠 𝐵𝐴𝑇,𝑑≥𝑃ℎ𝑠 𝐵𝐴𝑇,𝑐+ 𝑃ℎ𝑠 𝑐𝑎𝑟𝑔𝑎, ∀ ℎ∈𝐻, 𝑠∈𝑆 (37) 𝑆𝑂𝐶0 −𝑆𝑂𝐶𝑚í𝑛+ 𝜂𝐶𝐻∑(𝑧𝑃ℎ𝑠 𝑃𝑉+ 𝑃ℎ𝑠 𝐵𝐴𝑇,𝑑−𝑃ℎ𝑠 𝐵𝐴𝑇,𝑐) ≥ ∑∑ 𝛿 𝜂𝑑𝐸𝑑𝑖𝑗𝑥𝑖𝑗 𝑗∈𝑁 𝑖∈𝑁 ℎ∈𝐻 , ∀ 𝑠∈𝑆 (38) Por fim, o modelo PLIM resultante consiste em minimizar os custos de investimento e operação apresentados na equação (1) sujeito às restrições (2)–(13) e (15)–(38). 2.4. Geração fotovoltaica Para obter os dados de geração fotovoltaica, ou seja, a potência elétrica máxima (𝑃ℎ𝑠 𝑃𝑉) que os painéis fotovoltaicos devem fornecer, calcula-se a corrente 𝐼ℎ𝑠 e a tensão 𝑉ℎ𝑠 das células a partir de um perfil de irradiação solar horário, 𝐺ℎ𝑠. Todos os parâmetros e variáveis obtidos através da irradiação solar são dependentes dos cenários, para que o modelo de planejamento seja corretamente dimensionado de acordo com a disponibilidade solar. A formulação matemática utilizada baseou-se no trabalho de Tabares et al. [2020]. A energia fotovoltaica é representada pelas equações (39)–(43), para cada um dos cenários de irradiação 𝑠. A equação (39) calcula o fator de forma 𝐹, com a tensão de potência máxima 𝑉𝑚𝑝𝑝𝑡, a corrente de potência máxima 𝐼𝑚𝑝𝑝𝑡, a tensão de circuito aberto 𝑉𝑜𝑐 e a corrente de curto-circuito 𝐼𝑠𝑐, parâmetros definidos em função das características da célula fotovoltaica. A equação (40) calcula a temperatura na célula fotovoltaica 𝑇ℎ𝑠 em função da temperatura ambiente 𝑇𝑎, da temperatura nominal de operação da célula 𝑁𝑜𝑐𝑡 e da irradiação solar correspondente a cada cenário. A equação (41) modela a corrente fornecida pela célula fotovoltaica em função de sua temperatura e do coeficiente de temperatura para a corrente 𝐾𝑖. Da mesma forma, a tensão fornecida pela célula fotovoltaica, representada pela equação (42), é calculada em função de 𝑇ℎ𝑠 e do coeficiente de temperatura para a tensão 𝐾𝑣. Por fim, a equação (43) calcula a energia fotovoltaica em 𝑘𝑊 considerando o fator de forma e a corrente e tensão fornecidas pela célula. 𝐹= 𝑉𝑚𝑝𝑝𝑡𝐼𝑚𝑝𝑝𝑡 𝑉𝑜𝑐𝐼𝑠𝑐 (39) 𝑇ℎ𝑠= 𝑇𝑎+ (𝑁𝑜𝑐𝑡−20) 0.8𝐺ℎ𝑠 , ∀ ℎ∈𝐻, 𝑠∈𝑆 (40) 𝐼ℎ𝑠= 𝐺ℎ𝑠[𝐼𝑠𝑐+ 𝐾𝑖(𝑇ℎ𝑠−25)], ∀ ℎ∈𝐻, 𝑠∈𝑆 (41) 𝑉ℎ𝑠= 𝑉𝑜𝑐+ 𝐾𝑣𝑇ℎ𝑠, ∀ ℎ∈𝐻, 𝑠∈𝑆 (42) https://proceedings.science/p/193809?lang=pt-br DOI: 10.59254/sbpo-2024-193809 𝑃ℎ𝑠 𝑃𝑉= 𝐹𝑉ℎ𝑠𝐼ℎ𝑠 1000 , ∀ ℎ∈𝐻, 𝑠∈𝑆. (43) 3. Resultados e Discussões Nesta seção são apresentados os resultados do teste realizado em uma região do interior do estado de São Paulo que possui comunidades remotas, em que devem ser visitados 13 clientes; um depósito e uma estação de recarga, tendo em total 15 pontos, conforme ilustra a Figura 1. A Tabela 1 apresenta os parâmetros que foram adotados no modelo PLIM, os parâmetros técnicos dos painéis fotovoltaicos foram retirados do modelo exposto no site NeoSolar. O modelo foi implementado na linguagem de programação AMPL e resolvido usando o solver CPLEX em um computador com processador AMD Ryzen 7 5700 G. Os cenários adotados são correspondentes a alta, média e baixa irradiação solar e foram baseados no trabalho de Martinez et al. [2021]. Tabela 1. Parâmetros adotados no caso analisado. 𝛿 0,2 kWh/km 𝑐𝑑 0,2 R$/km 𝑃𝑏 𝐵𝐴𝑇,𝑐 5 kW 𝜆 1000 R$/h 𝑐𝑝 R$ 500 𝑃𝑏 𝐵𝐴𝑇,𝑑 5 kW 𝜙 10% 𝐸𝐵𝐴𝑇,𝑛𝑜𝑚 5 kWh 𝑃 𝑐𝑎𝑟𝑔𝑎 20 kW 𝜋𝑠 0,33 𝐼𝑠𝑐 18,32 A 𝑆𝑂𝐶𝑚á𝑥 60 kWh 𝜂𝑑𝐸, 𝜂𝐶𝐻, 𝜂𝑐, 𝜂𝑑 95% 𝐼𝑚𝑝𝑝𝑡 17,3 A 𝑆𝑂𝐶𝑚𝑖𝑛 10 kWh 𝜏̅ 18h 𝐾𝑖; 𝐾𝑣 0,04; -0,25 𝑇𝑎 25ºC 𝜏𝑚𝑖𝑛 𝐶𝐻 0,2 h 𝑁𝑎𝑛𝑜𝑠 10 anos 𝑣𝑐𝑡𝑒 40 km/h 𝜏𝑚𝑎𝑥 𝐶𝐻 4 h 𝑁𝑑𝑖𝑎𝑠 252 dias 𝑉𝑚𝑝𝑝𝑡 34,7 V 𝑐𝑏 R$ 8000 𝑁𝑜𝑐𝑡 44ºC 𝑉𝑜𝑐 41,6 V Figura 1. Distribuição geográfica da comunidade remota analisada. Fonte: Google Maps. Com estes parâmetros foram realizados quatro testes para a região analisada, modificando a capacidade das baterias da estação d recarga de 25%, 50%, 75% e 100%, visando observar o impacto no tempo para encontrar a solução ótima. Assim, na Figura 2 é possível observar a rota encontrada pelo modelo e na Tabela 2 é exposta a ordem da rota e o dimensionamento da estação de recarga autônoma, com 45 painéis fotovoltaicos e 2 baterias. Para os quatro testes analisados, os valores da função objetivo e tempo de solução são expressos na Tabela 3, onde pode ser observado que para a configuração em que a bateria inicia o dia e deve finalizar com as capacidades de 𝜔= 25, 50 𝑒 75% o valor da função objetivo é o mesmo, mudando apenas para o caso em que 𝜔= 100%. Isso é devido ao dimensionamento nestes três primeiros casos serem iguais, e no último caso ser necessário uma unidade a mais de painel fotovoltaico (46 em comparação a 45 expresso na Tabela 2), tornando este caso o mais caro. Em relação ao tempo necessário para encontrar a solução ótima, o caso em que se encontrou a solução mais rápido foi com a capacidade https://proceedings.science/p/193809?lang=pt-br DOI: 10.59254/sbpo-2024-193809 da bateria em 50%, em 2581 segundos (aproximadamente 43 minutos), e o que mais demandou tempo foi com 75%, onde foram necessários 5439 segundos (aproximadamente 90 minutos). Tabela 2. Solução proposta pelo modelo. Rota 1-3-2-7-8-11-13-14-12-9-10-6-15-5-4-1 Distância total percorrida 220 km Número de painéis fotovoltaicos 45 Número de baterias 2 Figura 2. Rota encontrada pelo algoritmo. Fonte: Google Maps. Tabela 3. Valores da função objetivo e tempo de solução para os testes realizados. Capacidade da bateria Função objetivo (R$) Tempo (s) 𝜔= 25% 113978,27 3171 𝜔= 50% 113978,27 2581 𝜔= 75% 113978,27 5439 𝜔= 100% 114478,27 3286 O estado de carga do VE ao longo da rota é representado na Figura 3, onde pode ser observado que o VE sai do depósito com a bateria completa e retorna ao depósito com ela no mínimo, sendo que o ponto 9’ representa o estado de carga em que chega na estação de recarga, carrega somente o necessário e sai com o estado de carga 9”. Em relação ao tempo de recarga, o VE carrega na estação por volta de 1 hora nos cenários de alta e média irradiação e cerca de 3 horas no cenário de baixa irradiação, devido a disponibilidade fotovoltaica, conforme a Figura 4. Em relação a estação de recarga, potência fotovoltaica disponível fornecida pelos painéis é apresentada na Figura 4, onde pode ser observado os perfis de irradiação adotados com mais clareza. Na Figura 5 são apresentadas as potências de recarga do VE nos casos de estudo, para os diferentes cenários de irradiação considerados. Na Figura 6 a energia da bateria ao longo do dia é ilustrada. O veículo chega na estação por volta das 12h e para os casos em que 𝜔= 50, 75 e 100% a energia da bateria é descarregada no cenário 3, em que a potência fotovoltaica disponível é menor, conforme a Figura 6 de (b) a (d). Para quando a bateria inicia o dia com 25% de capacidade, especialmente para o cenário 3, o veículo chega na estação às 12h e utiliza energia fotovoltaica para carregar durante 2 horas, e, na terceira hora, utiliza energia da bateria às 15h, depois da bateria também ter carregado até cerca de sua capacidade máxima ao longo do dia. https://proceedings.science/p/193809?lang=pt-br DOI: 10.59254/sbpo-2024-193809 Figura 3. Estado de carga do VE ao longo da rota, kWh. Figura 4. Potência fotovoltaica disponível, kW. Figura 5. Potência de carga do VE, kW. (a) 𝜔= 25% (b) 𝜔= 50% (c) 𝜔= 75% (d) 𝜔= 100% 0 10 20 30 40 50 60 Ordem da rota 1 3 2 7 8 11 13 14 12 9' 9'' 10 6 15 5 4 1 0 5 10 15 20 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 Hora Cenário 1 Cenário 2 Cenário 3 0 5 10 15 20 1 3 5 7 9 11 13 15 17 19 21 23 Hora Cenário 1 Cenário 2 Cenário 3 0 5 10 15 20 1 3 5 7 9 11 13 15 17 19 21 23 Hora Cenário 1 Cenário 2 Cenário 3 0 5 10 15 20 1 3 5 7 9 11 13 15 17 19 21 23 Hora Cenário 1 Cenário 2 Cenário 3 0 5 10 15 20 1 3 5 7 9 11 13 15 17 19 21 23 Hora Cenário 1 Cenário 2 Cenário 3 https://proceedings.science/p/193809?lang=pt-br DOI: 10.59254/sbpo-2024-193809 Figura 6. Energia das baterias, kWh. (a) 𝜔= 25% (b) 𝜔= 50% (c) 𝜔= 75% (d) 𝜔= 100% 4. Conclusões Este trabalho desenvolveu um modelo de Programação Linear Inteira Mista para o dimensionamento de uma estação autônoma de recarga de veículos elétricos (VEs), que leva em consideração o roteamento do VE no dimensionamento, assim como o uso de energia solar fotovoltaica e baterias. O modelo foi testado em um caso composto por 13 clientes localizados em pequenas comunidades remotas do centro urbano, onde é alocado o depósito. O caso de estudo corrobora que o atendimento de serviços de entrega e visitas técnicas é escasso nessas comunidades, assim, o método oferece o atendimento dos clientes com VEs e a recarga durante a visita nas comunidades remotas. Os resultados mostraram que seriam necessários 45 painéis fotovoltaicos e 2 baterias, e o VE percorrendo uma distância de 220 km, atendendo todos os clientes e carregando na estação de recarga localizada em uma comunidade remota. Os testes analisados compararam valores para a capacidade da bateria iniciar e terminar o dia em 25, 50, 75 e 100%, e mostraram que a solução encontrada mais rápida foi para o caso de 50%, com cerca de 43 minutos de processamento para encontrar a solução ótima. Além disso, também se observa que o VE passa cerca de 1 hora para carregar o necessário para completar a rota nos cenários de alta e média incidência solar em comparação a 3 horas no cenário de baixa incidência solar. Por fim, o método proposto foi formulado de acordo com as restrições de problema de roteamento e de recarga, além da modelagem da operação das baterias com um bom desempenho e pouco esforço computacional para encontrar a solução ótima. Como trabalhos futuros espera-se investigar outras fontes de energia no dimensionamento da estação de recarga, adotar mais cenários de irradiação e adotar o comportamento estocástico em outros parâmetros de estudo. Agradecimentos Os autores agradecem à CAPES código de financiamento 001, à Fundação de Amparo à Pesquisa do Estado de São Paulo (FAPESP), processos nº 2021/14389-3, nº 2023/02583-5 e nº 2022/03161- 4 e ao CNPq, processo nº 409359/2021-1, pelo apoio à pesquisa. 0 2 4 6 8 10 1 3 5 7 9 11 13 15 17 19 21 23 Hora Cenário 1 Cenário 2 Cenário 3 0 2 4 6 8 10 1 3 5 7 9 11 13 15 17 19 21 23 Hora Cenário 1 Cenário 2 Cenário 3 0 2 4 6 8 10 1 3 5 7 9 11 13 15 17 19 21 23 Hora Cenário 1 Cenário 2 Cenário 3 0 2 4 6 8 10 1 3 5 7 9 11 13 15 17 19 21 23 Hora Cenário 1 Cenário 2 Cenário 3 https://proceedings.science/p/193809?lang=pt-br DOI: 10.59254/sbpo-2024-193809"
        },
        {
            "titulo": "PROBLEMA INTEGRADO DE PRODUÇÃO E ROTEAMENTO COM FROTA HETEROGÊNEA: UMA ANÁLISE DE DUAS ABORDAGENS DE OTIMIZAÇÃO POR ENXAME DE PARTÍCULAS",
            "informacoes_url": "",
            "idioma": "português",
            "storage_key": "galoa-proceedings--sbpo-2024--193692.pdf",
            "autores": [
                {
                    "nome": "Yelky Castro Jimenez",
                    "afiliacao": "Universidade Estadual de Campinas",
                    "orcid": ""
                },
                {
                    "nome": "Diego Jacinto Fiorotto",
                    "afiliacao": "Universidade Estadual de Campinas",
                    "orcid": ""
                }
            ],
            "data_publicacao": "",
            "resumo": "Abordamos o problema integrado de roteamento e produção em um ambiente de uma única planta de produção, um único produto, sob a política de estoque nível máximo (Maximum Level) e com uma frota heterogênea em um horizonte de planejamento finito. Propomos duas abordagens de solução: a primeira, um algoritmo de otimização por enxame de partículas; e a segunda, uma abordagem híbrida que combina a otimização por enxame de partículas y uma heurística construtiva para a geração de soluções no problema de roteamento de veículos. Testamos essas metodologias em instâncias da literatura, constatando que a abordagem híbrida oferece soluções de melhor qualidade.",
            "keywords": [
                "Problema integrado de produção e roteamento",
                "otimização por enxame de partículas",
                "Vizinho mais próximo",
                "Otimização Combinatória",
                "Programação Matemática"
            ],
            "referencias": [
                "Adulyasak, Y., Cordeau, J. F., e Jans, R. (2014). Optimization-based adaptive large neighborhood search for the production routing problem. Transportation Science, 48:20–45. ISSN 15265447.",
                "Bard, J. F. e Nananukul, N. (2010). A branch-and-price algorithm for an integrated production and inventory routing problem. Computers and Operations Research, 37:2202–2217. ISSN 03050548.",
                "Brown, G., Keegan, J., Vigus, B., e Wood, K. (2001). The kellogg company optimizes production, inventory, and distribution. Interfaces, 31:1–15. ISSN 00922102.",
                "Chandra, P. e Fisher, M. L. (1994). Theory and methodology coordination of production and distribution planning *.",
                "Kennedy, J. e Eberhart, R. (1995). Particle swarm optimization. In Proceedings of ICNN’95 - International Conference on Neural Networks, volume 4, p. 1942–1948 vol.4.",
                "Çetinkaya, S., Üster, H., Easwaran, G., e Keskin, B. B. (2009). An integrated outbound logistics model for Frito-Lay: Coordinating aggregate-level production and distribution decisions. Interfaces, 39:460–475."
            ],
            "artigo_completo": "PROBLEMA INTEGRADO DE PRODUÇÃO E ROTEAMENTO COM FROTA HETEROGÊNEA: UMA ANÁLISE DE DUAS ABORDAGENS DE OTIMIZAÇÃO POR ENXAME DE PARTÍCULAS. RESUMO Abordamos o problema integrado de roteamento e produção em um ambiente de uma única planta de produção, um único produto, sob a política de estoque nível máximo (Maximum Level) e com uma frota heterogênea em um horizonte de planejamento finito. Propomos duas abordagens de solução: a primeira, um algoritmo de otimização por enxame de partículas; e a segunda, uma abordagem híbrida que combina a otimização por enxame de partículas y uma heurística construtiva para a geração de soluções no problema de roteamento de veículos. Testamos essas metodologias em instâncias da literatura, constatando que a abordagem híbrida oferece soluções de melhor qualidade. PALAVRAS CHAVE. Problema integrado de produção e roteamento, otimização por exame de partí- culas, Vizinho mas próximo. OC – Otimização Combinatória, PM - Programação Matemática 1. Introdução As decisões de produção, inventário e distribuição são essenciais na cadeia de suprimentos. Otimizar esses processos reduz custos, aumenta a eficiência e melhora a satisfação do cliente. Empresas como Kellogg Brown et al. [2001] e Frito-Lay Çetinkaya et al. [2009] obtiveram economias milionárias com uma otimização integrada. No entanto, a complexidade desses problemas integrados, classificados como NP-hard, requer soluções eficientes. Algoritmos avançados, como a otimização por enxame de partículas, são promissores. A integração das decisões de produção, inventário, distribuição e roteamento pode economizar entre 3% e 20% nos custos, segundo estudos de Chandra e Fisher [1994]. Nesta pesquisa, abordamos o problema integrado de roteamento e produção utilizando duas abordagens: otimização por enxame de partículas e uma híbrida que combina este algoritmo e uma heurística construtiva para às decisões de roteamento. Testamos nossas metodologias em instâncias propostas por Adulyasak et al. [2014], constatando que a abordagem híbrida oferece soluções de melhor qualidade em menor tempo. https://proceedings.science/p/193692?lang=pt-br 2. Notação matemática e modelagem proposta A modelagem apresentada é uma adaptação baseada na proposta de Bard e Nananukul [2010]). Ela é formu- lada com variáveis contínuas para representar as decisões de dimensionamento de lotes e gestão de inventário, variáveis inteiras para controlar as quantidades entregues por meio de uma frota heterogênea e variáveis biná- rias para o processo de planejamento de rotas. Em um grafo dirigido e completo denotado por G = (N, A), onde N = {0, 1, ..., |N|} é o conjunto de nós da rede e A = {(i, j)∀i ∈N, j ∈N|i ̸= j} é o con- junto de todos os possíveis arcos que compõem a rede. A fábrica, representada pelo nó 0, deve fornecer e satisfazer a demanda dos clientes i ∈Nc, denotados pelo conjunto Nc = {1, 2, ..., |N|}, em um hori- zonte de planejamento finito T = {1, 2, ..., |T |}, onde as entregas serão realizadas por uma frota de veículos K = {1, 2, ..., |K|} com capacidades diferentes. O objetivo é minimizar os custos de produção, estoque, distribuição e roteamento. Notação Definição u Custo unitário de produção f Custo fixo de configuração da produção c Capacidade da produção Qk Capacidade do veículo k ∈K hi Custo de estocar uma unidade no nó i ∈N li Nível de estoque máximo no nó i ∈N I0i Estoque inicial no nó i ∈N ctij Custo de percorrer a aresta (i, j) ∈A dit Demanda do cliente i ∈Nc no período t ∈T Mt Min{c, P|T | j=t P i∈Nc di,j} ∀t ∈T ˜ Mit Min{li, Min{Qk} ∀k ∈K, P|T | j=t di,j} ∀t ∈T , i ∈Nc pt Quantidade produzida no período t ∈T yt 1, se tem produção na fabrica no período t ∈T . 0, caso contrario. bkt 1, se o veículo k ∈K for utilizado no período t ∈T . 0, caso contrario. Iit Quantidade de unidades a estocar no nó i ∈N no período t ∈T qit Quantidades de unidades a serem enviados no cliente i ∈Nc no período t ∈T sit 1, se o cliente i ∈Nc for visitado no período t ∈T . 0, caso contrario. zikt 1, se o cliente i ∈Nc for visitado pelo veículo k ∈K no período t ∈T . 0, caso contrario. wikt Carga de um veículo k ∈K antes de fazer entregue ao cliente i ∈Nc no período t ∈T xijkt 1, se o veículo k ∈K percorre o arco (i, j) ∈A no período t ∈T . 0, caso contrario. Tabela 1: Notação matemática Função Objetivo: Minimizar o custo total min  X t∈T (u · pt) + X t∈T (f · yt) + X t∈T X i∈N (hi · Iit) + X t∈T X (i,j)∈A X k∈K (ctij · xijkt)   (1) Restrições: I0(t−1) + pt = I0t + X i∈Nc qit ∀t ∈T (2) Ii(t−1) + qit = dit + Iit ∀t ∈T , i ∈Nc (3) pt ≤Mt · yt ∀t ∈T (4) I0t + X i∈Nc qit ≤l0 ∀t ∈T (5) Ii(t−1) + qit −dit ≤li ∀t ∈T , i ∈Nc (6) sit ≤qit ≤˜ Mit · sit ∀t ∈T , i ∈Nc (7) zikt ≤sit ∀t ∈T , k ∈K, i ∈Nc (8) zikt ≤bkt ∀t ∈T , k ∈K, i ∈Nc (9) X j∈N|j̸=0 x0jkt = bkt ∀t ∈T , k ∈K (10) https://proceedings.science/p/193692?lang=pt-br X i∈N|i̸=0 xi0kt = bkt ∀t ∈T , k ∈K (11) X j∈N|i̸=j X k∈K xijkt = sit ∀t ∈T , i ∈Nc (12) X i∈N|i̸=j X k∈K xijkt = sjt ∀t ∈T , j ∈Nc (13) X j∈N|i̸=j xjikt + X j∈N|i̸=j xijkt = 2 · zikt ∀t ∈T , k ∈K, i ∈Nc (14) wikt −wjkt ≥qit −˜ Mit(1 −xijkt) ∀t ∈T , k ∈K, (i, j) ∈A|i ̸= 0 ∧j ̸= 0 (15) wikt ≤Qk · zikt ∀t ∈T , k ∈K, i ∈Nc (16) X k∈K zikt ≤sit ∀t ∈T , i ∈Nc (17) pt ≥0, yt ∈{0, 1} ∀t ∈T bkt ∈{0, 1} ∀t ∈T , k ∈K Iit ≥0, qit ≥0, sit ∈{0, 1} ∀t ∈T , i ∈Nc wikt ≥0, zikt ∈{0, 1} ∀t ∈T , k ∈K, i ∈Nc xijkt ∈{0, 1} ∀t ∈T , k ∈K, (i, j) ∈A (18) A expressão 1 define a função objetivo do problema, minimizando os custos de produção, configuração da produção, inventário e roteirização. As restrições estão agrupadas da seguinte forma: da 2 à 6, restrições relacionadas ao problema de produção; da 7 à 9 , restrições de acoplamento entre os dois problemas; da 10 à 17, restrições associadas ao problema de roteirização de veículos e distribuição; e a 18 estabelece o domínio das variáveis. 3. Algoritmo proposto O PSO pelas siglas em inglês (Particle Swarm Optimization) é um algoritmo de otimização baseado no com- portamento de enxame. Foi proposto por Kennedy e Eberhart [1995] e se inspira no movimento coletivo de organismos como bandos de pássaros ou cardumes de peixes. O algoritmo foi codificado conforme às res- trições mostradas no modelo da seção 2. Uma partícula é uma solução factível e completa do problema que armazena as quantidades produzidas (pt) se houver produção nesse período (yt), os estoques (Iit), a distri- buição das entregas (qit, sit, zikt) e as informações relacionadas ao planejamento de rotas (xijkt, wikt, bkt). Cada variável mantém sua natureza binária ou contínua conforme mostrado na tabela 1. Cada partícula possui dois espaços reservados: o primeiro guarda sua melhor posição histórica, e o segundo guarda a posição atual. Dessa forma, a população é formada por um número de partículas dado como parâ- metro. A população é inicializada colocando novas partículas tanto nos espaços reservados para as posições atuais quanto para as melhores posições históricas de cada partícula. Cada partícula é avaliada na função fitness, tanto na sua melhor posição histórica quanto na posição atual; a melhor avaliação será mantida como a melhor posição histórica na próxima iteração. Adicionalmente, em cada iteração, é guardada a informação da melhor partícula global. As novas posições de cada partícula são orientadas pela velocidade baseada na inércia (posição atual) e nas componentes cognitivas (melhor histórico) e sociais (melhor global), conforme descrito por Kennedy e Eberhart [1995]. No processo de otimização e convergência do algoritmo para a solução ótima, algumas partículas podem perder factibilidade, devido à natureza do movimento das partículas. Quando isso ocorre, a melhor posição histórica, que a priori é uma solução factível, é mantida e uma nova partícula é integrada na nova posição. O critério de parada do algoritmo é dado pelo número de iterações. Híbrido PSO-NNH Notamos que, na construção da partícula, há um bom comportamento nas decisões de produção, inventário e distribuição, mas não no planejamento de rotas. Este híbrido conserva a geração de soluções para as decisões de produção, inventário e distribuição utilizando a geração inicial de partículas e constrói as rotas por meio de uma heurística construtiva NNH (Nearest Neighbor Heuristic) para determinar soluções no problema de https://proceedings.science/p/193692?lang=pt-br roteamento de veículos com múltiplos períodos. A heurística busca minimizar a distância total percorrida por cada veículo, assegurando que as entregas aos clientes (qit sejam cumpridas dentro das capacidades dos veículos. 4. Experimentos computacionais e resultados Para a implementação dos algoritmos, foi utilizada uma máquina equipada com um processador Core i7 de 13ª geração e 16 GB de RAM. O desenvolvimento ocorreu no ambiente de programação Python 3.8, utilizando bibliotecas específicas para otimização e processamento de dados. Além disso, foi empregado o software Gurobi Optimizer 10.0.3 para resolver problemas de otimização. As instâncias de teste foram retiradas da literatura da pesquisa de Adulyasak et al. [2014], todas com um horizonte de planejamento de 6 períodos e 3 veículos, variando o número de nós entre 15, 25 e 50, incluindo o nó associado à fábrica. Os experimentos realizados com Gurobi foram utilizados para encontrar limites inferiores e avaliar a qualidade das soluções propostas. Cada experimento em Gurobi teve um limite de tempo de 3600 segundos. Os resultados obtidos são apresentados na tabela 2. Instancia Gurobi PSO H-PSO-NNH % Variação GAP Valor Fo LI GAP Valor FO GAP Tempo Valor FO GAP Tempo N15_I1 16725 16478 1,48% 20374 19,12% 44,05 18417 10,53% 11,05 -81,63% N15_I2 15487 15487 0,00% 18632 16,88% 38,57 17126 9,57% 45,27 -76,38% N15_I3 14438 13709 5,05% 16912 18,94% 6,99 15818 13,33% 15,75 -42,05% N15_I4 17597 17526 0,40% 20551 14,72% 145,83 19331 9,34% 72,71 -57,64% N15_I5 17434 16478 5,48% 20974 21,44% 14,16 18145 9,19% 61,32 -133,33% N25_I1 24685 23511 4,76% 31582 25,56% 11,85 28090 16,30% 98,46 -56,77% N25_I2 25591 24470 4,38% 32735 25,25% 28,44 28891 15,30% 239,46 -65,00% N25_I3 52043 44616 14,27% 79231 43,69% 62,68 60120 25,79% 13,46 -69,41% N25_I4 6857 5264 23,23% 13921 62,19% 83,91 9667 45,55% 35,46 -36,53% N50_I1 46460 43925 5,46% 69371 36,68% 384,8 54889 19,97% 102,42 -83,64% N50_I2 45992 40790 11,31% 66446 38,61% 19,3 51491 20,78% 484,71 -85,79% N50_I3 40347 35849 11,15% 60680 40,92% 289,09 46251 22,49% 42,52 -81,95% N50_I4 50453 39935 20,85% 60680 34,19% 139,41 51908 23,07% 283,58 -48,22% N50_I5 41353 36716 11,21% 61717 40,51% 20,19 46812 21,57% 31,75 -90,83% Tabela 2: Experimentos computacionais Os resultados mostram que o PSO-NNH superou o PSO em termos de qualidade de solução e tempo de execução em todas as instâncias testadas. Especificamente, a abordagem híbrida PSO-NNH forneceu solu- ções com custos totais mais próximos aos obtidos pelo Gurobi e em um tempo significativamente menor. A solução do PSO, embora boa, foi menos eficiente na geração de rotas, o que impactou os custos totais. 5. Conclusões O estudo abordou o problema integrado de produção e roteamento com uma frota heterogênea utilizando duas abordagens: o PSO e uma abordagem híbrida PSO-NNH. Os resultados dos experimentos mostraram que a abordagem híbrida proporciona soluções de melhor qualidade em um tempo menor, devido à combinação eficaz da otimização por enxame de partículas com a heurística construtiva de vizinho mais próximo para o problema de roteirização. A abordagem híbrida PSO-NNH demonstrou ser uma metodologia promissora para problemas complexos de produção e roteamento, oferecendo uma alternativa viável e eficiente para a solução desses problemas em ambientes de cadeias de suprimentos. Para trabalhos futuros, exploraremos outras heurísticas combinadas com PSO, bem como a aplicação desta abordagem em outros contextos de produção e distribuição."
        },
        {
            "titulo": "Algoritmos Para O Problema de Escalonamento de Conexões Sem Fio com Particionamento de Banda em Redes Wi-Fi",
            "informacoes_url": "https://proceedings.science/p/193596?lang=pt-br",
            "idioma": "português",
            "storage_key": "galoa-proceedings--sbpo-2024--193596.pdf",
            "autores": [
                {
                    "nome": "José Joaquim de Andrade Neto",
                    "afiliacao": "Universidade Federal de Minas Gerais",
                    "orcid": null
                },
                {
                    "nome": "Thiago Ferreira de Noronha",
                    "afiliacao": "Universidade Federal de Minas Gerais",
                    "orcid": null
                },
                {
                    "nome": "Marcos Augusto Menezes Vieira",
                    "afiliacao": "Universidade Federal de Minas Gerais",
                    "orcid": null
                }
            ],
            "data_publicacao": null,
            "resumo": "Nesse trabalho, estendemos o clássico problema da literatura de redes sem-fio, o Shortest Link Problem, com funcionalidades existentes em protocolos Wi-Fi. Nessa variante, decide-se de forma combinada o escalonamento de transmissões considerando o modelo de interferência SINR e o particionamento da faixa de banda disponível. Ainda, cada transmissão deve possuir uma taxa de transferência mínima, dada na entrada. Contribuímos com a literatura com uma heurística construtiva e uma formulação matemática baseada em programação inteira. Testamos a performance de cada algoritmo utilizando instâncias de benchmark geradas utilizando metodologias encontradas em trabalhos relacionados, onde cada instância simula uma rede com até 512 conexões. Os experimentos computacionais mostram que a formulação foi capaz de encontrar soluções ótimas para instâncias de até 256 conexões em até 7200 segundos. Além disso, a heurística foi capaz de encontrar soluções factíveis para as instâncias mais difíceis dos experimentos em menos de 1 segundo.",
            "keywords": [
                "Escalonamento de redes sem fio",
                "SINR",
                "Otimização Combinatória"
            ],
            "referencias": [
                "Cardieri, P. (2010). Modeling interference in wireless ad hoc networks. IEEE Communications Surveys & Tutorials, 12(4):551–572.",
                "Coleman, D. 802.11ax for dummies. Extreme Networks, 2020.",
                "Costa, J. M., Paniago, P. P., de Andrade, J., Noronha, T. F., e Vieira, M. A. M. (2019). Integer linear programming formulations for the variable data rate and variable channel bandwidth scheduling problem in wireless networks. Computer Networks, 165.",
                "Costa, J. M., Paniago, P. P., Noronha, T. F., e Menezes, M. A. V. (2017). A biased random-key genetic algorithm for the multi-period, multi-rate and multi-channels with variable bandwidth scheduling problem. In The 12th edition of the Metaheuristics International Conference (MIC 2017).",
                "Ephremides, A. e Truong, T. V. (1990). Scheduling broadcasts in multihop radio networks. IEEE Transactions on Communications, 38(4):456–460.",
                "Goussevskaia, O., Halldórsson, M. M., e Wattenhofer, R. (2014). Algorithms for wireless capacity. IEEE/ACM Transactions on Networking, 22(3):745–755.",
                "Goussevskaia, O., Oswald, Y. A., e Wattenhofer, R. (2007). Complexity in geometric sinr. In Proceedings of the 8th ACM international symposium on Mobile ad hoc networking and computing, p. 100–109.",
                "Goussevskaia, O., Vieira, L. F., e Vieira, M. A. (2016). Wireless scheduling with multiple data rates: From physical interference to disk graphs. Computer Networks, 106:64–76.",
                "Goussevskaia, O. e Wattenhofer, R. (2013). Scheduling with interference decoding: Complexity and algorithms. Ad hoc networks, 11(6):1732–1745.",
                "Goussevskaia, O., Wattenhofer, R., Halldórsson, M. M., e Welzl, E. (2009). Capacity of arbitrary wireless networks. In IEEE INFOCOM 2009, p. 1872–1880. IEEE.",
                "Gupta, P. e Kumar, P. R. (2000). The capacity of wireless networks. IEEE Transactions on Information Theory, 46(2):388–404.",
                "Halldórsson, M. M. (2009). Wireless scheduling with power control. In European Symposium on Algorithms, p. 361–372. Springer.",
                "Huang, B., Yu, J., Cheng, X., Chen, H., e Liu, H. (2017). Sinr based shortest link scheduling with oblivious power control in wireless networks. Journal of Network and Computer Applications, 77:64–72.",
                "Kesselheim, T. (2012). Approximation algorithms for wireless link scheduling with flexible data rates. In European Symposium on Algorithms, p. 659–670. Springer.",
                "Londe, M. A., Pessoa, L. S., Andrade, C. E., e Resende, M. G. (2024). Biased random-key genetic algorithms: A review. European Journal of Operational Research.",
                "Malik, A., Qadir, J., Ahmad, B., Yau, K.-L. A., e Ullah, U. (2015). Qos in ieee 802.11-based wireless networks: A contemporary review. Journal of Network and Computer Applications, 55(24–46).",
                "Moscibroda, T., Wattenhofer, R., e Weber, Y. (2006). Protocol design beyond graph-based models. In Proc. of the ACM Workshop on Hot Topics in Networks (HotNets-V), p. 25–30. Citeseer.",
                "Santi, P., Maheshwari, R., Resta, G., Das, S., e Blough, D. M. (2009). Wireless link scheduling under a graded sinr interference model. In Proceedings of the 2nd ACM international workshop on Foundations of wireless ad hoc and sensor networking and computing, p. 3–12.",
                "Vieira, F. R., de Rezende, J. F., e Barbosa, V. C. (2016). Scheduling wireless links by vertex multicoloring in the physical interference model. Computer Networks, 99:125–133.",
                "https://proceedings.science/p/193596?lang=pt-br DOI: 10.59254/sbpo-2024-193596"
            ],
            "artigo_completo": "Algoritmos Para O Problema de Escalonamento de Conexões Sem fio com Particionamento de Banda em Redes Wi-Fi. RESUMO Nesse trabalho, estendemos o clássico problema da literatura de redes sem-fio, o Shortest Link Problem, com funcionalidades existentes em protocolos Wi-Fi. Nessa variante, decide-se de forma combinada o escalonamento de transmissões considerando o modelo de interferência SINR e o particionamento da faixa de banda disponível. Ainda, cada transmissão deve possuir uma taxa de transferência mínima, dada na entrada. Contribuímos com a literatura com uma heurística cons- trutiva e uma formulação matemática baseada em programação inteira. Testamos a performance de cada algoritmo utilizando instâncias de benchmark geradas utilizando metodologias encontradas em trabalhos relacionados, onde cada instância simula uma rede com até 512 conexões. Os expe- rimentos computacionais mostram que a formulação foi capaz de encontrar soluções ótimas para instâncias de até 256 conexões em até 7200 segundos. Além disso, a heurística foi capaz de encon- trar soluções factíveis para as instâncias mais difíceis dos experimentos em menos de 1 segundo. PALAVRAS CHAVE. Escalonamento de redes sem fio; SINR; Otimização Combinatória. OC - Otimização Combinatória; PM - Programação Matemática https://proceedings.science/p/193596?lang=pt-br DOI: 10.59254/sbpo-2024-193596 1. Introdução Redes de computadores sem fio utilizam frequências de onda de rádio para a transmissão de dados entre dispositivos eletrônicos. Inevitavelmente, esse meio de comunicação está sujeito à interferências oriundas de outros dispositivos que emitem ondas eletromagnéticas na mesma faixa de frequência. É sabido que a interferência é uma característica intrínseca de transmissões sem fio, sendo impossível eliminá-la por completo. Além disso, se esta for alta o suficiente, pode ser im- possível fazer com que uma conexão sem fio seja ativada. Portanto, o desenvolvimento de técnicas para atenuar os seus efeitos possui um grande valor. Na literatura, o tradicional problema combinatório Shortest Link Schedule (SLS) aborda exatamente o contexto introduzido anteriormente. Dado um conjunto de conexões sem fio, deter- mine a menor quantidade de intervalos de tempo necessária para que todas as conexões possam transmitir com uma qualidade pré-determinada de sinal. É possível modelar o SLS utilizando técnicas de pesquisa operacional que serão detalhadas mais a frente. Por fim, à medida em que a internet torna-se cada vez mais ubíqua nas atividades rotineiras, endereçar o SLS é de suma im- portância para manter a qualidade de serviço (Malik et al. [2015]) das aplicações. Os trabalhos que endereçam soluções para o escalonamento de conexões sem-fio são es- sencialmente definidos por meios do que se define interferência. Idealmente, deve-se defini-lá de forma fiel às características físicas envolvidas. Por exemplo, barulho de ambiente, atenuação de sinal, barreiras físicas, entre outras. A literatura relacionada mostra, porém, que tal fidelidade aumenta a dificuldade de argumentação das decisões tomadas e possui um impacto relevante na complexidade de projetar algoritmos de escalonamento de redes sem-fio. Há uma preferência histórica entre os pesquisadores por utilizarem o modelo de Inter- ferência Física (ou modelo SINR), formalizado por Gupta e Kumar [2000]. Neste modelo, uma transmissão é considerada ativa se o Signal-to-interference-plus-noise-ratio (SINR) está acima de um limiar inferior, que é fixo e pré-definido pelo hardware. Uma das vantagens que o torna mais realístico frente a outros modelos é a consideração da interferência agregada entre dispositivos sem-fio. Isto é, uma transmissão causará interferência na outra desde que elas estejam transmitindo simultaneamente e utilizando o mesmo canal de comunicação. Esse é um contraponto à outros modelos de interferência, como o modelo por protocolos, também formalizado por Gupta e Ku- mar [2000], que restringe a interferência entre transmissões como uma entidade par-a-par, entre os dispositivos emissor e receptor da mesmas. É assumido que duas transmissões que transmitem em canais distintos não interferem entre si. Pensando nisso, os projetistas do protocolo Wi-Fi (Coleman [2020]) introduziram formas de particionar a faixa de banda disponível em diferentes canais de comunicação com diferentes larguras de banda. Consequentemente, obteve-se redes sem-fio com menos interferência acumulada. Na prática, o particionamento da banda permite escalonar mais conexões simultaneamente, além de permitir aumentar as taxas de transferência das transmissões. Apesar do ganho prático com o particionamento da banda, os algoritmos de escalona- mento de conexões sem-fio ganharam uma nova camada no processo decisório. Isto é, agora é pre- ciso decidir o particionamento da faixa de banda e a taxa de transferência das transmissões. Nesse trabalho, estendemos o clássico SLS para criar um novo problema que leva em consideração essas tarefas. A este problema, damos o nome de Minimum-Latency Variable Rate Variable Bandwidth Scheduling Problem (ML-VRBSP). No ML-VRBSP, cada transmissão deve ser obrigatoriamente escalonada em um dado intervalo de tempo e deve possuir uma taxa de transferência mínima. Os autores desse presente trabalham argumentam que o ML-VRBSP possui um apelo prático especialmente para certas topologias de redes. Considere redes corporativas, por exemplo. Elas são majoritariamente utilizadas em locais com grande densidade de dispositivos, tais como es- https://proceedings.science/p/193596?lang=pt-br DOI: 10.59254/sbpo-2024-193596 colas, shopping e escritórios. A Figura 1 mostra como elas podem ser organizadas. Normalmente, essas redes são caracterizadas pelo uso de um controlador central que comunica-se com um ou mais pontos de acesso e então, com a internet. Nesse caso, o controlador configura todos os pontos de acesso. Os pontos de acesso, por sua vez, comunicam-se com os clientes através de protocolos de rede sem-fio, como o Wi-Fi 6. Espera-se que essas redes sejam robustas o suficiente para suportar um alto número de clientes conectados simultaneamente. Malik et al. [2015] lista algumas qualida- des de serviços esperadas pelos clientes; em particular, a latência mínima é citada como uma das mais importantes. Felizmente, ela pode ser endereçada através do ML-VRBSP. Figura 1: Uma ilustração de como redes corporativas são organizadas. AP C1 C2 C3 C4 ethernet Controlador AP C5 C6 ethernet Internet O restante desse trabalho está organizado da seguinte forma. A seguir, na Seção 2, apre- sentamos formalmente o ML-VRBSP. Os trabalhos relacionados são discutidos na Seção 3. Na Seção 4, apresentamos algoritmos para resolver o ML-VRBSP, enquanto que os experimentos com- putacionais realizados para verificar a performance desses algoritmos são detalhados na Seção 5. Por fim, a Seção 6 apresenta as conclusões esse trabalho e os trabalhos futuros. 2. Definição do Problema Seja L = {1, 2, . . . , n} o conjunto de conexões, onde cada conexão i ∈L deve transmitir com uma velocidade mínima de ri. Além disso, uma conexão i ∈L representa um par de dispositi- vos (si, ri), sendo si o dispositivo emissor e ri o dispositivo receptor. Nesse trabalho, consideramos que cada dispositivo está posicionado em um plano cartesiano de duas dimensões e que a distância entre dois dispositivos (i, j) é dada pela distância euclidiana dos mesmos. Cada conexão i ∈L deve transmitir em um dado intervalo de tempo. Considere que T = {1, 2, . . . , t} é o conjunto que define os intervalos de tempo disponíveis, sendo t um limite superior para a quantidade de intervalos. No ML-VRBSP, o valor de t é um dado da entrada do problema. Note que t = |L| é um valor trivial e sempre viável. No Wi-Fi 6, cada conexão transmite utilizando um canal de comunicação cujo valor de largura de banda é definido pelo conjunto B = {20, 40, 80, 160}. Nesse protocolo, o espectro eletromagnético reservado para a transmissão de dados na faixa de 5GHz divide-se entre três sub- faixas de banda, cada uma com 160MHz, 240MHz e 100MHz, tal como apresentado na Figura 2. Consequentemente, cada sub-faixa pode admitir a utilização de mais de um canal ao mesmo tempo, desde que a soma da largura de banda dos canais utilizados não ultrapassem o máximo permitido. Considerando a primeira sub-faixa de banda, isso significa dizer que é possível ter, ao mesmo tempo, os canais {7, 8, 28, 38} (isto é, dois canais de 20MHz, um canal de 40MHz, e um canal de 80MHz) ou os canais {26, 27, 28, 29} (isto é, quatro canais de 40MHz). O raciocínio é análogo para as outras sub-faixas de banda. O conjunto de particionamento viáveis para a sub-faixas de banda é descrito pelo conjunto C = {1, 2, . . . , 45}, tal como apresentado na Figura 2. Note que existem pares de canais que utilizam a mesma faixa de frequência e que, portanto, se sobrepõem entre si. Seja Oc ⊂C o https://proceedings.science/p/193596?lang=pt-br DOI: 10.59254/sbpo-2024-193596 Figura 2: Faixas de frequência reservadas para transmissões que no protocolo Wi-Fi 6. (Costa et al. [2019]). (a) (b) (c) conjunto de canais que se sobrepõem com o canal c ∈C. Por exemplo, O32 = {13, 14, 32, 41, 45}, por que o canal 32 se sobrepõe com os canais 13, 14, 41 e 45. A largura de banda de cada canal é identificada por Bc ∈B, sendo c ∈C. Por exemplo, B1 = 20, B26 = 40, B38 = 80, e B44 = 160. Nesse trabalho, utilizamos o modelo SINR para calcular a qualidade do sinal de uma transmissão ⟨i, c, t⟩. Isto é, a qualidade de uma transmissão, dada por SINRi, é expressada pela razão entre a potência do sinal recebida no receptor ri e a interferência acumulada de outras trans- missões ⟨j, c, t⟩, onde i ̸= j, que transmitem no mesmo intervalo de tempo, mais uma constante N de barulho de ambiente. Especificamente, a potência recebida pelo receptor da transmissão ⟨i, c, t⟩ é expressada pela fórmula Qi = P(dsiri)−α, onde P é a potência do sinal em si, medida em Watts, e α é uma constante referente à atenuação do sinal eletromagnético no espaço. Na literatura, a potência recebida pela transmissão ⟨i, c, t⟩emitida pelo emissor de outra transmissão ⟨j, c, t⟩, onde i ̸= j, é conhecida por interferência e expressada pela fórmula Iij = P(dsjri)−α. Assim sendo, o SINRi da transmissão ⟨i, c, t⟩é dado pela seguinte fórmula: SINRi = Qi P j∈S,j̸=i Iij + N , ∀⟨i, c, t⟩∈S (1) Consideramos a tabela do Esquema de Modulação e Codificação (MCS, do inglês Modu- lation and Coding Scheme), exibida na Tabela 2, para determinar a taxa de transferência de uma transmissão no Wi-Fi 6. Seja M = {1, 2, . . . , 12} os tipos de modulação e codificação. Esse es- quema mapeia os valores de modulação e codificação m ∈M e largura de banda b ∈Bc para determinar o SINR mínimo qBc m que a transmissão ⟨i, c, t⟩necessita ter transmitir utilizando uma taxa de transferência de ¯rBc m . Os valores de qb m e ¯rb m, para todos os b ∈B e m ∈M, estão exibidos na Tabela 2 da seguinte forma: a Coluna 1 informa o tipo de MCS utilizado, enquanto que a Co- luna 2 informa o valor de SINR mínimo qb m para transmitir utilizando a taxa de transferência ¯rBc m , dado na Coluna 3, utilizando um canal de largura de banda b = 20 e MCS m ∈M. Os valores de qBc m e ¯rBc m para outros valores de largura de banda, isto é, b = 40, são exibidos nas Colunas 4 e 5; para b = 80, nas Colunas 6 e 7; para b = 160, nas Colunas 8 e 9, respectivamente. A título de ilustração, considerando a Tabela 2, uma transmissão ⟨i, c, t⟩que utiliza um canal c ∈C cuja largura de banda é de 80 MHz e possui um SINRi = 20.0 dB transmite com uma taxa de transferência de 216.2 Mbps. Mas, se SINRi ≥36.0 dB, então a taxa de transferência seria de 540.0 Mbps. Temos ainda que, se SINRi < 8.0 dB, o receptor ri da conexão não seria capaz de receber os dados, e essa transmissão não seria ativada. Portanto, sejam os valores de SINRi e Bça taxa de transferência de uma transmissão ⟨i, c, t⟩∈S é dada pela a seguinte fórmula: ¯r∗ i = max m∈M:SINRi≥qBc m ¯rBc m . (2) https://proceedings.science/p/193596?lang=pt-br DOI: 10.59254/sbpo-2024-193596 Tabela 1: Valores de SINR (dB) e taxas de transferência para cada largura de banda no Wi-Fi 6. MCS 20 MHz 40 MHz 80 MHz 160 MHz SINR Taxa SINR Taxa SINR Taxa SINR Taxa q20 m ¯r20 m q40 m ¯r40 m q80 m ¯r80 m q160 m ¯r160 m 0 2 8.6 5 17.2 8 36 11 72.1 1 5 17.2 8 34.4 11 72.1 14 144.1 2 7 25.8 10 51.6 13 108.1 16 216.2 3 10 34.4 13 68.8 16 144.1 19 288.2 4 14 51.6 17 103.2 20 216.2 23 432.4 5 18 68.8 21 137.6 24 288.2 27 576.5 6 19 77.4 22 154.9 25 324.3 28 648.5 7 20 86 23 172.1 26 360.3 29 720.6 8 25 103.2 19 206.5 31 432.4 34 864.7 9 27 114.7 30 229.4 33 480.4 36 960.8 10 30 129 33 258.1 36 540.4 39 1080.9 11 32 143.4 35 286.8 38 600.5 41 1201 Dada uma entrada representada por ⟨L, T, B, C, Oc, Cb, M, qb s, ¯rb s, P, dij, α, si, ri, ri⟩, o ML-VRBSP é matematicamente definido na Equação (3), onde ∆⊆2L×C×T é o conjunto de todas as soluções factíveis, isto é, escalonamentos ML-VRBSP S ∈∆que satisfazem a restrição r∗ i ≥ri para todas as tuplas ⟨i, c, t⟩∈S, e T : ∆7→T é uma função que computa a quantidade de intervalos de tempo são utilizados por S ∈∆. S∗= argmin S∈∆ T(S) (3) 3. Trabalhos Relacionados Pode-se argumentar que a escolha do modelo de interferência durante a modelagem de redes de computadores sem-fio é a decisão mais importante a ser tomada. Na literatura, o modelo SINR é amplamente o mais utilizado por trabalhos relacionados desde a sua formalização por Gupta e Kumar [2000] por ser considerado um modelo mais realístico do que a tradicional modelagem ba- seada em grafos, por exemplo. Naturalmente, há uma grande quantidade de trabalhos na literatura desenvolvendo algoritmos de escalonamento considerando esse modelo. Entretanto, Goussevskaia et al. [2007] provou que o problema de particionamento de conjuntos é redutível ao SLS quando esse é modelado utilizando o SINR. Consequentemente, quase todos os algoritmos são de natureza apro- ximada (e.g., Halldórsson [2009]; Goussevskaia e Wattenhofer [2013]; Goussevskaia et al. [2016]) ou heurísticas (e.g., Vieira et al. [2016]; Huang et al. [2017]). Quando aplicado à teoria de grafos, o modelo SINR permite aos pesquisadores de pesquisa operacional a desenvolverem algoritmos baseados em problemas clássicos da literatura. Vieira et al. [2016] endereça o problema de escalonamento de conexões como uma variante do problema de coloração de grafos. Já em Ephremides e Truong [1990], o mesmo problema é visto como uma variante do problema de conjunto independentes em grafos. Em contraponto ao modelo SINR, o modelo de interferência por protocolos considera que a interferência entre transmissões é uma característica par-a-par (ou binária), isto é, configura- se como uma relação entre duas transmissões. Dessa forma, esse modelo não considera a existência de interferência acumulada no receptor de cada transmissão. O modelo de protocolos é, dessa forma, menos realístico do que o SINR. Mas, apesar de preterido pelo SINR no desenvolvimento de algoritmos de escalonamento, vários trabalhos aplicam o modelo de protocolos para o estudo de protocolos de comunicação Moscibroda et al. [2006]. O estudo conduzido por Cardieri [2010] apresenta todos os detalhes de ambos os modelos e suas potenciais aplicações. https://proceedings.science/p/193596?lang=pt-br DOI: 10.59254/sbpo-2024-193596 Independentemente do modelo de interferência utilizado, a maior parte da literatura de- senvolve algoritmos de escalonamento de conexões baseados na mesma premissa: uma transmissão é considerada ativa quando a qualidade medida está acima de um limiar pré-estabelecido. Caso contrário, transmissão é infactível e nenhum dado é transferido. Esse relacionamento binário, dis- cutido pela primeira vez no contexto de escalonamento de conexões em Santi et al. [2009], é uma simplificação do que acontece na prática: a taxa de transferência é ajustada de forma inversamente proporcional à qualidade do sinal. Ainda há poucos trabalhos na literatura que endereçam diferentes valores de taxas de transferência. Além de Santi et al. [2009], Kesselheim [2012] apresenta um algoritmo aproximativo para uma variante do SLS em que todos as transmissões devem possuir uma taxa de transferência mínima. Goussevskaia et al. [2016] endereça o mesmo problema de Kesselheim [2012] e apresenta algoritmos aproximativos mais poderosos que os originais. Os trabalhos mencionados até então consideram que há apenas um canal de comunicação de largura de banda fixa (ou seja, |C| = |B| = 1) compartilhado por todas as transmissões. Mas, com a tecnologia OFDM, presente nos protocolos Wi-Fi (Coleman [2020]), a banda disponível para transmissões pode ser particionada em um ou mais canais de comunicação com diferentes largura de banda, reduzindo a interferência entre transmissões e aumentando as taxas de transferências. Até onde se sabe, não há trabalhos na literatura que estudam o problema de escalonamento de conexões sem fio considerando largura de banda e taxa de transmissão variável ao mesmo tempo. Uma variante do problema do escalonamento considera apenas um intervalo de tempo (|T| = 1), não exige que todas as conexões transmitam e o objetivo é maximizar a taxa de transferência de todas as transmissões. A essa variante, é dado o nome de problema da capacidade de redes sem- fio (ver Goussevskaia et al. [2009]). Há generalizações do problema da capacidade que considera largura de banda e taxas de transmissão variáveis. Costa et al. [2017] propõe uma heurística baseada na meta-heurística Biased random-key genetic algorithms (Londe et al. [2024]), enquanto Costa et al. [2019] propõe formulações baseadas em programação inteira. 4. Algoritmos para o ML-VRBSP Nessa seção, apresentamos dois algoritmos para encontrar soluções para o ML-VRBSP. Começamos pela heurística construtiva (CH) e finalizamos com uma formulação misto-inteira. 4.1. Heurística Construtiva O Algoritmo 1 apresenta detalhadamente os passos da heurística construtiva. A CH começa inicializando a solução incumbente S para o estado inicial, isto é S = ∅e ΨS = Ψ∅, onde Ψ∅= {1} × {25, 42, 43, 44, 45}. Em seguida, a CH itera por todas as conexões i ∈L, deci- dindo em qual canal c ∈C e em qual intervalo de tempo t ∈T será criada a transmissão ⟨i, c, t⟩. A inserção de uma transmissão é decidida entre duas opções: com a criação de uma nova trans- missão ⟨i, 44, τ⟩, utilizando um novo intervalo de tempo τ = T(S) + 1, ou com a criação de uma transmissão ⟨i, c, t⟩, sendo (c, t) ∈ΨS o primeiro par de canal e intervalo de tempo onde é possível inserir a conexão i ∈L sem quebrar a viabilidade da solução S. O procedimento auxiliar SplitInsert é explicado a seguir. Por fim, o laço é encerrado após iterar por todas as conexões i ∈L, e a CH retorna a solução incumbente S. O procedimento auxiliar SplitInsert recebe como entrada uma solução S, uma conexão i ∈L, um canal de comunicação c ∈C e um intervalo de tempo t ∈T. Em SplitInsert, duas soluções S1 e S2 são criadas a partir da solução S. Ambas as novas soluções possuem todas as transmissões de S, exceto aquelas que utilizam o canal c ∈C e o intervalo de tempo t ∈T. Seja c′ e c′′ dois canais que se sobrepõem com o canal c e que possuem metade da largura de banda de Bc. Note que sempre há somente duas opções para qualquer canal c ∈C cuja largura de banda é maior https://proceedings.science/p/193596?lang=pt-br DOI: 10.59254/sbpo-2024-193596 Algorithm 1: CH input : I = ⟨L, T, B, C, Oc, Cb, M, qb s, ¯rb s, P, dij, α, si, ri, ri⟩ output: S 1 S ←∅ 2 foreach i ∈L do 3 ω ←⟨(c, t) ∈ΨS : (S ∪{⟨i, c, t⟩}) ∈∆⟩ 4 if |ω| = 0 then 5 S ←S ∪{⟨i, 44, T(S) + 1⟩} 6 else 7 (c, t) ←ω0 8 S0 ←S ∪{⟨i, c, t⟩} 9 (S1, ΨS1), (S2, ΨS2) ←SplitInsert(I, S, i, c, t) 10 foreach (S′, ΨS′) ∈{S0, S1, S2} do 11 if S ∈∆then 12 (S, ΨS) ←(S′, ΨS′) 13 continue to line 16 14 end 15 end 16 end 17 end 18 return S do que 20 MHz. Então, cada transmissão ⟨j, c, t⟩, onde j ̸= i, é inserida em S1 no formato ⟨j, c′, t⟩ ou ⟨j, c′′, t⟩com igual probabilidade. Em seguida, a conexão i ∈L é inserida em S1 e em S2 no formato ⟨i, c′, t⟩e ⟨i, c′′, t⟩, respectivamente. Por fim, SplitInsert retorna duas novas soluções, isto é, S1 e S2, que diferem somente em uma transmissão. 4.2. Formulação Mista-Inteira Para o ML-VRBSP Começamos a apresentação da formulação misto-inteira notando que o SINR mínimo ne- cessário para que cada transmissão ⟨i, c, t⟩tenha uma taxa de transferência de ao menos ri depende diretamente do valor da largura de banda de c ∈C. Considere, por exemplo, que ri = 130 Mbps. Em uma transmissão ⟨i, c, t⟩onde Bc = 20, então o SINRi deve ser de ao menos 32 dB. Entre- tanto, a mesma taxa de transferência pode ser atingida com um SINRi de 14 dB caso Bc = 160. Portanto, seja βBc i uma variável que indica qual o SINR mínimo necessário que a transmissão ⟨i, c, t⟩precisa ter para transmitir com uma taxa de transferência maior ou igual a ri. Considere as variáveis de decisões s ∈B|T|, onde st = 1 se o intervalo de tempo t ∈T é utilizado, ou st = 0 caso contrário, e x ∈B|L|×|C|×|T|, onde xict = 1 se a transmissão ⟨i, c, t⟩ é utilizada, ou xict = 0 caso contrário. Considere também a variável auxiliar sIi ∈R que com- puta o valor correto da interferência acumulada no receptor ri da conexão i ∈L. Juntamente com Ii, sejam Î ∈R|L|×|C|×|T| ≥0 as variáveis auxiliares que armazenam o valor da interferência da conexão i ∈L quando transmitindo no canal c ∈C e intervalo de tempo t ∈T. Finalmente, seja z ∈B|L|×|C|×|T|, onde zict = 1 se a conexão i ∈L transmite utilizando um canal ¯c ∈Oc no intervalo de tempo t ∈T, ou zict = 0 caso contrário. https://proceedings.science/p/193596?lang=pt-br DOI: 10.59254/sbpo-2024-193596 Algorithm 2: SplitInsert input : ⟨I, S, ΨS, i, c, t⟩ output: {(S1, ΨS1), (S2, ΨS2)} 1 S1 ←{⟨j, c′, t⟩∈S : c′ ̸= c} 2 ΨS1 ←ΨS \\ (c, t) 3 (c′, c′′) ←(¯c ∈C : ¯c ∈Oc, B¯c = Bc/2) 4 foreach ⟨j, c, t⟩∈S : j ̸= i do 5 if Random([0, 1]) ≤0.5 then 6 S1 ←S1 ∪{⟨j, c′, t⟩} 7 else 8 S1 ←S1 ∪{⟨j, c′′, t⟩} 9 end 10 end 11 (S2, ΨS2) ←(S1, ΨS1) 12 (S1, ΨS1) ←(S1 ∪{⟨i, c′, t⟩}, ΨS1 ∪(c′, t)) 13 (S2, ΨS2) ←(S2 ∪{⟨i, c′′, t⟩}, ΨS2 ∪(c′′, t)) 14 return {(S1, ΨS1), (S2, ΨS2)} [B&C-F]: minimizar X t∈T st (4) sujeito a st+1 ≤st, ∀t = 1, 2, . . . , |T| −1, (5) X i∈L:i<t X c∈C xict = 0, ∀t ∈T, (6) X c∈C X t∈T xict = 1, ∀i ∈L, (7) zict = X ¯c∈Oc xl¯ct, ∀i ∈L, ∀c ∈C, ∀t ∈T, (8) Îict = X j∈L\\{j} P dα ji · zjct, ∀i ∈L, ∀c ∈C, ∀t ∈T, (9) Ii ≥Îict −Mi(1 −xict), ∀i ∈L, ∀c ∈C, ∀t ∈T, (10) Ii ≤Îict + Mi(1 −xict), ∀i ∈L, ∀c ∈C, ∀t ∈T, (11) SINRi ≥ X c∈C X t∈T βBc i xict, ∀i ∈L, (12) xict + xjct ≤1, ∀(i, j) ∈Θ, ∀c ∈C, ∀t ∈T, (13) s ∈B|T|, x, z ∈B|L|×|C|×|T|, Î ∈R|L|×|C|×|T| ≥0 , I ∈R|L|. (14) As equações (4)-(14) descrevem uma formulação válida para o ML-VRBSP. A função objetivo (4) minimiza o número de intervalos de tempo utilizados no escalonamento. As restrições (5)-(6) são restrições de quebra de simetria. A restrição (7) obriga todos as conexões a transmiti- rem. Respectivamente, as restrições (8)-(9) computam as transmissões ⟨l, ¯c, t⟩que interferem na transmissão ⟨i, c, t⟩e o valor total da interferência resultante no receptor ri de ⟨i, c, t⟩. O valor da variável de decisão Ii é decidido pelas restrições (10)-(11), onde M é um limite superior para Îict. A restrição (12) garante que todas as transmissões possuem uma taxa de transferência maior ou igual a ri, para toda transmissão ⟨i, c, t⟩. Por fim, considere Θ ∈L × L um conjunto de pares de conexões https://proceedings.science/p/193596?lang=pt-br DOI: 10.59254/sbpo-2024-193596 que, quando transmitindo simultaneamente, implica em ¯r∗ i < ri ou ¯r∗ j < rj. Tendo em vista, a restrição (13) impede que tais conexões (i, j) ∈Θ sejam ativadas utilizando canais sobrepostos no mesmo intervalo de tempo. Finalmente, o domínio das variáveis é garantido pela restrição (14). 5. Experimentos Computacionais Apresentamos nessa seção os experimentos computacionais realizados com os algoritmos CH e B&C-F, ambos implementados utilizando a linguagem C++ v20.0. Além disso, utilizamos o resolvedor matemático Gurobi v10.0 para resolver B&C-F. Os algoritmos foram executados em ser- vidores equipados com processadores Intel Core i7, 24 GB de memória RAM e sistema operacional Ubuntu 18.04 LTS. O critério de parada de cada algoritmo é dado pelo tempo máximo de execução, que foi setado para 7200 segundos (2 horas). Finalmente, os valores dos parâmetros N, α e P são iguais a 0.0, 3.0 e 1000.0, respectivamente (Goussevskaia et al. [2016], Vieira et al. [2016]). Os experimentos foram conduzidos com utilizando categorias de instâncias, chamadas de Du e Dr. As instâncias foram criadas seguindo a mesma estratégia observada em outros trabalhos da literatura (e.g. Goussevskaia et al. [2014, 2016]; Costa et al. [2019]). Em Du, uma instância para o ML-VRBSP segue o seguinte formato: primeiro, |L| dispositivos receptores são posicio- nados aleatoriamente em um plano cartesiano de dimensões 250 × 250 metros quadrados; então, |L| dispositivos emissores são posicionados aleatoriamente em uma distância de até 6 √ 2 metros do respectivo receptor. Além disso, em Du, o valor de ri, para cada i ∈L, é sorteado de forma uniforme no conjunto S b∈B ¯rb m. A seguir, apresentaremos os resultados para diferentes valores de |L|, isto é, |L| = {8, 16, 32, . . . , 512}. Finalmente, cada valor de |L| contém 30 instâncias. No total, a categoria Du é composta por 210 instâncias. A segunda categoria de instâncias, Dr, é criada de forma similar à Du. Entretanto, ela se diferencia na estratégia de geração dos valores para ri. Em Dr, temos que ri, para todo i ∈L, é igual à um valor sorteado aleatoriamente no intervalo [8.6, 1201], isto é, um valor entre o menor e maior valor possível de taxa de transmissão no Wi-Fi 6. A Tabela 2 e 3 apresenta os resultados dos experimentos para a categoria Du e Dr, respec- tivamente e estão organizadas da seguinte forma. Cada linha apresenta os resultados para instâncias conjunto de instâncias que possuem o mesmo número de conexões |L|, informadas pela Coluna 1. Ressaltamos que todas as colunas, exceto aquelas representadas por |L| e |ub|, informam a média aritmética da métrica utilizada na coluna citada. As colunas marcadas com −indicam que o algo- ritmo não conseguiu encontrar soluções factíveis para todas as instâncias de um mesmo conjunto. Além disso, o símbolo × indica que o algoritmo excedeu o limite de memória disponível e nenhum resultado foi computado em um dado conjunto de instâncias. Os resultados para a CH são apresentados pelas Colunas 2 a 4. Respectivamente, a Co- luna |ub| informa a quantidade de soluções factíveis encontradas pela CH para um determinado conjunto de instâncias. A coluna ¯ub informa a quantidade de intervalos de tempo utilizado pelas respectivas soluções (i.e., o limite superior), enquanto que a coluna t(s) informa quanto tempo a CH demorou para encontrar uma solução. Os resultados para B&C-F são apresentados nas colunas seguintes. A Coluna 5 é similar á Coluna 2, enquanto que a Coluna 6 informa quantas soluções ótimas foram encontradas no conjunto de instâncias citado. A coluna 7 a 9 informam, respectiva- mente, os limites superiores, inferiores e o gap de otimalidade (ubCH−ubB&C) ubCH daquele conjunto de instâncias. Além disso, o tempo necessário para B&C-F encontrar a solução ótima de cada instância é informado pela Coluna 10. Finalmente, a Coluna 11 informa o quão pior é a função objetivo de uma instância resolvida por CH, em comparação com B&C-F. 5.1. Resultados Computacionais Para Du A Tabela 2 mostra que a CH foi capaz de encontrar soluções factíveis para todas as 210 instâncias da categoria Du. Observa-se que o tempo computacional requerido pela CH para com- putar uma solução factível cresceu de forma proporcional à quantidade de conexões. Ainda assim, a https://proceedings.science/p/193596?lang=pt-br DOI: 10.59254/sbpo-2024-193596 CH foi capaz de computar soluções factíveis par as instâncias mais difíceis em menos de 1 segundo. Ainda de acordo com a Tabela 2, observa-se que o algoritmo B&C-F conseguiu encontrar soluções ótimas para todas as instâncias com até 64 conexões. Para as instâncias com 128 conexões, B&C-F foi capaz de encontrar 23 soluções ótimas, resultando em um gap médio de 8,88%. Infelizmente, B&C-F não foi capaz de encontrar soluções factíveis para todas as instâncias de 256 conexões con- siderando o tempo limite estabelecido, e não houve memória computacional suficiente para rodar o algoritmo nas instâncias com 512 conexões. Os experimentos com instâncias de Du mostram que B&C-F encontrou soluções melho- res, de acordo com a função objetivo, do que a CH, para as instâncias com até 128 conexões. A melhora mais expressiva foi observada nas instâncias com 128 conexões, ao passo de que a menos expressiva deu-se nas instâncias com 8 conexões. Tabela 2: Resultados consolidados dos experimentos com instâncias da categoria Du. CH B&C-F |L| |ub| ub t(s) |ub| #opt ub lb gap(%) t(s) %CH 8 30 1.10 0.00 30 30 1.00 1.00 0.00 0.04 5.00 16 30 1.60 0.00 30 30 1.16 1.16 0.00 0.13 20.55 32 30 2.50 0.00 30 30 1.66 1.66 0.00 2.59 33.05 64 30 3.70 0.00 30 30 2.26 2.26 0.00 22.18 36.88 128 30 6.40 0.00 30 23 3.66 3.30 8.88 2843.38 42.03 256 30 11.46 0.01 7 1 − 3.99 − 7200.00 − 512 30 20.86 0.06 × 0 × × × × × 5.2. Resultados Computacionais para Dr A Tabela 3 mostra que a heurística construtiva foi capaz de encontrar soluções factíveis para todas as 210 instâncias de Dr. É possível observar que o tempo computacional exigido pelo algoritmo manteve-se praticamente inalterado. Isto é, mesmo nas instâncias mais difíceis de Dr, a CH requer menos de 1 segundo para computar uma solução factível. Com relação à B&C-F, a Tabela 3 mostra que o mesmo encontrou soluções ótimas para to- das as instâncias com até 32 conexões. Com 64 conexões, B&C-F foi capaz de encontrar 27 soluções ótimas, resultando em um gap médio de 1,52%. Já com 128 conexões, apenas 4 soluções ótimas foram encontradas. Nesse caso, o gap médio foi de 17,23%. Além disso, B&C-F não conseguiu en- contrar soluções factíveis para todas as instâncias de 256 conexões. Finalmente, não houve memória computacional suficiente para rodar o algoritmo nas instâncias com 512 conexões. Seguindo o observado nos experimentos com instâncias da categoria Du, B&C-F obteve uma performance computacional significativamente melhor do que a CH, considerando os tempo de execução de cada algoritmo. Em particular, as melhoras mais e menos expressivas são observadas nas instâncias com 64 conexões e 8 conexões, respectivamente. Comparando as Colunas 6 e 10 das Tabelas 2 e 3, é possível concluir que as instâncias de Dr são mais difíceis do que as de Du. Por exemplo, enquanto que 30 soluções ótimas foram encontradas para as instâncias de Du com 64 conexões com apenas 22,18 segundos, 27 soluções ótimas foram encontradas nas instâncias equivalentes em Dr. No último caso, foram necessários aproximadamente 904,59 segundos para encontrar uma solução ótima. A piora de performance de B&C-F foi maior ainda nas 128 conexões, caindo de 23 soluções encontradas para apenas 4 encon- tradas, mesmo utilizando o dobro de tempo do que na primeira categoria. 6. Conclusões e Trabalhos Futuros Neste trabalho, introduzimos o Minimum-Latency Variable Rate Variable Scheduling Pro- blem. Nesse problema, decide-se de forma combinada o particionamento da banda Wi-Fi disponível https://proceedings.science/p/193596?lang=pt-br DOI: 10.59254/sbpo-2024-193596 Tabela 3: Resultados consolidados dos experimentos com instâncias da categoria Dr. CH B&C-F |L| |ub| ub t(s) |ub| #opt ub lb gap(%) t(s) %CH 8 30 1.7 0.00 30 30 1.46 1.46 0.00 0.03 10.55 16 30 2.9 0.00 30 30 2.33 2.33 0.00 0.14 18.05 32 30 4.83 0.00 30 30 3.70 3.70 0.00 0.97 22.55 64 30 8.33 0.00 30 27 5.93 5.83 1.52 904.59 28.68 128 30 14.2 0.00 30 6 11.34 9.27 17.23 6546.43 19.52 256 30 26.3 0.01 0 0 − 1.00 − 7200.00 − 512 30 48.46 0.07 × × × × × × × e o escalonamento das conexões de forma a minimizar a quantidade de intervalos de tempo ne- cessários para todas as conexões transmitirem utilizando uma taxa de transmissão mínima. Dessa forma, contribuímos com a literatura apresentando a primeira heurística construtiva (CH) e a pri- meira formulação misto-inteira baseada em programação inteira (B&C-F). Nesse trabalho, testamos a performance dos algoritmos propostos utilizando instâncias de benchmark que foram construídas replicando metodologias encontradas em trabalhos relaciona- dos. Especificamente, cada instância simula uma rede de computadores com um número fixo de conexões cujo dispositivos estão espalhados em um plano cartesiano de duas dimensões de área de 250 × 250m. Além disso, consideramos duas categorias de instâncias que diferenciam-se na geração do valor mínimo de taxa de transferência de cada transmissão. Os resultados obtidos destacam que a CH é capaz de computar soluções factíveis rapida- mente mesmo nas instâncias mais difíceis dos experimentos. Contudo, os resultados também des- tacaram a superioridade de B&C-F em computar soluções melhores que CH, melhorando a função objetivo em até 42,03%. Entretanto, observa-se que o B&C-F necessita de uma quantidade razoável de tempo ou memória computacional para encontrar soluções factíveis para as instâncias de tama- nho médio, como as com 256 ou mais conexões. Como trabalho futuro, esperamos desenvolver novas equações de quebra de simetria e propor novos cortes de dualidade para acelerar a convergência de algoritmos como B&C-F. Outra possibilidade de trabalho futuro envolve o desenvolvendo de limites superiores para o intervalo de tempo utilizado na entrada da formulação, consequentemente reduzindo a quantidade de memória necessária para a execução do mesmo. Agradecimentos Esse trabalho foi financiado parcialmente pela Coordenação de Aperfeiçoamento de Pes- soal de Nível Superior (CAPES), código de financiamento 001, pelo Conselho Nacional de Desen- volvimento Científico e Tecnológico (CNPQ), e pela Fundação de Amparo à Pesquisa do Estado de Minas Gerais (FAPEMIG)."
        },
        {
            "titulo": "Assegurando a Confidencialidade de Dados de Workflows Executados em Nuvens de Computadores: Abordagens Heurísticas e Exatas",
            "informacoes_url": "https://proceedings.science/p/193619?lang=pt-br",
            "idioma": "pt-br",
            "autores": [
                {
                    "nome": "Rodrigo Silva",
                    "afiliacao": "Instituto de Computação – Universidade Federal Fluminense (UFF)",
                    "orcid": ""
                },
                {
                    "nome": "Yuri Frota",
                    "afiliacao": "Instituto de Computação – Universidade Federal Fluminense (UFF)",
                    "orcid": ""
                },
                {
                    "nome": "Daniel de Oliveira",
                    "afiliacao": "Instituto de Computação – Universidade Federal Fluminense (UFF)",
                    "orcid": ""
                },
                {
                    "nome": "Esther Pacitti",
                    "afiliacao": "INRIA, University of Montpellier, CNRS, LIRMM",
                    "orcid": ""
                }
            ],
            "data_publicacao": "",
            "resumo": "As nuvens de computadores fornecem um ambiente sob demanda que permite aos usuários executar seus workflows locais em um ambiente elástico e com alta disponibilidade. Diversas aplicações podem ser modeladas como workflows, e muitas delas são intensivas em computação e produção de dados. Na nuvem, o local de armazenamento desses dados se torna uma preocupação quando a confidencialidade pode ser comprometida. Usuários maliciosos podem realizar inferências a respeito dos resultados e da própria estrutura dos workflows. A dispersão de dados, a criptografia e outros mecanismos podem ser adotados para aprimorar a privacidade dos dados, mas estes não podem ser adotados sem considerar o escalonamento do workflow, pois isso arrisca aumentar significativamente o tempo de execução e o custo financeiro.",
            "keywords": [
                "Armazenamento",
                "Confidencialidade",
                "CYCLOPS",
                "Nuvens",
                "Workflows"
            ],
            "storage_key": "galoa-proceedings--sbpo-2024--193619.pdf",
            "referencias": [
                "Abazari, F., Analoui, M., Takabi, H., e Fu, S. (2019). Mows: multi-objective workflow scheduling in cloud computing based on heuristic algorithm. Simulation Modelling Practice and Theory, 93: 119–132.",
                "de Oliveira, D., Liu, J., e Pacitti, E. (2019). Data-Intensive Workflow Management: For Clouds and Data-Intensive and Scalable Computing Environments. Synthesis Lectures on Data Management. Morgan & Claypool Publishers.",
                "Guerine, M., Stockinger, M. B., et al. (2019). A provenance-based heuristic for preserving results confidentiality in cloud-based scientific workflows. Fut. Gen. Comp. Sys., 97: 697 – 713.",
                "Juve, G., Chervenak, A. L., Deelman, E., Bharathi, S., Mehta, G., e Vahi, K. (2013). Characterizing and profiling scientific workflows. FGCS, 29(3): 682–692.",
                "Ristenpart, T., Tromer, E., Shacham, H., e Savage, S. (2009). Hey, you, get off of my cloud: Exploring information leakage in third-party compute clouds. In Proc. of the CCS ’09, p. 199–212.",
                "Sharif, S., Watson, P., et al. (2016). Privacy-aware scheduling saas in high performance computing environments. IEEE TPDS., 28(4): 1176–1188.",
                "Shishido, H., Estrella, J. C., et al. (2018). Multi-objective optimization for workflow scheduling under task selection policies in clouds. In CEC, p. 1–8.",
                "Sujana, J. A. J., Revathi, T., Priya, T. S., e Muneeswaran, K. (2019). Smart pso-based secured scheduling approaches for scientific workflows in cloud computing. Soft. Comp., 23(5): 1745–1765.",
                "Tawfeek, M. A. e AbdulHamed, A. A. (2018). Service flow management with multi-objective constraints in heterogeneous computing. In ICCES, p. 258–263.",
                "Teylo, L., de Paula Junior, U., et al. (2017). A hybrid evolutionary algorithm for task scheduling and data assignment of data-intensive scientific workflows on clouds. FGCS, 76: 1–17.",
                "Topcuoglu, H., Hariri, S., e Wu, M. (2002). Performance-effective and low-complexity task scheduling for heterogeneous computing. IEEE TPDS, 13(3): 260–274.",
                "Wen, Y., Liu, J., et al. (2020). Scheduling workflows with privacy protection constraints for big data applications on cloud. FGCS, 108: 1084–1091.",
                "Zamfiroiu, A., Petre, I., e Boncea, R. (2019). Cloud computing vulnerabilities analysis. In Proc. of the CCIOT ’19, p. 48–53.",
                "Zhou, A. C., Xiao, Y., Gong, Y., He, B., Zhai, J., e Mao, R. (2019). Privacy regulation aware process mapping in geo-distributed cloud data centers. IEEE TPDS, 30(8): 1872–1888."
            ],
            "artigo_completo": "Assegurando a Confidencialidade de Dados de Workflows Executados em Nuvens de Computadores: Abordagens Heurísticas e Exatas. RESUMO As nuvens de computadores fornecem um ambiente sob demanda que permite aos usuários executar seus workflows locais em um ambiente elástico e com alta disponibilidade. Diver- sas aplicações podem ser modeladas como workflows, e muitas delas são intensivas em computação e produção de dados. Na nuvem, o local de armazenamento desses dados se torna uma preocupação quando a confidencialidade pode ser comprometida. Usuários maliciosos podem realizar inferências a respeito dos resultados e da própria estrutura dos workflows. A dispersão de dados, a criptografia e outros mecanismos podem ser adotados para aprimorar a privacidade dos dados, mas estes não podem ser adotados sem considerar o escalonamento do workflow, pois isso arrisca aumentar sig- nificativamente o tempo de execução e o custo financeiro. Neste artigo, introduzimos a CYCLOPS, uma abordagem que visa executar workflows em nuvens de computadores de forma eficiente le- vando em consideração as restrições de confidencialidade dos dados produzidos e da estrutura do workflow. PALAVRAS CHAVE. Armazenamento, Confidencialidade, CYCLOPS, Nuvens, Workflows. https://proceedings.science/p/193619?lang=pt-br DOI: 10.59254/sbpo-2024-193619 1. Introdução Um Workflow é uma abstração muito usada para modelar processos complexos. Geral- mente representados como grafos acíclicos direcionados (DAGs), os workflows possuem nós que representam atividades e arestas que indicam as dependências de dados entre elas [de Oliveira et al., 2019]. A execução de uma atividade, chamada de ativação desde ponto em diante, consome arqui- vos e parâmetros de entrada. Embora possam ser implementados como scripts, é comum utilizar Sistemas de Gerência de Workflows de Big Data (SGWBDs), que permitem aos usuários especificar e executar os workflows, além de rastrear os dados de proveniência dos workflows. Devido à alta demanda por recursos, muitos workflows são executados em nuvens de computadores. Por isso, vários SGWBDs oferecem suporte para ambientes de nuvem, incluindo o Pegasus, o Parsl e o SecDATAVIEW. Escalonar as ativações do workflow na nuvem é um pro- blema NP-Difícil. Os SGWBDs procuram oferecer algoritmos de escalonamento otimizados que aproveitam os recursos da nuvem, como elasticidade e modelos de pagamento sob demanda. No entanto, o compartilhamento de recursos e o uso de áreas de armazenamento compartilhadas, conhe- cidas como buckets, expõem os workflows a várias classes de ataques [Zamfiroiu et al., 2019]. Por exemplo, Ristenpart et al. [2009] discutem diversas ameaças à confidencialidade dos dados arma- zenados em máquinas virtuais (MVs) da AWS e destacam a importância de proteger os resultados das execuções dos workflows de big data. Uma forma de reduzir o impacto de possíveis ameaças é por meio da criação de um plano de dispersão de dados que determina quais arquivos podem ser armazenados juntos, garantindo a confidencialidade dos dados na nuvem. Esse plano é representado neste artigo por um grafo de con- flitos, onde cada arco indica um conflito entre os arquivos, sendo crucial conhecer essas restrições para sua geração. Desenvolver um plano eficaz para os dados consumidos e produzidos pelos work- flows é essencial para aumentar a confidencialidade dos dados em SGWBDs. Entretanto, a dispersão dos dados não pode ser feita desacoplada do escalonamento do workflow, pois dependendo de onde os dados são armazenados e processados, pode haver impacto no tempo de execução do workflow. Neste artigo, é apresentada a abordagem denominada CYCLOPS , que preserva a con- fidencialidade dos dados enquanto reduz os custos e o tempo de execução dos workflows. Na CYCLOPS, as ativações são escalonadas considerando a heterogeneidade das MVs, usando metada- dos de segurança e o grafo de conflitos para dispersar eficientemente os dados entre os dispositivos de armazenamento.Isso minimiza o makespan e o risco de acesso malicioso, ao mesmo tempo que pode ser integrado aos SGWBDs existentes. As contribuições deste trabalho podem ser enumeradas como: a formulação do problema de escalonamento com confidencialidade dos dados como um problema de programação matemática mista (i); o desenvolvimento de uma heurística de escalonamento de workflows com restrições de confidencialidade (ii); e uma avaliação experimental da abordagem proposta usando workflows de benchmark conhecidos (iii). O restante deste documento está organizado da seguinte forma: a Seção 3 aborda a formulação matemática; a Seção 4 apresenta a heurística de escalonamento proposta; a Seção 5 exibe os resultados experimentais; a Seção 2 discute os trabalhos relacionados; e a Seção 6 conclui o trabalho. 2. Trabalhos Relacionados Diversos trabalhos têm como foco executar workflows em nuvens minimizando o makes- pan e custo financeiro. Como o enfoque deste trabalho está na segurança, serão apresentados os trabalhos que de alguma forma tratam de questões como segurança da informação e confidenci- alidade dos dados. Os trabalhos revisados são categorizados em 3 grupos: (i) dispersão dos da- dos; (ii) segurança por MV; e (iii) segurança por site. A primeira compreende os trabalhos que de alguma forma distribuem os dados pelos diversos dispositivos de armazenamentos, a segunda https://proceedings.science/p/193619?lang=pt-br DOI: 10.59254/sbpo-2024-193619 engloba os trabalhos que asseguram as informações associando MVs capazes de atender as deman- das de seguranças das ativações e, por fim, a terceira abrange os trabalhos que vinculam diferentes sites (pode-se considerar também regiões, data centers, nuvens privadas) a diferentes requisitos de segurança, mapeando assim as ativações mais sensíveis aos sites mais seguros. Na categoria de dispersão de dados, destaca-se o trabalho do Guerine et al. [2019], que propõem a dispersão dos dados em buckets na nuvem. Apesar de considerar tanto a dispersão de dados quanto a criptografia na solução final, a dispersão de dados é desvinculada do escalonamento das ativações do workflow, i.e., os dados podem ser armazenados em um dispositivo geograficamente muito distante da MV que irá processar os dados significando em um maior overhead na leitura/escrita dos dados. Na catego- ria de segurança por MV, trabalhos como Shishido et al. [2018] e Tawfeek e AbdulHamed [2018] implementam algoritmos baseados em algoritmos genético para escalonar ativações que produzem dados sensíveis em MVs específicas, ou seja, que possuem níveis ou padrões de segurança que aten- dam os requisitos de segurança. Similarmente, Sujana et al. [2019] e Abazari et al. [2019] propõem abordagens de escalonamento multicritério que consideram os requisitos de segurança das ativações do workflow. Todos esses trabalhos deixam de aproveitar uma maior segurança e confiabilidade que a dispersão dos dados é capaz de proporcionar. Na categoria de segurança por site, Sharif et al. [2016] e Wen et al. [2020] propõem algoritmos para preservar a privacidade, associando ativações e dados a nuvens privadas ou data centers específicos. Por sua vez, Zhou et al. [2019] definem as capacidades de segurança e privacidade de cada data center, distribuídos geograficamente, para a execução das ativações, visando atender aos requisitos de segurança e otimizar tempo e custo. No entanto, essas abordagens não abordam o acesso indevido a dados sensíveis em violações de segurança interna nem criptografia. Por outro lado, a abordagem proposta neste artigo introduz uma barreira a mais através da dispersão dados junto com o cálculo do escalonamento. 3. Formulação Matemática Workflow Descrição Ds Conjunto de dados estáticos (dados já existentes). Dd Conjunto de dados dinâmicos (dados produzidos durante a execução do workflow). D = Ds ∪Dd Conjunto de dados. O(d) Dispositivo que armazena dados estáticos d ∈Ds. W(d) Tamanho dos dados d ∈D. N Conjunto de ativações. B Conjunto de buckets (somente com serviço de armazenamento), com preço de pagamento variável, dependendo de quantos gigabytes são armazenados. M Conjunto de máquinas virtuais (com poder de processamento e serviço de armazenamento). M = (B ∪M) Conjunto de dispositivos. Lj Conjunto de intervalos de armazenamento {0 . . . | Lj |} do bucket j ∈B (intervalo L0 indica que o bucket não é usado). tmax Tempo máximo de execução para o workflow. T Conjunto de períodos de tempo viáveis (T = {1 . . . tmax}). tij Tempo de processamento de ativação i ∈N na máquina virtual j ∈M. −→t djp Tempo gasto pela máquina virtual j ∈M para ler os dados d ∈D armazenados no dispositivo p ∈M. ←−t djp Tempo gasto pela máquina virtual j ∈M para escrever os dados d ∈Dd armazenados no dispositivo p ∈M. ∆in(i) ⊆D Conjunto de dados necessários para a execução da ativação i ∈N. ∆out(i) ⊆Dd Conjunto de dados gerados pela ativação i ∈N. cmj Capacidade de armazenamento do dispositivo j ∈M. smjl Volume de armazenamento do bucket j ∈B no intervalo l ∈Lj, onde smj0 = 0. cM j O custo financeiro da contratação da máquina virtual j ∈M por um período de tempo. cB jl O custo financeiro da contratação do bucket j ∈B no intervalo l ∈Lj, onde cB j0 = 0. cmax O orçamento máximo financeiro disponível. https://proceedings.science/p/193619?lang=pt-br DOI: 10.59254/sbpo-2024-193619 Workflow Descrição αt, αb and αs Os pesos de tempo, custo e segurança que definem a relevância de cada objetivo (αt + αb + αs = 1). Segurança e Privacidade Descrição Gc = (D, Eh ∪Es, δ) Grafo de conflitos. R Conjunto de requisitos de segurança de ativações. lr max O valor máximo (nível) do requisito de segurança r ∈R. lri task O nível do requisito mínimo de segurança r ∈R exigido pela ativação i ∈N. lrj vm O nível do requisito de segurança r ∈R oferecido pela máquina virtual j ∈M. smax A exposição máxima de segurança e privacidade, definida como smax = P r∈R |N| · lr max + P (d1,d2)∈Es δd1d2. Variáveis Descrição xijt Variável binária que indica se a ativação i ∈N inicia sua execução na MV j ∈M no período t ∈T ou não. −→ x idjpt Variável binária que indica se a ativação i ∈N executando na MV j ∈M começa a ler os dados d ∈∆in(i) armazenados no dispositivo p ∈M no período t ∈T ou não. ←− x idjpt Variável binária que indica se a ativação i ∈N executando em j ∈M começa a escrever dados d ∈∆out(i) ⊂Dd no dispositivo p ∈M no período t ∈T ou não. ydjt Variável binária que indica se os dados d ∈D estão armazenados no dispositivo j ∈M no período t ∈T ou não. ydj Variável binária que indica se os dados d ∈D estão armazenados no dispositivo j ∈M em algum período de tempo. wd1d2 Variável binária que indica se os dados d1 e d2 estão armazenados no mesmo local ou não, onde (d1, d2) ∈Es. eri Variável contínua que indica o nível de exposição da execução da ativação i ∈N referente ao requisito de segurança r ∈R. bjl Variável binária que indica se o bucket j ∈B está sendo usado no intervalo l ∈Lj ou não. qjl Variável contínua que contém o tamanho total dos dados alocados no bucket j ∈B no intervalo l ∈Lj. vjt Variável binária que indica se a máquina virtual j ∈M é usada (contratada) no momento t ∈T. zT j Variável contínua que indica o tempo total de uso da máquina virtual j ∈M. zT Variável contínua que indica o tempo total para executar o workflow (makespan). O escalonamento de ativações do workflow realizado pela abordagem CYCLOPS é formu- lado como o problema de programação inteira chamado CYCLOPS-IP, conforme descrito a seguir: Um workflow pode ser representado como um grafo direcionado acíclico G = (N ∪D, A), onde o conjunto de vértices é composto por ativações (N) e arquivos de dados (D), enquanto que o con- junto de arcos A definem a relação de produção/consumo entre as ativações e os dados. Estes dados podem ser armazenados em MVs j ∈M ou em buckets j ∈B, porem apenas MVs possuem poder de processamento, logo, definimos nosso conjunto de dispositivos de M = (B ∪M). Além disso, ativações podem requerer requisitos de segurança (e.g., criptografias), definidos pelo conjunto R, que podem ser ofertados pelos dispositivos disponíveis. Cada requisito de segurança r ∈R possui lr max níveis de segurança. Denotamos por lrj vm o nível do requirimento de segurança r ∈R ofere- cido pela MV j ∈M. Similarmente, denotamos por lri task o nível do requisito de segurança r ∈R requerido pela ativação i ∈N. Defini-se D = Ds ∪Dd como o conjunto de todos os dados, onde cada dado d ∈D possui um tamanho W(d) e pode ser estático (Ds), com um dispositivo de ori- gem O(d) ∈M, ou dinâmico (Dd), gerado durante a execução do workflow. Além disso, define-se ∆in(i) como o conjunto de todos os dados de entrada da ativação i ∈N, e ∆out(i) como o conjunto de dados de saída gerados pela ativação. Ademais, tmax é definido como o tempo máximo esperado para a execução do workflow. Dessa forma, T = 1...tmax representa o conjunto de períodos de https://proceedings.science/p/193619?lang=pt-br DOI: 10.59254/sbpo-2024-193619 tempo viáveis. Cada bucket j ∈B é dividido em intervalos de armazenamento {0...|Lj|}, cada um com a capacidade smjl, indicando a faixa de volume utilizado (o intervalo 0 indica que o bucket não está em uso). Assim, cB jl é o custo de contratação do bucket j ∈B no intervalo l ∈Lj, e cM j é o custo financeiro de contratar uma MV j ∈M por um período de tempo (US$/minuto). O grafo de conflitos é definido como Gc = (D, Eh ∪Es, δ) onde as arestas (Eh ∪Es) representam os conflitos de confidencialidade. Definimos dois tipos de conflitos: hard (Eh) e soft (Es). Os conflitos hard definem pares de dados que não podem ser armazenados num mesmo dispositivo, enquanto que os conflitos soft definem pares de dados que não deveriam estar juntos mas podem estar perante o pagamento de uma penalidade δ. As Tabelas workflow, segurança e privacidade, e variáveis resumem os parâmetros e variáveis utilizados na formulação matemática proposta para CYCLOPS-IP. A abordagem começa pela definição da função objetivo, que visa minimizar 3 métricas: o tempo de execução do workflow (1), o custo financeiro (2), e a exposição à segurança e violação de privacidade (3). Os pesos αt, αb e αs são utilizados para determinar a importância de cada objetivo, e idealmente, sua soma deve ser igual a 1, permitindo um ajuste fino do modelo. Isso possibilita aos usuários escolher se desejam uma execução rápida, de baixo custo ou segura. É relevante observar que todos os 3 objetivos são normalizados usando tmax, cmax e smax, respectivamente. As restrições (4) asseguram que cada ativação seja executada. Já as restrições (5) e (6) estipulam que todas as operações de leitura e escrita, respectivamente, sejam realizadas. min αt · ( zT tmax )+ (1) αb · ( X j∈M cM j zT j cmax + X j∈B X l∈Lj cB jlqjl cmax )+ (2) αs · ( X r∈R X i∈N eri smax + X (d1,d2)∈Es δd1d2wd1d2 smax ) (3) X j∈M X t∈T xijt = 1, ∀i ∈N (4) X j∈M p∈M X t∈T −→ x idjpt = 1, ∀i ∈N, ∀d ∈∆in(i) (5) X j∈M p∈M X t∈T ←− x idjpt = 1, ∀i ∈N, ∀d ∈∆out(i) (6) As desigualdades (7) garantem que os dados d ∈∆out(i) só podem ser escritos se a ativação i for executada no momento correto. Adicionalmente, as restrições (8) determinam que os dados d não podem ser escritos antes do tempo de processamento da ativação i, que é responsável por sua escrita. É importante observar que ambos os conjuntos de restrições ((7) e (8)) operam em conjunto para garantir um tempo viável para o processo de escrita. ←− x idjpt ≤ t−tij X q=1 xijq, ∀i ∈N, ∀d ∈∆out(i), ∀j ∈M, ∀p ∈M, ∀t = (tij + 1) · · · TM (7) ←− x idjpt = 0, ∀i ∈N, ∀d ∈∆out(i), ∀j ∈M, ∀d ∈∆out(i), 1 ≤t ≤tij (8) As restrições (9) determinam que uma ativação só pode ser executada se todas as leituras necessárias forem concluídas em um tempo viável. https://proceedings.science/p/193619?lang=pt-br DOI: 10.59254/sbpo-2024-193619 xijt ≤ X p∈M t−− → t djp X q=1 −→ x idjpq, ∀i ∈N, ∀d ∈∆in(i), ∀j ∈M, ∀t ∈T, such (t −−→t djp) ≥1 (9) As desigualdades (10) garantem que apenas no máximo uma ação (execução, leitura ou escrita) possa ocorrer em um período de uma MV (e.g., uma MV não pode executar uma ativação e escrever dados ao mesmo tempo). Por outro lado, as desigualdades (11) determinam que ações passivas (um dado ser lido ou escrito em uma máquina) podem ser realizadas em paralelo. É impor- tante notar que qualquer ação (ativa ou passiva) realizada em uma MV j no período t terá a variável vjt definida como 1, indicando que a MV está em uso. X i∈N t X q=max (1,t−tij+1) xijq+ X i∈N X d∈∆out(i) X p∈M t X r=max (1,t−← − t djp+1) ←− x idjpr+ X i∈N X d∈∆in(i) X p∈M t X r=max (1,t−− → t djp+1) −→ x idjpr ≤vjt, ∀j ∈M, ∀t ∈T (10) X i∈N X d∈∆out(i) X p∈M t X r=max (1,t−← − t dpj+1) ←− x idpjr+ X i∈N X d∈∆in(i) X p∈M t X r=max (1,t−− → t dpj+1) −→ x idpjr ≤|M|.vjt, ∀j ∈M, ∀t ∈T (11) As restrições (12) asseguram que não haja dados dinâmicos no momento inicial da execu- ção do workflow. Por outro lado, as restrições (13) e (14) garantem que todos os dados estáticos estejam pré-armazenados em seus dispositivos de origem (i.e., uma MV ou um bucket). ydj1 = 0, ∀d ∈Dd, ∀j ∈M (12) ydj1 = 0, ∀d ∈Ds | j ∈(M\\O(d)) (13) ydjt = 1, ∀d ∈Ds | j ∈O(d), ∀t ∈T (14) As restrições (15) e (16) vinculam a variável de armazenamento y com as variáveis de escrita ←−x e de leitura −→x , garantindo um processo de escrita e leitura viável, respectivamente. Em detalhes, a restrição (15) garante que os dados só estarão armazenados em um dispositivo se já tiverem sido produzidos (escritos) anteriormente. Por outro lado, as restrições (16) garantem que os dados só serão lidos se estiverem previamente armazenados em um dispositivo. ydp(t+1) = ydpt + X j∈M ←− x idjp(t−← − t djp+1), ∀d ∈D, ∀p ∈M, ∀t ∈{1 . . . tmax −1}, such (t −←−t djp + 1) ≥1, d ∈∆out(i) (15) X j∈M −→ x idjpt ≤ydpt, ∀i ∈N, ∀d ∈∆in(i), ∀p ∈M, ∀t ∈T (16) https://proceedings.science/p/193619?lang=pt-br DOI: 10.59254/sbpo-2024-193619 As capacidades de armazenamento dos dispositivos (tanto buckets quanto discos de MV) são limitadas pelas restrições (17). As restrições (18) relacionam a última operação de escrita com o tempo de execução do workflow (makespan). Note que, em nosso modelo de aplicação, uma ativação sempre produz dados. As restrições (19) vinculam as variáveis vjt e zT j para estabelecer o tempo de alocação (pago) correto da MV j, enquanto as restrições (20) garantem que os custos financeiros não excedam o orçamento máximo definido pelos usuários. X d∈D ydjtW(d) ≤cmj, ∀j ∈M, ∀t ∈T (17) ←− x idjpt · (t + ←−t djp) ≤zT , ∀i ∈N, ∀d ∈∆out(i), ∀j ∈M, ∀p ∈M, ∀t ∈T (18) vjt · t ≤zT j , ∀j ∈M, ∀t ∈T (19) X j∈M cM j zT j + X j∈B X l∈Lj cB jlqjl ≤cmax (20) Além disso, a seguinte restrição operacional (21) deve ser satisfeita: uma ativação i só pode iniciar qualquer processo de leitura se todos os dados d ∈∆in(i) já estiverem disponíveis (i.e., se todos os dados d ∈(∆in(i) ∩Dd) estiverem escritos). X p∈M −→ x idjpt · |∆in(i)| ≤ X g∈∆in(i) X p∈M ygpt, ∀i ∈N, ∀d ∈∆in(i), ∀j ∈M, ∀t ∈T (21) As restrições (22) relacionam a variável de armazenamento y (associada ao período de tempo) com a variável de armazenamento y, que é independente do tempo. A restrição (23) ga- rante que dois dados conflitantes não sejam colocados no mesmo dispositivo (conflito hard). Da mesma forma, as desigualdades (24) garantem que se dois dados conflitantes forem armazenados no mesmo dispositivo, a variável de penalidade w equivalente seja atribuída ao valor 1 (conflito soft). As restrições (25) medem o nível de exposição, ou seja, o risco de se executar uma ativação ao considerar os requisitos de segurança. ydjt ≤ydj , ∀d ∈D, ∀j ∈M, ∀t ∈T (22) yd1j + yd2j ≤1 , ∀(d1, d2) ∈Eh, ∀j ∈M (23) yd1j + yd2j ≤1 + wd1d2 , ∀(d1, d2) ∈Es, ∀j ∈M (24) lri task − X j∈M X t∈T lrj vmxijt ≤eri , ∀i ∈N, ∀r ∈R (25) X l∈Lj qjl = X d∈D ydjW(d) , ∀j ∈B (26) X l∈Lj bjl = 1 , ∀j ∈B (27) X d∈D ydjW(d) ≤ X l∈Lj smjlbjl , ∀j ∈B (28) smj(l−1).bjl ≤qjl ≤smjl.bjl , ∀j ∈B, ∀l ∈Lj\\{0} (29) bjl ≤ X d∈D ydj , ∀j ∈B, ∀l ∈Lj\\{0} (30) A equação (26) calcula o volume dos dados armazenados em um mesmo bucket. As restrições (27) determinam os intervalos de armazenamentos l ∈Lj de cada bucket j ∈B, enquanto que as restrições (28) restringem os tamanhos de armazenamentos utilizados no buckets. Por sua https://proceedings.science/p/193619?lang=pt-br DOI: 10.59254/sbpo-2024-193619 vez, as restrições (27) e (29) garantem o uso adequado dos intervalos de armazenamento (bjl) de acordo com o volume total dos dados no bucket (qjl). Por fim, as restrições (30) impõem que, se um intervalo l ∈Lj\\{0} do bucket j ∈B estiver ativo, deve existir pelo menos algum dado associado ao bucket j. 4. Heurística Proposta A execução de workflows com restrições de confidencialidade, conforme a abordagem CYCLOPS descrita na Seção 3, pode ser planejada usando métodos exatos apenas para workflows de pequena escala, geralmente com menos de 15 ativações. Para workflows maiores, como os encon- trados no mundo real, métodos exatos tornam-se impraticáveis devido ao alto consumo de recursos computacionais e ao tempo de processamento. Em contrapartida, heurísticas e metaheurísticas ofe- recem alternativas eficazes e viáveis para resolver problemas complexos de otimização. Nesta seção, apresentamos uma heurística construtiva gulosa-aleatória denominada CYCLOPS-GRCH, projetada para escalonar as ativações de workflows com restrições de confidencialidade. Algorithm 1: CYCLOPS-GRCH Data: θRCL, β Result: schedule S 1 Record { 2 integer actindex, vmindex; 3 List of Indexes res; 4 float ofvalue; 5 } CandList; 6 S ←∅; N ←N; 7 while N ̸= ∅do 8 CandListtemp ←new(CandList); CandList ←new(CandList); CandListrestricted ← new(CandList); 9 foreach i ∈N do 10 foreach j ∈M do 11 if Gen(∆in(i)) then 12 OFvalue ←CalcOF (S, i, j); W ←EstRes(S, i, j, β) ; 13 CandListtemp.actindex ←i; CandListtemp.vmindex ←j; CandListtemp.res ←W; CandListtemp.ofvalue ←OFvalue; 14 CandList ←CandList ∪CandListtemp; 15 end 16 end 17 end 18 sort(CandList); 19 CandListrestricted ←GenRCL(CandList, θRCL); 20 (i∗, j∗, W ∗) ←draw(CandListrestricted); 21 S ←S ∪(i∗, j∗, W ∗); 22 N ←N\\{i∗}; 23 end O Algoritmo 1 apresenta o procedimento CYCLOPS-GRCH. Este algoritmo garante uma solução viável respeitando a precedência entre as ativações, ou seja, uma ativação só é escalonada quando os seus dados de entrada estão disponíveis. O loop mais externo (linha 7) itera até que todas as ativações do workflow sejam executadas em alguma MV. O algoritmo verifica se os dados necessários estão disponíveis para executar a ativação i ∈N numa MV j ∈M, usando a função Gen() (linha 11). Em seguida, calcula o custo de escalonar esta atividade na MV, utilizando a função CalcOF . Este custo é definido pelas Equações (1 - 3). Adicionalmente, a heurística estima os dispositivos W ⊆M que irão armazenar os dados de saída da ativação i (função EstRes()) da seguinte maneira: para todo dado d ∈∆out(i), o método seleciona aleatoriamente β dispositivos de M e, dentre eles, seleciona aquele com o menor custo na função objetivo que não viole restrições de capacidade e confidencialidade. O algoritmo então gera uma lista de atribuições atividade/MV https://proceedings.science/p/193619?lang=pt-br DOI: 10.59254/sbpo-2024-193619 candidatas (CandList) (linha 14), ordenando-as (de forma crescente) com base no valor ofvalue da função objetivo (linha 18) e cria uma Lista de Candidatos Restrita (CandListrestricted), usando o parâmetro θRCL, contendo os melhores candidatos (linha 19). Um candidato é escolhido aleatori- amente da CandListrestricted e adicionado à solução corrente S (linhas 20 e 21). Este processo é repetido até que todas as ativações do workflow estejam escalonadas para execução. Devido à na- tureza estocástica do CYCLOPS-GRCH, diferentes soluções são encontradas para os mesmos dados de entrada, o que justifica a execução do algoritmo 100 vezes para selecionar o melhor resultado entre todas as execuções. 5. Avaliação Experimental Preliminar Para testar a capacidade da abordagem, realizamos dois conjuntos de testes: (i) uma comparação entre a heurística CYCLOPS-GRCH e o método exato usando 6 pequenas instancias sintéticas, e (ii) uma avaliação do desempenho da heurística usando 3 workflows do mundo real. A Tabela 1 apresenta as especificações das instâncias utilizadas, onde, #Act. indica o número de ativações e #Arq. o número de arquivos (dados). As especificações de tmax e cmax, foram definidas empiricamente de forma garantir que ultrapassem os maiores makespans e custos financeiros encon- trados em testes preliminares. Nesses experimentos, os grafos de conflitos foram gerados por um script que avaliou os workflows e determinou as restrições para os dados usando as seguintes regras: arquivos de entrada e saída de uma mesma ativação não podem ser armazenados juntos (restrição hard) (i); arquivos de saída de ativações irmãs (mesmo nível no grafo) não devem ser armazenados juntos (restrição soft), e caso isso ocorra, o valor 1 de penalidade é aplicado para cada conflito entre 2 arquivos (ii). Ambos os métodos (heurístico e exato) foram implementados usando GCC 11.4.0 e IBM ILOG CPLEX 22.1.1.0, e executados em um PC Intel i7-10870H 4.80 GHz com 16GB RAM. Instância Sintética #Act. #Arq. tmax cmax Instância Real #Act. #Arq. tmax cmax Sintético 005 A 2 3 50 120 Montage 025 25 54 250 125 Sintético 005 B 2 3 100 120 Montage 050 50 107 500 250 Sintético 005 C 1 4 200 80 Montage 100 100 215 1.000 500 Sintético 010 A 4 6 170 168 Sintético 010 B 3 7 75 198 Sintético 010 C 4 6 300 440 Tabela 1: Características das instâncias de workflows sintéticas e reais 5.1. Instancias Sintéticas Considerando a impraticabilidade da solução exata para instâncias reais, foram criadas 6 pequenas instâncias sintéticas de workflows, permitindo assim a comparação da heurística com o método exato. Neste primeiro teste, para os parâmetros de entrada, optou-se pelo balanceamento dos objetivos, usando αt = 0.3, αb = 0.3 e αs = 0.4, com uma pequena prevalência para a confidencialidade dos dados. Para os parâmetros da heurística, testes empíricos foram realizados e os valores θLRC = 0.5 e β = 4 foram obtidos. Como configuração do cenário de dispositivos para este experimento, foram empregadas 4 MVs, com base na Tabela 2, uma de cada tipo disponível e todas com capacidade de criptografia de nível 1. Além disso, foram utilizados 2 buckets como dispositivos unicamente de armazenamento. Os valores Slowdown e Rede (Gbps) na Tabela 2 são utilizados para calcular os tempos de execução, escrita e leitura de cada par ativação/máquina como descritos em Teylo et al. [2017]. A Tabela 3 mostra os resultados para as instancias sintéticas, onde F.O. representa a Função Objetivo, Mks o Makespan em segundos, US$ o custo em dólares, Conf. a penalidade https://proceedings.science/p/193619?lang=pt-br DOI: 10.59254/sbpo-2024-193619 Tipo Disco (GB) Slowdown Rede (Gbps) Custo (US$) Criptografia MV1 80 1.53 4 0.02 1 ou 0 MV2 120 0.77 9 0.09 1 ou 0 MV3 160 0.38 10 0.16 1 ou 0 MV4 200 0.19 10 0.33 1 ou 0 Bucket 51200 - 25 0.023 - Tabela 2: Características das máquinas virtuais e dos Buckets utilizados na nuvem Heurística (CYCLOPS-GCH) Solução Exata Workflow F. O. Mks (s) US$ Conf. T (s) F. O. Mks (s) US$ Conf. T (s) Sintético 005 A 0,110 10,00 < 0, 01 0,13 < 0, 01 0,108 18,00 < 0, 01 0,00 35,27 Sintético 005 B 0,140 17,00 < 0, 01 0,22 < 0, 01 0,140 17,00 < 0, 01 0,22 568,45 Sintético 005 C 0,107 27,00 < 0, 01 0,17 < 0, 01 0,107 27,00 < 0, 01 0,17 73,16 Sintético 010 A 0,097 40,00 < 0, 01 0,07 < 0, 01 - - - - 3.772,37 Sintético 010 B 0,156 19,00 < 0, 01 0,20 < 0, 01 0,156 19,00 < 0.01 0.20 805,87 Sintético 010 C 0,126 59,00 < 0, 01 0,17 < 0, 01 - - - - 3.870,39 Tabela 3: Avaliação Experimental - CYCLOPS-GCH Versus Solução Exata de confidencialidade dos dados e T o tempo em segundos que o método levou para gerar a solução. Vale destacar que a coluna Conf. foi normalizada para facilitar a compreensão dos dados. O mo- delo matemático obteve soluções garantidamente ótimas para a maioria dos workflows sintéticos, excetuando a última e antepenúltima, devido ao tempo limite de 1 hora imposto ao CPLEX. En- quanto isso, a heurística produziu soluções satisfatórias, desempenhando 0,004% a mais de função objetivo na média em relação ao método exato. A diferença de desempenho entre as abordagem se devem, possivelmente, devido à execução atômica das ativações (leitura, processamento e escrita) da heurística em comparação com o método exato. Este último permite que leituras e escritas de dados ocorram desacopladas do processamento, otimizando assim as alocações das MVs. Porém, as conclusões mais importantes são os tempos de execuções do CYCLOPS-GRCH, que foram signifi- cativamente menores do que os do CPLEX, e os valores de confidencialidade baixos, demonstrando assim a eficácia da abordagem proposta. 5.2. Instâncias do Mundo Real O CYCLOPS-GRCH foi aplicado ao workflow do mundo real denominado Montage [Juve et al., 2013], utilizado para criar imagens mosaico a partir de fotografias astronômicas. Foram consideradas 3 variantes do Montage, onde cada uma possui diferentes quantidades de ativações. Neste experimento, vários cenários foram criados ajustando-se os pesos da função objetivo, são eles: Cenário 1 - Ênfase na redução do makespan - αt = 1, αb = 0, αs = 0 (i); Cenário 2 - Ênfase na redução dos custos financeiros - αt = 0, αb = 1, αs = 0 (ii); Cenário 3 - Ênfase na redução das penalidades de confidencialidade - αt = 0, αb = 0, αs = 1 (iii); Cenário 4 - Objetivos balanceados - αt = 0.33, αb = 0.33, αs = 0.33 (iv). Com base na Tabela 2, foram empregados 1 site com 4 MVs, uma de cada tipo, sendo as duas primeiras com capacidade de criptografia nível 1 e as demais sem criptografia (nível 0). Como todas as ativações foram definidas como tendo necessidade por criptografia, uma penalidade de 1 foi atribuída para cada ativação associada às MVs sem criptografia. Além disso, foram utilizados 16 buckets como dispositivos de apenas armazenamento. Diferentemente do método exato, a heurística conseguiu encontrar soluções viáveis para todas as instâncias de workflows do mundo real em menos de 20 segundos. Optou-se por usar https://proceedings.science/p/193619?lang=pt-br DOI: 10.59254/sbpo-2024-193619 Figura 1: GRCH Vs HEFT (Makespan) Figura 2: GRCH Vs HEFT (Custo) o HEFT [Topcuoglu et al., 2002] como referência para comparar os resultados obtidos com o CYCLOPS-GRCH. Embora o HEFT não aborde confidencialidade, é amplamente utilizado como algoritmo de escalonamento devido à sua capacidade de gerar soluções eficazes para workflows complexos em ambientes heterogêneos. A Figura 1 apresenta o makespan das heurísticas. Pode-se observar que o método CYCLOPS-GRCH atinge melhores resultados que o HEFT quando o makes- pan foi priorizado ou quando os objetivos estão balanceados. Como esperado, ao priorizar custo ou confidencialidade, o makespan aumentou. A Figura 2 apresenta o custo das heurísticas. Pode-se ob- servar que em todos os casos a CYCLOPS-GRCH obteve melhores resultados em relação ao HEFT, uma vez que esta heurística foca exclusivamente no makespan. A Figura 3 apresenta as penalidades de confidencialidade das heurísticas. Observa-se que em todos os casos a CYCLOPS-GRCH obteve melhores resultados em relação ao HEFT. Vale notar que a ênfase dada na confidencialidade foi capaz de zerar as penalidades em todas as instâncias deste experimento. De modo geral, a ênfase no makespan teve resultados bem parecidos que os dos objetivos balanceados, o motivo para isso se dá pela maior variabilidade dos valores de makespan das soluções, portanto, esta característica acaba se sobressaindo quando igualamos a importância dos objetivos. 6. Conclusões Muitas aplicações usam workflows de big data, onde dados sensíveis são gerados e ar- mazenados em buckets na nuvem, aumentando o risco de comprometer a confidencialidade. Este artigo aborda a execução eficiente de workflows com restrições de confidencialidade, propondo abordagens exatas e heurísticas, que integram o escalonamento das ativações com as restrições de confidencialidade e o plano de dispersão de dados. Avaliamos nossa abordagem usando instâncias de workflows sintéticos e reais, obtendo resultados promissores para garantir a confidencialidade e minimizar custos. Como próximo passo, planejamos evoluir a heurística proposta com a inclusão de métodos de perturbações e buscas locais, abordando vários outros workflows do mundo real."
        },
        {
            "titulo": "Otimização Multiobjetivo Para o Problema de Seleção de Fornecedores e Compra de Materiais Hospitalares",
            "informacoes_url": "https://proceedings.science/p/193655?lang=pt-br",
            "idioma": "português",
            "storage_key": "galoa-proceedings--sbpo-2024--193655.pdf",
            "autores": [
                {
                    "nome": "Gabriel Vinicius Bacci",
                    "afiliacao": "Instituto de Ciências Matemáticas e de Computação (ICMC), Universidade de São Paulo",
                    "orcid": ""
                },
                {
                    "nome": "Artur Lovato Cunha",
                    "afiliacao": "Preditiva Tecnologia da Informação",
                    "orcid": ""
                },
                {
                    "nome": "Maristela Oliveira Santos",
                    "afiliacao": "Instituto de Ciências Matemáticas e de Computação (ICMC), Universidade de São Paulo",
                    "orcid": ""
                }
            ],
            "data_publicacao": "",
            "resumo": "Neste artigo é proposto um método para auxiliar na gestão de compras de insumos hospitalares, utilizados pelo centro cirúrgico de um hospital. Sendo eles medicamentos e insumos descartáveis. Os insumos são fornecidos por diferentes fornecedores, cada um oferecendo um conjunto específico de itens necessários para atender à demanda do hospital. Neste problema, busca-se minimizar os recursos financeiros gastos na aquisição dos itens, ao mesmo tempo em que se tenta utilizar o menor número possível de fornecedores. Objetivos que são conflitantes, não havendo uma solução única que os otimize simultaneamente. Um modelo de otimização inteira biobjetivo é proposto e utilizou o método epsilon-restrito para obter a fronteira de Pareto aproximada. Nos testes computacionais, foram utilizados dados reais de um hospital do interior de SP combinados com informações coletadas da internet. Nas análises realizadas, são mostrados os trade-offs entre o número de fornecedores e os custos dos insumos.",
            "keywords": [
                "Gestão Hospitalar",
                "Otimização Inteira Multiobjetivo",
                "Método Epsilon-Restricto"
            ],
            "referencias": [
                "Aliano Filho, A. (2016). Novas Extensões de Técnicas de Escalarizações no Problema de Corte Unidimensional Inteiro Multiobjetivo. PhD thesis, Instituto de Matemática, Estatística e Computação Científica, Universidade Estadual de Campinas.",
                "Andreoli, G. L. M. e Dias, C. N. (2015). Planejamento e gestão logística de medicamentos em uma central de abastecimento farmacêutico hospitalar. RAHIS- Revista de Administração Hospitalar e Inovação em Saúde.",
                "Cardoen, B., Belloen, J., e Vanhoucke, M. (2015). On the design of custom packs: grouping of medical disposable items for surgeries. International Journal of Production Research, 53(24): 7343–7359.",
                "Cardoso, A. A. B., Souza, L. M., Reis, A. d. O., e Palha, V. M. (2020). Gestão de custos em organizações hospitalares: sistemática por centro de custos. Semina: Ciências Sociais e Humanas, 41 (1):123–138.",
                "da Silva Mundim, A. A. (2024). Roteamento de Estoque e Transporte de Carga Multimodal: Otimização Bi-objetivo com Considerações Ambientais e Econômicas. PhD thesis, Programa de Pós-Graduação em Ciências de Computação e Matemática Computacional (PPG-CCMC).",
                "de Medicamentos Equivalentes, L. (2024). Guia de equivalentes: consulta de medicamentos similares equivalentes. https://guiadeequivalentes.com.br. Acesso em: 12 de abril de 2024.",
                "Dias, L. L. B., Santos, M. O. d., Okano, E. Y., e Nascimento, M. C. V. (2021). Modelo matemático para a determinação de kits cirúrgicos padronizados. Anais Simpósio Brasileiro de Pesquisa Operacional(SBPO).",
                "Garcia, S. D., Haddad, M. C. L., Dellaroza, M. S. G., Costa, D. B., e Miranda, J. M. (2012). Gestão de material médico-hospitalar e o processo de trabalho em um hospital público. Revista Brasileira de Enfermagem, 65(2).",
                "Haimes, Y. Y., Lasdon, L. S., e Wismer, D. A. (1971). On a bicriterion formulation of the problems of integrated system identification and system optimization. IEEE Transactions on Systems.",
                "Javadi, M., Lotfi, M., Osorio, G. J., Ashraf, A. E., Nezhad, A. E., Gough, M., e Catalao, J. P. (2020). A multi-objective model for home energy management system self-scheduling using the epsilon-constraint method. In IEEE 14th International Conference on Compatibility, Power Electronics and Power Engineering (CPE-POWERENG), p. 175–180.",
                "Lingg, M., Wyss, K., e Durán-Arenas, L. (2016). Effects of procurement practices on quality of medical device or service received: a qualitative study comparing countries. BMC Health Services Research, 16(1):362.",
                "Maria, J. e Loureiro, S. A. (2010). Gestão de estoques: implantação de revisão da política de estoques na farmácia do centro cirúrgico. Laboratório de Aprendizagem em Logística e Transportes, Faculdade de Engenharia Civil, Arquitetura e Urbanismo, Universidade Estadual de Campinas.",
                "Martins, P. G. e Alt, P. R. C. (2000). Administração de materiais e recursos patrimoniais. Saraiva.",
                "Oliveira, C. (2017). Gestão de estoques a partir da lista de materiais (bill of materials): o caso de um hospital universitário. PhD thesis, Trabalho de conclusão de graduação da Escola de Engenharia da Universidade Federal do Rio Grande do Sul.",
                "Paschoal, M. L. H. e Castilho, V. (2010). Consumo de materiais em centro cirúrgico após implementação de sistema de gestão informatizado. Revista Brasileira de Enfermagem, 63:887 – 893. ISSN 0034-7167.",
                "Paulus Júnior, A. (2005). Gerenciamento de recursos materiais em unidades de saúde. Revista Espaço para a Saúde, 7(1):30–45.",
                "Remédios, C. (2024). Consulta remédios: compre online nas farmácias de todo Brasil. https://consultaremedios.com.br. Acesso em: 12 de abril de 2024.",
                "Shariatzadeh, M., Antunes, C. H., e Lopes, M. A. R. (2023). Bi-objective optimization of ev charging in a workplace parking lot. In 2023 International Conference on Smart Energy Systems and Technologies (SEST), p. 1–6."
            ],
            "artigo_completo": "Otimização Multiobjetivo Para o Problema de Seleção de Fornecedores e Compra de Materiais Hospitalares. RESUMO Neste artigo é proposto um método para auxiliar na gestão de compras de insumos hos- pitalares, utilizados pelo centro cirúrgico de um hospital. Sendo eles medicamentos e insumos descartáveis. Os insumos são fornecidos por diferentes fornecedores, cada um oferecendo um con- junto específico de itens necessários para atender à demanda do hospital. Neste problema, busca-se minimizar os recursos financeiros gastos na aquisição dos itens, ao mesmo tempo em que se tenta utilizar o menor número possível de fornecedores. Objetivos que são conflitantes, não havendo uma solução única que os otimize simultaneamente. Um modelo de otimização inteira biobjetivo é proposto e utilizou o método epsilon-restrito para obter a fronteira de Pareto aproximada. Nos testes computacionais, foram utilizados dados reais de um hospital do interior de SP combinados com informações coletadas da internet. Nas análises realizadas, são mostrados os trade-offs entre o número de fornecedores e os custos dos insumos. PALAVRAS CHAVE. Gestão Hospitalar, Otimização Inteira Multiobjetivo, Método Epsilon- Restrito. Tópicos PM – Programação Matemática, SA – PO na Área de Saúde https://proceedings.science/p/193655?lang=pt-br DOI: 10.59254/sbpo-2024-193655 1. Introdução Os hospitais são entidades que mais consomem os recursos destinados à saúde Cardoen et al. [2015]. O setor cirúrgico é o que representa maiores gastos em um hospital. Segundo Maria e Loureiro [2010], uma gestão adequada de estoque dos itens utilizados pelo centro cirúrgico pode reduzir de forma significativa os custos hospitalares. Nesse sentido, podemos encontrar na literatura trabalhos que propõem uma abordagem para gerenciar melhor o abastecimento hospitalar, buscando um melhor controle de estoque, ou a redução total dos custos, como Paschoal e Castilho [2010], Oliveira [2017] e Cardoso et al. [2020]. A administração dos recursos materiais engloba a sequência de operações que tem seu início na identificação do fornecedor Martins e Alt [2000]. Segundo Paulus Júnior [2005], uma uni- dade de gerenciamento de materiais em hospitais deve visar, entre outros fatores, ter conhecimento sobre o mercado e os fornecedores disponíveis. Determinar quais fornecedores serão utilizados para atender a demanda de um hospital, bem como seu processo de contratação, geralmente não é uma tarefa simples, conforme destacado por Lingg et al. [2016] e Andreoli e Dias [2015]. Além disso, esse processo de aquisição pode influenciar de forma significativa o trabalho dos profissionais que atuam nessa área, como investigado por Garcia et al. [2012]. Neste estudo, o processo de aquisição de insumos, abrangendo múltiplos períodos, bem como a seleção de fornecedores que serão contratados pelo hospital, é abordado como um Problema de Otimização Multiobjetivo (POM). Será proposto um modelo biobjetivo para este problema, com o objetivo de encontrar um equilíbrio entre os recursos financeiros despendidos na aquisição e ar- mazenamento dos itens e a quantidade de fornecedores utilizados. Para escalarizar o POM abordado e obter seu conjunto de soluções eficientes é utilizado o método do epsilon-restrito, como visto por Aliano Filho [2016]. Na literatura, existem estudos que utilizam este método para obter o conjunto eficiente de soluções de um POM com duas funções objetivo, como Shariatzadeh et al. [2023], Javadi et al. [2020] e da Silva Mundim [2024]. Devido à natureza potencialmente conflitante do POM considerado, o método proposto permitirá a análise do trade-off entre os objetivos, auxiliando assim o tomador de decisão a identificar a solução eficiente que melhor atenda às suas necessidades. Este trabalho está organizado da seguinte maneira. Na Seção 2, será descrito o problema abordado neste trabalho. Na Seção 3 será descrita a modelagem do problema, apresentando o modelo elaborado e detalhando os parâmetros, variáveis, funções objetivos e restrições utilizadas pelo mesmo. A Seção 4 descreve como o método do epsilon-restrito foi aplicado para encontrar o conjunto de soluções eficientes, geradas pelo modelo. Na Seção 5 é apresentado os testes computa- cionais realizados. Por fim, a Seção 6 apresenta as conclusões obtidas. 2. Descrição do Problema O problema proposto consiste em determinar quais itens serão comprados em cada pe- ríodo considerado. Isso inclui a possibilidade de estocar itens para utilizá-los em períodos posteri- ores, visando atender toda a demanda do setor cirúrgico do hospital para a realização de cirurgias de diversos procedimentos cirúrgicos. Os itens considerados podem ser divididos em duas clas- ses, sendo elas \"Drogas/Medicamentos\"e \"Materiais hospitalares\". Cada item pertencente à classe “Drogas/Medicamentos” possui um princípio ativo, que é responsável pelo seu efeito farmacoló- gico. Itens com o mesmo principio ativo podem ser usados como substitutos entre si. Para os itens da classe \"Materiais hospitalares\", considera-se que seu princípio ativo é o próprio item. Estes in- sumos, são fornecidos por uma variedade de fornecedores, cada uma disponibilizando um conjunto específico de itens. Cada fornecedor estabelece um valor mínimo de venda, denominado carrinho mínimo, tornando a aquisição viável somente se o valor total dos itens, adquiridos deste fornecedor, atender https://proceedings.science/p/193655?lang=pt-br DOI: 10.59254/sbpo-2024-193655 ou exceder esse limite. Frequentemente, para atender à demanda do centro cirúrgico, o hospital precisa adquirir itens de múltiplos fornecedores. Consequentemente, o processo de contratação se torna progressivamente mais complexo à medida que o número de fornecedores utilizados aumenta, especialmente em contextos de recursos públicos. Diante deste cenário, o objetivo é encontrar alternativas que permitam minimizar tanto a quantidade de recursos despendidos na aquisição e armazenamento de itens quanto o número de fornecedores utilizados. 3. Modelagem do problema É considerado que todo item, possui um principio ativo i. Todo item com princípio ativo i pode ser substituído por outro com o mesmo princípio ativo, incluindo ele mesmo, conforme ilustrado na Figura 1. Por conveniência, o princípio ativo i é chamado de item i, e o item que o representa é designado como item alternativo a. Por exemplo, no contexto de um centro cirúrgico, se houver dois itens com o mesmo princípio ativo (a e b), ambos podem ser usados com resultados equivalentes, como ilustrado pela Figura 2. No entanto, seus custos e unidades podem ser distintos. Figura 1: Ilustrando a possibilidade de itens alternativos Figura 2: Ilustrando a possibilidade de itens alternativos O modelo proposto nesta etapa aborda o planejamento para aquisição de itens ao longo de um horizonte composto por múltiplos períodos. Adicionalmente, são levados em consideração diversos fornecedores, juntamente com seus requisitos de compra mínima (carrinho mínimo) e as embalagens de itens que oferecem. É importante ressaltar que um único item pode ser disponibili- zado por diversos fornecedores distintos. https://proceedings.science/p/193655?lang=pt-br DOI: 10.59254/sbpo-2024-193655 3.1. Parâmetros e Variáveis Na modelagem proposta, o parâmetro I representa o conjunto de itens cirúrgicos i consi- derados. O parâmetro Ai representa um conjunto de itens alternativos a que podem substituir o item i. O parâmetro F representa o conjunto de fornecedores f disponíveis e T o conjunto de períodos t considerados. O parâmetro H simboliza o número máximo de itens alternativos a permitidos para o mesmo item i. ca f representa o respectivo custo de compra um item alternativo a do fornecedor f e pa f simboliza quantos itens alternativos a, a caixa do fornecedor f, contém. βa, representa o custo de armazenamento de um item a. Bf simboliza o valor mínimo de compra de um fornecedor f. Dit, expressa quantos itens i são necessários para um período t. Por fim, M expressa um número suficientemente grande. Além disso, foi necessário o uso do parâmetro auxiliar δa if que indica se um item alternativo a para o item i é fornecido pelo fornecedor f, valendo 1 em caso afirmativo e 0 caso contrário. A variável inteira xa ift representa o número de caixas de itens alternativos a, para um determinado item i, comprados do fornecedor f em um período t. A variável inteira Ea it simboliza o número de itens alternativos a, para um item i, em estoque, no final do período t. A variável binária sft é usada para indicar se algum item do fornecedor f foi comprado no período t. A variável binária hia verifica se um item alternativo a é usado como alternativo para o item i. Por fim, a variável binária yf é usada para indicar se o fornecedor f foi selecionado ou não. Um resumo dos parâmetros e variáveis descritas é apresentado na Tabela 1. Tabela 1: Parâmetros e variáveis para o modelo. Parâmetros I Conjunto de itens, i ∈I. F Conjunto de fornecedores, f ∈F. T Conjunto de períodos, t ∈T. Ai Conjunto de itens alternativos a para o item i, a ∈Ai. H Número máximo de itens alternativos a permitidos para o item i. Bf Valor mínimo de compra para o fornecedor f. ca f Custo associado a compra de uma caixa do item alternativo a, fornecido pelo fornecedor f. pa f Quantidade de itens alternativos a presentes na caixa fornecida pelo fornecedor f. βa Custo de estocar uma unidade do item alternativo a. δa if 1, se o item alternativo a para o item i é vendido pelo fornecedor f. 0, caso contrário. M Número suficientemente grande. Dit Demanda do item i o período t. Variáveis ha i 1, se o item alternativo a é usado para representar o item i. 0, caso contrário. yf 1, se o fornecedor f é selecionado. 0, caso contrário. sft 1, se algum item do fornecedor f é comprado no período t. 0, caso contrário. xa ift Caixas de itens alternativos a para o item i comprados do fornecedor f no período t. Ea it Quantidade de itens alternativos a para o item i em estoque, no final do período t. 3.2. Modelo Elaborado Minimizar FCT = X a X i X f X t (ca fxa ift) + X a X i X t (βaEa it) (1) Minimizar FFC = X f yf (2) https://proceedings.science/p/193655?lang=pt-br DOI: 10.59254/sbpo-2024-193655 Sujeito a: X a X i|δa if=1 (ca fxa ift) ≥Bfsft ∀f ∈F, ∀t ∈T (3) xa ift ≤Mha i ∀a ∈Ai, ∀i ∈I, ∀f ∈F, ∀t ∈T (4) xa ift ≤Msft ∀a ∈Ai, ∀i ∈I, ∀f ∈F, ∀t ∈T (5) P a ha i ≤H ∀i ∈I (6) sft ≤yf ∀f ∈F, ∀t ∈T (7) X a Ea it−1 + X a X f|δa if=1 pa fxa ift − X a Ea it = Dit ∀i ∈I, ∀t ∈T (8) xa ift ∈N ∀a ∈Ai, ∀i ∈I, ∀f ∈F, ∀t ∈T (9) Ea it ∈N ∀a ∈Ai, ∀i ∈I, ∀t ∈T (10) ha i ∈{0, 1} ∀a ∈Ai, ∀i ∈I (11) sft ∈{0, 1} ∀f ∈F, ∀t ∈T (12) yf ∈{0, 1} ∀f ∈F (13) A função objetivo (1) minimiza o custo de compra e estoque dos itens, enquanto (2) mini- miza o número de fornecedores utilizados. As restrições (3) garantem que os itens sejam adquiridos apenas de fornecedores que podem fornecê-los e cujos preços atinjam o mínimo de compra. As restrições (4) asseguram que um item alternativo a só possa ser adquirido se for viável como subs- tituto para o item i. As restrições (5) garantem que um item alternativo a só possa ser adquirido de um fornecedor f se este puder fornecer algum item no período t. As restrições (6) limitam o número máximo de tipos de itens alternativos a distintos para o item i. As restrições (7) garantem que só sejam comprados itens de fornecedores válidos. As restrições (8) asseguram que a demanda necessária do item i para o período t seja atendida. As restrições (9) - (13) são de domínios das variáveis. 4. Método epsilon-restrito O método epsilon-restrito foi proposto por Haimes et al. [1971] e pode ser de grande ajuda para resolver problemas de otimização multiobjetivo. Mais detalhes sobre o método, principalmente para o caso biobjetivo, podem ser encontrados em Aliano Filho [2016]. Neste artigo, a função FCT foi escolhida como função-objetivo para o subproblema res- trito, e a função FFC foi escolhida como restrição, pois seu valor objetivo só assume valores inteiros e sua amplitude é consideravelmente menor, se comparada a FCT . O problema restrito é definido a seguir, onde ρ > 0: Minimizar FCT + ρ · FFC Sujeito a: FFC < ϵ (3) −(12) (14) O parâmetro ρ é um pequeno valor positivo que é adicionado à função objetivo para dar uma pequena prioridade à minimização do número de fornecedores utilizados, permitindo assim encontrar o conjunto de soluções eficientes do nosso problema. Como FFC toma apenas valores inteiros num intervalo fechado, é razoável considerar ϵ variando no intervalo I = [LFC, UFC], onde LFC e UFC é o menor e o maior valor que FFC https://proceedings.science/p/193655?lang=pt-br DOI: 10.59254/sbpo-2024-193655 pode assumir, respectivamente, para garantir que todas as soluções eficientes sejam obtidas. Uma nova solução eficiente é obtida, resolvendo o problema 14, para cada valor de ϵ no intervalo I. Primeiro, é necessário calcular os pontos lexicográficos LFC e UFC, resolvendo, respec- tivamente, 15 e 16, obtendo assim duas soluções eficientes. Logo após, será resolvido a sequência de subproblemas restritos, iniciando com ϵ = LFC + δ, incrementando-o de δ unidades até que atinja ϵ = UFC −δ, valor máximo de I. Minimizar FCT + ρ · FFC Sujeito a: (3) −(12) (15) Minimizar FFC + ρ · FCT Sujeito a: (3) −(12) (16) 5. Testes Computacionais 5.1. Dados Utilizados Para testar o modelo proposto, foi utilizada uma base de dados fornecida pela Santa Casa de São Carlos, SP, complementada com dados coletados dos sites de Medicamentos Equivalentes [2024] e Remédios [2024]. Detalhes adicionais sobre a base de dados e os sites utilizados serão apresentados, respectivamente, nas Subseções 5.1.1 e 5.1.2. A partir desses dados, foram elaboradas 12 instâncias para testar o modelo, conforme descrito na Subseção 5.1.3. 5.1.1. Base de Dados A base de dados utilizada refere-se às movimentações farmacêuticas do centro cirúrgico, contendo informações sobre mais de 2200 itens, abrangendo mais de 13 mil cirurgias e 897 tipos de procedimentos cirúrgicos. A análise dos dados revelou que um número limitado de tipos de procedimentos representa uma parcela significativa do volume total de cirurgias realizadas, sendo que os 20 procedimentos mais frequentes correspondem a 50% do volume total de cirurgias. Os itens considerados para determinar a demanda foram aqueles com uma taxa de uso de pelo menos 30% nos procedimentos considerados, resultando em um total de 228 itens. Além disso, a base de dados inclui informações sobre as datas de realização das cirurgias, que variam de 1º de janeiro de 2017 a 12 de junho de 2018. Para os testes, foi utilizado um período de uma semana, extraindo-se 10 períodos de teste, começando em 1º de janeiro e terminando em 12 de março de 2017, totalizando aproximadamente dois meses e meio. Com base na utilização dos 228 itens determinados, foi determinada a demanda de cada um deles para cada período. Esses dados também foram utilizados em Dias et al. [2021]. 5.1.2. Coleta de Dados A base de dados mencionada na Subseção 5.1.1 não contém informações sobre custos dos insumos, fornecedores e alternativas dos itens selecionados. Para contornar essa limitação, foram desenvolvidos dois programas utilizando a linguagem de programação Python. O primeiro pro- grama tem como objetivo encontrar itens alternativos para os 228 itens previamente identificados, utilizando o site de Medicamentos Equivalentes [2024]. O segundo programa busca identificar for- necedores, bem como seus respectivos custos e tamanhos de embalagens, para os itens alternativos encontrados pelo primeiro programa, utilizando o site Remédios [2024]. Após todas as análises, foram identificados 405 itens alternativos para os 228 itens iniciais. Para 146 itens, não foi possível encontrar alternativas além do próprio item original; para 44 itens, foi encontrada 1 alternativa; para 8 itens, foram encontradas 2 alternativas; para 3 itens, foram encontradas 3 alternativas; e para 27 itens, foram encontradas 4 alternativas. O segundo programa identificou 30 fornecedores que fornecem pelo menos um dos itens alternativos obtidos. https://proceedings.science/p/193655?lang=pt-br DOI: 10.59254/sbpo-2024-193655 5.1.3. Instâncias Com base nos dados descritos na Subseção 5.1, foram elaboradas 12 instâncias para os experimentos computacionais, variando o número de itens, fornecedores e períodos. Os itens con- siderados podem ser os 100 primeiros ou todos os 228 obtidos. Os períodos são os primeiros 4 (aproximadamente 1 mês) ou todos os 10 (aproximadamente 2 meses e meio). Os fornecedores podem ser os primeiros 10, 20 ou todos os 30. Mais detalhes são apresentados na Tabela 2. Tabela 2: Descrição das instâncias. Instância Fornecedores(F) Itens(I) Itens alternativos totais(Ai) Períodos(T) 1 10 100 181 4 2 10 100 181 10 3 10 228 405 4 4 10 228 405 10 5 20 100 181 4 6 20 100 181 10 7 20 228 405 4 8 20 228 405 10 9 30 100 181 4 10 30 100 181 10 11 30 228 405 4 12 30 228 405 10 5.2. Ambiente de Teste Os testes foram realizados em um computador com processador Intel Core i7-2600 CPU (3.40GHz) e 16.0GB de memória RAM, sob o sistema operacional Windows 10. O modelo foi implementado em Python, utilizando o solver Gurobi 10.0.2, acessado via licença acadêmica. 5.3. Resultados Obtidos Nesta Seção será apresentado os resultados dos experimentos computacionais realizados. O objetivo é demonstrar a eficiência do método epsilon-restrito (Seção 4) ao calcular e analisar o trade-off entre as soluções eficientes (Seção 3). Inicialmente, os pontos lexicográficos de cada instância foram calculados com um limite de tempo de 3 horas. O solver encontrou a solução comprovadamente ótima, de ambos os pontos, apenas para a instância 1. Porém, o gap encontrado pelo solver para as instâncias foi, no pior dos casos, inferior a 5%. O gap é dado por: gap = |fp −fd|/|fp|, onde fp é o limite superior e fd é o limite inferior. Assim, as soluções encontradas são potencialmente os pontos extremos de Pareto de suas respectivas instâncias. Detalhes adicionais são fornecidos na Tabela 3. A análise da Tabela 3 revela que o intervalo de fornecedores permitidos para a geração da aproximação da curva de Pareto varia de 5 a 17 no caso mais extremo, dado que FFC só pode assu- mir valores discretos. Com isso, foi possível calcular todos as soluções potencialmente eficientes, da aproximação da curva de Pareto, gerada pelos pontos lexicográficos exibidos na Tabela 3. Um limite de tempo de 1 hora foi estabelecido para este cálculo. Entre as instâncias analisadas, apenas a instância 1 apresentou todas as soluções com- provadamente eficientes. A instância 12 exibiu o maior gap na maioria dos casos. Exceto para a primeira solução, que é comprovadamente de Pareto, todas as outras foram consideradas poten- cialmente de Pareto e utilizadas na análise do trade-off entre os objetivos. As instâncias com 10 fornecedores (Tabela 4) apresentaram o menor gap, mas sua aproximação da curva de Pareto, com apenas 3 pontos, limita uma análise significativa do trade-off. As instâncias com 20 fornecedores (Tabela 5) mostraram um gap moderado e uma aproximação da curva de Pareto mais ampla com 8 pontos. As instâncias com 30 fornecedores (Tabela 6) tiveram um gap relativamente maior, mas sua https://proceedings.science/p/193655?lang=pt-br DOI: 10.59254/sbpo-2024-193655 Tabela 3: Pontos lexicográficos para todas as instâncias. Instância Min FF C + ρ ∗FCT Min FCT + ρ ∗FF C FF C FCT runtime (s) gap % FCT FF C runtime (s) gap % 1 5 28290.33 0.39 0.01 18107.37 7 472.45 0.01 2 5 75575.29 1.76 0.01 50030.41 7 10800.52 0.21 3 5 57098.92 0.56 0 44562.44 7 10800.56 0.01 4 5 154680.71 4.35 0 121676.29 7 10801.02 0.05 5 5 28288.14 1.13 0 13492.03 12 10801.37 0.13 6 5 75535.64 11.67 0.01 36648.32 12 10800.20 1.46 7 5 57067.92 1.74 0 37619.57 11 10800.62 0.03 8 5 154677.24 67.39 0 100662.40 12 10800.45 0.24 9 5 28270.33 1.87 0 9677.39 12 10800.44 0.12 10 5 75531.55 10800.78 0.01 23953.18 15 10800.27 4.73 11 5 57020.92 6.54 0 24254.68 17 10800.36 0.05 12 5 154677.24 433.53 0 58535.11 17 10800.50 2.85 aproximação da curva de Pareto mais ampla com 13 pontos permite uma análise mais aprofundada do trade-off. Tabela 4: Resultados obtidos em cada um dos pontos da Curva de Pareto para as instâncias com 10 fornecedores Instância ϵ1 ϵ2 ϵ3 FF C FCT gap % FF C FCT gap % FF C FCT gap % 1 5 28290.33 0.01 6 18541.15 0.01 7 18107.37 0.01 2 5 75575.29 0.01 6 51261.73 0.07 7 50030.41 0.21 3 5 57098.92 0 6 45155.66 0.01 7 44562.44 0.01 4 5 154680.71 0 6 123080.06 0.05 7 121676.29 0.05 Os resultados indicam que as instâncias com mais fornecedores, mesmo quando limita- das ao mesmo número de fornecedores das instâncias com menos opções, apresentam um custo de aquisição de itens significativamente menor. Isso sugere que a consideração de uma gama maior de fornecedores no planejamento da gestão de compras, apesar de aumentar a complexidade do modelo, pode resultar em soluções relativamente melhores, utilizando o mesmo número de forne- cedores. https://proceedings.science/p/193655?lang=pt-br DOI: 10.59254/sbpo-2024-193655 Tabela 5: Resultados obtidos em cada um dos Pontos da aproximação da Curva de Pareto para as instâncias com 20 fornecedores Instância ϵ1 ϵ2 ϵ3 ϵ4 FF C FCT gap % FF C FCT gap % FF C FCT gap % FF C FCT gap % 5 5 28288.14 0 6 18541.15 0.01 7 15084.38 0.09 8 14371.23 0.08 6 5 75535.64 0.01 6 51261.73 0.33 7 43179.72 0.35 8 40842.87 0.45 7 5 57067.92 0 6 45155.66 0.01 7 41500.97 0.03 8 38664.63 0.03 8 5 154677.24 0 6 123072.88 0.15 7 114289.19 0.18 8 105924.68 0.17 Instância ϵ5 ϵ6 ϵ7 ϵ8 FF C FCT gap % FF C FCT gap % FF C FCT gap % FF C FCT gap % 5 9 13921.72 0.10 10 13619.59 0.14 11 13502.15 0.15 12 13492.03 0.13 6 9 39192.68 1.06 10 37400.63 0.71 11 36793.54 1.86 12 36648.32 1.46 7 9 37866.60 0.04 10 37638.34 0.04 11 37619.57 0.03 - - - 8 9 104103.09 0.20 10 102317.93 0.30 11 101748.16 1.06 12 100662.40 0.24 Figura 3: Fronteiras de Pareto Foi elaborado uma visualização da aproximação da curva de Pareto para as instâncias 3, https://proceedings.science/p/193655?lang=pt-br DOI: 10.59254/sbpo-2024-193655 Tabela 6: Resultados obtidos em cada um dos Pontos da aproximação da Curva de Pareto para as instâncias com 30 fornecedores Instância ϵ1 ϵ2 ϵ3 ϵ4 ϵ5 FF C FCT gap %FF C FCT gap %FF C FCT gap %FF C FCT gap % FF C FCT gap % 9 5 28270.33 0 6 18541.15 0.08 7 14129.15 0.05 8 10571.59 0.12 9 10254.57 0.04 10 5 75531.55 0.01 6 51261.73 0.64 7 37906.73 0.82 8 27769.45 1.48 9 24810.81 2.96 11 5 57020.92 0 6 40566.70 0.01 7 35700.66 0.09 8 32152.80 0.18 9 28963.37 0.06 12 5 154677.24 0 6 110126.15 0.28 7 94294.93 0.22 8 81680.25 0.27 9 78218.82 12.37 Instância ϵ6 ϵ7 ϵ8 ϵ9 ϵ10 FF C FCT gap % FF C FCT gap % FF C FCT gap % FF C FCT gap % FF C FCT gap % 9 10 9797.29 0.12 11 9680.56 0.20 12 9677.39 0.12 - - - - - - 10 10 24545.12 7.23 11 24232.62 4.95 12 24129.33 5.72 13 23984.45 3.75 14 23978.04 4.59 11 10 27248.47 0.04 11 26169.34 0.06 12 25394.59 0.02 13 24922.17 0.03 14 24471.32 0.10 12 10 70034.77 6.31 11 67248.29 9.39 12 65509.95 10.79 13 63995.03 10.76 14 61094.67 7.17 Instância ϵ11 ϵ12 ϵ13 FF C FCT gap % FF C FCT gap % FF C FCT gap % 9 - - - - - - - - - 10 15 23953.18 4.73 - - - - - - 11 15 24265.86 0.15 16 24262.87 0.10 17 24254.68 0.05 12 15 60403.45 6.55 16 58742.54 3.52 17 58535.11 2.85 7 e 11, pois elas apresentam o mesmo número de itens e períodos, variando apenas o número de fornecedores, um gap relativamente baixo para todos os valores obtidos e , respectivamente, 3, 7 e 13 pontos na sua aproximação da curva de Pareto. Com isso, será possível visualizar como essa curva se comporta para diferentes valores de fornecedores, essas curvas são exibidas na Figura 3. Com base nos resultados obtidos e na figura exibida, é perceptível que existe um trade-off significativo entre os objetivos. Sendo que a curva apresenta um decrescimento elevado no começo, como é possível ver na Figura 3 e depois de um certo valor, aproximadamente no meio do intervalo da curva, ela se torna quase constante, não havendo, após esse valor, uma diminuição significativa de custo a medida que o número de fornecedores usados aumenta. 6. Conclusão Este trabalho teve como objetivo principal desenvolver um modelo multiobjetivo para mi- nimizar os recursos despendidos pelo hospital na aquisição e armazenamento de itens, bem como o número de fornecedores utilizados. O método do epsilon-restrito foi empregado para obter o con- junto de soluções eficientes, possibilitando a análise do trade-off entre os objetivos. Os resultados indicaram um claro trade-off entre os objetivos, com a aproximação da curva de Pareto exibindo um decréscimo acentuado inicialmente, que diminui à medida que se utiliza um maior número de fornecedores. Estes resultados permitem ao tomador de decisão, encarregado da gestão de compra dos itens, avaliar qual das soluções eficientes na fronteira de Pareto melhor atende ao seu objetivo no momento. Vale ressaltar que as instâncias com menor número de fornecedores apresentam uma apro- ximação da curva de Pareto com intervalo reduzido, o que pode dificultar a análise do trade-off. Observou-se que, mesmo quando as instâncias com mais fornecedores estavam limitadas ao mesmo número de fornecedores, o custo de compra dos itens era relativamente menor do que nas instân- cias com menos fornecedores. Isso sugere que considerar um maior número de fornecedores pode https://proceedings.science/p/193655?lang=pt-br DOI: 10.59254/sbpo-2024-193655 resultar em soluções de melhor qualidade. Como trabalho futuro, a análise de instâncias maiores poderia elucidar até que ponto um horizonte maior de fornecedores pode beneficiar a gestão hos- pitalar, considerando o custo de aquisição dos itens e a complexidade do modelo resultante. Além disso, também é possível realizar a criação de alguma heurística, para tentar melhorar a qualidade das soluções obtidas."
        },
        {
            "titulo": "Uma Heurística Híbrida GRASP+VND para o Problema de Alocação de Berços com Múltiplas Cargas",
            "informacoes_url": "https://proceedings.science/p/193664?lang=pt-br",
            "idioma": "pt-br",
            "storage_key": "galoa-proceedings--sbpo-2024--193664.pdf",
            "autores": [
                {
                    "nome": "Breno Leite Zupeli",
                    "afiliacao": "Universidade Federal do Espírito Santo (UFES)",
                    "orcid": ""
                },
                {
                    "nome": "Maria Claudia Silva Boeres",
                    "afiliacao": "Universidade Federal do Espírito Santo (UFES)",
                    "orcid": ""
                },
                {
                    "nome": "Renato Elias Nunes de Moraes",
                    "afiliacao": "Universidade Federal do Espírito Santo (UFES)",
                    "orcid": ""
                }
            ],
            "data_publicacao": "",
            "resumo": "Terminais de Granéis Sólidos (TGS) manipulam e armazenam cargas secas a granel, transportadas sem embalagem em grandes quantidades. Utilizados globalmente, facilitam a exportação de materiais como minério de ferro e grãos. Este estudo é motivado por um dos maiores TGS do mundo, localizado no Brasil. Estudamos o Problema de Alocação de Berços (PAB) em TGS, onde berços operam diferentes tipos de cargas a taxas variadas, com tempos dependentes do berço e da carga. O PAB designa um conjunto de navios a um layout de berços em um horizonte de tempo definido. Apresentamos um Procedimento de Busca Adaptativa Gulosa Randomizada (GRASP em inglês) e sua hibridização com o algoritmo Descida por Vizinhança Variável (VND em inglês), GRASP+VND, que resolvem instâncias geradas a partir de dados reais do Complexo Portuário de Tubarão. Os resultados são comparados aos de um modelo matemático do problema, demonstrando que os algoritmos fornecem soluções de alta qualidade.",
            "keywords": [
                "Problema de Alocação de Berços",
                "Logística de portos graneleiros",
                "Meta-heurística híbrida GRASP+VND"
            ],
            "referencias": [
                "Aiex, R. M., Resende, M. G., e Ribeiro, C. C. (2007). Ttt plots: a perl program to create time-to-target plots. Optimization Letters, 1(4):355–366.",
                "Banos, R. S., Rosa, R. A., Mauri, G. R., e Ribeiro, G. M. (2016). Modelo matemático e meta-heurística simulated annealing para o problema de alocação de berços com múltiplas cargas. Transportes, 24(1):51–62.",
                "Barros, V. H., Costa, T. S., Oliveira, A. C., e Lorena, L. A. (2011). Model and heuristic for berth allocation in tidal bulk ports with stock level constraints. Computers & Industrial Engineering, 60(4):606 – 613.",
                "Bierwirth, C. e Meisel, F. (2010). A survey of berth allocation and quay crane scheduling problems in container terminals. European Journal of Operational Research, 202(3):615 – 627.",
                "Bierwirth, C. e Meisel, F. (2015). A follow-up survey of berth allocation and quay crane scheduling problems in container terminals. European Journal of Operational Research, 244(3):675 – 689.",
                "Cordeau, J.-F., Laporte, G., Legato, P., e Moccia, L. (2005). Models and tabu search heuristics for the berth-allocation problem. Transportation Science, 39(4):526–538.",
                "Ernst, A. T., Oğuz, C., Singh, G., e Taherkhani, G. (2017). Mathematical models for the berth allocation problem in dry bulk terminals. Journal of Scheduling, 20(5):459–473.",
                "Feo, T. A. e Resende, M. G. C. (1995). Greedy randomized adaptive search procedures. Journal of Global Optimization, 6(2):109–133.",
                "Hansen, P., Mladenović, N., Todosijević, R., e Hanafi, S. (2017). Variable neighborhood search: basics and variants. EURO Journal on Computational Optimization, 5(3):423–454.",
                "Kordić, S., Davidović, T., Kovač, N., e Dragović, B. (2016). Combinatorial approach to exactly solving discrete and hybrid berth allocation problem. Applied Mathematical Modelling, 40(21):8952 – 8973.",
                "Lodewijks, G., Schott, D., e Ottjes, J. (2007). Modern dry bulk terminal design. Bulk Solids Handling, 27(6):364.",
                "Oliveira, R. M., Mauri, G. R., e Lorena, L. A. N. (2012). Clustering search for the berth allocation problem. Expert Systems with Applications, 39(5):5499 – 5505.",
                "Prais, M. e Ribeiro, C. C. (2000). Reactive GRASP: An application to a TDMA traffic assignment problem. INFORMS Journal on Computing, 12:164–176.",
                "Rashidi, H. e Tsang, E. P. (2013). Novel constraints satisfaction models for optimization problems in container terminals. Applied Mathematical Modelling, 37(6):3601–3634.",
                "Resende, M. G. e Ribeiro, C. C. (2016). Optimization by GRASP. Springer.",
                "Rosa, R. D. A., Ribeiro, G. M., Mauri, G. R., e Fracaroli, W. (2017). Planning the berth allocation problem in developing countries with multiple cargos and cargo priority by a mathematical model and a clustering search metaheuristic. International Journal of Logistics Systems and Management, 28(4):397–418.",
                "Scarpino, A. B. A., dos Reis, W. W. F., Moraes, R. E. N., e Boeres, M. C. S. (2018). Heurística methods to solve the berth allocation problem in iron ore export terminals. In L Simpósio Brasileiro de Pesquisa Operacional, p. 1–12, Rio de Janeiro.",
                "Stahlbock, R. e Voß, S. (2008). Operations research at container terminals: a literature update. OR spectrum, 30(1):1–52.",
                "Umang, N., Bierlaire, M., e Vacca, I. (2013). Exact and heuristic methods to solve the berth allocation problem in bulk ports. Transportation Research Part E: Logistics and Transportation Review, 54:14 – 31.",
                "Vale (2023). Administração do complexo portuário de Tubarão e Praia Mole (TPM).",
                "https://www.marinha.mil.br/cpes/sites/www.marinha.mil.br.cpes/files/Porto%20de%20Tubarão%20e%20Praia%20Mole.pdf. [Online; accessed 22-May-2024]."
            ],
            "artigo_completo": "Uma heurística híbrida GRASP+VND para o Problema de Alocação de Berços com Múltiplas Cargas. RESUMO Terminais de Granéis Sólidos (TGS) manipulam e armazenam cargas secas a granel, transportadas sem embalagem em grandes quantidades. Utilizados globalmente, facilitam a expor- tação de materiais como minério de ferro e grãos. Este estudo é motivado por um dos maiores TGS do mundo, localizado no Brasil. Estudamos o Problema de Alocação de Berços (PAB) em TGS, onde berços operam diferentes tipos de cargas a taxas variadas, com tempos dependentes do berço e da carga. O PAB designa um conjunto de navios a um layout de berços em um horizonte de tempo definido. Apresentamos um Procedimento de Busca Adaptativa Gulosa Randomizada (GRASP em inglês) e sua hibridização com o algoritmo Descida por Vizinhança Variável (VND em inglês), GRASP+VND, que resolvem instâncias geradas a partir de dados reais do Complexo Portuário de Tubarão. Os resultados são comparados aos de um modelo matemático do problema, demonstrando que os algoritmos fornecem soluções de alta qualidade. PALAVRAS CHAVE. Problema de Alocação de Berços, Logística de portos graneleiros, meta- heurística híbrida GRASP+VND. Tópicos (indique, em ordem de PRIORIDADE, o(s) tópicos(s) de seu artigo): OC - Otimização Combinatória, MH - Meta-heurísticas. https://proceedings.science/p/193664?lang=pt-br DOI: 10.59254/sbpo-2024-193664 1. Introdução Terminais de granéis sólidos (Dry Bulk Terminals - DBT) são centros de transporte para a movimentação de materiais secos a granel, transportados sem embalagem (sem recipientes) em grandes quantidades. Produtos a granel secos típicos, como minério de ferro, carvão e grãos, são essenciais para o desenvolvimento das atividades de produção e para a manutenção do bem estar do indivíduo. Diante do aumento da demanda global por esses materiais [Lodewijks et al., 2007], houve um crescimento significativo no transporte desses produtos nas últimas décadas. Este estudo foi motivado pelo terminal de exportação do Porto de Tubarão, localizado em Vitória, no estado do Espírito Santo. O porto está entre os terminais de exportação de minério de ferro mais rápidos do mundo [Vale, 2023]. A eficiência de distribuição aos respectivos navios (ou embarcações) das cargas em um terminal de exportação como o Porto de Tubarão deve ser controlada pelo operador portuário de forma a proporcionar um planejamento logístico seguro e econômico. Um aspecto importante para uma melhor gestão em um terminal portuário é a alocação dos navios que chegam aos berços de forma eficiente. Assim, o foco deste artigo é o problema de alocação de berços (Berth Allocation Problem - BAP), considerando o berço como um recurso discreto (o cais é dividido em várias posições de atracação específicas e apenas um navio pode ser atendido por vez) em um DBT de exportação com comportamento dinâmico de chegada dos navios (os horários de chegada das embarcações são fixos, portanto, os navios não podem atracar antes da hora prevista de chegada). O problema de alocação de berços consiste em, dado um conjunto de embarcações a serem atracadas, suas características e demandas, determinar as posições e os tempos de atracação de cada embarcação, minimizando o custo total e respeitando as restrições do porto. O objetivo mais usual é minimizar o tempo de permanência dos navios no porto (reduzir o tempo de espera para atracar) mais o tempo para operar [Bierwirth e Meisel, 2010]. Abrangentes revisões da literatura sobre aplicações, modelos e algoritmos para o tema são encontradas em [Stahlbock e Voß, 2008; Bierwirth e Meisel, 2010; Rashidi e Tsang, 2013; Bierwirth e Meisel, 2015]. Especificamente para DBT tem-se os trabalhos de [Umang et al., 2013; Kordi´c et al., 2016; Barros et al., 2011; Ernst et al., 2017]. Umang et al. [2013] propuseram vários modelos e heurísticas para o BAP em terminais de granel com berços especializados em movimentação de cargas específicas. [Kordi´c et al., 2016] propôs um modelo e algumas heurísticas para regras de implementação de BAP discreto fornecidas pelo operador do terminal. Alguns autores propuseram modelos para o BAP para portos de granel, considerando restrições de marés [Barros et al., 2011; Ernst et al., 2017]. Na versão do BAP tratada neste artigo o tempo de operação depende da relação entre o berço que o navio irá atracar e da carga transportada, portanto, o tempo de operação não é conhe- cido a priori. Esse problema foi tratado por Banos et al. [2016], que o denominaram Problema de Alocação de Berços com Múltiplas Cargas (PAB-MC). Eles apresentaram uma formulação ma- temática baseada no Problema de Roteamento de Veículos com Múltiplos Depósitos e com Janela de Tempo proposto por Cordeau et al. [2005] e uma meta-heurística Simulated Annealing para resolver instâncias com base nos dados reais do Complexo Portuário de Tubarão. Diferentemente dos métodos exatos e heurísticos utilizados na literatura para resolver o PAB-MC e suas variantes [Banos et al., 2016; Rosa et al., 2017], este estudo emprega uma aborda- gem com metaheurística híbrida, chamada GRASP+VND, para resolver as instâncias do problema apresentadas em Banos et al. [2016]. Portanto, o objetivo deste estudo é investigar o desempenho do método híbrido no PAB-MC, considerando para o problema: (1) a implementação da meta- heurística Greedy Randomized Adaptive Search Procedure (GRASP) [Feo e Resende, 1995] e (2) a implementação da meta-heurística híbrida GRASP+VND na qual a busca local do GRASP é apri- morada pelo uso da meta-heurística Variable Neighborhood Descent (VND) [Hansen et al., 2017]. https://proceedings.science/p/193664?lang=pt-br DOI: 10.59254/sbpo-2024-193664 Os experimentos computacionais relatados demonstram a eficiência do algoritmo proposto, que foi capaz de encontrar todas as soluções ótimas conhecidas e aprimorou os melhores valores conhecidos de todas as instâncias utilizadas. O restante deste artigo está organizado da seguinte maneira. Na Seção 2 são apresenta- das as características específicas do PAB-MC considerado. Na Seção 3 são descritos os algoritmos propostos e implementados para resolver o PAB-MC. Os experimentos e os resultados computaci- onais são descritos na Seção 4. Por fim, a Seção 5 apresenta as principais conclusões baseadas nos resultados experimentais obtidos e possíveis trabalhos futuros. 2. Definição do Problema Neste trabalho, é estudado o problema discreto de alocação de berços com múltiplas car- gas (DBAP-MC) [Banos et al., 2016]. O DBAP-MC é baseado em [Cordeau et al., 2005], que resolveu o DBAP inspirado no Problema de Roteamento de Veículos com Múltiplos Depósitos e Janela de Tempo. A principal diferença entre os modelos matemáticos propostos por [Banos et al., 2016] e por [Cordeau et al., 2005] está nos tempos de atendimento dos navios. Enquanto Cordeau et al. [2005] consideram os tempos de atendimento dos navios em cada berço, uma entrada do mo- delo, Banos et al. [2016] propõem que o tempo de atendimento dependa da relação entre o navio, sua carga e o berço, portanto, sendo conhecido somente após a resolução do modelo. No DBAP-MC são considerados como conjuntos de entrada o conjunto de navios V = {1, 2, . . . , |V|}; o conjunto de berços B = {1, 2, . . . , |B|} e o conjunto de cargas operadas pelo porto C = {1, 2, . . . , |C|}. Os parâmetros associados a cada navio i ∈V e a cada berço b ∈B são apresentados, respectivamente, nas Tabelas 1 e 2. Tabela 1: Parâmetros relacionados aos navios Parâmetro Descrição ai tempo de chegada ci tempo máximo de permanência, toda a operação no navio i deve ser concluída antes deste prazo oi comprimento fi calado Qi ⊆C conjunto de cargas qij quantidade (toneladas) da carga j ∈Qi a ser processada no porto pelo navio i Tabela 2: Parâmetros relacionados aos berços Parâmetro Descrição sb tempo de abertura eb tempo de fechamento wb comprimento hb profundidade do cais Rb ⊆C Conjunto de cargas que podem ser ma- nipuladas no berço b N b ⊆V Conjunto de navios que podem ser ma- nipulados no berço b lb j capacidade de processamento da carga j ∈Rb pelo berço b Cada navio i ∈V deve ser atribuído a apenas um berço b ∈B, que por sua vez, pode atender no máximo um navio por vez. Um navio i ∈V pode ser atribuído a um berço b ∈B se e somente se o berço b manipula a carga do navio i, isto é, se Qi ⊆Rb e se seu comprimento e calado forem compatíveis ((oi, fi) ≤(wb, hb)). A função de atracação k : V →B associa a cada navio i ∈V, o berço b ∈B que satisfaça às condições acima. Além disso, para cada navio i ∈V, seu tempo de atendimento tk(i) i depende do berço k(i) = b ∈B onde é atracado e da carga Qi armazenada no navio i, a ser manipulada pelo berço b tal que Qi ⊆Rb. Desta forma, o tempo de atendimento tk(i) i de um navio i ∈V, atracado no berço k(i) é dado por tk(i) i = P j∈Qi qij/lk(i) j . Como resposta, espera-se o conjunto dos tempos de atracação T k(i) i , para cada um dos navios i ∈V quando atracados nos berços k(i) ∈B. Uma melhor descrição e formulações matemáticas do DBAP-MC são fornecidas por [Banos et al., 2016; Rosa et al., 2017]. Neste contexto, o tempo de atendimento de um navio é definido como o tempo entre a sua chegada ao porto e a conclusão das operações de carregamento ou descarregamento, T k(i) i − https://proceedings.science/p/193664?lang=pt-br DOI: 10.59254/sbpo-2024-193664 Figura 1: Representação das variáveis de tempo ai + tk(i) i (veja Figura 1). Uma solução para o DBAP-MC é representada como um conjunto S = {T k(1) 1 , T k(2) 2 , . . . , T k(|V|) |V| }, ou seja, a solução é a atribuição do tempo de atracação T k(i) i para todo navio i ∈V junto com a determinação do berço k(i) ∈B ao qual i foi alocado. O objetivo do DBAP-MC é minimizar o tempo total de atendimento e, dada uma solução S, sua função objetivo (FO) é calculada como FO(S) = P i∈V(T k(i) i −ai + tk(i) i ). Tabela 3: Exemplo de Parâmetros dos navios Navios quantidade de carga (qij) i ai ci oi fi j = 1 j = 2 j = 3 j = 4 1 5 16 20 12 2 – – – 2 6 18 25 15 – 8 – 10 3 3 12 20 15 – – 4 – 4 3 22 30 18 2 – 4 – 5 11 20 25 15 – – – 30 Um exemplo para o problema DBAP-MC é o apresentado pelas Tabelas 3, 4 e 5 (en- trada) e Figura 2 (saída). Um conjunto de valores para os parâmetros dos navios são mostrados na Tabela 3, para os parâmetros dos berços na Tabela 4 e para os tempos de atendimento (tk(i) i ) na Tabela 5. No caso dinâmico, os navios podem chegar a qualquer momento ao longo do horizonte de planejamento, indicado pela barra verde em cada berço (veja Figura 2). Observe na figura, que tempos ociosos podem aparecer na janela de tempo de funcionamento do berço. Os berços 1 e 2 são abertos nos tempos 4 e 3, e fechados nos tempos 20 e 18, respectivamente. Observe ainda que o navio i = 2 não pode atracar no berço b = 2 porque este berço não manipula a carga j = 2. O navio i = 4 não pode atracar no berço b = 2 porque o4 > w2 (Veja Tabelas 3 e 4). Tabela 4: Exemplo de Parâmetros dos berços Berços Capacidade de processamento (lb j) b sb eb wb hb j = 1 j = 2 j = 3 j = 4 1 4 20 30 20 2 2 1 5 2 3 18 25 20 1 – 4 6 Na solução DBAP-MC apresentada na Figura 2, os navios v1 e v2 são atribuídos ao berço 1, enquanto os navios v3, v4 e v5 são atribuídos ao berço 2. O navio v1 chega no tempo 5 e logo é atribuído ao berço 1, ficando por 1 unidade de tempo lá, conforme indicado na Tabela 5, tk(1) 1 = 1. O navio v2 é atribuído ao berço 1 após a saída do navio v1 e permanece por 6 unidades de tempo. As 6 unidades de tempo correspondem (ver Tabela 5) às 4 unidades de tempo necessárias para processar q22 = 8 toneladas da carga j = 2 no berço 1 com capacidade lk(2)=1 2 = 2, ou seja, q22/lk(2)=1 2 = 8/2 = 4 somadas às 2 unidades de tempo necessárias para processar q24 = 10 toneladas da carga j = 4 no berço 1 com capacidade lk(2)=1 4 = 5, ou seja, q24/lk(2)=1 4 = 10/5 = 2. https://proceedings.science/p/193664?lang=pt-br DOI: 10.59254/sbpo-2024-193664 Tabela 5: Exemplo de Tempos de Atendimento qij/lk(i)=1 j qij/lk(i)=2 j tk(i) i i j = 1 j = 2 j = 3 j = 4 j = 1 j = 2 j = 3 j = 4 k(i) = 1 k(i) = 2 1 2/2 – – – 2/1 – – – 1 2 2 – 8/2 – 10/5 – – – – 6 – 3 – – 4/1 – – – 4/4 – 4 1 4 2/2 – 4/1 – 2/1 – 4/4 – 5 3 5 – – – 30/5 – – – 30/6 6 5 A mesma análise pode ser feita para determinar os tempos de atendimento dos navios v3, v4 e v5. Observa-se que, como o navio v4 chega no tempo a4 = 3 e é atribuído ao berço k(4) = 2 no tempo T k(4) 4 = 4, ele precisa esperar T k(4) 4 −a4 = 1 unidade de tempo. Por esse motivo, é ne- cessária mais uma unidade de tempo para as operações de carga e descarga iniciarem. Considerando que tk(4) 4 = 3 (veja Tabela 5), o tempo total que o navio v4 permanece no porto é igual a 4 unidades de tempo, que são contabilizadas no valor da função objetivo. Ou seja T k(4) 4 −a4+tk(4) 4 = 4−3+3, onde k(4) = 2. Supondo que o navio v4 fosse atendido pelo berço 1, ou seja k(4) = 1, o valor contabilizado seria T k(4) 4 −a4 + tk(4) 4 = 4 −3 + 5. Figura 2: Exemplo de solução de alocação de berços A solução DBAP-MC da Figura 2 pode ser representada como S = {T 1 1 = 5, T 1 2 = 6, T 2 3 = 3, T 2 4 = 4, T 2 5 = 11}. Nesse exemplo, t1 = 1, t2 = 6, t3 = 1, t4 = 3 e t5 = 5. Portanto, os navios v1 a v5 permanecem no porto por 1, 6, 1, 4 e 5 unidades de tempo, respectivamente, e o valor da função objetivo é fDBAP−MC = 17 unidades de tempo. 3. Heurísticas para Solucionar o DBAP-MC O GRASP [Feo e Resende, 1995] é uma meta-heurística bastante utilizada em vários tipos de aplicações de problemas de otimização. Consiste de um processo iterativo de múltiplos inícios (multi-start). Sua implementação mais simples considera, a cada iteração, a construção de uma solução inicial seguida de uma busca local para melhoria dessa solução. Neste trabalho é proposto um algoritmo utilizando o GRASP, que dispõe de um meca- nismo baseado em uma Lista Restrita de Candidatos (LRC) utilizada na construção da solução ini- cial. O uso da LRC é uma estratégia construtiva aleatória. Dados um conjunto X = {x1, x2, ..., x|X|} de todos os elementos candidatos a compor uma solução e uma função gulosa g para computar seus custos, onde g(X) = min1≤j≤|X|g(xj) e g(X) = max1≤j≤|X|g(xj) sejam, respectiva- mente, o mínimo e máximo valor guloso sobre todos os elementos candidatos viáveis para com- por a solução, a LRC é formada por todos os elementos viáveis xℓ∈X, 1 ≤ℓ≤|X|, tal que g(xℓ) ≤g(X) + α(g(X) −g(X)), com 0, 0 < α ≤1, 0. O caso α = 0, 0 corresponde a um algoritmo guloso puro, enquanto α = 1, 0 é equivalente a uma construção totalmente aleatória. Em seguida, um elemento xℓé aleatoriamente selecionado da LRC para ser parte da solução. O tama- nho da LRC é determinado pelo parâmetro α, que pode assumir uma constante ou se auto-ajustar https://proceedings.science/p/193664?lang=pt-br DOI: 10.59254/sbpo-2024-193664 a cada β iterações, atualizando a probabilidade de cada α ser escolhido, chamado α reativo. Neste último caso, um conjunto A de valores reais entre 0 e 1 é definido para α. Os valores de α que ge- rarem melhores soluções terão suas probabilidades aumentadas e, consequentemente, nas próximas iterações terão maior chance de serem escolhidos. O GRASP com α reativo é denotado de GRASP Reativo [Prais e Ribeiro, 2000]. Seguindo o processo de multi-start, soluções iniciais diferentes são criadas a fim de promover a diversificação, sendo cada uma submetida a uma busca local. A melhor solução entre todas as iterações é a saída do algoritmo. Nesta seção propomos e descrevemos o GRASP reativo para resolver o DBAP-MC. A Seção 3.1 descreve o algoritmo GRASP básico. O procedimento construtivo aleatório é apresentado na Seção 3.2. As buscas locais e o VND são apresentados na Seção 3.3. 3.1. GRASP Reativo para o DBAP-MC Algoritmo 1: GRASP Reativo para o DBAP-MC Entrada: V, B, seed, A, β Saída: A melhor solução encontrada Sbest 1 Sbest ←∅; 2 FO(Sbest) ←+∞; 3 α ←Escolhe Alfa(A, seed); 4 repita 5 S ←ConstrutivoAleatorio(B, V, α); 6 S′ ←BuscaLocal(S, B, V); 7 se FO(S′) < FO(Sbest) então 8 Sbest ←S′; 9 fim se 10 α ←Atualiza Alfa(A, β); 11 até critério de parada alcançado; 12 retorna Sbest No Algoritmo 1 é apresentado o o pseudocódigo do GRASP para resolver o DBAP-MC. A entrada para o algoritmo consiste do conjunto de navios V, junto com os parâmetros da Tabela 1, o conjunto de berços B, junto com os parâmetros da Tabela 2 e os parâmetros para implementação do α reativo: a semente aleatória seed, o conjunto A com os valores de α e o parâmetro β que define a quantidade de iterações para que se atualize as probabilidades de α. Nas linhas 1 a 3 do Algoritmo 1 são inicializadas, respectivamente, a melhor solução encontrada até então Sbest como ∅(vazia), o seu valor de função objetivo FO(Sbest) como +∞e o valor de α, usando a função Escolhe Alfa() que retorna um valor aleatório do conjunto A baseado no valor da semente seed. No laço das linhas 4 a 11, ocorre a fase de construção aleatória da solução inicial (linha 5), onde se cria, iterativamente, uma solução viável S (ver Seção 3.2). Em seguida, na linha 6, S é submetida à busca local. No decorrer da fase de busca local refina-se a solução S através de uma busca em sua vizinhança. Ao final dessa fase, é encontrada a solução ótima local (ver Seção 3.3). Caso a solução ótima local seja melhor que a melhor solução encontrada até o momento Sbest, a melhor solução é atualizada com o valor da solução atual (linhas 7 a 9). Na linha 10 o parâmetro α é ajustado usando a estratégia reativa descrita em [Prais e Ribeiro, 2000] com a distribuição de probabilidade sendo atualizada a cada β iterações. Esse processo de duas fases do GRASP se repete até que uma determinada condição de parada seja alcançada, linha 11. A melhor solução encontrada ao final de todas as iterações do GRASP é retornada como resultado (Sbest) na linha 12. https://proceedings.science/p/193664?lang=pt-br DOI: 10.59254/sbpo-2024-193664 3.2. Heurística Construtiva Aleatória Na fase de construção da solução inicial (linha 5 do Algoritmo 1), uma heurística cons- trutiva aleatória é utilizada para construir uma solução viável S que será então submetida à fase de busca local (linha 6 do Algoritmo 1). A heurística implementada está baseada em Scarpino et al. [2018], na qual, dada uma sequência arbitrária de navios (ordem de leitura da instância de entrada), seleciona-se um berço aleatoriamente de uma LRC. A construção da LRC é guiada por uma função gulosa baseada no número de navios atualmente alocados em cada berço. Essa função é definida como g(B) = min1≤b≤|B| |nb|, onde |nb| é o número de navios atualmente alocados no berço b. A primeira etapa do algoritmo termina quando todo navio i ∈V foi alocado a exatamente um berço k(i) = b ∈B, respeitadas todas as restrições do problema. A segunda etapa da heurística construtiva consiste em estabelecer a ordem de atendi- mento e, consequentemente, o tempo de atracação T k(i) i de cada navio i alocado ao berço k(i). Considerando que no DBAP-MC o tempo de operação depende da relação entre o berço que o na- vio irá atracar e da carga transportada, neste trabalho, é proposto o critério de ordenação baseado no custo total da operação dos navios nos berços, buscando reduzir o custo total de operação dos berços. Para isso, levam-se em consideração o tempo de processamento dos navios e o horário de abertura do berço. Durante a ordenação em um berço b, ao comparar dois navios i e j sub- sequentes, é calculado o tempo total de processamento desses dois navios nessa ordem, ou seja, max(sb, ai) + tb i + max(max(sb, ai) + tb i, aj) + tb j, que, observando a disposição da solução apre- sentada na Figura 3 e, utilizando o berço 2 e os navios v4 e v3 como i e j respectivamente, resulta em max(3, 3)+3+max(max(3, 3)+3, 3)+1 = 13. Em seguida, é realizada uma troca na ordem de processamento dos dois navios, que resulta em max(3, 3)+1+max(max(3, 3)+1, 3)+3 = 10. Caso a troca resulte em um valor maior, a troca é desfeita. Se resultar em um valor menor, como nesse caso, a troca é mantida, refletindo essa redução no valor da função objetivo. Esse pro- cessamento é realizado em cada par de navios para cada berço. O resultado do processamento do algoritmo é exibido na Figura 3. Ao término da segunda etapa, tem-se uma solução viável S = {T k(1) 1 , T k(2) 2 , . . . , T k(|V|) |V| }. Figura 3: Exemplo de solução de alocação de berços usando o critério de ordenação por custo da operação 3.3. Busca Local A segunda fase do GRASP (linha 6 do Algoritmo 1) consiste na aplicação, a cada iteração, de busca local na solução construtiva aleatória realizada na primeira fase (linha 5 do Algoritmo 1). Neste trabalho, a proposta foi implementar um GRASP no qual a estratégia de busca local é o método de Descida em Vizinhança Variável (VND – Variable Neighborhood Descent) [Hansen et al., 2017]. O VND é um método de busca local que consiste em explorar o espaço de soluções através de trocas sistemáticas de vizinhanças, aceitando somente soluções de melhoria da solução corrente e retornando à primeira estrutura quando uma solução melhor é encontrada. O método VND utilizado possui dois tipos de movimentos (descritos em Oliveira et al. [2012]), visando alterar a solução realizando buscas em sua vizinhança: o movimento move move um navio atracado a um determinado berço, para um berço diferente e o movimento swap seleciona https://proceedings.science/p/193664?lang=pt-br DOI: 10.59254/sbpo-2024-193664 dois navios atracados a berços diferentes, trocando-os. Após o movimento dos navios, a sequência de navios nos berços afetados é reordenada utilizando o critério por tempo de chegada ou o critério por custo da operação (Seção 3.2). Uma busca pela vizinhança consiste em aplicar todas as possi- bilidades de movimento (move ou swap) e escolher o melhor vizinho (melhor aprimorante). Neste trabalho os dois movimentos (move e swap) e os dois critérios de ordenação de navios nos berços (tempo de chegada e custo da operação) foram combinados para formar o con- junto N = {N1, N2, N3, N4}, de quatro estruturas de vizinhança utilizadas na heurística VND, cuja implementação segue a versão Sequential VND using the best improvement search strategy, descrita em Hansen et al. [2017]. A ordem de aplicação foi definido como: N1, movimento move com critério de ordenação por tempo de chegada; N2, movimento swap com critério de ordenação por tempo de chegada; N3, movimento move com critério de ordenação por custo da operação e N4, movimento swap com critério de ordenação por custo da operação. 4. Resultados Computacionais Todos os algoritmos foram codificados em C e compilados com o compilador gcc versão 5.4.0. Os experimentos foram realizados em um computador com processador Intel Core i7-6800K de 3.4GHz com 64GB de memória RAM e sistema operacional Ubuntu 16.04. A Tabela 6 apresenta detalhes das onze instâncias utilizadas nos testes e disponibilizadas por Banos et al. [2016], como o número de berços (|B|) e navios (|V|). Banos et al. [2016] apresenta os resultados ótimos para as 5 primeiras instâncias da Tabela 6 e os melhores resultados conhecidos para as outras 6 instâncias. Tabela 6: Conjunto de instâncias para o DBAP-MC Instância |B| |V| Instância |B| |V| Instância |B| |V| B04N010 4 10 B15N010 15 10 B11N100 11 100 B07N010 7 10 B07N100 7 100 B11N150 11 150 B09N010 9 10 B07N150 7 150 B11N250 11 250 B11N010 11 10 B07N250 7 250 Foram executados um algoritmo que realiza a construção de uma solução de forma pu- ramente gulosa (alpha = 0, 0) e três versões do algoritmo GRASP, a saber: o GRASPtemp, cuja busca local é executada com o movimento move e, em seguida, com o movimento swap ambos com critério de ordenação por tempo de chegada; o GRASPoper, com execução da busca local de forma análoga ao GRASPtemp, porém utilizando critério de ordenação por custo da operação e finalmente o GRASPV ND, que utiliza como busca local a heurística VND descrita na Seção 3.3. Os algoritmos GRASPtemp, GRASPoper e GRASPV ND foram executados 10 vezes para cada instância, com diferentes sementes para a geração de números aleatórios, considerando como critério de parada o tempo de execução de uma hora ou até atingir 1200 iterações sem melhoria da melhor solução. Esse número de iterações foi escolhido arbitrariamente. A distribuição da probabilidade da estratégia de α reativo foi atualizada após cada β = 20 iterações. A Tabela 7 fornece os resultados médios obtidos por todos os algoritmos para cada ins- tância. A coluna Guloso indica o valor da função objetivo encontrada pelo algoritmo construtivo utilizando o parâmetro α igual a 0, 0, consequentemente, não há variação no resultado médio pois a solução encontrada é sempre a mesma. A Fig. 4 mostra o comportamento padrão do algoritmo aleatorizado implementado com estratégia reativa. Na Fig. 4 foi utilizada a instância B07N250 e o GRASPV ND restrito a 200 iterações, o suficiente para mostrar o comportamento padrão de cada iteração. Para cada iteração (eixo x) a cruz violeta representa o valor da função objetivo da solução inicial construída pelo construtivo aleatório e o xis laranja representa o valor da função objetivo https://proceedings.science/p/193664?lang=pt-br DOI: 10.59254/sbpo-2024-193664 Tabela 7: Resultados médios (10 execuções para cada instância do problema) GRASPtemp GRASPoper GRASPV ND Instância Guloso t(s) iter. FO t(s) iter. FO t(s) iter. FO g.(%) B04N010 660,63 0,01 246,60 517,69 0,00 5,40 517,69 0,00 5,40 517,69 21,64 B07N010 587,04 0,00 2,20 555,98 0,00 2,20 555,98 0,00 2,20 555,98 5,29 B09N010 902,03 0,03 240,80 661,40 0,00 1,10 661,40 0,00 1,10 661,40 26,68 B11N010 455,15 0,12 712,70 245,74 0,00 1,40 241,02 0,00 1,40 241,02 47,05 B15N010 264,31 0,00 1,20 117,84 0,00 1,10 115,82 0,00 1,10 115,82 56,18 B07N100 38153,21 0,30 7,20 21462,75 254,41 970,70 16816,52 257,12 944,10 16753,94 56,09 B07N150 66652,27 8,99 568,70 60334,47 646,69 769,80 40720,12 285,74 313,50 39952,76 40,06 B07N250 169792,70 145,91 286,80 63878,70 749,31 58,00 61911,49 752,03 55,90 58672,83 65,44 B11N100 9870,08 18,62 676,30 3297,40 67,69 399,30 3553,77 40,17 214,40 3235,46 67,22 B11N150 18976,74 23,78 247,00 6594,08 192,20 226,70 7007,83 106,34 111,30 6395,09 66,30 B11N250 60954,11 111,40 225,40 11934,45 835,34 101,50 17806,33 813,60 92,60 11856,54 80,55 Média 33388,02 28,11 292,26 15418,23 249,60 230,65 13628,00 205,00 158,45 12632,59 62,16 após a aplicação da busca local na solução inicial. A linha turquesa representa o melhor valor da função objetivo encontrado até aquele momento. A diferença média, ou ganho médio, entre o valor da função objetivo da solução inicial (Guloso) e após a aplicação da busca local é mostrada na Tabela 7 na coluna g.(%) calculada como (GRASPV ND(FO) −Guloso)/(GRASPV ND(FO)). O ganho, conforme mostrado, pode chegar a 80, 55%. As colunas FO dos algoritmos GRASPtemp e GRASPoper mostram ganhos semelhantes mas menores que os alcançados pelo GRASPV ND que se beneficia da combinação de todas as busca locais implementadas. 50000 100000 150000 200000 250000 300000 350000 0 50 100 150 200 Função Objetivo iteração construtivo busca local melhor Figura 4: Evolução das soluções para a instância B07N250 A Tabela 7 também mostra, respectivamente, na coluna t(s) e iter., o tempo médio em segundos e número médio de iterações que cada algoritmo leva para encontrar a melhor solução. O tempo e as iterações posteriores que não melhoraram a melhor solução não foram computadas. É possível verificar que o GRASPtemp leva no máximo 145,91 segundos para encontrar a melhor solução, enquanto que os demais algoritmos podem gastar até 835,34 segundos. O maior tempo e número de iterações dos algoritmos GRASPoper e GRASPV ND mostram que as busca locais com critério de ordenação por custo da operação aumentam a diversificação e intensificação da busca local fazendo o tempo computacional crescer e, ao mesmo tempo, aumentando a efetividade e ro- https://proceedings.science/p/193664?lang=pt-br DOI: 10.59254/sbpo-2024-193664 Tabela 8: Resultados obtidos por todos os algoritmos para todas as instâncias. GRASPtemp GRASPoper GRASPV ND Instância MSCa t(s) Melhor g.(%) t(s) Melhor g.(%) t(s) Melhor g.(%) B04N010 ∗517,69 0,04 517,69 0,00 0,00 517,69 0,00 0,00 517,69 0,00 B07N010 ∗555,98 0,00 555,98 0,00 0,00 555,98 0,00 0,00 555,98 0,00 B09N010 ∗661,40 0,10 661,40 0,00 0,00 661,40 0,00 0,00 661,40 0,00 B11N010 ∗241,02 0,22 243,15 -0,88 0,00 241,02 0,00 0,00 241,02 0,00 B15N010 ∗115,82 0,00 117,84 -1,74 0,00 115,82 0,00 0,00 115,82 0,00 B07N100 24480,00 0,50 21462,75 12,33 695,21 16405,28 32,98 713,57 16393,62 33,03 B07N150 51690,00 20,23 60331,87 -16,72 1204,49 40013,02 22,59 858,67 39216,92 24,13 B07N250 128570,00 331,02 63628,99 50,51 2657,35 58237,36 54,70 1996,04 55080,22 57,16 B11N100 5060,00 35,99 3273,77 35,30 214,77 3383,61 33,13 142,56 3203,69 36,69 B11N150 12150,00 75,48 6560,84 46,00 687,88 6755,50 44,40 731,52 6050,23 50,20 B11N250 30230,00 347,51 11796,79 60,98 3484,45 16709,38 44,73 3026,88 11261,49 62,75 a MSC marcadas em ∗(asterisco) são valores ótimos obtidos pelo CPLEX [Banos et al., 2016]. bustez dos algoritmos ao explorar mais soluções na vizinhança. Essas características podem também ser visualizadas na Fig. 5 que mostra uma rápida convergência do GRASPoper e do GRASPV ND quando comparados ao GRASPtemp. A Fig. 5 exibe um gráfico de tempo até o alvo (time to tar- get [Aiex et al., 2007; Resende e Ribeiro, 2016]) para a instância de teste B09N010 (com o valor de alvo definido como o valor ótimo de 661, 40 e 200 execuções aleatoriamente independentes). Nesse tipo de gráfico cada algoritmo é representado por uma curva e quanto mais a esquerda estiver a curva, melhor será o seu desempenho. Os valores alvo foram escolhidos de forma a permitirem a comparação entre os algoritmos mais e menos efetivos. No gráfico apresentado na Figura 5, a pro- babilidade de que GRASPoper e do GRASPV ND encontrarem o valor alvo em até 10−3 segundos é de 100%, caindo para menos de 5% para GRASPtemp. A Fig. 6 exibe um gráfico de tempo até o alvo para a instância de teste B07N150 (com o valor de alvo definido como 43000, 00, ou seja 5, 6% maior que o melhor valor 40720, 12 encontrado pelo GRASPoper e 200 execuções aleatoriamente independentes). Em nenhuma execução o algoritmo GRASPtemp convergiu para o alvo estabele- cido e por isso não é mostrado na Fig. 6. No gráfico apresentado na Fig. 6, a probabilidade de que o GRASPV ND encontre o valor alvo em 101 segundos é de aproximadamente 65%, caindo para aproximadamente 12% para GRASPoper. Figura 5: Distribuição de tempo para a instância B09N010 com alvo 661, 40. 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 10-4 10-3 10-2 10-1 100 Probabilidade Tempo (segundos) GRASPVND GRASPoper GRASPtemp Figura 6: Distribuição de tempo para a instância B07N150 com alvo 43000, 00. 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 10-1 100 101 102 Probabilidade Tempo (segundos) GRASPVND GRASPoper A Tabela 8 apresenta os melhores resultados encontrados por cada algoritmo para cada https://proceedings.science/p/193664?lang=pt-br DOI: 10.59254/sbpo-2024-193664 instância, e os compara com os melhores resultados conhecidos da literatura. A tabela também mostra o maior tempo t(s) em segundos que cada algoritmo levou para alcançar o melhor resultado (o tempo e as iterações posteriores que não melhoraram a melhor solução não foram computados) e ganho percentual g.(%) da solução de cada algoritmo quando comparada à Melhor Solução Co- nhecida (MSC) na literatura, calculada como (Melhor−MSC)/(Melhor). Os maiores ganhos estão marcados em negrito. A Tabela 8 mostra que o GRASPtemp gasta menos tempo que os outros algo- ritmos e é capaz de encontrar valores de função objetivo melhores que o GRASPoper nas instâncias maiores: B11N100, B11N150 e B11N250. Os resultados também mostram que quando combina- das as buscas locais de GRASPtemp de GRASPoper para formar o GRASPV ND, esse último é capaz de encontrar todas os melhores valores de função objetivo sem aumento no tempo computacional quando comparado ao GRASPoper. O GRASPV ND foi capaz de melhorar em até 62,75% o valor da melhor solução conhecida das instâncias analisadas. 5. Conclusões e Trabalhos Futuros Neste artigo foram propostas variações do algoritmo GRASP para solução do DPAB-MC. Dentre elas, a variante híbrida com a busca local aprimorada pelo uso do VND, destacou-se por encontrar os melhores resultados. O sucesso dessa versão pode ser atribuído ao fato de combinar estratégias de busca local propostas para o BAP padrão com outras desenvolvidas nesse trabalho especificamente para o problema PAB-MC característico de terminais marítimos de granéis sólidos. Os experimentos computacionais mostraram que a heurística híbrida desenvolvida neste trabalho teve um desempenho muito bom, obtendo soluções subótimas muito boas para problemas de teste em tempos de computação razoáveis. O algoritmo é muito robusto, encontrando siste- maticamente a mesma solução em um pequeno intervalo de tempo. Além disso, a hibridização do GRASP com o VND contribuiu para tornar a heurística mais efetiva, encontrando todos os melhores resultados independente das características das instâncias. Para trabalhos futuros, sugere-se a hibridização de outras metaheurísticas, como a busca tabu, com a incorporação de novas buscas locais, vizinhanças e módulos de mineração de dados. Outra linha de investigação que pode ser iniciada é a construção de mais instâncias para DPAB-MC. 6. Agradecimentos Esta pesquisa foi realizada com apoio parcial da Coordenação de Aperfeiçoamento de Pessoal de Nível Superior - Brasil (CAPES) - Código de Financiamento 001 e da Fundação de Amparo à Pesquisa do Espírito Santo (FAPES), projetos 368/2022 - P: 2022-NGKM5 e 129/2021 - P: 2021-GL60J."
        },
        {
            "titulo": "Método Exato para o Roteamento de Veículos com Empacotamento Bidimensional e Conflitos",
            "informacoes_url": "https://proceedings.science/p/193481?lang=pt-br",
            "idioma": "português",
            "storage_key": "galoa-proceedings--sbpo-2024--193481.pdf",
            "autores": [
                {
                    "nome": "Ana Clara Nascimento dos Santos",
                    "afiliacao": "Universidade Federal de Itajubá",
                    "orcid": ""
                },
                {
                    "nome": "Pedro Henrique Del Bianco Hokama",
                    "afiliacao": "Universidade Federal de Itajubá",
                    "orcid": ""
                },
                {
                    "nome": "Mário César San Felice",
                    "afiliacao": "Universidade Federal de São Carlos",
                    "orcid": ""
                }
            ],
            "data_publicacao": "",
            "resumo": "Neste artigo, apresentamos o Problema do Roteamento de Veículos Capacitados com Restrições de Carregamento Bidimensional e Conflitos, que consiste em encontrar rotas para uma frota de veículos que deve atender as demandas de um conjunto de clientes sem exceder a capacidade dos veículos.",
            "keywords": [
                "Roteamento",
                "Empacotamento com Conflitos",
                "Programação Inteira"
            ],
            "referencias": [
                "Abdal-Hammed, M. K., Hifi, M., e Wu, L. (2014). Large neighborhood search for the vehicle routing problem with two-dimensional loading constraints. In 2014 International Conference on Control, Decision and Information Technologies (CoDIT), p. 054–059. IEEE.",
                "Arpini, B. P. e Rosa, R. A. (2017). Uma revisão sistemática da literatura sobre o problema de roteirização de veículos capacitados com restrições de carregamento bidimensional (2l-cvrp). TRANSPORTES, 25(1):61–72.",
                "Capua, R., Frota, Y., Vidal, T., e Ochi, L. S. (2015). Um algoritmo heurístico para o problema de bin packing com conflitos. Anais do XLVII Simpósio Brasileiro de Pesquisa Operacional. https://proceedings.science/p/193481?lang=pt-br DOI: 10.59254/sbpo-2024-193481",
                "Clarke, G. e Wright, J. W. (1964). Scheduling of vehicles from a central depot to a number of delivery points. Operations research, 12(4):568–581.",
                "Dantzig, G. B. e Ramser, J. H. (1959). The truck dispatching problem. Management science, 6(1):80–91.",
                "Dolan, E. D. e Moré, J. J. (2002). Benchmarking optimization software with performance profiles. Mathematical programming, 91(2):201–213.",
                "Epstein, L., Levin, A., e Van Stee, R. (2008). Two-dimensional packing with conflicts. Acta Informatica, 45:155–175.",
                "Ferreira, K. M., de Queiroz, T. A., e Toledo, F. M. B. (2021). An exact approach for the green vehicle routing problem with two-dimensional loading constraints and split delivery. Computers & Operations Research, 136:105452.",
                "Gendreau, M., Iori, M., Laporte, G., e Martello, S. (2008). A tabu search heuristic for the vehicle routing problem with two-dimensional loading constraints. Networks: An International Journal, 51(1):4–18.",
                "Gendreau, M., Laporte, G., e Semet, F. (2004). Heuristics and lower bounds for the bin packing problem with conflicts. Computers & Operations Research, 31(3):347–358.",
                "Hamdi-Dhaoui, K., Labadie, N., e Yalaoui, A. (2011). The vehicle routing problem with conflicts. IFAC Proceedings Volumes, 44(1):9799–9804.",
                "Hokama, P., Miyazawa, F. K., e Xavier, E. C. (2016). A branch-and-cut approach for the vehicle routing problem with loading constraints. Expert Systems with Applications, 47:1–13.",
                "Iori, M., Salazar-González, J.-J., e Vigo, D. (2007). An exact approach for the vehicle routing problem with two-dimensional loading constraints. Transportation science, 41(2):253–264.",
                "Khanafer, A., Clautiaux, F., e Talbi, E.-G. (2012). Tree-decomposition based heuristics for the two-dimensional bin packing problem with conflicts. Computers & Operations Research, 39(1):54–63.",
                "Leung, S. C., Zhou, X., Zhang, D., e Zheng, J. (2011). Extended guided tabu search and a new packing algorithm for the two-dimensional loading vehicle routing problem. Computers & Operations Research, 38(1):205–215.",
                "Muritiba, A. E. F., Iori, M., Malaguti, E., e Toth, P. (2010). Algorithms for the bin packing problem with conflicts. Informs Journal on computing, 22(3):401–415.",
                "Niskanen, S. (2002). Cliquer - routines for clique searching. URL https://users.aalto.fi/~pat/cliquer.html. Acesso em: 09/09/2022.",
                "Smith, B. M. (1995). A tutorial on constraint programming. Technical Report 95.14, University of Leeds, School of Computer Studies.",
                "Toth, P. e Vigo, D. (2014). Introduction to vehicle routing problems. In Vehicle routing: problems, methods, and applications, chapter 1, p. 1–23. SIAM.",
                "Wei, L., Zhang, Z., Zhang, D., e Lim, A. (2015). A variable neighborhood search for the capacitated vehicle routing problem with two-dimensional loading constraints. European Journal of Operational Research, 243(3):798–814."
            ],
            "artigo_completo": "Método Exato para o Roteamento de Veículos com Empacotamento Bidimensional e Conflitos. RESUMO Neste artigo, apresentamos o Problema do Roteamento de Veículos Capacitados com Restrições de Carregamento Bidimensional e Conflitos, que consiste em encontrar rotas para uma frota de veículos que deve atender as demandas de um conjunto de clientes sem exceder a capaci- dade dos veículos. Além disso, é necessário encontrar um empacotamento bidimensional para os itens, respeitando a ordem de descarregamento e os conflitos entre eles. Apresentamos um algoritmo de Branch-and-Cut que utiliza um modelo em Programação Linear Inteira e propomos melhorias envolvendo quebras de simetrias e pré-processamentos. Utilizamos um modelo de Programação por Restrição para determinar se um conjunto de itens pode ser alocado em um veículo e dessa forma encontrar cortes violados. Testes foram realizados em instâncias adaptadas da literatura e consta- tamos que as melhorias implementadas obtiveram um impacto modesto no tempo de execução e possibilitaram ao modelo dobrar o número de soluções ótimas alcançadas. PALAVRAS CHAVE. Roteamento, Empacotamento com Conflitos, Programação Inteira. Tópicos (Otimização Combinatória, Logística e Transportes) https://proceedings.science/p/193481?lang=pt-br DOI: 10.59254/sbpo-2024-193481 1. Introdução Nos setores de logística e distribuição, há uma busca constante por eficiência, a fim de re- duzir custos e tornar o processo mais sustentável. Entretanto, existem situações que aumentam esse desafio, como quando as etapas de armazenamento e distribuição envolvem itens que não podem ser alocados juntos devido ao risco de contaminação ou incompatibilidade entre materiais. Neste trabalho consideramos a versão bidimensional, que ocorre quando os itens a serem transportados são frágeis, altos ou possuem um formato específico que impossibilita o empilhamento vertical. Neste contexto, surge o Problema do Roteamento de Veículos Capacitados com Restrições de Carregamento Bidimensional e Conflitos (Capacitated Vehicle Routing Problem with Two- dimensional Loading Constraints and Conflicts - 2L-CVRPC), caracterizado por demandar rotas para uma frota de veículos, considerando a necessidade de atender a um conjunto específico de clientes sem ultrapassar a capacidade dos veículos. Além disso, a complexidade do problema é ampliada pela exigência de encontrar um empacotamento bidimensional viável dos itens a serem entregues, respeitando a ordem de descarregamento e considerando os conflitos entre itens. O 2L-CVRPC é NP-difícil e vem da combinação de dois problemas de otimização. O pri- meiro é o clássico Problema de Roteamento de Veículos Capacitados (Capacitated Vehicle Routing Problem - CVRP), em que se buscam as melhores rotas para atender a uma série de clientes, de modo que a capacidade dos veículos seja respeitada. O segundo é o Problema do Empacotamento Bidimensional em Contêineres na Presença de Conflitos (Two-dimensional Bin Packing Problem With Conflicts - 2BPPC), em que itens retangulares de tamanhos variados devem ser alocados no menor número possível de recipientes idênticos, respeitando as restrições de conflito entre os itens. O problema do empacotamento tem sido amplamente explorado devido a sua relevância na otimização de espaço para armazenamento e transporte de produtos. Uma de suas variações é a que considera conflitos entre os itens. Gendreau et al. [2004] estão entre os primeiros a abordar o Problema do Empacotamento Unidimensional em Contêineres na Presença de Conflitos, utilizando heurísticas baseadas no algoritmo First Fit Decreasing (FFD), em procedimentos de coloração de grafos, em cliques e em limitantes inferiores. Muritiba et al. [2010], ao trabalharem com o mesmo problema, empregaram uma abordagem exata baseada na formulação do problema da cobertura por conjuntos. Capua et al. [2015] também abordaram este problema, usando um método baseado na metaheurística Iterated Local Search, além de um algoritmo Large Neighborhood Search. Epstein et al. [2008], ao abordarem o 2BPPC utilizaram uma estratégia de resolução baseada em algoritmos de aproximação, centrada na coloração de grafos. Khanafer et al. [2012] também exploraram este mesmo problema, propuseram um framework baseado na decomposição em árvore para resolvê-lo, e apresentaram várias heurísticas para tornar o uso da decomposição eficaz. Paralelamente, o problema de Roteamento de Veículos (VRP) também tem sido extensi- vamente estudado, devido a suas aplicações na logística e distribuição, onde a eficiência nas rotas é essencial para a redução de custos e tempo. Dantzig e Ramser [1959] são responsáveis por aquele que é considerado o artigo seminal do VRP. Nele abordaram o Problema do Despacho de Caminhões, que consiste em buscar um roteamento de distância mínima para uma frota de ca- minhões que transportam gasolina da central de distribuição para um grande número de postos a serem abastecidos. Clarke e Wright [1964] generalizaram esse problema para atender a um con- junto de clientes localizados ao redor do depósito de forma dispersa, empregando uma frota de veículos com capacidades variadas, que foi denominado Problema do Roteamento de Veículos. A combinação do 2BPP e do VRP deu origem ao Problema de Roteamento de Veículos Capacitados com Restrições de Carregamento Bidimensionais (Two-Dimensional Loading Capa- citated Vehicle Routing Problem - 2L-CVRP), que une a complexidade de definir rotas e alocar itens. Iori et al. [2007] introduziram o 2L-CVRP e apresentaram uma abordagem exata, que visa a https://proceedings.science/p/193481?lang=pt-br DOI: 10.59254/sbpo-2024-193481 minimização do custo de roteamento, invocando de maneira iterativa um algoritmo de Branch-and- Bound para verificar a viabilidade dos carregamentos. Além de adotar heurísticas para melhoria do desempenho geral. Gendreau et al. [2008], ao trabalharem com o mesmo problema, propuseram uma Tabu Search, na qual a resolução do componente de carregamento do problema é abordada por meio de heurísticas, limitantes inferiores e um procedimento de Branch-and-Bound. Leung et al. [2011] também investigaram o 2L-CVRP e utilizaram um algoritmo que une Tabu Search e Exten- ded Guided Local Search, além de propor novas heurísticas para o 2BPP. Hamdi-Dhaoui et al. [2011] analisaram a variação do VRP denonimada The Vehicle Rou- ting Problem With Conflicts (VRPC), que leva em consideração propriedades físicas dos itens, em especial casos de materiais perigosos, de modo que itens conflitantes não possam ser transportados no mesmo veículo. Os autores apresentaram um modelo matemático, heurísticas e meta-heurísticas, incluindo uma Iterated Local Search e um Greedy Randomized Adaptive Search Procedure - Evo- lutionary Local Search (GRASP-ELS). Eles também propuseram um limitante inferior. Abdal-Hammed et al. [2014] proposeram um algoritmo Large Neighborhood Search para solucionar o 2L-CVRP, que possui duas fases, a primeira gera uma ordem de posicionamento e aplica uma estratégia bottom-left a esta ordem para empacotar os pedidos nos veículos e uma se- gunda fase que encontra uma rota viável para os veículos. Wei et al. [2015] também abordaram o mesmo problema, propondo um algoritmo Variable neighborhood search para o roteamento e adaptando uma heurística skyline para examinar as restrições de empacotamento. Hokama et al. [2016] propuseram um algoritmo Branch-and-Cut para resolver o 2L-CVRP e o 3L-CVRP, que adota múltiplas abordagens para podar a árvore de enumeração. O empacotamento é atacado com diferentes abordagens algorítmicas, entre elas Branch-and-Bound, programação por restrições e meta-heurísticas. Os autores também apresentaram novas heurísticas, uma delas baseada no algo- ritmo Bottom-Left e a outra no Biased Random-Key Genetic Algorithm (BRKGA). Arpini e Rosa [2017] forneceram uma extensa revisão sistemática da literatura sobre o 2L-CVRP. Ferreira et al. [2021] exploraram o 2L-CVRP e três variantes: (i) permitindo entrega fracionada (2L-SDVRP), na qual um cliente pode ser atendido por mais de um veículo; (ii) com requisitos verdes (G2L-CVRP), que leva em consideração as emissões de CO2; e (iii) a integração da entrega fracionada com requisitos verdes (G2L-SDVRP). Para cada variante, são apresentados modelos matemáticos e cada caso é solucionado com Branch-and-Cut. Os autores desenvolveram um procedimento personalizado para resolver o subproblema de empacotamento, incluindo limites inferiores, uma heurística de base construtiva e uma formulação em Programação por Restrições. O presente trabalho propõe uma formulação em Programação Linear Inteira para o 2L- CVRPC e, para fortalecer esta formulação, restrições obtidas via pré-processamentos e cortes são apresentadas. Duas das famílias de restrições propostas apresentam um número exponencial de restrições, a que elimina subciclos e a que garante que os itens sejam empacotáveis, o que torna inviável a adição explícita de ambas ao modelo. Portanto, utilizamos a técnica de Branch-and- Cut, adicionando essas restrições apenas quando detectamos que foram violadas. Como resultado conseguimos mais que dobrar o número de soluções ótimas para alguns casos. O restante deste artigo está organizado da seguinte forma. Na Seção 2 apresentamos a definição formal do 2L-CVRPC, as notações que serão utilizadas e a formulação matemática do problema. A Seção 3 apresenta o Problema do Empacotamento Bidimensional com Restrições de Descarregamento (Two-Dimensional Orthogonal Packing Problem With Unloading Constraints - 2OPP-UL) e sua modelagem em Programação por Restrição. A seção 4 detalha as melhorias. Os resultados dos experimentos para o 2L-CVRPC com instâncias adaptadas da literatura e a conclusão são encontrados nas Seções 5 e 6, respectivamente. https://proceedings.science/p/193481?lang=pt-br DOI: 10.59254/sbpo-2024-193481 2. Descrição do 2L-CVRPC e Modelagem em Programação Linear Inteira Nesta seção apresentamos a descrição formal do 2L-CVRPC, e uma modelagem em Programação Linear Inteira (PLI) para o problema, além de melhorias para fortalecer o modelo. Definição 2.1 (2L-CVRPC) Problema do Roteamento de Veículos Capacitados com Restri- ções de Carregamento Bidimensional e Conflitos. Uma instância do 2L-CVRPC é composta por: (i) Um conjunto K de veículos idênticos com compartimento de carga de largura W, altura H e peso suportado D. Os itens devem ser retirados a partir da borda superior do veículo e a remoção dos itens de um cliente não pode ser obstruída por itens a serem descarregados posteriormente. (ii) um grafo completo não direcionado G = (V, E), no qual V = {0, 1, . . . , n} é um conjunto com n + 1 vértices, que correspondem ao depósito (vértice 0) e seus n clientes. Cada aresta (i, j) ∈E representa o caminho entre dois clientes e possui um custo associado cij que é caracterizado pela distância euclidiana entre os vértices. (iii) Cada cliente i ∈{1, . . . , n} apresenta um conjunto Ii de itens, com peso total di. Cada item p ∈Ii tem largura wp e altura hp. (iv) Uma matriz Z, cujo elemento zij assume o valor 1 se e somente se, as demandas dos clientes i e j forem conflitantes. O objetivo é minimizar o custo total percorrido e uma solução deve satisfazer às seguintes restrições: 1. Toda rota começa e termina no depósito; 2. Todos os veículos devem ser utilizados; 3. As demandas de todos os clientes devem ser completamente atendidas; 4. Cada cliente deve ser visitado apenas uma vez e por apenas um veículo; 5. O peso suportado pelo veículo não deve ser excedido; 6. Clientes com itens conflitantes não devem estar na mesma rota; 7. Cada item deve ser alocado em exatamente um veículo; 8. A orientação de cada item é fixa, não são permitidas rotações; 9. Itens não devem se sobrepor ou exceder as bordas do veículo. 10. Os itens devem ser posicionados de forma que possam ser retirados movendo-se no sentido da abertura do contêiner, sem mover itens que serão entregues posteriormente. D 1 2 3 4 5 6 7 8 9 D 1 2 3 4 5 6 7 8 9 1 2 2 3 3 4 5 4 6 7 8 9 (a) Conjunto de 12 itens a serem entregues. D 1 2 3 4 5 6 7 8 9 (b) Conjunto de 5 conflitos entre os clientes. Figura 1: Exemplo de instância do 2L-CVRPC com 9 clientes. https://proceedings.science/p/193481?lang=pt-br DOI: 10.59254/sbpo-2024-193481 D 1 2 3 4 5 6 7 8 9 1 2 2 3 3 4 5 4 6 7 8 9 Figura 2: Exemplo de solução para a instância da Figura 1a, na qual a subrota azul representa o trajeto do veículo 1, a subrota roxa representa o trajeto do veículo 2 e a subrota laranja representa o trajeto do veículo 3. Ao centro de cada trajeto é apresentado o empacotamento dos itens no veículo. A Figura 1 apresenta uma instância do 2L-CVRPC com n = 9 clientes, 3 veículos e 12 itens no total, sendo os itens representados ao lado do cliente de destino. A Figura 1b apresenta os conflitos entre os clientes: 1 −8, 1 −9, 2 −3, 2 −4, 3 −6. A solução para a instância, apresentada na Figura 2, respeita a ordem de descarregamento dos itens nas subrotas, bem como os conflitos. 2.1. Formulação Matemática A formulação em PLI para o 2L-CVRPC é uma adaptação da formulação do VRPC [Hamdi-Dhaoui et al., 2011] com a adição de restrições que satisfaçam o empacotamento com ordem de descarregamento. Apesar do grafo de entrada não ser orientado, nossa formulação utiliza variáveis com três índices [Toth e Vigo, 2014] indicando o sentido em que uma aresta foi percorrida. Mais precisamente, temos variáveis binárias dos tipos αk ij e βk i . Para cada trio i, j e k, αk ij indica que o veículo k percorre a aresta {i, j} no sentido de i para j, enquanto βk i indica que o vértice i é visitado pelo veículo k. Considere P como o conjunto das subrotas cujos itens dos clientes não conseguem ser empacotados naquela ordem. Minimize: |K| X k=1 X i,j∈V :i̸=j cijαk ij (1) Sujeito à: n X i=1 diβk i ≤D, ∀k ∈K (2) |K| X k=1 βk i = 1, ∀i ∈V \\ {0} (3) |K| X k=1 βk 0 = |K| (4) X i∈V :i̸=j αk ij = βk j , ∀j ∈V, ∀k ∈K (5) X j∈V :j̸=i αk ij = βk i , ∀i ∈V, ∀k ∈K (6) https://proceedings.science/p/193481?lang=pt-br DOI: 10.59254/sbpo-2024-193481 X i,j∈S αk ij ≤|S| −1, S ⊆V \\ {0}, 2 ≤|S| ≤n −1, ∀k ∈K (7) X (i,j)∈P αk ij ≤|P| −1, P ∈P, k ∈K (8) n X j=1 zij.βk j ≤n.(1 −βk i ), ∀i ∈V \\ {0}, ∀k ∈K (9) αk ij ∈{0, 1}, ∀i, j ∈V 2, ∀k ∈K (10) βk i ∈{0, 1}, ∀i ∈V, ∀k ∈K (11) O objetivo definido por (1) consiste em minimizar o custo total ao atender a demanda dos clientes. As restrições (2) garantem que o peso total dos itens seja suportado pelo veículo ao qual foram atribuídos. O conjunto de restrições (3) certifica que cada cliente será atendido por exatamente um veículo. A restrição (4) assegura que serão feitas |K| rotas, ou seja, toda a frota será utilizada. As restrições (5) garantem que o veículo chegue ao vértice que lhe foi atribuído, enquanto (6) garantem que ele deve deixar o vértice após a entrega. O conjunto de restrições (7) elimina os subciclos que não contêm o depósito. As restrições (8) garantem que as rotas sejam viáveis em relação ao empacotamento dos itens a ela atribuídos. As restrições (9) asseguram que itens conflitantes não sejam atribuídos à mesma rota. Por fim, as restrições (10) e (11) apontam o domínio das variáveis binárias. É importante ressaltar que o número de subciclos é exponencial, o que impossibilita que todas as restrições (7) sejam inseridas. Recorremos então ao uso de Lazy Constraints para rela- xar esse conjunto de restrições e adicioná-las sob demanda. De modo semelhante, após detectar que a rota passa pelo depósito, é necessário resolver um problema NP-difícil para identificar se ela pertence ao conjunto P. Nesse ponto, surge o Problema do Empacotamento Bidimensional com Restrições de Descarregamento (2OPP-UL), que verifica se o empacotamento de um conjunto de itens é factível ou não. Para resolvê-lo, utilizamos a técnica de Programação por Restrições, abordada mais adiante na Seção 3. 2.2. Separação de Cortes Como as restrições (7) são em número exponencial, o modelo não começa com todas elas. Temos de resolver o problema de separação, a fim de adicionar algumas destas restrições sob de- manda. Para tanto, a partir de uma solução inteira do Branch-and-Bound realizamos uma busca em largura para identificar subciclos, que são ciclos isolados, sem o depósito. Quando encontrado um subciclo, adicionamos a restrição (7) correspondente (L1). Uma variação desse método é adicionar uma restrição correspondente para os possíveis veículos (L2). Caso contrário, se a subrota passa pelo depósito, verificamos sua viabilidade em relação ao empacotamento. Para saber se o empacotamento é ou não viável, é necessário solucionar o 2OPP-UL. Com o objetivo de evitar chamar o solver para empacotamentos que já foram testados antes, armazenamos uma tabela de empacotamentos viáveis e outra de inviáveis. No caso dos empacotamentos viáveis, guardamos a chave (ordem dos nós) e o valor (coordenada x e y) de cada um deles. Para os empa- cotamentos inviáveis, guardamos apenas a ordem dos nós. Se o empacotamento for encontrado na tabela de viáveis, não é necessário inserir qualquer restrição. Se ele já estiver armazenado na tabela de inviáveis, uma restrição do tipo (8) é inserida. O mesmo ocorre se ele não foi encontrado em nenhuma das tabelas e a resolução do 2OPP-UL retornou que o empacotamento era inviável. https://proceedings.science/p/193481?lang=pt-br DOI: 10.59254/sbpo-2024-193481 Além disso, foi proposta uma variação (S) na qual é possível considerar também as sub- sequências ao consultar as tabelas. Seja seq a sequência dos vértices do empacotamento atual. Se seq for subsequência de alguma das chaves da tabela de viáveis, sabemos que seq possui um empacotamento viável. De modo complementar, se alguma sequência da tabela de inviáveis é sub- sequência de seq, então não será necessário resolver novamente o empacotamento para seq, pois sabemos que ela é inviável. Atribuímos as siglas L1, L2 e S às diferentes versões da Lazy Constraints para facilitar a identificação das mesmas na Seção 5. 3. Descrição 2OPP-UL e Modelagem em Programação Por Restrições Nesta seção será abordada a versão de decisão do 2OPP-UL e sua modelagem em programação por restrições. Definição 3.1 (2OPP-UL) Problema do Empacotamento Bidimensional com Restrições de Des- carregamento Uma instância do 2OPP-UL é formada por um contêiner B de altura H e largura W, e um conjunto de itens T, no qual cada item i possui sua respectiva altura hi e largura wi. Em uma solução para este problema, cada item de T deve ser empacotado em B, os itens não devem se sobrepor ou exceder as bordas do contêiner e não é permitido rotacioná-los. Além disso, o empa- cotamento deve respeitar a ordem de descarregamento, os itens que serão retirados primeiro devem estar posicionados próximo à abertura superior de B. Sem perder a generalidade, consideramos as dimensões do contêiner e dos itens como inteiros. 1 2 3 4 5 6 7 8 9 10 11 12 1 2 3 4 B 3 1 2 (a) Instância com contêiner B de altura 3 e largura 4 e o conjunto de 3 itens, cujos números identificam a ordem em que devem ser descarregados. 1 2 3 4 5 1 2 3 4 1 3 2 (b) Solução respeitando sentido de descarregamento. Figura 3: Exemplo para o Problema do Empacotamento com Restrições de Descarregamento. A Figura 3a é um exemplo de uma instância do 2OPP-UL com 3 itens. O item azul tem largura 2 e altura 1 e será descarregado primeiro, o item laranja tem largura 2 e altura 3 e será descarregado após o azul, o último a ser descarregado será o item vermelho, um quadrado com altura e largura iguais a 2. O contêiner é um retângulo com W = 4 e H = 3. Já a Figura 3b apresenta uma solução para essa instância, na qual é possível empacotar os itens com o vermelho no ponto (0, 0), o laranja à direita dele e o azul acima do vermelho. Vale notar que o empacotamento deve ser possível sem rotacionar os itens e que nesse momento não existem conflitos. E em ambas as figuras, a seta indica a direção e sentido do descarregamento. 3.1. Modelagem Matemática Optamos por utilizar a Programação por Restrições (Constraint Programming - CP), método que utiliza um conjunto de variáveis e outro de restrições (condições, propriedades ou re- quisitos) para modelar o problema. As variáveis podem assumir diferentes valores contidos em https://proceedings.science/p/193481?lang=pt-br DOI: 10.59254/sbpo-2024-193481 um conjunto finito, nomeado Domínio. A solução é encontrada pesquisando sistematicamente as possíveis atribuições de valores às variáveis, geralmente guiadas por heurísticas [Smith, 1995]. A solução é considerada viável quando satisfaz todas as restrições. Na modelagem do 2OPP-UL são usadas duas variáveis para cada item i, Xi é a posição da borda esquerda do item no eixo x (direção da largura), e Yi é a posição da borda inferior do item no eixo y (direção da altura). O domínio dessas variáveis é D(Xi) = {0, . . . , W −wi} e D(Yi) = {0, . . . , H −hi} para cada i, com os valores nesses intervalos sendo discretos. Estes domínios asseguram que nenhum item ultrapasse os limites do veículo. Para garantir que os itens não se sobreponham, temos a seguinte restrição para cada par i e j de um mesmo cliente: [Xi + wi ≤Xj] ou [Xj + wj ≤Xi] ou [Yi + hi ≤Yj] ou [Yj + hj ≤Yi] . (12) Caso o item i pertença a um cliente que será visitado antes do cliente que receberá o item j, a seguinte restrição é adicionada para assegurar que os itens serão facilmente retirados pela abertura superior do veículo conforme a ordem de descarregamento: [Xi + wi ≤Xj] ou [Xj + wj ≤Xi] ou [Yj + hj ≤Yi] . (13) 4. Melhorias Foram desenvolvidas melhorias para o modelo apresentado. Ainda que essas novas restrições não sejam necessárias para o funcionamento do modelo, adicioná-las faz com que as soluções sejam encontradas mais rapidamente. Cada melhoria recebeu uma sigla entre parênteses após o seu nome para que possa ser identificada com mais facilidade na Seção 5. Veículos Consecutivos (V): É uma quebra de simetrias para aumentar eficiência, em que restrin- gimos as opções de veículo pelo qual cada um dos |K| primeiros clientes pode ser atendido. Dessa forma o cliente i ∈{1, . . . , |K|} deverá estar em um dos i primeiros veículos. i−1 X k=0 βk i = 1 i ∈{1, . . . , |K|} (14) Adicionando Conflitos por Cliques (C): Considere o grafo Gc = (V, Ec), no qual os vértices são os clientes e as arestas representam os conflitos entre eles. Seja C uma clique em Gc, no 2L-CVRPC ela representa um conjunto de clientes que devem ser atendidos por |C| veículos distintos, já que possuem conflitos com todos os outros clientes que também compõem a clique. Portanto, são inseridas as restrições de que itens da mesma clique não podem ser transportados no mesmo veículo, (15), fortalecendo o modelo. Para essa abordagem, foi uti- lizada a biblioteca Cliquer [Niskanen, 2002] adaptada para C++, que apresenta funções para a busca de Cliques Maximais em grafos. Por meio dessas funções, as cliques são encontradas e adicionadas a uma coleção de cliques C. X i∈C βk i ≤1 k ∈K, C ∈C (15) 5. Resultados Computacionais Todos os modelos e algoritmos descritos foram implementados em C++ e compilados com g++ 9.4 em ambiente Linux utilizando um computador com processador de 2.30GHz e 8GB de memória RAM. O resolvedor de PLI foi o IBM Cplex 22.1 e o resolvedor de CP foi o IBM CP Optimizer 22.1, ambos do mesmo pacote. https://proceedings.science/p/193481?lang=pt-br DOI: 10.59254/sbpo-2024-193481 Os testes foram executados nas instâncias apresentadas por Iori et al. [2007] para o pro- blema do roteamento de veículos com restrições de carregamento bidimensional. Nelas são consi- deradas as classes r = 2, . . . , 5, e o número de itens gerados para cada cliente é um valor inteiro uniformemente aleatório no intervalo [1, r]. Foram selecionadas 95 instâncias, com base no número de clientes, valor que se correlaciona com o nível de dificuldade do problema do roteamento. Opta- mos por realizar os testes com as instâncias que continham até 50 clientes. Para cada instância, uma matriz simétrica de conflitos foi gerada entre os nós (clientes), onde a presença de um conflito é determinada aleatoriamente com base na probabilidade ψ forne- cida, i.e., cada par de nós é avaliado uma vez de modo independente, sendo registrado um conflito entre eles na matriz com probabilidade ψ. Conjecturamos que a presença de conflitos contribui para a complexidade do problema, de modo a torná-lo mais difícil. Porém, parece razoável que uma quantidade excessiva de conflitos limita tanto as escolhas, a ponto de eliminar soluções viáveis e tor- nar o problema mais fácil. Para verificar essas hipóteses, testamos nossos algoritmos com conjuntos de instâncias que apresentam diferentes probabilidades ψ de conflitos: 5%, 10% e 20%. A partir do modelo (1)-(11) do 2L-CVRPC foram implementas as versões de Lazy Cons- traints L1, L2 e S (descritas na Seção 2.2), bem como as melhorias V e C (descritas na Seção 4). Optamos por agrupar essas versões e melhorias em configurações incrementais, verificando o tempo em que cada uma consegue resolver as instâncias. Por exemplo, enquanto L1 corresponde à implementação do modelo (1)-(11) apenas com a primeira variação da Lazy Constraint, L1VSC indica que foram adicionadas as melhorias V, S e C. Os resultados dos testes são apresentados por meio de gráficos de perfis de desempenho (performance profiles) [Dolan e Moré, 2002], utilizados para comparar o desempenho de vários algoritmos sobre um conjunto de instâncias. Dada uma instância, temos a solução de cada algoritmo e a melhor solução obtida entre eles. Assim, para cada algoritmo podemos calcular a razão entre sua solução e a melhor obtida, o que chamamos de performance gap. O eixo y do gráfico representa a porcentagem das instâncias, enquanto o eixo x corresponde ao performance gap. Nos gráficos abaixo, cada curva representa uma configuração do nosso algoritmo, identificada pelas siglas das melhorias e variações de parâmetro que a compõem. Em perfis de desempenho, consideramos que a curva com uma maior área sob ela fornece os melhores resultados. Vale ressaltar que, independente das melhorias, com tempo suficiente é possível atingir uma solução ótima. Contudo, o algoritmo para solucionar o empacotamento pode ser chamado di- versas vezes durante a solução de uma instância. Por isso, limitamos a 60 segundos o tempo de execução do solver para cada empacotamento, de forma que não sendo encontrado um empacota- mento nesse tempo ele é considerado inviável. Quando esse tempo é excedido, não garantimos a solução ótima, mas é possível identificar os casos em que isso ocorre durante a execução. Se de- sejável, pode-se não limitar o tempo do empacotamento para garantir soluções ótimas. Além disso, o tempo total de execução do solver para o 2L-CVRPC foi limitado a 10 minutos. A Figura 4a apresenta a comparação entre as variações do algoritmo para instâncias com 5% de chance de conflito. Nela é possível notar que a configuração L1+V obteve as melhores soluções para um pouco menos de 70% das instâncias. No entanto, a variação L1V + S obteve melhor desempenho geral. A Figura 4b monstra que para as instâncias com 10% de conflitos ini- cialmente L1VS + C está acima das demais variações, com as melhores soluções para aproxima- damente 70% das instancias. A Figura 4c apresenta a comparação das configurações do algoritmo para 20% de conflitos . É possível observar que a configuração L2VSC inicialmente obteve as me- lhores soluções para cerca de 60% das instâncias. Entretanto, a variação do algoritmo com melhor performance para esse tipo de instância foi L1V + S. Por fim, as Tabelas 1, 2 e 3 mostram os tempos médios de resolução das instâncias por https://proceedings.science/p/193481?lang=pt-br DOI: 10.59254/sbpo-2024-193481 1.00 1.01 1.05 1.20 40 50 60 70 80 90 100 L1 L1 + V L1V + S L1VS + C L2VSC (a) 5% de conflito. 1.00 1.01 1.05 1.20 40 50 60 70 80 90 100 L1 L1 + V L1V + S L1VS + C L2VSC (b) 10% de conflito. 1.00 1.01 1.05 1.20 40 50 60 70 80 90 100 L1 L1 + V L1V + S L1VS + C L2VSC (c) 20% de conflito. Figura 4: Comparação do impacto de cada variação do algoritmo de acordo com quantidade de conflitos. O eixo x está em escala logarítmica. L1 L1 + V L1V + S L1VS + C L2VSC Nº de Clientes Freq. T(s) MIP Gap O T(s) MIP Gap O T(s) MIP Gap O T(s) MIP Gap O T(s) MIP Gap O 15 10 331.1471 0.0240 7 101.5001 0 10 98.2511 0 10 60.8627 0 10 98.4405 0 10 20 10 599.8310 0.2377 0 599.9343 0.2075 0 599.8813 0.2039 0 586.3614 0.1313 1 562.8862 0.1147 2 21 10 603.9915 0.2267 0 511.4724 0.1167 2 511.6644 0.1149 2 488.9257 0.1765 3 457.3420 0.1155 4 22 10 513.5859 0.2377 2 472.2166 0.1431 3 462.5440 0.1364 3 498.5674 0.1143 2 435.1564 0.1418 3 25 5 599.8284 0.4367 0 599.8290 0.3755 0 599.8128 0.3782 0 610.6572 0.3921 0 605.6800 0.3968 0 29 10 614.7983 0.8255 0 613.3976 0.7586 0 613.6164 0.7586 0 628.1025 0.8023 0 608.2360 0.7820 0 30 5 599.6054 0.6734 0 599.8174 0.4457 0 599.8150 0.4416 0 599.8172 0.5299 0 599.9470 0.4160 0 32 15 608.0855 0.6846 0 600.2618 0.7469 1 589.6103 0.7469 1 611.6827 0.7375 1 620.1259 0.7533 0 35 5 599.8896 0.5567 0 599.9032 0.4443 0 599.8482 0.4434 0 599.8636 0.4240 0 599.8594 0.5348 0 40 5 599.9438 0.6866 0 599.9238 0.4226 0 599.8748 0.4262 0 599.8700 0.6541 0 599.8426 0.5391 0 44 5 609.4168 0.8972 0 606.2882 0.9028 0 600.5114 0.9028 0 641.6902 0.9035 0 619.2332 0.8913 0 50 5 602.4476 0.8827 0 610.0710 0.7786 0 607.7836 0.7786 0 648.4444 0.8863 0 601.9782 0.8788 0 Total 566.42608 0.48897 9 527.03474 0.42431 16 523.59953 0.42312 16 529.52790 0.44481 17 516.37054 0.43289 19 Tabela 1: Instâncias com 5% de conflito. L1 L1 + V L1V + S L1VS + C L2VSC Nº de Clientes Freq. T(s) MIP Gap O T(s) MIP Gap O T(s) MIP Gap O T(s) MIP Gap O T(s) MIP Gap O 15 10 392.3338 0.0356 6 33.2287 0 10 35.3723 0 10 47.9242 0 10 54.4216 0 10 20 10 600.9447 0.2489 0 546.9822 0.1090 2 556.8915 0.1168 1 554.7576 0.1074 2 531.2450 0.1265 3 21 10 599.8443 0.2634 0 547.7539 0.1306 2 553.3225 0.1475 2 592.8609 0.1330 1 599.8161 0.1244 0 22 10 562.9176 0.1859 1 442.5485 0.1497 3 434.7599 0.1618 3 460.5798 0.1254 3 470.1541 0.1487 3 25 5 599.8660 0.3854 0 599.5652 0.3681 0 599.7970 0.3837 0 599.8504 0.3431 0 599.7966 0.2894 0 29 10 554.8653 0.6935 1 555.7751 0.7289 1 552.3565 0.7333 1 555.7283 0.6977 1 552.4993 0.6883 1 30 5 600.1712 0.6779 0 599.8750 0.5629 0 600.1292 0.5674 0 599.8638 0.4344 0 599.8802 0.5738 0 32 15 621.3685 0.7189 0 573.1391 0.6673 1 571.7273 0.6715 1 572.6989 0.6583 1 583.7232 0.6568 1 35 5 610.3860 0.5402 0 599.9404 0.6590 0 599.9096 0.6645 0 602.1816 0.5697 0 599.9072 0.6664 0 40 5 600.6300 0.5533 0 599.8782 0.4426 0 602.0546 0.4457 0 599.8956 0.7877 0 599.8782 0.6531 0 44 5 600.1628 0.8347 0 651.1200 0.8828 0 604.3222 0.8839 0 610.2218 0.8855 0 606.5514 0.8185 0 50 5 619.3536 0.8937 0 615.9080 0.8942 0 625.1730 0.8947 0 611.1010 0.8846 0 607.4020 0.8834 0 Total 574.55191 0.46824 8 507.27795 0.42356 19 505.89330 0.43017 18 513.94276 0.42141 18 514.78198 0.42267 18 Tabela 2: Instâncias com 10% de conflito. número de clientes. Apresentamos nestas tabelas a quantidade de instâncias por número de clientes “Freq.”, a comparação dos tempos médios “T(s)”, MIP Gap médio e número de soluções ótimas encontradas “O”. O MIP gap é dado por lp−ld lp , onde lp é o limitante primal e ld é o limitante dual. Quando a inviabilidade de uma instância é comprovada, fazemos Mip gap igual a 0. Caso uma solução viável não seja encontrada, consideramos o Mip gap como 1. Na Tabela 1 podemos notar que, adicionando as melhorias encontramos soluções ótimas para instâncias em que anteriormente o ótimo não havia sido atingido no limite de tempo. Para instâncias com mais de 32 clientes, a dificuldade aumenta significativamente, como evidenciado pela ausência de soluções ótimas. Na Tabela 2 obtivemos o maior número de soluções ótimas na configuração L1 + V, além de redução de tempo médio para a maioria das categorias de cliente. Por último, na Tabela 3 podemos notar que, como conjecturado, foi possível resolver de modo ótimo https://proceedings.science/p/193481?lang=pt-br DOI: 10.59254/sbpo-2024-193481 L1 L1 + V L1V + S L1VS + C L2VSC Nº de Clientes Freq. T(s) MIP Gap O T(s) MIP Gap O T(s) MIP Gap O T(s) MIP Gap O T(s) MIP Gap O 15 10 268.2909 0.0184 8 18.3814 0 10 12.2314 0 10 10.2004 0 10 8.8938 0.0000 10 20 10 599.8118 0.2363 0 524.4688 0.1182 3 524.0891 0.1178 3 452.5543 0.1093 3 471.9124 0.1114 3 21 10 599.8198 0.3003 0 423.5886 0.0726 5 419.2479 0.0697 5 418.7724 0.0882 4 407.7764 0.0929 5 22 10 546.2055 0.1989 1 476.8498 0.0945 3 443.3649 0.0864 4 441.9067 0.0947 4 434.0243 0.1082 4 25 5 599.8184 0.4029 0 603.7512 0.3883 0 599.1742 0.3862 0 599.7508 0.3674 0 597.1474 0.3492 0 29 10 543.5316 0.6752 1 544.1061 0.6760 1 547.8203 0.6760 1 559.5059 0.5649 1 628.5426 0.6759 1 30 5 599.8452 0.5650 0 602.4672 0.5683 0 599.7942 0.5677 0 611.6638 0.5284 0 599.4386 0.5437 0 32 15 565.7979 0.5776 1 566.3696 0.4521 1 567.7471 0.4506 1 569.2544 0.5374 1 568.4584 0.6441 1 35 5 599.8558 0.5665 0 599.7854 0.5401 0 599.8474 0.5453 0 599.8644 0.6542 0 599.8164 0.5497 0 40 5 599.9134 0.6788 0 599.8250 0.5671 0 599.8798 0.5671 0 600.0000 1.0000 0 599.7980 0.4510 0 44 5 560.0536 0.7297 1 482.4860 0.8000 1 482.4020 0.8000 1 481.7938 0.7128 1 484.2106 0.7234 1 50 5 615.7620 0.9083 0 599.9282 0.9005 0 599.9640 0.9005 0 613.2106 0.8978 0 599.9800 0.8910 0 Total 546.73480 0.44434 12 482.21795 0.37070 24 477.77948 0.36938 25 472.62769 0.39405 24 478.31922 0.39036 25 Tabela 3: Instâncias com 20% de conflito. mais instâncias com alta probabilidade de conflitos, inclusive para uma instância com 44 clientes. No geral, as melhorias colaboraram para uma leve redução no tempo de execução, e pos- sibilitaram a ampliação do número de soluções ótimas encontradas. Além disso, comparando os resultados para instâncias com 20% de conflitos em contraste com aquelas com 10% ou 5%, pode- mos observar que para as primeiras foi obtido maior número de soluções ótimas em menor tempo. Isto corrobora nossa hipótese de que muitos conflitos acabam simplificando o problema ao eliminar soluções viáveis. Por outro lado, não observamos diferenças significativas no tempo ou qualidade das soluções obtidas ao variar os conflitos entre 5% e 10%. Parece interessante em trabalhos futuros testar instâncias com menos conflitos, para avaliar o impacto nos resultados. 6. Conclusões Neste artigo abordamos o 2L-CVRPC que combina o problema do roteamento de veículos com o problema do empacotamento bidimensional com conflitos. Apresentamos um modelo em PLI para o problema que possui um número exponencial de restrições, aquelas que eliminam subciclos e conjuntos de itens que não são empacotáveis em um mesmo veículo. Por esse motivo, não adicio- namos essas restrições a priori, mas apenas quando detectamos que uma delas foi violada durante o Branch-and-Cut. Notadamente, descobrir se um conjunto de itens possui um empacotamento em um contêiner é um problema NP-Difícil. Para resolver o problema do empacotamento utilizamos uma formulação em Programação por Restrições. Para a Formulação em PLI foram apresenta- das duas melhorias envolvendo pré-processamentos e quebras de simetria, que, juntamente com as variações da Lazy Constraint, possibilitaram o aumento no número de soluções ótimas encontradas. Nos próximos passos desta pesquisa pretendemos melhorar o desempenho do algoritmo apresentado, por meio de novas abordagens, como heurísticas de inicialização, novas rotinas de separação e outras formas de quebra de simetria."
        },
        {
            "titulo": "OTIMIZAÇÃO DE RECEITAS NO TRANSPORTE FERROVIÁRIO DE PASSAGEIROS: UMA ABORDAGEM DE PROGRAMAÇÃO INTEIRA MISTA",
            "informacoes_url": "https://proceedings.science/p/193699?lang=pt-br",
            "idioma": "português",
            "storage_key": "galoa-proceedings--sbpo-2024--193699.pdf",
            "autores": [
                {
                    "nome": "Urango, W. N.",
                    "afiliacao": "Universidade Estadual de Campinas (UNICAMP)",
                    "orcid": ""
                },
                {
                    "nome": "Fiorotto, D. J.",
                    "afiliacao": "Universidade Estadual de Campinas (UNICAMP)",
                    "orcid": ""
                },
                {
                    "nome": "Martinez, K. P.",
                    "afiliacao": "ExPretio Technologies",
                    "orcid": ""
                },
                {
                    "nome": "De Sousa, V.",
                    "afiliacao": "ExPretio Technologies",
                    "orcid": ""
                }
            ],
            "data_publicacao": "",
            "resumo": "O revenue management se encarrega de otimizar as receitas ao comercializar um produto ou serviço, ao mesmo tempo que responde a perguntas como: quais produtos vender? A quem vender esses produtos? Em que momento devem ser vendidos? E qual é o melhor preço de venda?. O revenue management é aplicado a diferentes indústrias. Este trabalho é aplicado ao transporte ferroviário de passageiros, onde se propõe um modelo misto inteiro, levando em consideração uma demanda independente. O modelo foi aplicado a instâncias reais. Entre as principais observações, notou-se que as soluções ótimas são encontradas explorando no máximo 1 nó, tanto para instâncias médias (de 115 e 215 origem-destino) quanto grandes (de 256 origem-destino), e que os tempos para encontrar essas soluções são relativamente altos.",
            "keywords": [
                "Modelagem Matemática",
                "Programação Mista Inteira",
                "Transporte Ferroviário de Passageiros"
            ],
            "referencias": [
                "An, J., Mikhaylov, A., e Jung, S.-U. (2021). A linear programming approach for robust network revenue management in the airline industry. Journal of Air Transport Management, 91:101979.",
                "Ciancimino, A., Inzerillo, G., Lucidi, S., e Palagi, L. (1999). A mathematical programming approach for the solution of the railway yield management problem. Transportation Science.",
                "Zhao, X. e Zhao, P. (2019). A seat assignment model for high-speed railway ticket booking system with customer preference consideration. Transportmetrica A Transport Science, 15(2):776–806."
            ],
            "artigo_completo": "OTIMIZAÇÃO DE RECEITAS NO TRANSPORTE FERROVI ÁRIO DE PASSAGEIROS: UMA ABORDAGEM DE PRORAMAÇÃO INTEIRA MISTA. RESUMO O revenue management se encarrega de otimizar as receitas ao comercializar um produto ou serviço, ao mesmo tempo que responde a perguntas como: quais produtos vender? A quem vender esses produtos? Em que momento devem ser vendidos? E qual é o melhor preço de venda?. O revenue management é aplicado a diferentes indústrias. Este trabalho é aplicado ao transporte ferroviário de passageiros, onde se propõe um modelo misto inteiro, levando em consideração uma demanda independente. O modelo foi aplicado a instâncias reais. Entre as principais observações, notou-se que as soluções ótimas são encontradas explorando no máximo 1 nó, tanto para instâncias médias (de 115 e 215 origem-destino) quanto grandes (de 256 origem-destino), e que os tempos para encontrar essas soluções são relativamente altos. PALAVRAS CHAVE. Modelagem Matemática, Programação Mista Inteira, Transporte Fer- roviário de Passageiros Tópicos (PM - Programação Matemática, L&T - Logística e Transportes) 1. Introdução A gestão de receitas (RM, do inglês Revenue Management) se concentra principalmente em prever a demanda, enquanto ajusta o preço e a disponibilidade de produtos para corresponder a essa demanda An et al. [2021]. Inicialmente, o campo de RM foi desenvolvido pela indústria aérea, mas foi aplicado com sucesso a outros setores industriais, como hospitalidade, restaurantes, varejo, serviços de aluguel e transporte de passageiros em geral Ciancimino et al. [1999]. O objetivo dos sistemas de RM é otimizar a disponibilidade e o preço dos produtos para gerar a máxima quantidade de receita possível. Em particular, o principal objetivo da RM no transporte ferroviário de passageiros pode ser ilustrado com o seguinte exemplo: um operador de transporte define um itinerário para um trem específico, no qual se especificam a origem, o destino e o horário de partida. Os clientes, ou seja, os possíveis passageiros, podem comprar bilhetes antecipadamente para viajar nesse trem. Referimo-nos às classes comerciais ou produtos tarifários como os bilhetes disponíveis para venda; e ao horizonte de reserva como o período de tempo decorrido entre o momento em que os bilhetes estão disponíveis pela primeira vez para compra e a partida do trem. O horizonte de reserva ge- ralmente é dividido em dias, de modo que cada período representa um certo dia (ou conjunto de dias) antes da partida. O principal objetivo da RM neste contexto é controlar a disponibilidade dos produtos tarifários ao longo do horizonte de reserva para maximizar a receita total. Mais especifica- mente, o processo de otimização visa determinar a quantidade de bilhetes de cada produto que deve estar disponível para venda em cada período do horizonte de reserva, a fim de maximizar a receita associada a cada partida de trem. Um dos elementos-chave para maximizar as receitas totais é um modelo preciso da de- manda. Combinar a oferta e a demanda para otimizar as receitas implica compreender como pen- sam os clientes e requer uma previsão precisa das ações dos clientes quando se deparam com uma determinada oferta de produtos Zhao e Zhao [2019]. Para os fins deste trabalho, usamos uma simplificação do comportamento da demanda e assumimos que ela é independente, o que signi- fica que cada cliente compra um produto específico independentemente da oferta disponível no momento da compra. 2. Modelagem Matematica O modelo proposto é baseado em fluxo e leva em consideração uma demanda indepen- dente. Além disso, o modelo segue o seguinte raciocínio: imagine que existe um grupo de pessoas que deseja viajar de E1 a E2 em um trem com capacidade de 10 assentos, e que o horizonte de reserva abrange dois períodos, P1 e P2 (onde P2 é o dia de partida). Suponha que a previsão de demanda seja maior em P2 do que em P1. Nesse caso, é necessário controlar para que não se- jam disponibilizados todos os assentos para venda em P1, a fim de aproveitar a maior demanda https://proceedings.science/p/193699?lang=pt-br de P2. Portanto, deve-se ”assegurar”assentos em P1 para não disponibilizá-los nesse período. Es- ses assentos assegurados são representados como ”X”, e as variáveis correspondentes aos assentos disponibilizados para venda são denominadas ”Y”. Assim, se se deseja disponibilizar apenas 3 assentos no período P1, teríamos Y = 3 e X = 7. No caso de querer disponibilizar o restante dos as- sentos em P2, teríamos Y = 7 e X = 0, assumindo que todos os bilhetes disponibilizados no período P1 tenham sido vendidos. O modelo completo é o seguinte: Conjuntos O : Conjunto de Estações de Origem OD : Conjunto de Origem-Destino com itinerario NAD: Conjunto de Origem-Destino que N ÃO são Adjacentes e que tem itinerario V : Conjunto de vagões do trem Kv: Conjunto de Classes comerciais de cada vagão em V T : Conjunto de Check-Points (Períodos) Parâmetros Q : Capacidade do trem Pijvk : Preços das passagem no Origem-Destino (i, j), vagão v e Classe de Control k, con (i, j) ∈ OD, v ∈V, k ∈Kv Dijvkt: Demanda das passagem no Origem-Destino (i, j), vagão v e Classe de Control k, con (i, j) ∈OD, v ∈V, k ∈Kv, t ∈T Variáveis de decisão Xijvkt : Quantidade de passagem segurados no Origem-Destino (i, j), vagão v e com classe de control k no período t, com (i, j) ∈OD, v ∈V, k ∈Kv, t ∈T Yijvkt : Quantidade de passagem autorizados no Origem-Destino (i, j), vagão v e com classe de control k no período t, com (i, j) ∈OD, v ∈V, k ∈Kv, t ∈T BNAijvkt: É uma variavel binaria que toma o valor de 1 quando Yijvkt ̸= 0 e toma valor de 0 caso contrario, aplica-se apenas a Origem-Destino que não são adjacentes, con (i, j) ∈NAD, v ∈ V, k ∈Kv, t ∈T Variável auxiliar Ai : Quantidade de assentos vazios disponíveis para venda na estação i ∈I ao longo do horizonte de reserva Observação: Um Origem-Destino é considerado adjacente se conecta diretamente a origem e o destino sem quaisquer outras estações intermediárias entre eles, caso contrário, eles não serão adja- centes. Por outro lado, a variável Ai é uma variável auxiliar utilizada para armazenar o número de assentos vazios em cada estação de origem no horizonte de reserva. Max Z = X (i,j)∈OD X v∈V X k∈Kv X t∈T PijvkXijvkt (1) s.a. Ai = Ai−1 − X (i,j)∈OD/j≥i X v∈V X k∈Kv X t∈T Xi−1,j,v,k,t + X (i,j)∈OD/j<i X v∈V X k∈Kv X t∈T Xjivkt, ∀i ∈O (2) X (i,j)∈OD X v∈V X k∈Kv X t∈T Xijvkt ≤Ai, ∀i ∈O/i < j, i < n (3) Yijvkt ≥Yi,j,v,k+1,t, ∀(i, j), v, k, t/i < j, k < ∥K∥, Pijvk ≥Pi,j,v,k+1 (4) Xijvkt ≤Dijvkt, ∀(i, j), v, k, t/i < j (5) https://proceedings.science/p/193699?lang=pt-br X (i,j)∈OD X v∈V X t∈T Yi,j,v,k,t ≤Q, k = min{Kv}, ∀i ∈OD (6) Yi,j,v,k,t ≥Xi,j,v,k,t, k = max{Kv}, ∀(i, j), v, t (7) Yi,j,v,∥Kv∥−k,t ≥Xi,j,v,∥Kv∥−k,t + Yi,j,v,∥Kv∥k+1,t, ∀(i, j), v, k ∈Kv/k ≤∥Kv∥−1, t ∈T (8) BNAo,d,v,k,t ≤Yo,d,v,k,t ≤BNAo,d,v,k,tQ, ∀(o, d) ∈NAD, v, k, t (9) BNAo,d,v,k,t ≤Yi,j,v,k,t ≤BNAo,d,v,k,tQ, ∀(o, d) ∈NAD, (i, j) ∈BRI(o,d), v, k, t (10) X0,j,v,k,t = 0, ∀j, k, t (11) A0 = Q (12) Xijvkt, Yijvkt, Ai ∈Z+, BNAijvkt ∈{0, 1} (13) Onde a equação 1 é a função objetivo e representa a soma do produto das variáveis garan- tidas pelo preço correspondente; a equação 2 é uma restrição de fluxo que calcula a disponibilidade do trem (assentos vazios) em cada estação de origem; a restrição 3 garante que o número de assentos garantidos não exceda a capacidade do trem em cada estação de origem; a restrição 4 é de hierarquia e garante que a quantidade de assentos autorizados (ou disponíveis para venda) para as classes mais caras seja maior que para as classes mais baratas; a restrição 5 garante que as quantidades garantidas não excedam a demanda; a restrição 6 garante que a classe mais cara para cada Origem-Destino não exceda a capacidade do trem; as restrições 7 e 8 são as restrições que relacionam as variáveis de garantia e de autorizações; as restrições 9 e 10 são projetadas para aqueles Origens-Destinos que contêm outros Origem-Destino e garantem que as classes dos Origem-Destino contidos dentro de outros mantenham a mesma estrutura das classes daqueles que os contêm; as restrições 11 e 12 são de inicialização, e a restrição 13 corresponde às restrições de domínio das variáveis de decisão. 3. Experimentos e resultados computacionais O modelo foi executado em uma máquina com sistema operacional de 64 bits, Windows 11 Pro, processador 13th Gen Intel(R) Core(TM) i7-13700T de 1,40 GHz e com 16 GB de RAM. Além disso, foram utilizadas a linguagem de programação Python 9.10 e o solucionador Gurobi na versão 10.0.3. As instâncias analisadas são reais e foram fornecidas por uma empresa canadense. Ressalta-se que cada instância foi executada apenas uma vez, pois o problema está sendo resolvido exatamente. Instância Característica [OD,PeríodoÇlass] Tempo Solução N° Nós Explorado N° Iterações N° Soluções Z I1 [256, 5, 15] 57,62 0 0 1 28633,95 I2 [256, 10, 15] 126,20 0 0 1 59786,82 I3 [256, 20, 15] 336,35 1 1373 9 88837,17 I4 [256, 40, 15] 812,56 1 3490 10 95368,87 I5 [215, 5, 15] 24,88 0 0 1 49676,24 I6 [215, 10, 15] 62,11 0 0 1 69815,41 I7 [215, 20, 15] 153,28 1 1591 10 75814,29 I8 [215, 40, 15] 404,10 1 4984 10 76475,68 I9 [150, 5, 15] 3,25 0 0 1 48396,59 I10 [150, 10, 15] 7,87 0 0 1 74597,84 I11 [150, 20, 15] 19,88 1 658 8 87890,45 I12 [150, 40, 15] 45,85 1 1337 10 88123,45 Tabela 1: Resultado ótimo das instâncias aplicando o modelo proposto https://proceedings.science/p/193699?lang=pt-br Onde o tempo de solução está em segundos; as características entre colchetes são o número de Origens-Destinos da instância, o número de períodos e o número de classes comerci- ais respectivamente, e Z é o valor ótimo encontrado. 4. Conclusões Dos resultados na Tabela 1, pode-se mencionar que: 1) A formulação proposta é eficiente quando se trata de encontrar a solução ótima no espaço de busca, pois basta explorar o primeiro nó para encontrá-la. 2) O problema tem múltiplas soluções a partir de instâncias de tamanho médio, por exemplo, as instâncias I3, I4, I7, I8, I11, I12. Isso dá a possibilidade de revisar os valores das variáveis e verificar quais são mais convenientes para aplicar na prática, sob critérios adicionais. 3) Os tempos necessários para encontrar a solução não são atraentes para o âmbito empresarial, pois são muito altos, e é preciso lembrar que cada instância representa apenas um trem para uma única viagem."
        },
        {
            "titulo": "Heurísticas construtivas e busca local para o problema job shop flexível com flexibilidade de sequência e efeito de aprendizado",
            "informacoes_url": "https://proceedings.science/p/193581?lang=pt-br",
            "idioma": "português",
            "storage_key": "galoa-proceedings--sbpo-2024--193581.pdf",
            "autores": [
                {
                    "nome": "Kennedy A. G. Araújo",
                    "afiliacao": "Departamento de Matemática Aplicada, IME-USP, Universidade de São Paulo",
                    "orcid": ""
                },
                {
                    "nome": "Ernesto G. Birgin",
                    "afiliacao": "Departamento de Ciência da Computação, IME-USP, Universidade de São Paulo",
                    "orcid": ""
                },
                {
                    "nome": "Débora P. Ronconi",
                    "afiliacao": "Departamento de Engenharia de Produção, EPUSP, Universidade de São Paulo",
                    "orcid": ""
                }
            ],
            "data_publicacao": "",
            "resumo": "Este artigo explora o problema job shop flexível com flexibilidade de sequência e efeito de aprendizado (FJSSFLE). Apresentamos duas heurísticas construtivas baseadas em regras de despacho juntamente com uma busca local que usa uma vizinhança reduzida para resolver o problema. Apresentamos experimentos computacionais que mostram sua eficácia para achar boas soluções para instâncias de pequeno e grande porte do FJSSFLE, e também evidencia vantagens e desvantagens de cada método.",
            "keywords": [
                "Job shop flexível",
                "Heurísticas Construtivas",
                "Regras de despacho",
                "Busca Local",
                "Otimização Combinatória"
            ],
            "referencias": [
                "Álvarez-Valdés, R., Fuertes, A., Tamarit, J. M., Giménez, G., e Ramos, R. (2005). A heuristic to schedule flexible job-shop in a glass factory. European Journal of Operational Research, 165(2): 525–534.",
                "Andrade-Pineda, J. L., Canca, D., González-R, P. L., e Calle, M. (2020). Scheduling a dual-resource flexible job shop with makespan and due date-related criteria. Annals of Operations Research, 291(1): 5–35.",
                "Birgin, E. G., Feofiloff, P., Fernandes, C. G., De Melo, E. L., Oshiro, M. T. I., e Ronconi, D. P. (2014). A MILP model for an extended version of the flexible job shop problem. Optimization Letters, 8(4): 1417–1431.",
                "Cormen, T. H., Leiserson, C. E., Rivest, R. L., e Stein, C. (2022). Introduction to Algorithms. The MIT Press, Cambridge, MA, USA, 4th edition.",
                "De Moerloose, P., e Maenhout, B. (2023). A two-stage local search heuristic for solving the steelmaking continuous casting scheduling problem with dual shared-resource and blocking constraints. Operational Research, 23(1): 2.",
                "Gan, P. Y., e Lee, K. S. (2002). Scheduling of flexible-sequenced process plans in a mould manufacturing shop. The International Journal of Advanced Manufacturing Technology, 20(3): 214–222.",
                "Leung, J. Y.-T., Li, H., e Pinedo, M. (2005). Order scheduling in an environment with dedicated resources in parallel. Journal of Scheduling, 8(5): 355–386.",
                "Lunardi, W. T., Birgin, E. G., Laborie, P., Ronconi, D. P., e Voos, H. (2020). Mixed integer linear programming and constraint programming models for the online printing shop scheduling problem. Computers and Operations Research, 123: 105020.",
                "Lunardi, W. T., Birgin, E. G., Ronconi, D. P., e Voos, H. (2021). Metaheuristics for the online printing shop scheduling problem. European Journal of Operational Research, 293(2): 419–441.",
                "Mastrolilli, M., e Gambardella, L. M. (2000). Effective neighbourhood functions for the flexible job shop problem. Journal of Scheduling, 3(1): 3–20.",
                "Yu, L., Zhu, C., Shi, J., e Zhang, W. (2017). An extended flexible job shop scheduling model for flight deck scheduling with priority, parallel operations, and sequence flexibility. Scientific Programming, 2017: 1–15."
            ],
            "artigo_completo": "Heurísticas construtivas e busca local para o problema job shop flexível com flexibilidade de sequência e efeito de aprendizado. RESUMO Este artigo explora o problema job shop flexível com flexibilidade de sequência e efeito de aprendizado (FJSSFLE). Apresentamos duas heurísticas construtivas baseadas em regras de des- pacho juntamente com uma busca local que usa uma vizinhança reduzida para resolver o problema. Apresentamos experimentos computacionais que mostram sua eficácia para achar boas soluções para instâncias de pequeno e grande porte do FJSSFLE, e também evidencia vantagens e desvanta- gens de cada método. PALAVRAS CHAVE. Job shop flexível, Heurísticas Construtivas, Regras de despacho, Busca Local. Otimização Combinatória https://proceedings.science/p/193581?lang=pt-br DOI: 10.59254/sbpo-2024-193581 1. Introdução O job shop flexível (FJS) com flexibilidade de sequenciamento é um ambiente de produção com uma ampla gama de aplicações práticas relevantes, especialmente na indústria de impressão sob demanda atualmente [Lunardi et al., 2020, 2021]. Hoje, empresas no ramo de impressão sob demanda devem lidar com produção personalizada e priorizar a entrega pontual em um esforço para atender às necessidades de seus clientes. Nesse contexto, as atividades de produção são organizadas em máquinas flexíveis para gerenciar melhor a execução da ampla gama de tarefas demandadas. Outros ramos que se encaixam nesse ambiente de produção incluem a indústria de vidro [Alvarez- Valdes et al., 2005], a indústria de moldes [Gan e Lee, 2002], o agendamento de operações de suporte de aeronaves em decks de voo [Yu et al., 2017], o agendamento de pedidos de reparo em oficinas de reparo de colisão automotiva [Andrade-Pineda et al., 2020] e a construção de programas de produção para a produção de aço [De Moerloose e Maenhout, 2023]. Portanto, é importante que os métodos de resolução estejam preparados para lidar com as mais diversas características dos problemas reais encontrados neste ambiente de produção. Um desses fatores é o efeito de aprendizado, ou seja, como o tempo de processamento de uma operação varia com o número de vezes que é executada. Naturalmente, o uso de tempos de processamento que não são totalmente consistentes com a realidade pode levar a cronogramas imprecisos e resultar em perdas econômicas significativas. O problema FJS é uma extensão do problema clássico job shop (JS), no qual cada opera- ção pode ser processada por uma entre um conjunto de máquinas, em vez de uma única máquina. Essa característica é conhecida como flexibilidade de roteamento. Duas características adicionais são consideradas no presente trabalho: flexibilidade de sequenciamento e efeito de aprendizado. No FJS sem flexibilidade de sequenciamento, existe o conceito de uma tarefa, que consiste em um conjunto de operações que devem respeitar uma ordem sequencial de execução (primeiro a primeira operação, depois a segunda, depois a terceira, etc). A flexibilidade de sequenciamento consiste em considerar que as precedências entre as operações de uma mesma tarefa são dadas por um grafo ací- clico direcionado (DAG) arbitrário. Em um problema de agendamento clássico, dada uma operação e uma máquina que pode processar essa operação, é dado um tempo de processamento fixo que cor- responde ao tempo demandado pela máquina para processar a operação. O efeito de aprendizado corresponde ao adicional da vida real que consiste no fato de que uma pessoa aprende através da execução de uma tarefa repetitiva e, quanto mais vezes a executam, mais rápido o fazem. Neste trabalho, consideramos uma função de aprendizado que depende da posição que uma operação ocupa dentro da lista de operações executadas por uma máquina, ou seja, uma função de efeito de aprendizado baseada na posição com o objetivo de minimizar o maior tempo de completação, i.e. o makespan. O restante deste artigo está organizado da seguinte forma. Na Seção 2, construímos solu- ções viáveis para o problema, que podem ser representadas por DAG, através de heurísticas cons- trutivas. Na Seção 3, introduzimos o conceito de vizinhança, analisamos diferentes estratégias para a busca local. A Seção 4 é dedicada a experimentos numéricos com os métodos propostos. Conclu- sões e direções futuras de trabalho são apresentadas na seção final. 2. Heurísticas Construtivas Os dados de uma instância do FJSSFLE baseado na posição consistem em (a) um conjunto de operações O e um conjunto de máquinas F; (b) para cada operação i ∈O, um subconjunto Fi ⊆F contendo as máquinas que podem processar i; (c) para cada par operação-máquina (i, k) com i ∈O e k ∈Fi, um tempo de processamento padrão pik; e (d) um conjunto de arcos bA ⊆ O×O representando as relações de precedência entre as operações. O efeito de aprendizado é dado por uma função ψα(p, r) que, dado um tempo de processamento padrão p e uma posição r, retorna https://proceedings.science/p/193581?lang=pt-br DOI: 10.59254/sbpo-2024-193581 o tempo de processamento real de uma operação com tempo de processamento padrão p quando processada na r-ésima posição de uma máquina. O parâmetro α > 0 representa a taxa de efeito de aprendizado. No trabalho atual, consideramos ψα(p, r) = ⌊100·p/rα+1/2⌋. Um exemplo simples de uma instância é mostrado na Figura 1. Uma solução viável para uma instância do FJS com flexibilidade de sequenciamento e efeito de aprendizado baseado na posição pode ser representada por um DAG G = (V, A) con- forme mostrado na Figura 2a. Esse grafo é às vezes referido como grafo de solução na literatura. Os vértices de G, representados pelo conjunto V , correspondem às operações mais os vértices fic- tícios s e t, ou seja, V = O ∪{s, t}. Os arcos, representados pelo conjunto A, correspondem aos arcos em bA representando as relações de precedência entre operações (em preto na figura), arcos que saem de s para operações que não têm predecessores e arcos que vão para t de operações que não precedem nenhuma outra operação (em roxo na figura). Arcos que partem de s e arcos que che- gam em t são chamados de arcos fictícios. Além disso, os arcos tracejados representam a atribuição de operações a máquinas e a ordem em que as operações são processadas por cada máquina. Esses arcos são chamados de arcos de máquina. Cada nó i ∈V \\ {s, t} = O, ou seja, cada operação, tem um valor wi associado a ele que representa seu tempo de processamento real, que é calculado com a função de aprendizado usando o tempo de processamento padrão da operação e a posição que a ope- ração ocupa na máquina à qual foi atribuída. Os nós s e t estão associados ao valor zero. O caminho mais longo entre os nós s e t é chamado de caminho crítico (destacado em amarelo na figura), e seu comprimento corresponde ao tempo de conclusão (makespan) da solução representada. 1 2 3 4 5 Machines 1 2 Operations 1 1 1 2 1 1 3 1 1 4 10 10 5 1 1 Figura 1: À esquerda, representação das restrições de precedência das operações por um DAG D = (O, b A), onde O = 1, 2, . . . , 5 representa o conjunto de operações e b A = (1, 2), (2, 3), (4, 5) é o conjunto de arcos que representa as restrições de precedência. Neste exemplo simples, as restrições de precedência são dadas por uma ordem linear, ou seja, não há flexibilidade de sequenciamento. Esta instância tem duas máquinas e cada uma das cinco operações pode ser processada em qualquer uma das duas máquinas, ou seja, F = 1, 2 e Fi = F para todos i ∈O. Isso significa que há flexibilidade de roteamento completa. A tabela à direita mostra os tempos de processamento padrão pik das cinco operações em cada uma das duas máquinas. Nesta seção, propomos duas heurísticas construtivas para o FJSSFLE. Heurísticas cons- trutivas são algoritmos que constroem uma solução viável do zero, selecionando e sequenciando iterativamente uma operação de cada vez. As duas heurísticas construtivas propostas são baseadas na regra de tempo de início mais cedo (EST) [Birgin et al., 2014] e na regra de tempo de conclusão mais cedo (ECT) [Leung et al., 2005]. O objetivo é utilizá-las para fornecer uma solução viável inicial para uma busca local que será usada para resolver um conjunto de instâncias de teste. A solução final é representada por um grafo direcionado acíclico (DAG), adaptado de Mastrolilli e Gambardella [2000]. O Algoritmo 1 apresenta a heurística construtiva baseada na regra de tempo de início mais cedo (EST). Em que, a cada iteração, a operação que pode ser executada mais cedo será alocada. No https://proceedings.science/p/193581?lang=pt-br DOI: 10.59254/sbpo-2024-193581 1 w1 = 100 2 w2 = 100 3 w3 = 25 s 4 w4 = 500 5 w5 = 33 t 1 w1 = 100 2 w2 = 50 3 w3 = 20 s 4 w4 = 333 5 w5 = 25 t (a) (b) Figura 2: Nesta figura, consideramos a instância na Figura 1 com taxa de aprendizado α = 1. O digrafo à esquerda (Figura 2a) representa uma solução viável na qual a máquina 1 (associada à cor ciano) processa apenas a operação 2, enquanto a máquina 2 (associada à cor laranja) processa as operações 1, 4, 5 e 3 nessa ordem. Os números coloridos representam o tempo de processamento real das operações, com a influência do efeito de aprendizado. O caminho crítico, cujo comprimento corresponde ao makespan, é dado pelo caminho s, 1, 4, 5, 3, t (destacado em amarelo na imagem). O digrafo à direita (Figura 2b) representa a solução viável obtida realocando a operação 2, que não estava no caminho crítico, da máquina 1 para a máquina 2 entre as operações 1 e 4. A solução viável construída, com caminho crítico dado por s, 1, 2, 4, 5, 3, t, tem um makespan menor que o original (528 contra 658). algoritmo, temos como entrada o conjunto de operações, O, o conjunto de máquinas, F, matriz dos tempos de processamento p e conjunto de arcos de precedência Â. O valor rop v se refere ao tempo que a operação v está pronta para ser processada, wv se refere ao seu tempo de processamento atual e cv ao seu tempo de conclusão. Do lado das máquinas, rmac k representa o instante em que a máquina k é liberada e gk representa sua primeira posição livre, que é aquela que seria ocupada se uma operação fosse atribuída a ela (ambas as quantidades se referem ao sequenciamento parcial sendo construído). fv indicará a qual máquina a operação v foi atribuída e cada máquina k terá uma lista ordenada Qk com a sequência de operações a serem processadas. Após as inicializações (linhas 2 a 5), vem o loop principal, que é executado enquanto ainda houver operações não sequenciadas. Entre as não sequenciadas, o tempo em que elas estão disponíveis é calculado para todas aquelas que já têm todas as operações precedentes agendadas (linhas 7 a 9). Na linha 10, observando os tempos em que as operações e das máquinas estariam disponíveis, é calculado o instante mais cedo rmin em que uma operação poderia ser sequenciada e o conjunto E de pares operação/máquina que poderiam começar naquele instante rmin é construído. Como observado em [Birgin et al., 2014], |E| pode ser bastante grande e uma regra de desempate pode melhorar significativamente o desempenho do método. Assim, na linha 11, entre todos os pares operação/máquina em E, levando em consideração o efeito de aprendizado, o par (ˆv, ˆk) com o tempo de processamento mais curto é par escolhido. Na linha 12, wˆv, fˆv e cˆv são definidos e o tempo rmac ˆk e a posição livre gˆk da máquina ˆk são atualizados. Nas linhas 13 e 14, o arco da máquina correspondente é inserido no grafo G (o arco não deve ser inserido se a operação ˆv for a primeira da máquina ˆk). Por fim, a lista de operações atribuídas à máquina ˆk é atualizada e a operação agendada é removida do conjunto de operações ainda não agendadas. Depois que todas as operações foram agendadas, o caminho crítico em G é calculado (linha 16) para determinar o valor de makespan Cmax. Isso é feito com uma adaptação do algoritmo de Bellman-Ford para caminho máximo em O(|O|). As inicializações nas linhas de 2 a 5 do Algoritmo 1 têm complexidade O(|O|+| b A|+|F|). Dentro do loop principal (linhas de 6 a 15), as linhas de 7 a 9 têm complexidade O(|A|) = O(| bA| + |O| + |F|), as linhas de 10 a 11 têm complexidade O(|O| + P i∈O |Fi|), e a linha 12 tem complexidade O(|O|). Como o loop principal é executado |O| vezes, sua complexidade total é O(|O|(| bA| + |F| + P i∈O |Fi|)). https://proceedings.science/p/193581?lang=pt-br DOI: 10.59254/sbpo-2024-193581 Como a complexidade do loop principal é maior que a complexidade da inicialização e da linha 16, então a complexidade do Algoritmo 1 é dada pela complexidade de seu loop principal. É importante notar que γ = P i∈O |Fi| está entre |O| e |O||F|, mas preferimos manter a complexidade expressa como uma função de γ porque γ é uma medida do tamanho da entrada que depende da flexibilidade de sequenciamento da instância em consideração. Também é importante notar que a complexidade do algoritmo depende da flexibilidade de roteamento das operações, ou seja, depende do número de relações de dependência em bA. Portanto, é importante representar uma instância de forma que bA corresponda a uma redução transitiva do digrafo de precedências. Algorithm 1: Computa um grafo de solução G = (V, A), f, Q, e w usando a heurística EST. Então, em G, computa o maior caminho P de s a t e seu compri- mento Cmax. Input: O, F, p, bA Output: f, w, Q, G = (V, A), U, P, Cmax, τ 1 function EST(O, F, p, bA, f, w, Q, G, U, P, Cmax, τ) 2 Atribua A ←bA ∪{(s, j) | (·, j) ̸∈bA} ∪{(i, t) | (i, ·) ̸∈bA} e defina V := O ∪{s, t} e G = (V, A). 3 Atribua rop v ←+∞para todo v ∈V e defina rop s := 0, ws := wt := 0, e cs := 0. 4 Atribua rmac k ←0 e gk ←1 para todo k ∈F. 5 Inicie Π ←V \\ {s, t} como o conjunto de operações não sequenciadas, e Qk como uma lista vazia para todo k ∈F. 6 while Π ̸= ∅do 7 for v ∈Π do 8 if Π ∩{i | (i, v) ∈A} = ∅then 9 rop v ←max{ci | i ∈V \\ Π tal que (i, v) ∈A} 10 Atribua rmin = min{max(rop v , rmac k ) | v ∈Π, k ∈Fv} e seja E o conjunto dos pares (v, k) com v ∈Π e k ∈Fv tal que max(rop v , rmac k ) = rmin. 11 (ˆv, ˆk) ←argmin{rmin + ψα(pv,k, gk) | (v, k) ∈E}. 12 Defina wˆv := ψα(pˆv,ˆk, gˆk), fˆv := ˆk e cˆv := max(rop ˆv , rmac ˆk ) + wˆv, e atribua rmac ˆk ←cˆv e gˆk ←gˆk + 1. 13 if |Qˆk| ̸= 0 then 14 Seja Qˆk = i1, . . . , i|Qˆk|. Atribua A ←A ∪{(i|Qˆk|, ˆv)}. 15 Insira ˆv no final de Qˆk e atribua Π ←Π \\ {ˆv}. 16 CaminhoCritico(F, f, w, Q, G, U, P, Cmax, τ). O caminho crítico no grafo direcionado G = (V, A) pode ser calculado com uma adapta- ção [Cormen et al., 2022, §22.2] do algoritmo de Bellman-Ford em O(|V |+|A|). Além do caminho crítico P, o algoritmo deve retornar uma ordenação topológica U dos vértices de G e um vetor τ de dimensão |F|. O vetor τ armazena, no elemento τk, a maior posição na lista Qk (lista de operações atribuídas à máquina k) que contém uma operação no caminho crítico. O algoritmo para a heurística construtiva baseada na regra ECT é muito semelhante ao Algoritmo 1, exceto por um detalhe. Na heurística construtiva baseada no EST, primeiro calcula- mos o instante rmin, que é o instante mais cedo em que uma operação não agendada poderia ser https://proceedings.science/p/193581?lang=pt-br DOI: 10.59254/sbpo-2024-193581 iniciada. Todos os pares operação/máquina que poderiam começar nesse instante são considerados, e o par com o menor tempo de processamento é selecionado. Mas, como todos começariam no instante rmin, dizer que o par com o menor tempo de processamento é escolhido é o mesmo que dizer que o par que termina mais cedo é selecionado. Essa é a ideia que é levada ao extremo na heurística construtiva baseada na regra ECT: sem limitar a escolha aos pares operação/máquina que poderiam começar o mais cedo possível, escolhemos o par operação/máquina que terminará mais cedo, mesmo que o processamento da operação não comece o mais cedo possível. A complexidade de tempo no pior caso do algoritmo para a heurística ECT é a mesma que a do Algoritmo 1. A heurística baseada em EST dá prioridade aos pares operação/máquina que podem co- meçar mais cedo. No início da construção, isso corresponde, aproximadamente, a dar prioridade a todas as primeiras operações de cada tarefa, que são operações que não têm precedentes (ope- rações 1 e 4 no exemplo da Figura 1). Ainda assim, devido à intenção de agendar operações o mais cedo possível, é possível que a preferência seja dada a máquinas vazias, construindo soluções que usam várias máquinas. Ao agendar rapidamente as primeiras operações de cada trabalho, mais operações têm seus precedentes agendados, aumentando o número de possibilidades (espaço de busca) nas iterações futuras do método. Por outro lado, a heurística baseada na regra ECT escolhe os pares operação/máquina que terminam mais cedo, independentemente de serem aqueles que po- dem começar mais cedo ou não. Essa estratégia pode limitar o número de pares operação/máquina disponíveis em iterações futuras, reduzindo o espaço de busca do método. Além disso, a escolha pelo par operação/máquina que pode terminar mais cedo, combinada com o efeito de aprendizado, leva o método a agendar operações em máquinas que já têm várias operações atribuídas a elas, já que quanto maior a posição na máquina, menor o tempo de processamento (reduzido pelo efeito de aprendizado baseado em posição). Isso leva à construção de soluções em que nem todas as má- quinas são usadas. Dependendo da taxa de aprendizado α considerada e da densidade do DAG de precedências da instância em questão, uma heurística pode ser melhor que a outra. 3. Vizinhança Reduzida e Busca Local Dada uma solução viável e um DAG G = (V, A) que a representa, uma nova solução viá- vel pode ser construída removendo uma operação da máquina à qual foi atribuída e reinserindo-a na mesma máquina, mas em outra posição ou em outra máquina. Quando uma operação é removida, os arcos de máquina adjacentes a ela devem ser removidos e um novo arco indo da operação anterior para a seguinte à removida (se ambas existirem) deve ser criado. Quando a operação é reinserida, uma operação reversa similar também deve ser feita. Ao reinserir a operação, é importante verifi- car se um ciclo não é produzido no digrafo. Somente reinserções que não criam ciclos constroem um digrafo que corresponde a uma solução viável. Quando não há efeito de aprendizado, é co- nhecido [Mastrolilli e Gambardella, 2000] que há chances de construir uma solução viável melhor removendo e realocando operações que fazem parte do caminho crítico apenas. Se uma operação não faz parte do caminho crítico, sua remoção e reinserção não pode diminuir o comprimento do ca- minho crítico. Pode aumentá-lo ou criar outro caminho ainda mais longo. Isso é falso ao considerar o efeito de aprendizado. Um exemplo é mostrado na Figura 2b. Dada uma solução viável, podemos definir sua vizinhança como o conjunto de todas as soluções viáveis que podem ser obtidas removendo e reinserindo uma única operação. Quando não há efeito de aprendizado, apenas a remoção e reinserção de operações do caminho crítico podem levar a vizinhos melhores, ou seja, vizinhos com menor makespan. Este fato é amplamente utili- zado para gerar apenas vizinhos promissores. A observação no parágrafo anterior mostra que essa redução não pode ser usada no problema que estamos considerando no presente trabalho. Isso nos leva a analisar se toda remoção e reinserção que não gera ciclos tem o potencial de gerar um vizinho com makespan menor ou se qualquer redução de vizinhança é possível. O ponto principal é obser- https://proceedings.science/p/193581?lang=pt-br DOI: 10.59254/sbpo-2024-193581 var que quando uma operação é removida de uma máquina, as operações que estavam sequenciadas para serem processadas posteriormente nessa máquina têm sua posição diminuída em uma unidade e, consequentemente, seu tempo de processamento real aumentado. Da mesma forma, na máquina onde a operação é inserida, as operações programadas para serem processadas após a operação inserida têm sua posição aumentada em uma unidade e, portanto, seu tempo de processamento é diminuído. Essas modificações podem mudar o makespan, seja melhorando ou piorando. Considere uma solução viável representada por um DAG G = (V, A). Seja P um caminho crítico em G, com comprimento Cmax. Seja i ∈O uma operação arbitrária. Chamamos de fi a máquina à qual i está atribuída. Seja k ∈F uma máquina arbitrária. Chamamos Qk = i1, . . . , i|Qk| a lista ordenada de operações atribuídas à máquina k. Se uma operação i está atribuída à máquina fi e está na posição γ de Qfi, então seu tempo de processamento real é dado por wi = ψα(pi,fi, γ). Pretendemos calcular todos os vizinhos da solução representada por G, f, Q e w. Os vizinhos serão construídos, para todo v ∈O, removendo v e reinserindo v em todos os lugares possíveis que não gerem um ciclo. Queremos determinar se existem inserções que podem ser ignoradas porque sabemos a priori que não levarão a uma redução no makespan. Seja v ∈O uma operação arbitrária. O cálculo dos vizinhos da solução atual (associados à remoção e reinserção de v) começa calculando um digrafo G− v = (V −, A−) no qual a operação v é removida. Esse grafo é às vezes referido como um grafo reduzido na literatura. As quantidades f−, Q−e w−associadas a G− v também são calculadas. Esse digrafo com suas informações associadas é uma estrutura intermediária necessária para o cálculo dos vizinhos e, como a operação v não está atribuída a nenhuma máquina, não representa uma solução viável. Essa tarefa é implementada no Algoritmo RemoveOp. Além disso o conjunto R← v de vértices que alcançam v e o conjunto de vértices R→ v que são alcançados a partir de v em G− v são calculados, o que será útil para detectar ciclos em futuras reinserções de v. O caminho mais longo P−no digrafo G− v é calculado, o que será útil para determinar se uma reinserção tem chances de reduzir o makespan ou não. Chamamos ξ de comprimento de P−. (Não o chamamos de C− max porque como G− v não representa uma solução viável, então o comprimento do caminho P−não representa um makespan.) Junto com o cálculo de P−, o algoritmo também calcula, para cada máquina k, a menor posição τk tal que, para todo γ > τk, a γ-ésima operação processada pela máquina k não está em P−. (Se a máquina k não processa nenhuma operação em P−, então τk = 0.) Seja G o digrafo, com as quantidades associadas f, Q e w, representando a solução viável atual. Seja P o caminho crítico em G, com comprimento Cmax. Seja v a operação que removemos e desejamos reinserir. Seja G− v o digrafo com v removido e deixe f−, Q−e w−serem as quantidades associadas a G− v . Seja P−o caminho crítico em G− v , com comprimento ξ, e, para cada máquina k, deixe τk ser a menor posição em Qk tal que cada operação em uma posição após τk não esteja em P−. Deixe κ ser uma máquina e γ ser uma posição na lista Q− κ tal que inserir v na posição γ de Q− κ não gere um ciclo. Tal inserção tem chance de gerar um novo digrafo cuja solução viável associada tenha um makespan menor que Cmax? Se ξ ≥Cmax e γ > τk, então a resposta é não. Isso ocorre porque o caminho P−com comprimento ξ não menor que Cmax já existe e a inserção de v na máquina κ, em uma posição γ posterior a τk, não modificará o tempo de processamento real de nenhuma operação em P−. Se ξ < Cmax ou ξ ≥Cmax, mas γ ≤τk, então as chances existem. Deve-se notar que, estritamente falando, o fato de v estar em P ou não não está relacio- nado à resposta à pergunta acima. Mas antecipando algo que virá mais tarde, como a redução de vizinhança orientada pela resposta à pergunta pode ser bastante pequena, consideraremos nos expe- rimentos, de forma heurística, v ∈P como equivalente ou fortemente correlacionado a ξ < Cmax. Ou seja, consideraremos que remover uma operação do caminho crítico provavelmente implicará em ξ < Cmax. Isso é muito plausível para valores moderados do fator de aprendizado α, nos quais https://proceedings.science/p/193581?lang=pt-br DOI: 10.59254/sbpo-2024-193581 uma possível redução de uma unidade na posição da máquina de algumas operações do caminho crítico não anula o benefício de remover uma operação do caminho crítico. A tarefa de reinserir v em G− v na posição γ da máquina κ gera um DAG que chamamos de G+ v . Essa tarefa é semelhante à tarefa de remoção. A construção de G+ v , suas quantidades associadas f+, Q+ e w+, e seu caminho crítico P+ com comprimento C+ max é implementada no InsereOp. O Algoritmo 2 implementa uma busca local pelo melhor vizinho com a redução de vizinhança já discutida. Ele corresponde a uma busca local clássica com uma estratégia de melhor vizinho (best improvement). O único detalhe relevante que resta a ser explicado é como determinar se uma inserção gera um ciclo ou não. Um ciclo será criado em G+ v apenas se v for inserido em uma posição que deixe algum u ∈R← v para ser processado após v na máquina κ ou algum u ∈R→ v para ser processado antes de v na máquina κ. Os limites γ e ¯γ tais que γ +1 ≤γ ≤¯γ evitam ciclos, são calculados nas linhas 7 e 8. Uma possível redução desse intervalo é calculada nas linhas 9 e 10, eliminando a possibilidade de fazer inserções após τκ se ξ ≥Cmax, como já discutido. Algorithm 2: Busca local com vizinhança reduzida e estratégia de best improve- ment. Input: O, F, p, G = (V, A), f, w, Q, P, Cmax Output: G⋆= (V ⋆, A⋆), f⋆, w⋆, Q⋆, P⋆, C⋆ max 1 function BuscaLocal(O, F, p, G, f, w, Q, P, Cmax, G⋆, f⋆, w⋆, Q⋆, P⋆, C⋆ max) 2 do 3 Cbn max ←+∞ 4 for v ∈O do 5 RemoveOp(O, p, v, f, Q, w, G, f−, Q−, w−, G− v , P−, ξ, R← v , R→ v , τ) 6 for k ∈Fv do 7 Assuma γ a posição da última operação em Q− k = i1, . . . , i|Q− k | tal que iγ ∈R← v e assuma γ = 0 se iℓ̸∈R← v para todo ℓ= 1, . . . , |Q− k |. 8 Assuma ¯γ a posição da primeira operação em Q− k = i1, . . . , i|Q− k | tal que i¯γ ∈R→ v e assuma ¯γ = |Q− k | + 1 se iℓ̸∈R→ v para todo ℓ= 1, . . . , |Q− k |. 9 if ξ ≥Cmax then 10 ¯γ ←min{¯γ, τk}, onde τk é tal qual não existe operação crítica após τk em Q− k (τk = 0 se não há operação crítica em Q− k ). 11 for γ = γ + 1, . . . , ¯γ do 12 InsereOp(O, p, v, γ, k, f−, Q−, w−, G− v , f+, Q+, w+, G+ v , P+, C+ max) 13 if C+ max < Cbn max then 14 Gbn, fbn, wbn, Qbn, Pbn, Cbn max ← G+ v , f+, w+, Q+, P+, C+ max 15 δ ←Cmax −Cbn max 16 if δ > 0 then 17 G, f, w, Q, P, Cmax ←Gbn, fbn, wbn, Qbn, Pbn, Cbn max 18 while δ > 0 19 G⋆, f⋆, w⋆, Q⋆, P⋆, C⋆ max ←G, f, w, Q, P, Cmax https://proceedings.science/p/193581?lang=pt-br DOI: 10.59254/sbpo-2024-193581 4. Experimentos Computacionais Nesta seção, apresentamos experimentos numéricos. Primeiro, desejamos avaliar as duas heurísticas construtivas apresentadas. Segundo, desejamos avaliar diferentes estratégias para a busca local proposta e tentar inferir qual é mais eficaz na busca por soluções de melhor qualidade. Em todos os casos, consideramos as 50 instâncias introduzidas por Birgin et al. [2014] com a taxa de aprendizado α ∈{0, 1; 0, 2; 0, 3} para um total de 150 instâncias. Os experimentos foram realizados em uma máquina com processador Intel i9-12900K (12ª geração) operando a 5,200GHz e 128 GB de RAM. As heurísticas construtivas e busca local foram implementadas na linguagem de programação C++. O código foi compilado usando g++ 10.2.1. Na Tabela 1 o resumo dos resultados da avaliação duas heurísticas construtivas é apresen- tado. Para cada grupo instância e taxa de aprendizado, a média do makespan e número de vitórias, entre as soluções encontradas pelas duas heurísticas construtivas, são apresentados. Em todas as instâncias, as heurísticas construtivas levam menos de 0.001 segundos de tempo de CPU para cons- truir uma solução. Para as instâncias testadas há uma clara vantagem da heurística construtiva EST nas instâncias do tipo DA, enquanto, por outro lado, há uma clara vantagem da heurística constru- tiva ECT nas instâncias do tipo Y. A estratégia gulosa de ECT de escolher o par operação/máquina que termina primeiro parece compensar em situações onde, porque já há pouca flexibilidade de sequenciamento, a escolha gulosa não causa uma grande diminuição do espaço de busca. DAFJS YFJS EST ECT EST ECT α = 0, 1 makespan 65.249,50 67.439,80 87.865,80 80.338,80 #vitórias 20 10 5 15 α = 0, 2 makespan 54.310,83 57.746,00 74.373,85 68.682,05 #vitórias 24 6 7 13 α = 0, 3 makespan 45.578,87 48.181,97 65.850,25 59.452,35 #vitórias 28 2 7 13 Tabela 1: Tabela resumo dos experimentos computacionais para os valores de makespan para as instâncias de teste resolvidas com as heurísticas construtivas. Avaliamos agora variações da busca local descrita no Algoritmo 2. No algoritmo, a busca local usa a estratégia de best improvement e faz uso da redução do vizinhança. Portanto, chama- mos essa versão de “busca local com a estratégia de best improvement e vizinhança reduzida”. A redução de vizinhança é implementada nas linhas 9 e 10. Se removermos essas duas linhas, ob- temos uma versão que chamamos de “busca local com best improvement e vizinhança completa”. A versão com vizinhança reduzida não considera vizinhos que são garantidamente piores do que a solução atual. Portanto, a solução obtida com vizinhança reduzida deve ser idêntica à solução obtida com o vizinhança completa. (Na verdade, todos as iterações das duas versões devem ser idênticos e não apenas a solução final). Apenas uma redução do tempo de CPU é esperada. Deci- dimos considerar ainda outra versão que apresentaria uma redução mais drástica no tempo de CPU, embora com possível perda de qualidade na solução. Chamamos essa versão de “busca local com best improvement e vizinhança cortada”. Esta versão consiste em alterar v ∈O para v ∈P na linha 4 do Algoritmo 2. Ou seja, apenas as operações no caminho crítico são realocadas, uma vez que há uma maior tendência para essas realocações gerarem vizinhos de melhor qualidade. Temos então três versões diferentes da busca local com a estratégia de best improvement que são distinguí- veis pela vizinhança usada: completa, reduzida e cortada. Cada uma delas corresponde a variações https://proceedings.science/p/193581?lang=pt-br DOI: 10.59254/sbpo-2024-193581 mínimas do Algoritmo 2 conforme já descrito. Além disso, consideramos as mesmas três versões, mas usando a estratégia de interromper a busca da vizinhança ao encontrar o primeiro vizinho que melhora a solução atual, ou seja, a estratégia de first improvement. Essa mudança corresponde, no Algoritmo 2, a interromper o laço da linha 4 na primeira vez que a linha 16 é executada. Os resultados das seis variações da busca local aplicadas às 150 instâncias consideradas são mostrados na Tabela 2. Nas tabelas, mostramos o makespan médio das soluções obtidas, o nú- mero de iterações médio que a busca local fez até encontrar uma solução que é melhor do que todos os seus vizinhos (este é o critério de parada conforme descrito no Algoritmo 2), e o tempo médio de CPU em segundos. A tabela também não mostra nada relacionado à vizinhança completa. O que deve ser dito sobre o uso da vizinhança completa é que, em todas as instâncias, como esperado, a solução obtida foi idêntica à solução obtida com a vizinhança reduzida, o número de iterações também foi o mesmo, e a vizinhança reduzida promoveu uma redução de 52,51% no tempo de CPU. Quando comparamos as estratégias de first e best improvement, os resultados são bas- tante semelhantes, mas a estratégia do melhor aprimoramento sempre encontra soluções de melhor qualidade usando menos tempo de CPU. Especificamente, a estratégia de best improvement retorna soluções que são, em média, 1,02% e 0,70% melhores do que as soluções retornadas pela estratégia de primeira melhoria, quando consideramos as vizinhanças reduzida e cortada, respectivamente. Portanto, daqui em diante, focamos em avaliar a vizinhança reduzida e a vizinhança cortada à es- tratégia do melhor aprimoramento. A vizinhança cortada elimina, em média, 90,34% das soluções da vizinhança reduzida, promovendo uma redução proporcional no tempo de CPU. No entanto, adotar a vizinhança cortada pode levar a uma perda de qualidade na solução final obtida pelo método de busca local. Em média, quando comparado com a busca local com vizinhança reduzida, a busca local com a vizinhança cortada encontra soluções com um makespan 0,69% pior. Quando comparamos a solução final com a solução inicial, a busca local usando a vizinhança reduzida melhora a solução inicial em, em média, 6,88%, enquanto a busca local usando a vizinhança cortada melhora a solução inicial em 6,11%. Em conclusão, a busca local com a vizinhança cortada é significativamente mais rápida do que a busca local com a vizinhança reduzida e encontra soluções apenas ligeiramente piores do que as soluções encontradas por esta última. DAFJS YFJS First Improvement Best Improvement First Improvement Best Improvement Cortada Reduzida Cortada Reduzida Cortada Reduzida Cortada Reduzida α = 0, 1 makespan 59.008,00 58.925,53 58.305,43 57.974,70 71.528,60 71.895,70 71.227,20 70.704,30 #iterações 27,73 61,37 14,53 20,90 18,15 57,1 8,30 19,60 tempo 0,009 0,070 0,016 0,073 0,011 0,264 0,012 0,243 #vitórias 3 2 7 10 5 7 4 11 α = 0, 2 makespan 50.713,70 50.400,03 49.944,33 49.835,73 62.812,75 62.184,05 62.154,65 61.446,60 #iterações 18,83 39,4 12,03 15,90 14,05 51 7,70 17,20 tempo 0,005 0,051 0,011 0,051 0,009 0,309 0,010 0,225 #vitórias 3 8 7 13 5 8 7 12 α = 0, 3 makespan 42.854,47 42.315,00 42.383,17 42.018,73 55.087,10 54.328,30 54.883,00 53.749,15 #iterações 17,3 36,23 9,33 14,77 10,05 38,9 6,35 16 tempo 0,006 0,048 0,009 0,054 0,007 0,208 0,009 0,201 #vitórias 2 8 9 15 6 10 7 14 Tabela 2: Resumo dos experimentos com as estratégias e vizinhanças usadas para a busca local usando as instâncias propostas por Birgin et al. [2014] com taxa de aprendizagem α ∈{0, 1; 0, 2; 0, 3}. https://proceedings.science/p/193581?lang=pt-br DOI: 10.59254/sbpo-2024-193581 5. Conclusões Neste trabalho, abordamos o problema de sequenciamento do job shop flexível com fle- xibilidade de sequenciamento e efeito de aprendizado baseado na posição. Utilizamos um con- junto de 50 instâncias que se transformam em 150 instâncias variando a taxa de aprendizado α ∈{0, 1; 0, 2; 0, 3}. Propomos duas heurísticas construtivas baseadas em regras de despacho. Também introduzimos uma busca local com diversas estratégias e vizinhanças para melhorar as soluções das heurísticas iniciais. Para a busca local, mostramos que, na presença do efeito de apren- dizado, a abordagem clássica de considerar realocações de operações apenas no caminho crítico falha em considerar vizinhos potencialmente melhores do que a solução atual. Consequentemente, propusemos uma nova redução de vizinhança que não elimina vizinhos potencialmente melhores do que a solução atual e reduz a vizinhança em aproximadamente 50%. Além disso, propusemos um corte de vizinhança que reduz significativamente o tamanho da mesma (em cerca de uma ordem de magnitude) e encontra soluções que são no máximo 1% piores. A busca local introduzida e/ou as vizinhanças podem ser utilizados no desenvolvimento de meta-heurísticas de trajetória. Como trabalhos futuros, pretendemos considerar diferentes efeitos de aprendizado, que não dependem apenas da posição da operação na máquina à qual foi atribuída. Também pretendemos considerar funções objetivo que levem em conta o consumo de energia, e adaptar o problema para diversas aplicações do mundo real."
        },
        {
            "titulo": "Limites de Geração de Colunas para o Problema de Alocação Dinâmica de Berços",
            "informacoes_url": "https://proceedings.science/p/193371?lang=pt-br",
            "idioma": "português",
            "storage_key": "galoa-proceedings--sbpo-2024--193371.pdf",
            "autores": [
                {
                    "nome": "Lucas Guilhon",
                    "afiliacao": "Pontifícia Universidade Católica do Rio de Janeiro (PUC-Rio)",
                    "orcid": ""
                },
                {
                    "nome": "Letícia Caldas",
                    "afiliacao": "Pontifícia Universidade Católica do Rio de Janeiro (PUC-Rio)",
                    "orcid": ""
                },
                {
                    "nome": "Rafael Martinelli",
                    "afiliacao": "Pontifícia Universidade Católica do Rio de Janeiro (PUC-Rio)",
                    "orcid": ""
                }
            ],
            "data_publicacao": "",
            "resumo": "O Problema de Alocação Dinâmica de Berços (DBAP) é fundamental na logística marítima e na gestão portuária, envolvendo a atribuição eficiente de berços aos navios que chegam ao porto.",
            "keywords": [
                "Alocação Dinâmica de Berços",
                "Geração de Colunas",
                "Logística Marítima"
            ],
            "referencias": [
                "Baldacci, R., Mingozzi, A., e Roberti, R. (2011). New route relaxation and pricing strategies for the vehicle routing problem. Operations research, 59(5):1269–1283.",
                "Christensen, C. e Holst, C. (2008). Berth allocation in container terminals master’s thesis department of informatics and mathematical modelling technical university of denmark.",
                "Cordeau, J.-F., Laporte, G., Legato, P., e Moccia, L. (2005). Models and tabu search heuristics for the berth-allocation problem. Transportation science, 39(4):526–538.",
                "Guo, L., Zheng, J., Liang, J., e Wang, S. (2023). Column generation for the multi-port berth allocation problem with port cooperation stability. Transportation Research Part B: Methodological, 171:3–28.",
                "Imai, A., Nishimura, E., e Papadimitriou, S. (2001). The dynamic berth allocation problem for a container port. Transportation Research Part B: Methodological, 35(4):401–417.",
                "Imai, A., Sun, X., Nishimura, E., e Papadimitriou, S. (2005). Berth allocation in a container port: using a continuous location space approach. Transportation Research Part B: Methodological, 39(3):199–221.",
                "Kramer, A., Lalla-Ruiz, E., Iori, M., e Voß, S. (2019). Novel formulations and modeling enhancements for the dynamic berth allocation problem. European Journal of Operational Research, 278(1):170–185.",
                "Lalla-Ruiz, E., Melián-Batista, B., e Marcos Moreno-Vega, J. (2012). Artificial intelligence hybrid heuristic based on tabu search for the dynamic berth allocation problem. Engineering applications of artificial intelligence, 25(6):1132–1141. ISSN 0952-1976.",
                "Lalla-Ruiz, E., Izquierdo, C. E., Batista, B. M., e Moreno-Vega, J. M. (2015). Decentralized cooperative metaheuristic for the dynamic berth allocation problem. Inteligência Artificial, 18(55):1–11.",
                "Lin, S.-W. e Ting, C.-J. (2014). Solving the dynamic berth allocation problem by simulated annealing. Engineering optimization, 46(3):308–327.",
                "Lin, S.-W., Ying, K.-C., Wan, S.-Y., et al. (2014). Minimizing the total service time of discrete dynamic berth allocation problem by an iterated greedy heuristic. The Scientific World Journal, 2014.",
                "Martinelli, R., Pecin, D., e Poggi, M. (2014). Efficient elementary and restricted non-elementary route pricing. European Journal of Operational Research, 239(1):102–111.",
                "Mauri, G. R., Oliveira, A. C., e Lorena, L. A. N. (2008). A hybrid column generation approach for the berth allocation problem. In European Conference on Evolutionary Computation in Combinatorial Optimization, p. 110–122. Springer.",
                "Monaco, M. F. e Sammarra, M. (2007). The berth allocation problem: a strong formulation solved by a lagrangean approach. Transportation Science, 41(2):265–280.",
                "Nishi, T., Okura, T., Lalla-Ruiz, E., e Voß, S. (2020). A dynamic programming-based matheuristic for the dynamic berth allocation problem. Annals of Operations Research, p. 1–20. ISSN 0254-5330.",
                "Robenek, T., Umang, N., Bierlaire, M., e Ropke, S. (2014). A branch-and-price algorithm to solve the integrated berth allocation and yard assignment problem in bulk ports. European Journal of Operational Research, 235(2):399–411.",
                "Saadaoui, Y. (2016). The berth allocation problem at port terminals: a column generation framework."
            ],
            "artigo_completo": "Limites de Geração de Colunas para o Problema de Alocação Dinâmica de Berços. RESUMO O Problema de Alocação Dinâmica de Berços (DBAP) é fundamental na logística marítima e na gestão portuária, envolvendo a atribuição eficiente de berços aos navios que che- gam ao porto. Este estudo explora o DBAP utilizando uma metodologia de geração de colunas, demonstrando sua eficácia na resolução do problema. A abordagem proposta estabelece novos li- mites inferiores para instâncias ainda não resolvidas na literatura e produz resultados em um tempo significativamente menor comparado ao modelo indexado por tempo. Especificamente, a geração de colunas identificou três novos limites inferiores para essas instâncias, e igual ou o melhor valor conhecido em 76,4% das instâncias restantes. A geração de colunas emerge como uma metodologia promissora para futuras resoluções, conforme evidenciado pelos resultados. PALAVRAS CHAVE. Alocação Dinâmica de Berços, Geração de Colunas, Logística Marítima. Tópicos. OC – Otimização Combinatória, PM – Programação Matemática. https://proceedings.science/p/193371?lang=pt-br DOI: 10.59254/sbpo-2024-193371 1. Introdução O Problema de Alocação de Berços (do inglês, Berth Allocation Problem - BAP) é um problema de otimização comum na logística marítima e na gestão portuária. Envolve determinar a atribuição ideal de berços aos navios que chegam a um porto, considerando diversas restrições e objetivos. O objetivo principal é maximizar a eficiência geral do porto e, ao mesmo tempo, atender às restrições operacionais. No porto, a disponibilidade de berços é limitada, cada um com suas próprias capacidades e características. Os diferentes navios apresentam uma variedade de requisitos e restrições, incluindo tamanho, calado e tipo de carga transportada. Além disso, há várias restrições operacionais, como tempo, marés e outras considerações, que influenciam a programação e a duração da permanência de um navio no cais. É crucial garantir o cumprimento dos regulamentos de segurança e proteção, pois eles podem afetar diretamente a alocação de berços. A alocação eficiente é fundamental para minimizar o tempo que um navio passa no cais, o que permite um retorno mais rápido e aumenta a produtividade portuária. Para isso, é essencial otimizar a alocação, aproveitando ao máximo os recursos e infraestrutura disponíveis. A solução do problema de alocação de berços normalmente envolve o uso de técnicas e algoritmos de otimização. Estes podem incluir modelos de programação matemática, métodos heurísticos, algoritmos meta-heurísticos e abordagens de simulação. Vários modelos matemáticos, como formulações de programação linear inteira (do inglês, Integer Linear Programming - ILP), são usados para representar formalmente o problema de alocação de berços. No entanto, devido à complexidade e ao tamanho das instâncias do mundo real, métodos exatos podem apresentar dificuldades para encontrar soluções ideais em um período de tempo razoável. As variações do BAP são conhecidas como problemas NP-difíceis [Monaco e Sammarra, 2007]. Considerando os trabalhos que utilizaram uma abordagem exata para o problema, Monaco e Sammarra [2007] revisaram e compararam cinco diferentes modelos para a formulação dinâmica do problema, considerando os trabalhos de Imai et al. [2001], Cordeau et al. [2005] e Christensen e Holst [2008]. Uma formulação de particionamento de conjuntos generalizada (do inglês, Gene- ralized Set Partitioning Problems - GSPP), proposta por Christensen e Holst [2008], se mostrou superior a todas as outras para as instâncias de Cordeau et al. [2005]. Embora a abordagem GSPP seja capaz de resolver problemas de tamanho relativamente grande, a principal desvantagem é a explosão no número de atribuições viáveis de embarcações com o aumento no tamanho do problema. Essa característica faz com que a metodologia de otimização fique sem memória [Saadaoui, 2016]. Diversos trabalhos utilizando abordagens heurísticas, meta-heurísticas e matheurísticas foram publicados. Entre eles, destaca-se Lalla-Ruiz et al. [2012], que utilizaram uma metaheurística híbrida que combina Busca Tabu com religamento de caminhos (do inglês, Path Relinking - PR). Lin et al. [2014], propuseram um algoritmo guloso iterado (do inglês, Iterated Greedy Algorithm - IG), enquanto Lin e Ting [2014], utilizaram abordagens baseadas no Simulated Annealing (SA). LallaRuiz et al. [2015], propuseram uma metaheurística cooperativa descentralizada (do inglês, Decentralized Cooperative Metaheuristic - DCM). Por fim, Nishi et al. [2020] propuseram uma matheurística baseada em programação dinâmica. Considerando os trabalhos que utilizaram Geração de Colunas (GC) em sua abordagem, Robenek et al. [2014] estudaram o problema integrado de alocação de berços e atribuição de pátios no contexto de portos graneleiros. Um algoritmo de solução exato baseado em branch-and-price e uma meta-heurística baseada em busca crítica de vizinhança foram propostas para resolver o problema em larga escala. Os autores destacaram que a principal fonte da complexidade do tempo foi a solução dos subproblemas na estrutura de GC. https://proceedings.science/p/193371?lang=pt-br DOI: 10.59254/sbpo-2024-193371 Guo et al. [2023] consideraram o BAP com múltiplos portos (do inglês, Multi-port Berth Allocation Problem - MPBAP) juntamente com o problema de estabilidade da cooperação portuária (do inglês, Port Cooperation Stability Problem - PCSP). O MPBAP considera o desvio de navios com tempos de espera excessivos para portos vizinhos e o PCSP, investiga como agrupar múltiplos portos vizinhos. Para todos os grupos de portos possíveis, um modelo de programação inteira mista (do inglês, Mixed-integer Programming - MIP) para o MPBAP é proposto, e uma abordagem de GC é desenvolvida para resolvê-lo. Com base em soluções ótimas do MPBAP, o PCSP pode ser formulado como um modelo de programação binária para determinar grupos de portos ideais. O algoritmo de GC proposto foi capaz de resolver o modelo MIP para instâncias com quatro portos e 160 embarcações em três minutos. Saadaoui [2016] abordou a limitação da abordagem GSPP e apresentou uma estrutura de GC onde atribuições são geradas dinamicamente para resolver grandes instâncias do BAP. A autora propôs um algoritmo baseado em geração de colunas e que pode ser facilmente adaptado para resolver qualquer variante do BAP. Experimentos computacionais em um conjunto de instâncias artificiais indicam que a metodologia proposta pode resolver problemas de tamanhos muito grandes até a otimização ou quase otimização em tempo computacional de apenas alguns minutos. Mauri et al. [2008] propuseram um algoritmo de geração de colunas híbridas para resolver o modelo de Cordeau et al. [2005]. O problema principal foi resolvido pelo modelo de programação linear utilizando a técnica de GC. O subproblema foi resolvido usando uma metaheurística de base evolutiva, chamada algoritmo de treinamento populacional. A abordagem proposta não garante encontrar soluções ótimas para o BAP, porque o subproblema de geração de colunas foi resolvido através de uma heurística. No entanto, os resultados mostram soluções de boa qualidade e obtidas em tempos de processamento razoáveis, em comparação com a Busca Tabu e o CPLEX. A literatura apresenta os diversos esforços em desenvolver abordagens capazes de soluci- onar problemas reais, isto é, grandes instâncias, com diversas restrições, em razoável tempo com- putacional. Esses esforços são justificados pois o BAP é crucial no contexto da gestão portuária, pois impacta diretamente a eficiência, a relação custo-benefício e o desempenho geral das operações logísticas marítimas. A alocação eficiente de berços contribui para reduzir os tempos de espera dos navios, aumentar a produtividade e melhorar a produtividade geral do porto. Embora várias abordagens de Geração de Colunas (GC) já tenham sido propostas na lite- ratura, nosso trabalho se destaca por apresentar uma metodologia aprimorada para uma variação do BAP, o problema de alocação dinâmica de berços (do inglês, Dynamic Berth Allocation Problem - DBAP). A inovação deste trabalho reside em uma formulação eficiente do subproblema de pricing e na utilização de uma relaxação de rotas, que juntas ajudam a reduzir o tempo de resolução total da geração de colunas. Nossa abordagem oferece vantagens em termos de eficiência computacio- nal, especialmente para instâncias de grande porte, proporcionando soluções viáveis em tempos de processamento menores. Na Seção 2, é apresentada a definição do problema, a formulação de tempo indexada, seguida da geração de colunas desenvolvida. Resultados computacionais e instâncias utilizadas são apresentados na Seção 3 e as conclusões e trabalhos futuros na Seção 4. 2. Metodologia 2.1. Definição do Problema Diferentes variações do BAP foram propostas na literatura. As restrições no BAP depen- dem da formulação específica do problema e dos atributos considerados. A representação formal pode ser ajustada com base em características e requisitos específicos do problema. De acordo com Imai et al. [2005] algumas restrições comuns incluem restrições espaciais, como o número e ta- manho dos berços e restrições de profundidade da água. De acordo com as posições de atracação https://proceedings.science/p/193371?lang=pt-br DOI: 10.59254/sbpo-2024-193371 viáveis, o problema pode ser classificado como discreto, onde o cais é particionado em uma série de seções, chamadas de berços. No traçado contínuo, não há compartimentação do porto e, quando navios de grande porte podem ocupar mais de um berço ou pequenas embarcações podem compar- tilhar um berço, temos o layout híbrido. As restrições temporais podem incluir horários de chegada e partida dos navios, datas de vencimento e janelas de tempo para serviço. As restrições de tempo de manuseio podem considerar tempos de manuseio fixos ou dependentes da posição. De acordo com Imai et al. [2001] e conside- rando o horário de chegada dos navios, o caso estático assume que os navios já aguardam no porto e podem atracar imediatamente e, para o caso de chegada dinâmica, os navios chegam ao longo do horizonte de tempo. A variação mais referenciada do problema é a DBAP [Kramer et al., 2019], proposta por Imai et al. [2001]. O DBAP pode ser formalmente definido como um problema de otimização que visa determinar a atribuição mais eficiente de berços em um porto para navios que chegam, sujeito a diversas restrições e objetivos. Uma representação formal do problema considera um conjunto de berços B, e um conjunto de navios N. Cada navio i ∈N está disponível para ser atendido em uma dada janela de tempo [si, fi], onde si e fi representam o tempo de chegada e partida do navio, respectivamente. Além disso, cada berço b ∈B está disponível para atender navios em um período restrito [sb, fb]. Cada navio i possui um tempo de serviço ρib, que depende do berço de atendimento b, e uma prioridade pi. O objetivo geral do problema é minimizar o tempo total de fluxo ponderado para atender os navios que chegam, ou seja, o tempo decorrido entre a chegada dos navios ao terminal e a conclusão das operações associadas multiplicado pelos seus valores de prioridade. Observe que uma vez que um navio começou a ser atendido por um berço, seu processamento não pode ser interrompido e reiniciado posteriormente no mesmo ou em outro berço. 2.2. Formulação Indexada no Tempo A formulação indexada no tempo (do inglês Time-Indexed - TI) considera o DBAP como um problema de máquinas paralelas, incorporando datas de início de disponibilidade e datas de entrega para minimizar o tempo total de fluxo ponderado. A disponibilidade dos berços e a com- patibilidade entre navios e berços também são consideradas. Segundo Kramer et al. [2019], define- se uib = min(fi, fb) −ρib, como o tempo limite para a permanência do navio i no berço b, e lib = max(si, sb), como o início da janela de tempo em que o navio i pode ser atendido no berço b. A formulação TI do DBAP é apresentada a seguir, sendo a variável de decisão xibt igual a 1 se o navio i é alocado ao berço b no instante de tempo t, e 0 caso contrário. min X i∈N X b∈B uib X t=lib pixibt(t + ρib −si) (1) sujeito a X b∈B uib X t=lib xibt = 1 ∀i ∈N (2) X i∈N min(t,uib) X r=max(lib,t+1−ρib) xibr ≤1 ∀b ∈B, t ∈[sb, fb −1] (3) xibt ∈{0, 1} ∀i ∈N, b ∈B, t ∈[lib, uib] (4) A Função Objetivo (1) busca minimizar o tempo total de fluxo dos navios ponderado por suas prioridades, no qual o tempo total de fluxo é calculado como o tempo decorrido entre a chegada https://proceedings.science/p/193371?lang=pt-br DOI: 10.59254/sbpo-2024-193371 dos navios ao berço e a conclusão das operações associadas. Essa modelagem contém um número pseudo-polinomial de variáveis O(|N| · T) e restrições O(|N| + T), em que T = P b∈B(fb −sb) As Restrições em (2) garantem que cada navio é alocado a exatamente um berço em um instante de tempo. As Restrições em (3) garantem que cada berço possui no máximo um navio alocado em um instante de tempo. Por fim, as Restrições (4) descrevem os domínios das variáveis. A performance dessa formulação foi testada no trabalho de Kramer et al. [2019]. Para instâncias que possuem até 120 navios, a formulação TI conseguiu encontrar resultados ótimos em uma média de 23 minutos. No entanto, quando se trata de instâncias com mais de 150 navios, o desempenho os resolvedores se deteriora, não conseguindo encontrar soluções ótimas para a maioria das instâncias em um tempo limite de duas horas. Por este motivo, com a intenção da obtenção de melhores limites para as instâncias grandes do problema, o método de geração de colunas da próxima seção é apresentado. 2.3. Geração de Colunas A fim de se obter melhores limites para o DBAP, uma geração de colunas pode ser desen- volvida para o problema. Seja Ωb o conjunto de todas as programações viáveis para o berço b ∈B. O problema principal da geração de colunas utiliza uma formulação do problema de partição de conjuntos (do inglês, Set Paritioning Problem - SPP) para encontrar a melhor programação consi- derando todos os berços. É utilizado um conjunto de variáveis binárias λb p, b ∈B, p ∈Ωb, onde λb p = 1 representa a utilização da programação p no berço b, ou zero caso contrário. Além disso, o custo total de uma programação p ∈Ωb é representado por cb p e a constante ¯yb ip indica quantas vezes o navio i ∈N é atribuído ao berço b na programação p. Por fim, a formulação do SPP é apresentada a seguir. min X b∈B X p∈Ωb cb pλb p (5) sujeito a X b∈B X p∈Ωb ¯yb ipλb p = 1 ∀i ∈N (6) X p∈Ωb λb p = 1 ∀b ∈B (7) λb p ∈{0, 1} ∀b ∈B, p ∈Ωb (8) (9) A Função Objetivo (5) minimiza o custo total das programações utilizadas nos berços. As Restrições (6) garantem que todos os navios são programados exatamente em um berço. As Restrições (7) forçam a utilização de apenas uma programação por berço. Por fim, as Restrições (8) indicam o domínio das variáveis. A formulação (5)-(8) claramente possui um número exponencial de variáveis, visto a possibilidade de combinações de navios nos berços. Por este motivo, para a resolução do pro- blema principal, um algoritmo de geração de colunas é utilizado, onde apenas um subconjunto das programações de cada berço Ωb é considerado durante a resolução. A cada iteração do algoritmo, um subproblema de pricing é resolvido para cada berço, gerando novas programações e, por con- sequência, novas variáveis λb p para o problema principal. Sejam βi e γb as variáveis duais associadas às restrições (6) e (7) respectivamente. O custo reduzido ¯cb p de uma variável λb p é apresentado na Equação (10). https://proceedings.science/p/193371?lang=pt-br DOI: 10.59254/sbpo-2024-193371 ¯cb p = cb p −γb − X i∈N ¯yb ipβi (10) O subproblema de pricing pode ser resolvido utilizando uma programação dinâmica, onde o estado de uma programação parcial P de um berço b pode representado pelo rótulo Lb(P) = (t(P), ¯c(P), Π(P)), sendo t(P) o último instante de tempo da programação parcial P, ¯c(P) o custo reduzido acumulado na programação parcial P, e Π(P) o conjunto dos navios presentes na programação parcial P. O algoritmo então inicia com a programação parcial trivial vazia Lb(Pi) = (−γb, ∅), e efetua extensões para novas programações parciais, desde que estas sejam viáveis. Uma extensão viável de uma programação parcial P1 para um navio i gera uma nova programação parcial P2 definida na Equação (11), caso t(P1) + ρib < min(fi, fb) e i /∈Π(P1). Lb(P2) = (max(t(P1), ti) + ρib, ¯c(P1) + pi(t(P) + ρib −ti) −βi, Π(P1) ∪{i}) (11) De forma a reduzir o número de rótulos gerados durante a execução da programação dinâmica, uma regra de dominância é utilizada, garantindo que um rótulo Lb(P2) que pode ser estendido para os mesmos estados que outro rótulo Lb(P1), porém com um custo reduzido maior, seja descartado durante a execução do algoritmo. A regra de dominância completa para Lb(P1) ⪯ Lb(P2) é apresentada na Equação (12). Lb(P1) ⪯Lb(P2) sse ¯c(P1) ≤¯c(P2) ∧t(P1) ≤t(P2) ∧Π(P1) ⊆Π(P2) (12) A regra de dominância acima é utilizada para rótulos terminando no mesmo instante de tempo, i.e., rótulos com o mesmo valor de t(P). Esta política pode ser facilmente implementada com a utilização de um vetor contendo uma lista de rótulos para cada possível instante de tempo do horizonte de planejamento. A programação dinâmica então efetua todas as extensões possíveis, seguindo a ordem dos instantes de tempo, utilizando a regra de dominância apresentada, até que nenhum novo rótulo é gerado. Uma outra forma de melhorar o desempenho do subproblema de pricing é a utilização de uma relaxação de rotas, como a relaxação conhecida como ng-rotas [Baldacci et al., 2011]. Nesta relaxação, a memória de uma programação parcial P, definida anteriormente como Π(P) guarda apenas um subconjunto dos navios visitados seguindo a regra descrita a seguir. Seja uma programação parcial P = {v1, v2, . . . , vp} com p navios visitados, e um subconjunto de navios Ni associado a cada navio i ∈N, definido como a “memória” do navio i. A memória ng da programação parcial P é então definida na equação (13). Os conjuntos Ni são construídos baseados na proximidade das janelas de tempos dos navios. Π(P) = ( vk ∈P \\ {vp} : vk ∈ p\\ s=k+1 Nvs ) ∪{vp} (13) Com o intuito de reduzir ainda mais o tempo de resolução da geração de colunas, uma versão heurística simplificada do algoritmo de pricing é utilizada, onde, em vez de armazenar uma lista de rótulos não-dominados para cada instante de tempo no vetor da programação dinâmica, é armazenado apenas o rótulo com o menor valor de custo reduzido, assim não havendo a necessidade da utilização da dominância nesta versão heurística do pricing [Martinelli et al., 2014]. O algoritmo de geração de colunas inicia gerando uma solução primal utilizando um al- goritmo construtivo simples, e as programações encontradas para cada berço são adicionadas na https://proceedings.science/p/193371?lang=pt-br DOI: 10.59254/sbpo-2024-193371 formulação de partição de conjuntos. A cada iteração, a solução dual é obtida da formulação, e o subproblema de pricing heurístico é resolvido para cada berço, gerando um novo conjunto de programações com custo reduzido negativo, que são adicionadas à formulação, iniciando assim uma nova iteração do método principal. Quando nenhuma nova programação de custo reduzido negativo é encontrada para todos os berços, o subproblema de pricing exato é resolvido para todos os berços. Caso alguma nova programação seja encontrada, na próxima iteração o método retorna à utilização do pricing heurístico. Caso contrário, o algoritmo termina, encontrando assim o valor ótimo para a relaxação linear do problema. 3. Resultados Computacionais Esta seção apresenta os experimentos computacionais realizados com os modelos TI e de partição de conjuntos resolvido por geração de colunas. Para permitir um comparativo das soluções fracionárias da geração de colunas, o modelo TI será rodado tanto na formulação original quanto com as restrições de integralidade relaxada. Ambos os modelos foram implementados na linguagem de programação Julia 1.10.3 e resolvidos utilizando o solver Gurobi na versão 11.0.2. A execução ocorreu em uma única thread, com um tempo limite de uma hora (3.600 segundos), em um sistema equipado com processador Intel Core i7-8700K CPU @ 3.70GHz e 64 GB de RAM. 3.1. Instâncias de Teste Neste trabalho, consideramos um subconjunto das instâncias propostas pelos trabalhos de Cordeau et al. [2005], Lalla-Ruiz et al. [2012], Nishi et al. [2020] e Kramer et al. [2019]. Essas instâncias variam entre 30 e 250 navios e entre 3 e 20 berços, totalizando 110 instâncias considera- das. Dentre essas instâncias, 20 não possuem solução ótima conhecida até o momento. A tabela 1 apresenta o número de instâncias de teste para cada combinação de navios e berços: Navios Berços Quantidade 200 15 10 250 20 10 30 3 10 5 10 40 5 10 7 10 55 5 10 7 10 10 10 60 5 10 7 10 Tabela 1: Número de instâncias de teste para cada combinação de navios e berços. 3.2. Comparação dos Resultados 3.2.1. Instâncias com ótimo conhecido Os resultados indicam que tanto a geração de colunas quanto o modelo TI relaxado apre- sentam resultados próximos ao ótimo para as instâncias menores, onde a solução ótima já é co- nhecida. A Figura 1 apresenta o Gap, que consiste na diferença percentual entre a solução ótima conhecida e a solução obtida pelo modelo, logo, um Gap positivo indica que a solução obtida é inferior à solução ótima. Os valores representam a média dos gaps das instâncias agrupadas por número de navios e berços. No geral, o método de GC apresentou um gap médio de 0.08% e o TI relaxado um gap médio de 0.11%. https://proceedings.science/p/193371?lang=pt-br DOI: 10.59254/sbpo-2024-193371 Figura 1: Diferença percentual entre a solução ótima conhecida e a solução obtida pelo modelo Fonte: Autores, 2024. Na Figura 2, observa-se o tempo total de execução dos modelos testados. Os valores representam a média do tempo das instâncias também agrupadas por número de navios e berços. No geral, o método de GC apresentou um tempo de médio total ∼50% inferior ao tempo médio do modelo TI relaxado. Figura 2: Tempo médio de execução por grupo de instâncias Fonte: Autores, 2024. Ambos os métodos apresentaram resultados próximos ao ótimo, o que indica que essas relaxações são fortes. Ademais, a geração de colunas mostrou um desempenho superior ao modelo TI relaxado, alcançando um gap médio menor em todos os grupos, e um tempo médio inferior em todos os grupos. https://proceedings.science/p/193371?lang=pt-br DOI: 10.59254/sbpo-2024-193371 3.2.2. Instâncias em aberto Para as instâncias em aberto, a Tabela 2 é apresentada. Esta tabela reúne os resultados da literatura, dos modelos TI (MIP/relaxado) e da geração de colunas. Como é possível observar, a geração de colunas obteve resultados próximos ao limite inferior da literatura, com um tempo de execução significativamente menor. Em comparação com o modelo TI relaxado, a geração de co- lunas apresentou resultados de melhor qualidade e, do mesmo modo que também obteve tempos de execução inferiores. Ademais, destacamos na tabela em negrito os resultados em que as abordagens conseguiram atingir1 os limites da literatura, e sublinhamos aqueles que superaram os limites. No total, foram três novos limites inferiores encontrados pela geração de colunas, e uma nova instância resolvida pelo modelo TI inteiro (f200x15-05)2. Esses novos limites inferiores, e tempos claramente menores, concretizam a superioridade do modelo de partição de conjuntos re- solvido por geração de colunas em relação ao modelo indexado pelo tempo relaxado. Instance Literatura TI MIP TI Relaxado Geração de Colunas LB UB LB UB Tempo Root Tempo Root Tempo f200x15-01 12604 12609 12604 12663 3600.0 12603.29 197.2 12603.29 34.6 f200x15-02 10319 10319 10318 10354 3600.0 10317.60 218.6 10317.60 35.7 f200x15-03 11296 11355 11305 11364 3600.0 11288.14 144.2 11304.35 57.2 f200x15-04 15441 15441 15435 15463 3600.0 15431.80 193.7 15435.22 60.8 f200x15-05 18166 18352 18170 18170 3600.0 18157.25 235.1 18165.61 51.0 f200x15-06 16869 16869 16869 16869 1625.8 16867.05 209.3 16868.14 46.8 f200x15-07 13025 13226 13026 13099 3600.0 13023.01 149.4 13025.85 66.2 f200x15-08 14182 14259 14193 14330 3600.0 14156.33 191.0 14192.11 45.1 f200x15-09 18118 18118 18117 18172 3600.0 18115.79 215.2 18116.30 52.1 f200x15-10 17102 17118 17103 17181 3600.0 17093.79 208.0 17102.67 42.7 f250x20-01 15633 15769 15633 15765 3600.0 15632.16 344.9 15632.31 97.9 f250x20-02 15776 15915 15776 15936 3600.0 15774.94 813.3 15775.14 112.2 f250x20-03 16519 16606 16519 16635 3600.0 16518.81 384.7 16518.81 96.0 f250x20-04 16423 16481 16423 16457 3600.0 16422.64 446.8 16422.64 83.1 f250x20-05 15661 15837 15661 15909 3600.0 15660.97 578.4 15660.97 86.1 f250x20-06 20060 20060 20060 20060 929.6 20060.00 492.8 20060.00 93.6 f250x20-07 14284 14362 14284 14424 3600.0 14283.31 328.2 14283.31 101.8 f250x20-08 16305 16383 16304 16483 3600.0 16303.70 448.5 16303.70 94.2 f250x20-09 15864 15917 15864 15934 3600.0 15863.52 425.0 15863.81 94.8 f250x20-10 16283 16371 16283 16441 3600.0 16282.48 363.3 16282.48 92.2 Tabela 2: Comparação entre todos os modelos para instâncias em aberto 4. Conclusões e Trabalhos Futuros Neste trabalho, abordamos o Problema de Alocação Dinâmica de Berços utilizando uma metodologia de geração de colunas. Os resultados computacionais comprovam a eficácia da geração de colunas para a resolução do DBAP, estabelecendo novos limites inferiores para instâncias ainda em aberto na literatura e obtendo resultados em um tempo consideravelmente menor do que o modelo indexado por tempo. 1Os limites inferiores, quando arredondados para o inteiro acima, são iguais ao limite superior da literatura, foram considerados como atingidos. 2O modelo TI inteiro conseguiu resolver esta instância devido a melhoria nos resolvedores comerciais desde a última execução dos modelos da literatura. https://proceedings.science/p/193371?lang=pt-br DOI: 10.59254/sbpo-2024-193371 Nossa pesquisa demonstra que a geração de colunas é uma ferramenta poderosa para o DBAP, com o potencial de resolver problemas que antes eram intratáveis. Considerando as 20 instâncias em aberto na literatura, a geração de colunas foi capaz de identificar 3 novos limites inferiores e igualou o melhor valor conhecido em 13 das 17 instâncias restantes. Como um trabalho futuro, recomendamos a exploração de uma abordagem de Branch- and-Price para alcançar soluções inteiras para o DBAP. Esta metodologia surge como promissora, uma vez que a geração de colunas produz soluções com uma pequena diferença entre o limite inferior alcançado e o limite superior conhecido, o que é uma característica altamente desejável para a etapa inicial da árvore de Branch-and-Price."
        },
        {
            "titulo": "Um algoritmo híbrido para o problema de escalonamento integrado de satélites ágeis de observação da Terra",
            "informacoes_url": "https://proceedings.science/p/193400?lang=pt-br",
            "idioma": "português",
            "storage_key": "galoa-proceedings--sbpo-2024--193400.pdf",
            "autores": [
                {
                    "nome": "Yure",
                    "afiliacao": "Universidade Federal da Paraíba, PPGI",
                    "orcid": "yure.trs@gmail.com"
                },
                {
                    "nome": "Guilherme O. Chagas",
                    "afiliacao": "CIRRELT e Faculté des Sciences de l’Administration, Université Laval, Qu´ebec, Canada",
                    "orcid": "guilherme.oliveira-chagas.1@ulaval.ca"
                },
                {
                    "nome": "Leandro C. Coelho",
                    "afiliacao": "CIRRELT, Faculté des Sciences de l’Administration e Canada Research Chair in Integrated Logistics, Université Laval, Qu´ebec, Canada",
                    "orcid": "leandro.coelho@fsa.ulaval.ca"
                },
                {
                    "nome": "Anand Subramanian",
                    "afiliacao": "Universidade Federal da Paraíba, Departamento de Sistemas de Computação",
                    "orcid": "anand@ci.ufpb.br"
                }
            ],
            "data_publicacao": "",
            "resumo": "Satélites têm aplicações importantes atualmente, como no monitoramento de desastres naturais. Este trabalho aborda o problema de escalonamento integrado de satélites ágeis de observação da Terra, cujo objetivo é maximizar a soma dos lucros associados às requisições de observação atendidas e a quantidade de dados transmitidos para as estações terrestres.",
            "keywords": [
                "Satélites de observação da Terra",
                "Escalonamento de satélites",
                "Algoritmo híbrido"
            ],
            "referencias": [
                "Barbulescu, L., Watson, J.-P., Whitley, L. D., e Howe, A. E. (2004). Scheduling space–ground communications for the air force satellite control network. Journal of Scheduling, 7:7–34.",
                "Bensanna, E., Verfaillie, G., Agnèse, J., Bataille, N., e Blumstein, D. (1996). Exact and approximate methods for the daily management of an earth observation satellite. In Proc. of the 4th Int. Symposium on Space Mission Operations and Ground Data Systems, Munich, Germany.",
                "Chang, Z., Zhou, Z., Xing, L., e Yao, F. (2021). Integrated scheduling problem for earth observation satellites based on three modeling frameworks: an adaptive bi-objective memetic algorithm. Memetic Computing, 13(2):203–226.",
                "Cho, D.-H., Kim, J.-H., Choi, H.-L., e Ahn, J. (2018). Optimization-based scheduling method for agile earth-observing satellite constellation. Journal of Aerospace Information Systems, 15(11):611–626.",
                "Kramer, A. e Subramanian, A. (2019). A unified heuristic and an annotated bibliography for a large class of earliness–tardiness scheduling problems. Journal of Scheduling, 22(1):21–57.",
                "Lemaître, M., Verfaillie, G., Jouhaud, F., Lachiver, J.-M., e Bataille, N. (2002). Selecting and scheduling observations of agile satellites. Aerospace Science and Technology, 6(5):367–381.",
                "Liu, X., Laporte, G., Chen, Y., e He, R. (2017). An adaptive large neighborhood search metaheuristic for agile satellite scheduling with time-dependent transition time. Computers & Operations Research, 86:41–53.",
                "Marinelli, F., Nocella, S., Rossi, F., e Smriglio, S. (2011). A lagrangian heuristic for satellite range scheduling with resource constraints. Computers & Operations Research, 38(11):1572–1583.",
                "Spangelo, S., Cutler, J., Gilson, K., e Cohn, A. (2015). Optimization-based scheduling for the single-satellite, multi-ground station communication problem. Computers & Operations Research, 57:1–16.",
                "Wang, P., Reinelt, G., Gao, P., e Tan, Y. (2011). A model, a heuristic and a decision support system to solve the scheduling problem of an earth observing satellite constellation. Computers & Industrial Engineering, 61(2):322–335.",
                "Wang, X., Wu, G., Xing, L., e Pedrycz, W. (2020). Agile earth observation satellite scheduling over 20 years: Formulations, methods, and future directions. IEEE Systems Journal, 15(3):3881–3892.",
                "Wolfe, W. J. e Sorensen, S. E. (2000). Three scheduling algorithms applied to the earth observing systems domain. Management Science, 46(1):148–166.",
                "Zufferey, N., Amstutz, P., e Giaccari, P. (2008). Graph colouring approaches for a satellite range scheduling problem. Journal of Scheduling, 11:263–277."
            ],
            "artigo_completo": "Um algoritmo híbrido para o problema de escalonamento integrado de satélites ágeis de observação da Terra. RESUMO Satélites têm aplicações importantes atualmente, como no monitoramento de desas- tres naturais. Este trabalho aborda o problema de escalonamento integrado de satélites ágeis de observação da Terra, cujo objetivo é maximizar a soma dos lucros associados às requisições de observação atendidas e a quantidade de dados transmitidos para as estações terrestres. Para so- lucionar o problema, foi proposto um algoritmo híbrido que combina um resolvedor MIP e uma heurística. Experimentos computacionais foram feitos em instâncias propostas para avaliar a perfor- mance do algoritmo em comparação com uma abordagem da literatura e também à de um resolvedor MIP. Em relação ao método da literatura, soluções de qualidade superior foram encontradas para 29 das 32 instâncias. Comparado ao resolvedor MIP, o algoritmo encontrou soluções competitivas, especialmente para as instâncias mais desafiadoras, apresentando uma melhora de até 25.93%. PALAVRAS CHAVE. Satélites de observação da Terra. Escalonamento de satélites. Algo- ritmo híbrido. Tópicos: OC – Otimização Combinatória, L&T – Logística e Transportes. https://proceedings.science/p/193400?lang=pt-br DOI: 10.59254/sbpo-2024-193400 1. Introdução Satélites são utilizados atualmente para diversas tarefas, como por exemplo para fornecer conexão à Internet em áreas remotas ou para monitoramento da Terra. Nesse último caso, eles podem fornecer dados históricos para ajudar na prevenção de desastres naturais, como as enchentes que recentemente acometeram o estado do Rio Grande do Sul, ou no combate ao desmatamento ilegal em áreas de preservação ambiental. Diversas empresas já lançaram constelações, ou frotas, de satélites de órbita baixa. Esses satélites são equipados com instrumentos como câmeras e têm quantidades de memória e de energia limitadas. Por um lado, a memória pode ser liberada por meio do download dos dados obtidos para estações terrestres. Por outro lado, a energia, consumida em atividades de observação, de download, e de mudança de pose do satélite, pode ser renovada periodicamente nas órbitas com iluminação solar. Diariamente, pessoas civis ou militares enviam requisições, com diferentes prioridades, para obtenção de imagens de determinados locais do planeta. Como a órbita do satélite é conhecida, é possível saber em quais janelas de tempo um local pode ser observado, bem como quando uma operação de download pode ser realizada. Vale destacar que devido à periodicidade dos satélites, existem múltiplas janelas de tempo envolvendo o mesmo par de local (ou estação) e satélite. O objetivo do problema de escalonamento integrado de satélites ágeis de observação da Terra (PEISAT), consiste em maximizar a quantidade de requisições atendidas, bem como de dados transmitidos para as estações terrestres, respeitando restrições de energia, memória e janelas de tempo. O satélite considerado neste trabalho é do tipo ágil, apresentando mobilidade nos eixos pitch e roll, conforme ilustrado na Figura 1. Órbita Nadir Satélite Trajetória θ θ: pitch máx. Figura 1: Ângulo de pitch máximo dos satélites. O ângulo de roll depende da direção do satélite com relação à trajetória. A Figura 2 ilustra um exemplo de solução parcial para o PEISAT. Neste exemplo, a energia é considerada suficiente e o armazenamento interno é limitado a 15 unidades de dados. O satélite começa observando o local 1 no tempo t1. Depois de 7.5 unidades de tempo, ele começa a ajustar sua pose para observar o local 2, no tempo t2. Ao final dessa operação, o armazenamento interno do satélite (Mem) contém 15 unidades de dados, enviados para a estação g no tempo t3, após um tempo de transição. O alvo 3 não pode ser coletado porque o satélite precisa primeiro fazer o download dos dados associados a pelo menos um dos locais observados. O download para estação g não pode ser escalonado imediatamente no início da sua janela de tempo (Jt) devido ao longo tempo de transição necessário depois da última tarefa realizada. A solução parcial é finalizada com a aquisição do local 4, a partir do tempo t4. O satélite termina com 7.5 unidades de dados armazenados referentes à última observação. Na literatura, existem diversos estudos envolvendo problemas de escalonamento de satélites, sendo possível destacar três categorias principais de problemas. A primeira classe en- volve o escalonamento apenas de tarefas de observação (ver por exemplo Wolfe e Sorensen [2000]; Lemaître et al. [2002]; Liu et al. [2017]). Para uma revisão mais detalhada sobre o problema de escalonamento de satélites ágeis de observação da Terra, ver Wang et al. [2020]. O segundo clus- ter contempla problemas de escalonamento de atividades de comunicação entre satélites e estações https://proceedings.science/p/193400?lang=pt-br DOI: 10.59254/sbpo-2024-193400 Órbita Trajetória Intervalo de obs. g 1 2 3 4 Tempo 0 10 20 30 40 50 60 70 80 90 100 t1 t2 t3 t4 Satélite Id Local Estação terrestre Observação Download Tempo transição Ocioso Id : Mem : [a, b] Jt 1 : 7.50 : [05, 30] 2 : 15.0 : [25, 50] 3 : − : [30, 55] g : 0.00 : [35, 75] 4 : 7.50 : [70, 95] Figura 2: Exempo de solução parcial. terrestres, incluindo tarefas de download. Zufferey et al. [2008]; Marinelli et al. [2011]; Spangelo et al. [2015] são alguns exemplos de trabalhos nessa categoria. Os problemas de escalonamento de observações e de downloads, envolvendo satélites, são ambos NP-hard [Bensanna et al., 1996; Barbulescu et al., 2004]. Já a terceira classe consiste da versão integrada de ambos os problemas. Dentre os estudos realizados, os mais próximos deste trabalho são: Wang et al. [2011]; Cho et al. [2018]; Chang et al. [2021]. Mesmo nas versões separadas dos problemas, os modelos propostos acabam intratáveis. A versão integrada é ainda mais complexa, por isso os autores muitas vezes não incorporam devidamente aspectos importantes do problema, por exemplo relacionados à energia e aos tempos de transição. Neste trabalho, é proposto um modelo de programação linear inteira mista para resolver o problema de escalonamento integrado de satélites ágeis de observação da Terra. Para resolver o problema, utiliza-se um algoritmo híbrido, chamado variable MIP neighborhood descent (VMND), que combina o resolvedor MIP ao procedimento variable neighborhood descent (VND). Os testes foram realizados em um conjunto de instâncias propostas. Para comparar o VMND com a literatura, o modelo apresentado foi modificado para resolver o problema de escalonamento de constelação de satélites (PECS). A abordagem de Cho et al. [2018] para o PECS é comparada ao VMND. Foram resolvidas 32 instâncias, das quais o algoritmo híbrido apresentou soluções melhores em 29 e empatou em uma. O VMND também foi comparado ao resolvedor MIP, apresentando resultados de qualidade superior, principalmente nas instâncias de tamanho maior. 2. Formulação matemática As seguintes premissas são adotadas neste trabalho: (i) tarefas não podem ser interrom- pidas depois de iniciadas; (ii) os alvos do tipo observação podem ser capturados de uma única vez; (iii) estações terrestres podem atender a no máximo um satélite por vez, assim como satélites po- dem executar no máximo uma operação (observação ou download) por vez; (iv); de forma análoga a Wang et al. [2011], o tempo de transição dos satélites é uma função das mudanças nos ângulos de pitch e de roll, e não há sobreposição entre janelas de tempo de observação e de downalod; (v) cada satélite possui um único instrumento óptico, idêntico ao dos demais; e (vi), a energia coletada pelos paineis solares dos satélites nas zonas de exposição ao sol, durante as janelas de tempo, é desconsiderada. Para cada satélite i ∈S e cada alvo τ ∈T, Γτ i = {(a1 iτ, b1 iτ), . . . , (ariτ iτ , briτ iτ )} é definido como o conjunto de janelas de tempo de oportunidades (ou o conjunto de tarefas) nas quais alvo τ é visível ao satélite i (seja para observação, se τ ∈O; ou para download, se τ ∈G). Além disso, 0 ≤aγ iτ < bγ iτ ≤H para γ = 1, . . . , riτ e Γ é o conjunto de todas as tarefas. Seja o grafo ponderado, orientado e conexo G = (V, A), no qual V é o conjunto de vértices e A é o conjunto de arcos. Cada vértice em V corresponde a uma tarefa em Γ. V também contém vértices source e sink. Existe um arco entre dois vértices desse grafo caso um satélite possa executar as tarefas correspondentes em Γ, uma depois da outra. Além disso, cada vértice p ∈V https://proceedings.science/p/193400?lang=pt-br DOI: 10.59254/sbpo-2024-193400 está associado à duração (δp) e ao lucro (ρp) da tarefa correspondente τ ∈T, e com uma janela de tempo (aip, bip) do satélite i ∈S que pode executar a tarefa. Considere também δ0 = δn+1 = 0, ρ0 = ρn+1 = 0, (ai0, bi0) = (0, 0), (ain+1, bin+1) = (H, H), e φi 0 = φi n+1 = 0, ∀i ∈S. A Tabela 1 resume a notação matemática adotada. Tabela 1: Notação matemática. Dados c número de alvos, c = |T| k número de estações terrestres, k = |G| m número de satélites, m = |S| n número de tarefas (janelas de tempo de oportunidade), n = |Γ| o número de locais de observação, o = |O| h número de dias do horizonte de planejamento [0, H] tempos de início e de fim do horizonte de planejamento, respectivamente (aip, bip) janela de tempo da tarefa p ∈V, satélite i ∈S δp duração da tarefa p ∈V, dada pela duração da tarefa relacionada τ ∈T ρp lucro associado à tarefa p ∈V, dado pelo lucro da tarefa relacionada τ ∈T θobs ângulo máximo de pitch para tarefas de observação θdwn ângulo máximo de pitch para tarefas de download ϕobs ângulo máximo de roll para tarefas de observação ϕdwn ângulo máximo de roll para tarefas de download φi p ângulo de roll necessário para que o satélite i ∈S execute tarefa p ∈Vi ¯Eobs consumo médio de energia por unidade de tempo para observações ¯Edwn consumo médio de energia por unidade de tempo para downloads ∆σ tempo mínimo de transição das estações terrestres entre duas tarefas E0 energia inicial dos satélites Emax capacidade máxima de energia dos satélites ϵi pq ganho de energia de i ∈S entre o fim da janela de tempo de p e oinício da janela de tempo de q, p, q ∈Vi ¯Lobs taxa média de ganho de dados (por segundo) ¯Ldwn taxa média de transferência de dados (por segundo) L0 armazenamento inicial dos satélites Lmax capacidade de armazenamento dos satélites ω1, ω2, ω3, ω4 constantes não-negativas (em segundos por grau), que dependem do satélite β1, β2 constantes não-negativas (em segundos), que dependem do satélite Conjuntos G estações terrestres homogêneas O locais (ou pontos) para observação S satélites homogêneos T alvos, com T = G ∪O Γ tarefas (janelas de tempo de oportunidade) Γi tarefas visíveis ao satélite i ∈S, Γi ⊆Γ Γτ i tarefas envolvendo τ ∈T e satélite i ∈S, Γτ i ⊆Γi G grafo, G = (V, A) V vértices, V = {0, p1, . . . , pn, n + 1} V′ vértices tarefa, V′ = V \\ {0, n + 1} Vi vértices tarefa que podem ser executados por i ∈S, {0, n + 1} inclusos, Vi = Di ∪Oi V′ i vértices tarefa que podem ser executados por i ∈S, V′ i = D′ i ∪O′ i A arcos entre vértices de V D vértices cujas tarefas correspondentes em Γ são de download, {0, n + 1} inclusos, D ⊂V Di vértices tarefa de download do satélite i ∈S, {0, n + 1} inclusos, Di ⊆D D′ i vértices tarefa de download do satélite i ∈S, D′ i = Di \\ {0, n + 1} Dg i vértices tarefa de download envolvendo satélite i ∈S e estação g ∈G, Dg i ⊆Di D′g i vértices tarefa de download envolvendo satélite i ∈S e estação g ∈G, D′g i = Dg i \\ {0, n + 1} O vértices cujas tarefas correspondentes em Γ são de observação, {0, n + 1} inclusos, O ⊂V Oi vértices tarefa de observação do satélite i ∈S, {0, n + 1} inclusos, Oi ⊆O O′ i vértices tarefa de observação do satélite i ∈S, O′ i = Oi \\ {0, n + 1} Oτ i vértices tarefa de observação envolvendo satélite i ∈S e tarefa τ ∈T O PEISAT é modelado como um problema de programação não linear inteira mista (1)– (28). Nessa formulação, as seguintes variáveis são utilizadas: (i) xi pq – variável de decisão binária https://proceedings.science/p/193400?lang=pt-br DOI: 10.59254/sbpo-2024-193400 usada para indicar se tarefas p, q ∈Vi são adotadas uma depois da outra pelo satélite i ∈S. xi pq é criada somente se a tarefa q pode ser realizada depois da tarefa p; (ii) yi pq – variável de decisão binária utilizada para indicar se tarefas p e q (p, q ∈Oi ou p, q ∈Di) são escolhidas como tarefas consecutivas pelo satélite i ∈S. Análogo ao xi pq, yi pq é criada somente se a tarefa q pode ser executada após a tarefa p. Ademais, yi pq é adicionada se restrições de tempo de transição são necessárias entre as tarefas p e q; e (iii) zgii′ pq – variável de decisão binária usada para indicar se tarefas de download p ∈Dg i e q ∈Dg i′, envolvendo a estação g ∈G, são adotadas pelos satélites i e i′, respectivamente. A variável zgii′ pq existe apenas se restrições de tempo de transição são necessárias para essas tarefas As variáveis de decisão contínuas usadas no modelo (1)–(28) são descritas a seguir: (i) di p – variável contínua e não negativa para a duração da tarefa p ∈Vi do satélite i ∈S. Se p ∈O′ i, di p = δp; caso contrário, se p ∈D′ i, δp ≤di p ≤Lmax ¯Ldwn . Ademais, se p ∈{0, n + 1}, di p = 0; (ii) li p – variável contínua e não negativa que indica a quantidade de memória utilizada pelo satélite i ∈S no final da execução da tarefa p ∈Vi; (iii) ei p – variável contínua e não negativa que indica a quantidade de energia do satélite i ∈S no final da execução da tarefa p ∈Vi; (iv) ti p – variável contínua e não negativa utilizada para indicar o tempo de início da tarefa p ∈V′ i, dentro da janela de tempo (aip, bip), pelo satélite i ∈S. Se p ∈{0, n + 1}, aip ≤ti p ≤bip; (v) ϑi p – variável contínua e não negativa representando o ângulo de pitch do satélite i ∈S para executar a tarefa p ∈Vi; (vi) ∆li p – variável contínua e não negativa indicando a alteração no armazenamento do satélite i ∈S após execução da tarefa p ∈Vi; (vii) ∆ei p – variável contínua e não negativa indicando a quantidade de energia consumida pelo satélite i ∈S na tarefa p ∈Vi; e (viii) ∆si pq – variável contínua e não negativa para o tempo de transição necessário pelo satélite i ∈S entre tarefas p, q ∈Vi. As variáveis xi pq e yi pq, bem como as restrições associadas a elas, consideram p ̸= q. De forma similar, as variáveis zgii′ pq , e todas as restrições associadas a elas, assumem i ̸= i′. A formulação não linear do problema é apresentada a seguir. max X i∈S X p∈Oi\\{n+1} X q∈Vi\\{0} (ρp + δp)xi pq − 1 ¯Ldwn X i∈S li n+1 (1) subject to X p∈Vi\\{n+1} xi pq − X r∈Vi\\{0} xi qr = 0, i ∈S, q ∈V′ i (2) X q∈Vi\\{0} xi 0q = 1, i ∈S (3) X p∈Vi\\{n+1} xi pn+1 = 1, i ∈S (4) X i∈S X p∈Oτ i X q∈Vi\\{0} xi pq ≤1, τ ∈T (5) yi pq + yi qp = min    X r∈Vi\\{0} xi pr, X u∈Vi\\{0} xi qu   , i ∈S, p ∈Vi \\ {n + 1}, q ∈V′ i (6) ϑi p = θobs \u001a 2 ti p −aip bip −aip −1 \u001b , i ∈S, p ∈Oi (7) ϑi p = θdwn \u001a 2 ti p −aip bip −aip −1 \u001b , i ∈S, p ∈Di (8) ∆si pq = ω1|φi p −φi q| + ω2|ϑi p −ϑi q| + β1, i ∈S, p, q ∈Oi (9) ∆si pq = ω3|φi p −φi q| + ω4|ϑi p −ϑi q| + β2, i ∈S, p, q ∈Di (10) yi pq(ti p + di p + ∆si pq −ti q) ≤0, i ∈S, p ∈Vi \\ {n + 1}, q ∈Vi \\ {0} (11) https://proceedings.science/p/193400?lang=pt-br DOI: 10.59254/sbpo-2024-193400 zgii′ pq + zgi′i qp = min    X r∈Vi\\{0} xi pr, X u∈Vi′ \\{0} xi′ qu   , g ∈G, i, i′ ∈S, p ∈D′g i , q ∈D′g i′ (12) zgii′ pq (ti p + di p + ∆σ −ti′ q ) ≤0, g ∈G, i, i′ ∈S, p ∈D′g i , q ∈D′g i′ (13) aip ≤ti p ≤bip −δp, i ∈S, p ∈V′ i (14) ti p + di p ≤bip, i ∈S, p ∈D′ i (15) δp ≤di p ≤Lmax ¯Ldwn , i ∈S, p ∈D′ i (16) li 0 = L0, i ∈S (17) δp ≤li p ≤Lmax, i ∈S, p ∈O′ i (18) 0 ≤li p ≤Lmax, i ∈S, p ∈Di (19) ∆li p = ( ¯Lobsdi p, se p ∈Oi, −¯Ldwndi p, caso contrário. i ∈S, p ∈Vi \\ {0} (20) xi pq(li p + ∆li q −li q) = 0, i ∈S, p ∈Vi \\ {n + 1}, q ∈Vi \\ {0} (21) ei 0 = E0, i ∈S (22) 0 ≤ei p ≤Emax, i ∈S, p ∈Vi (23) ∆ei p = ( ¯Eobsdi p, se p ∈Oi, ¯Edwndi p, caso contrário. i ∈S, p ∈Vi \\ {0} (24) xi pq(ei q −min{Ei max, ei p + ϵi pq −∆ei q}) = 0, i ∈S, p ∈Vi \\ {n + 1}, q ∈Vi \\ {0} (25) xi pq(ti p + di p −ti q) ≤0, i ∈S, p ∈Vi \\ {n + 1}, q ∈Vi \\ {0} (26) ∆li p, ϑi p ∈R, di p, ei p, li p, ti p, ∆ei p ∈R≥0, ∀i ∈S, ∀p ∈Vi (27) xi pq ∈{0, 1}, yi pq ∈{0, 1}, ∆si pq ∈R≥0, ∀i ∈S, ∀p, q ∈Vi (28) zgii′ pq ∈{0, 1}, ∀g ∈G, ∀i, i′ ∈S, ∀p ∈Dg i , ∀q ∈Dg i′. (29) A função objetivo (1) maximiza a soma dos lucros dos locais observados e a quantidade de dados transmitidos para as estações terrestres. As restrições de conservação de fluxo (2) garantem que a quantidade de fluxo entrando e saindo de um nó sejam iguais, exceto pelo nó de source (3) e o nó de sink (4). As restrições (5) definem a quantidade máxima de observações por local. Diferentemente das variáveis xi pq, que consideram apenas tarefas adotadas uma após a outra, as variáveis yi pq levam em conta quaisquer p e q. Isso é modelado por meio das restrições (6). Os ângulos de pitch do satélite i ∈S no início de tarefas de observação e de download são definidos pelas restrições (7) e (8), respectivamente. O tempos de transição ∆si pq do satélite i ∈S entre tarefas de observação (p, q ∈Oi) e de download (p, q ∈Di) são dados pelas restrições (9) e (10), respectivamente. Esses tempos ∆si pq são então utilizados nas restrições (11) para garantir que o satélite consiga ajustar sua pose entre tarefas de observação ou de download. As restrições (12) modelam variáveis de decisão zgii′ pq , usadas nas restrições (13) para assegurar que o tempo de transição da estação g, entre duas atividades de download, seja respei- tado. As desigualdades (14) asseguram que o tempo de início de qualquer tarefa p esteja dentro da janela de tempo correspondente. Os limites envolvendo variáveis di p são estabelecidos pelas restrições (15) e (16). A quantidade de memória ocupada inicialmente pelos satélites é estabelecida nas restrições (17), enquanto restrições (18) e (19) impõem limites mínimos e máximos na capaci- dade de armazenamento dos satélites. De maneira análoga, as restrições (22) definem a quantidade inicial de energia dos satélites e as restrições (23) configuram as quantidades mínimas e máximas de energia armazenada na bateria. As variações de armazenamento e de energia são tratadas pe- las restrições (21) e (25), respectivamente. As variáveis xi pq, ti p e ti q são conectadas por meio das restrições (26). Por último, as restrições (27)–(29) definem os domínios das variáveis. Todas as restrições não-lineares apresentadas podem ser linearizadas. Em particular, as restrições (11), (13), (21), (25) e (26) podem ser linearizadas com restrições Miller–Tucker–Zemlin. https://proceedings.science/p/193400?lang=pt-br DOI: 10.59254/sbpo-2024-193400 Dessa forma, o modelo final pode ser representado por um problema de programação linear inteira mista. No restante deste trabalho, a versão linear do modelo será considerada. 3. Algoritmo proposto Uma estratégia eficiente com tarefas fictícias foi implementada com o intuito de reduzir a quantidade de variáveis e de restrições, mas preservando o espaço de soluções original associado a uma instância. Tal estratégia consiste em criar um novo grafo no qual, exceto pelos vértices imediatamente após o source e logo antes do sink, um vértice fictício (ou dummy) está associado a cada vértice, conforme mostra a Figura 3. 0 f2 f3 f4 6 1 2 3 4 5 Dummy Tarefa Figura 3: Estratégia eficiente para uma instância com 5 tarefas. Na Figura 3, os nós f1, f2 e f3 correspondem a nós dummy e os arcos indicam quais variáveis xi pq são criadas. A explicação de alguns pormenores dessa estratégia, bem como a prova de que ela minimiza a quantidade de arcos criados, foge do escopo deste trabalho. 3.1. A heurística VMND A ideia principal da heurística VMND utilizada neste trabalho (Algoritmo 1) é explorar, de maneira controlada, o espaço de soluções associado a uma instância. Isso é feito por meio das estruturas de vizinhança, que fixam os bounds das variáveis xi pq antes de execuções do resolvedor MIP. Algorithm 1 VMND 1: procedure VMND(N, time limit) 2: time limit′ ←Divide time limit proporcionalmente entre build initial solution e as vizinhanças. 3: runtime ←build initial solution(time limit′(0)) 4: rem time ←time limit −runtime 5: for k = 1 to |N| 6: time limit′ ←Divide rem time proporcionalmente entre as vizinhanças restantes. 7: s∗, runtime ←N (k)(time limit′(k)) 8: rem time ←rem time −runtime. 9: end 10: return s∗ 11: end O procedimento VMND começa dividindo o tempo limite (linha 2) entre (i) a função que constrói a solução inicial e (ii) as estruturas de vizinhança. O critério dessa divisão será discutido na Seção 4.2. Em seguida, uma solução inicial é construída (linha 3) em no máximo time limit′(0). O laço de repetição principal do algoritmo (linhas 5–9) é executado |N| vezes. Em cada iteração, o tempo limite que resta é proporcionalmente dividido entre as vizinhanlas remanescentes (linha 6). A vizinhança selecionada é aplicada (linha 7) e o tempo restante calculado novamente (linha 8). No final do algoritmo, a solução incumbente é retornada (linha 10). 3.2. Estruturas de vizinhança As estruturas de vizinhança controlam o esforço computacional da execução do resolvedor MIP alterando os bounds das variáveis xi pq. Há duas possibilidades para esses limites: (i) livres – limites inferior e superior iguais a 0 e 1, respectivamente; e (ii) fixos – ambos os limites inferior e superior iguais a 0 ou a 1, dependendo do valor encontrado pelo resolvedor para xi pq na execução https://proceedings.science/p/193400?lang=pt-br DOI: 10.59254/sbpo-2024-193400 anterior. No começo de cada iteração do VMND, os limites de todas as variáveis xi pq estão fixos, de acordo com a solução incumbente, e são liberados dependendo da estrutura de vizinhança a ser aplicada. • α κ unsch targets: os limites são liberados para as variáveis ou arcos xi pq envolvendo tarefas da solução incumbente e (i) tarefas do tipo download ou dummy, ou (ii) tarefas associadas com α% dos alvos não escalonados, ordenados em ordem não-decrescente. Não é possível calcular, de maneira direta, a porcentagem relativa dos bounds liberados por iteração do laço principal desta vizinhança. • intra sat: libera os bounds dos arcos associados a um satélite por iteração. Este procedimento tem m iterações no seu laço principal. Em cada uma das iterações, os limites de 1 m% do número total de arcos são liberados. • λ mult sats: divide as tarefas disponíveis para cada satélite em λ intervalos. Em cada iteração, os limites são liberados para as variáveis xi pq cujas tarefas p e q estejam ambas no intervalo selecionado. Desta forma, a estrutura λ mult sats tem λ iterações e em cada uma, os limites liberados representam 1 λm% do total de tarefas. • doub sats: similar à intra sat, mas considerando, em vez de um único satélite, todas as combinações de pares de satélites. O procedimento leva \u0000m 2 \u0001 = m! 2!(m−2)! iterações e, em cada uma, os bounds associados a 2 m% de todas as tarefas são liberados. O esforço computacional aumenta exponencialmente com a quantidade de bounds libera- dos. Como o intuito do VMND é fazer pequenas melhorias em cada iteração, também são consi- deradas algumas variações dos operadores α κ unsch targets, intra sat e doub sats, que liberam os limites de menos arcos: (i) dwn tasks – um caso especial da vizinhança α κ unsch tagets, na qual α = 1, κ = 1, e somente os limites de arcos na solução ou entre tarefas na solução e tarefas de download são liberados; (ii) µ intra sat – similar a intra sat, mas dividindo as tarefas disponíveis para cada satélite em dois intervalos (µm iterações) com os mesmos números de tarefas, cada. Os bounds são liberados para os arcos em um intervalo ( 1 µm%) por vez; e (iii) π doub sats – difere de doub sats porque os arcos associados a cada satélite são divididos em π intervalos (2 \u0000m π \u0001 iterações). Desse modo, os limites de 2π m % dos arcos são liberados por iteração. Nas vizinhanças baseadas em intervalos (i.e., µ intra sat, λ mult sats e π doub sats), os limites de um arco não são liberados se alguma das tarefas é do tipo observação e o local associado já foi escalonado por um arco fora do intervalo selecionado. 4. Experimentos computacionais O algoritmo proposto foi implementado com a linguagem de programação C++ e com- pilado com o g++, versão 12.3.0. Além disso, foi utilizado o Gurobi, versão 11.0.1, para resolver os problemas de programação linear. Todos os testes descritos nesta seção, bem como todos os algoritmos, foram executados em uma mesma máquina Intel® Core™i9-13900K CPU 3.0 GHz, com 32 threads e 128 GB de memória RAM. Para fins de comparação com a literatura, é possível adaptar o modelo discutido para resol- ver um outro problema chamado problema de escalonamento de constelação de satélites (PECS). Cho et al. [2018] utilizaram uma abordagem de duas fases (chamada programação linear binária em duas etapas – PLBDE) para resolver o PECS, na qual a solução para o problema de escalona- mento de atividades de download é utilizada como entrada para o problema de escalonamento de observações. Os autores também implementaram um algoritmo first-in first-out (FIFO). A única https://proceedings.science/p/193400?lang=pt-br DOI: 10.59254/sbpo-2024-193400 diferença entre o PEISAT e o PECS é que este último considera satélites não-ágeis. Sendo assim, apenas restrições (9) e (10) precisam ser modificadas. O modelo proposto (1)–(28), apesar de tratar diversos aspectos relevantes do problema real, exige muito esforço computacional. É possível reduzir parte deste esforço, eliminando-se as variáveis yi pq. Tendo por base a desigualdade triangular, as variáveis yi pq e as restrições (6) e (11) são removidas do modelo e as seguintes restrições são adicionadas. ∆si pq = max{ω1, ω3}|φi p −φi q| + max{ω2, ω4}|ϑi p −ϑi q| + max{β1, β2}/2, i ∈S, p ∈Oi, q ∈Di (30) ∆si pq = max{ω1, ω3}|φi p −φi q| + max{ω2, ω4}|ϑi p −ϑi q| + max{β1, β2}/2, i ∈S, p ∈Di, q ∈Oi (31) xi pq(ti p + di p + ∆si pq −ti q) ≤0, i ∈S, p ∈Vi \\ {n + 1}, q ∈Vi \\ {0} (32) 4.1. Benchmark Para criar as instâncias para ambos os problemas PEISAT e PECS, foi considerado o conjunto de dados utilizado em Cho et al. [2018], projetado a partir de missões do mundo real. Mais especificamente, 32 instâncias foram criadas, divergindo em termos da quantidade de locais para observação o, de satélites m, de estações terrestres k e de dias h no horizonte de planejamento. Além disso, as seguintes modificações foram realizadas: (i) números associados às janelas de tempo arredondados para o inteiro mais próximo; e (ii) tarefas de observação com overlaps com tarefas de download removidas. Informações adicionais sobre as instâncias podem ser encontradas em Cho et al. [2018]. 4.2. Calibração dos parâmetros As instâncias do benchmark foram divididas em 8 grupos, de acordo com o número de locais para observação e de satélites. Para a calibração dos parâmetros, a instância com o maior horizonte de planejamento e menor número de estações terrestres foi selecionada de cada grupo. Como o objetivo do VMND é relacionado à qualidade das soluções, o resolvedor foi configurado para encontrar, rapidamente, boas soluções para o problema. Caso o resolvedor não consiga encontrar uma solução inicial em time limi′(0), uma solução vazia é adotada, apenas com as tarefas de source e de sink conectadas sem nenhuma ta- refa intermediária de observação ou de download. Com exceção de algumas vizinhanças, cujos esforços computacionais não podem ser dire- tamente deduzidos, os tempos limites das iterações dos movimentos de vizinhança são configurados de forma proporcional à quantidade de bounds liberados pelas estruturas. O tempo limite para uma iteração de um movimento que libera os limites dos arcos associados a um único satélite é chamado de tsat. Esse valor é recalculado a cada iteração do laço principal do VMND. Os seguintes limites de tempo foram adotados para cada iteração das estruturas: tl = tsat para build initial solution, α κ unsch targets, intra sat e dwn tasks; tl = mtsat λ para λ mult sats; tl = 2tsat para doub sats; tl = tsat µ para µ intra sat; e tl = 2tsat π para π doub sats. Foi usada uma abordagem incremental, similar à descrita em Kramer e Subramanian [2019], para selecionar a ordem de aplicação das estruturas de vizinhança. Os operadores foram aplicados em ordem não-decrescente de esforço computacional (determinado pela porcentagem de arcos cujos limites foram liberados). Há algumas exceções para essa regra, como por exemplo as vizinhanças α κ unsch targets e dwn tasks, nas quais o esforço computacional depende da solução incumbente. A Tabela 2 apresenta os resultados obtidos para diferentes configurações de estruturas de vizinhanças do VMND aplicado ao PECS. O “Tempo limite (s)” leva em conta o tempo total de https://proceedings.science/p/193400?lang=pt-br DOI: 10.59254/sbpo-2024-193400 Tabela 2: Diferentes configurações de estruturas de vizinhança do VMND para o PECS. Configuração Vizinhanças (N) Tempo limite (s) Gap (%) 1 70 2 unsch targets + 80 2 unsch targets 600 2.43 + 90 2 unsch targets + 100 2 unsch targets 2 60 2 unsch targets + 600 1.99 3 50 2 unsch targets + 600 2.11 4 60 2 unsch targets + 70 2 unsch targets + 80 2 unsch targets 3600 1.84 + 90 2 unsch targets + 100 2 unsch targets 5 + dwn tasks 3600 0.58 6 + 2 intra sat 3600 0.26 7 + intra sat 3600 0.25 8 + dwn tasks 3600 −0.09 9 + 4 mult sats 3600 −0.34 10 + dwn tasks 3600 −0.34 11 + 2 doub sats + doub sats 3600 −0.65 12 + dwn tasks 3600 −0.68 13 + 2 mult sats 3600 −0.82 14 + 1 mult sats 3600 −0.89 15 + dwn tasks 3600 −0.83 execução do algoritmo, enquanto o “Gap (%)” indica a média dos gaps percentuais entre o valor encontrado pelo VMND e a melhor solução entre a heurística FIFO e o PLBDE. A busca local é iniciada com a aplicação da estrutura α κ unsch targets à solução inicial. Para simplificar, o nome α κ será utilizado em vez de α κ unsch targets. As configurações 1, 2 e 3 da Tabela 2 contêm os resultados de diferentes combinações de α κ, com tempo limite total de 600 segundos. O valor κ = 2 foi adotado por oferecer transações mais suaves entre execuções consecu- tivas da vizinhança α κ. Inicialmente, na configuração 1, as vizinhanças 70 2, 80 2, 90 2 e 100 2 são aplicadas, nessa ordem. Em seguida, na configuração 2, a vizinhança 60 2 é adicionada antes das vizinhanças da configuração 1. De forma análoga, a vizinhança 50 2 é inserida, na configuração 3, antes das vizinhanças da configuração 2. Como há piora no “Gap (%)”, a configuração 3 é des- cartada (riscado na vizinhança 50 2 adicionada na configuração 3). A configuração 4 contém o resultado do VMND com configuração 2 e tempo limite total de 3600 segundos. Na configuração 5, a vizinhança dwn tasks é inserida após as vizinhanças da configuração 4. De agora em diante, dwn tasks será testada após a exploração de vizinhanças semelhantes (configurações 8, 10, 12 e 15) para facilitar o download de dados, o que corresponde a metade do objetivo do problema. O pro- cesso de adição de vizinhança após as vizinhanças da configuração anterior, com descarte quando há piora, continua até a configuração 15, com a melhor sequência ocorrendo na configuração 14. 4.3. Comparação com a literatura A Tabela 3 apresenta os resultados da heurística VMND aplicada ao PECS. A coluna “Obj.” reporta o valor da função objetivo obtido pelo VMND, enquanto o “Gap (%)” foi calculado de forma análoga ao da Seção 4.2. Como retratado na Tabela 3, a heurística alcançou os melhores resultados para quase todas as instâncias. Em apenas 3 instâncias o VMND não foi capaz de obter soluções melhores, empa- tando em uma delas. Com relação às instâncias com 200 e 400 locais para observação, a heurística VMND obteve uma média de gaps −1.97% melhor com relação aos algoritmos da literatura. Já nas instâncias com 600 e 800 locais para observação, a média dos gaps foi de −0.44%. 4.4. Resultados A Tabela 4 mostra os resultados do algoritmo VMND comparado ao MIP solver, ambos resolvendo o PEISAT. O VMND apresentou resultados de qualidade superior na maioria das instâncias, prin- cipalmente naquelas com 600 e 800 locais para observação, nas quais a média dos gaps foi de https://proceedings.science/p/193400?lang=pt-br DOI: 10.59254/sbpo-2024-193400 Tabela 3: Resultados obtidos pelo VMND para o PECS. Instância FIFO PLBDE VMND Instância FIFO PLBDE VMND c m k h Obj. Gap(%) c m k h Obj. Gap(%) 200 1 1 1 1440 1600 1640 −2.50 600 3 2 2 14220 16230 16330 −0.62 200 1 1 2 3290 3730 3820 −2.41 600 3 2 3 18950 21500 21340 0.74 200 1 2 1 1970 2120 2190 −3.30 600 3 4 2 16670 19610 19630 −0.10 200 1 2 2 3910 4150 4290 −3.37 600 3 4 3 21850 25070 25160 −0.36 200 3 1 1 4760 5192 5360 −3.24 600 6 2 2 24700 29590 29610 −0.07 200 3 1 2 9050 9910 10030 −1.21 600 6 2 3 30950 35180 35380 −0.57 200 3 2 1 6000 6330 6540 −3.32 600 6 4 2 28910 32920 33180 −0.79 200 3 2 2 9870 10480 10620 −1.34 600 6 4 3 33670 35330 35380 −0.14 400 1 1 1 1590 1850 1850 0.00 800 3 2 2 16030 18090 18370 −1.55 400 1 1 2 3650 4440 4460 −0.45 800 3 2 3 21550 24320 24360 −0.16 400 1 2 1 2370 2580 2630 −1.94 800 3 4 2 18660 21870 22190 −1.46 400 1 2 2 4820 5370 5490 −2.23 800 3 4 3 24760 28690 28930 −0.84 400 3 1 1 5340 6012 6180 −2.79 800 6 2 2 27720 34020 33870 0.44 400 3 1 2 11140 12840 13010 −1.32 800 6 2 3 35980 42290 42710 −0.99 400 3 2 1 7140 7860 7960 −1.27 800 6 4 2 33480 39460 39640 −0.46 400 3 2 2 12790 14490 14610 −0.83 800 6 4 3 40990 45210 45280 −0.15 Média 5571 6185 6292 −1.97 Média 25568 29336 29460 −0.44 Tabela 4: Resultados obtidos pelo VMND para o PEISAT. Instância MIP solver VMND Instância MIP solver VMND c m k h Obj. Gapopt(%) Obj. Gap(%) c m k h Obj. Gapopt(%) Obj. Gap(%) 200 1 1 1 1540 41.35 1540 0.00 600 3 2 2 14130 47.05 14280 −1.06 200 1 1 2 3420 32.33 3420 0.00 600 3 2 3 19010 37.59 19300 −1.53 200 1 2 1 1940 15.07 1940 0.00 600 3 4 2 16770 24.14 16910 −0.83 200 1 2 2 3810 18.83 3810 0.00 600 3 4 3 22110 18.30 22370 −1.18 200 3 1 1 4880 27.10 4880 0.00 600 6 2 2 26860 22.32 27570 −2.64 200 3 1 2 9070 10.60 9070 0.00 600 6 2 3 26420 29.98 33270 −25.93 200 3 2 1 5790 12.67 5790 0.00 600 6 4 2 29460 11.18 30270 −2.75 200 3 2 2 9660 3.80 9660 0.00 600 6 4 3 33910 3.37 34030 −0.35 400 1 1 1 1770 81.11 1770 0.00 800 3 2 2 15380 59.12 15790 −2.67 400 1 1 2 4110 63.04 4110 0.00 800 3 2 3 20850 52.10 21540 −3.31 400 1 2 1 2260 44.14 2260 0.00 800 3 4 2 18270 34.42 18610 −1.86 400 1 2 2 4730 40.36 4730 0.00 800 3 4 3 24210 31.16 24970 −3.14 400 3 1 1 5790 69.90 5790 0.00 800 6 2 2 26680 56.25 31190 −16.90 400 3 1 2 11900 38.30 11940 −0.34 800 6 2 3 30890 49.10 36050 −16.70 400 3 2 1 6980 40.84 6980 0.00 800 6 4 2 32150 29.34 35910 −11.70 400 3 2 2 12930 27.84 12990 −0.46 800 6 4 3 40580 13.39 42400 −4.48 Média 5661 34.45 27.37 −0.05 Média 24855 32.42 26529 −6.06 https://proceedings.science/p/193400?lang=pt-br DOI: 10.59254/sbpo-2024-193400 −6.06%, com o menor valor do gap chegando a −25.93% em uma das instâncias. Nas instâncias com 200 locais, o VMND e o resolvedor MIP empataram. Já nas instâncias com 400 pontos para observação, o VMND se mostrou superior em duas instâncias, com gaps de −0.34% e de −0.46%. 5. Conclusão e trabalhos futuros Este trabalho investigou a aplicação de um algoritmo híbrido, que combina um resolvedor MIP à heurística variable neighborhood descent (VND), aplicada ao problema de escalonamento integrado de satélites de observação da Terra (PEISAT). O PEISAT é modelado como um problema de programação linear inteira mista. Para realizar os experimentos computacionais, instâncias foram criadas a partir de um conjunto de dados relacionados a um trabalho da literatura. Também foi dis- cutido como adaptar o modelo proposto para resolver o problema de escalonamento de constelação de satélites (PECS). Por último, os resultados obtidos pelo VMND foram comparados aos resul- tados dos métodos propostos por Cho et al. [2018] no PECS. Além disso, o VMND também foi confrontado com o resolvedor MIP. Em ambos os casos, o algoritmo híbrido apresentou resultados melhores. Trabalhos futuros incluem o estudo de alvos do tipo “área”, que não podem ser observados de uma única vez. Também é relevante estudar como incluir nas restrições a energia consumida pelos satélites nas mudanças de pose entre atividades consecutivas."
        },
        {
            "titulo": "Resolução do Problema de Programação de Horários Escolares Usando Busca Local - Uma Revisão de Literatura",
            "informacoes_url": "https://proceedings.science/p/193614?lang=pt-br",
            "idioma": "português",
            "autores": [
                {
                    "nome": "Thiago E. dos Santos",
                    "afiliacao": "Instituto Federal De Educação, Ciência E Tecnologia Do Sudeste De Minas Gerais",
                    "orcid": ""
                },
                {
                    "nome": "Shayane G. Vilela",
                    "afiliacao": "Instituto Federal De Educação, Ciência E Tecnologia Do Sudeste De Minas Gerais",
                    "orcid": ""
                },
                {
                    "nome": "Antônio R. Santana",
                    "afiliacao": "Instituto Federal De Educação, Ciência E Tecnologia Do Sudeste De Minas Gerais",
                    "orcid": ""
                },
                {
                    "nome": "Heber F. Amaral",
                    "afiliacao": "Instituto Federal De Educação, Ciência E Tecnologia Do Sudeste De Minas Gerais",
                    "orcid": ""
                }
            ],
            "data_publicacao": "",
            "resumo": "Este artigo apresenta uma Revisão Sistemática de Literatura (RLS) sobre a aplicação de algoritmos de busca local para resolver o problema de programação de horários escolares (time-tabling problem).",
            "keywords": [
                "Revisão Sistemática de Literatura",
                "Busca Local",
                "Programação de Horários Escolares"
            ],
            "storage_key": "galoa-proceedings--sbpo-2024--193614.pdf",
            "referencias": [
                "Aarts, E., Korst, J. H., e van Laarhoven, P. J. (1997). Simulated annealing. E. Aarts, J. K. Lenstra, eds., Local Search in Combinatorial Optimization, volume 91120. John Wiley and Sons, New York, NY.",
                "Abuhamdah, A., Ayob, M., Kendall, G., e Sabar, N. R. (2014). Population based local search for university course timetabling problems. Applied Intelligence, 40:44–53.",
                "Awad, F. H., Al-Kubaisi, A., e Mahmood, M. (2022). Large-scale timetabling problems with adaptive tabu search. Journal of Intelligent Systems, 31(1):168–176.",
                "Babaei, H., Karimpour, J., e Hadidi, A. (2015). A survey of approaches for university course timetabling problem. Computers & Industrial Engineering, 86:43–59.",
                "Bardadym, V. A. (1995). Computer-aided school and university timetabling: The new wave. In international conference on the practice and theory of automated timetabling, p. 22–45. Springer.",
                "Bashab, A., Osman, A., Hashem, I., Aggarwal, K., Mukhlif, F., Ghaleb, F., e Abdelmaboud, A. (2022). Optimization techniques in university timetabling problem: Constraints, methodologies, benchmarks, and open issues. Computers, Materials Continua, 74:6461–6484.",
                "Brito, S. S., Fonseca, G. H., Toffolo, T. A., Santos, H. G., e Souza, M. J. (2012). A sa-vns approach for the high school timetabling problem. Electronic Notes in Discrete Mathematics, 39:169–176.",
                "Cassemiro, M., Miranda, D. S., e Wanner, E. F. (2014). Desenvolvimento de um modelo híbrido baseado em algoritmo genético e busca tabu para resolução do problema de quadro de horários escolar. Anais do XLVI SBPO, p. 1870–1878.",
                "Da Fonseca, G. H. G., Santos, H. G., Toffolo, T. A. M., Brito, S. S., e Souza, M. J. F. (2016). Goal Solver: a hybrid local search based solver for high school timetabling. Annals of Operations Research, 239:77–97.",
                "Demirović, E. e Musliu, N. (2017). Maxsat-based large neighborhood search for high school timetabling. Computers & Operations Research, 78:172–180.",
                "Even, S., Itai, A., e Shamir, A. (1975). On the complexity of time table and multi-commodity flow problems. In 16th annual symposium on foundations of computer science (sfcs 1975), p. 184–193. IEEE.",
                "Fonseca, G. H. G. e Mafia, G. (2020). Um algoritmo heurístico aplicado ao problema de programação de horários universitários do decsi/ufop.",
                "Fonseca, G. H. e Santos, H. G. (2014). Variable neighborhood search based algorithms for high school timetabling. Computers & Operations Research, 52:203–208.",
                "Freire, J. e Melo, R. (2016). Formulações, heurísticas e um limite combinatório para o problema de alocação de salas de aula com demandas flexíveis. Anais do XLVIII Simpósio Brasileiro de Pesquisa Operacional, 722:729.",
                "Furtado, R. B. L. (2022). Abordagens para geração de tabelas de horários escolares: uma revisão sistemática da literatura.",
                "Glover, F. e Laguna, M. (1998). Tabu Search. Springer US, Boston, MA. ISBN 978-1-4613-0303-9. URL https://doi.org/10.1007/978-1-4613-0303-9_33.",
                "Goh, S. L., Kendall, G., e Sabar, N. R. (2017). Improved local search approaches to solve the post enrolment course timetabling problem. European Journal of Operational Research, 261(1):17–29.",
                "Goh, S. L., Kendall, G., Sabar, N. R., e Abdullah, S. (2020). An effective hybrid local search approach for the post enrolment course timetabling problem. Opsearch, 57:1131–1163.",
                "Jardim, A. M., Semaan, G. S., e Penna, P. H. V. (2016). Uma heurística para o problema de programação de horários: um estudo de caso. Anais do XLVIII Simpósio Brasileiro de Pesquisa Operacional (SBPO).",
                "Johnson, D. S., Papadimitriou, C. H., e Yannakakis, M. (1988). How easy is local search? Journal of computer and system sciences, 37(1):79–100.",
                "Kheiri, A., Özcan, E., e Parkes, A. J. (2016). A stochastic local search algorithm with adaptive acceptance for high-school timetabling. Annals of Operations Research, 239:135–151.",
                "Lourenço, H. R., Martin, O. C., e Stützle, T. (2019). Iterated local search: Framework and applications. Handbook of metaheuristics, p. 129–168.",
                "Mladenović, N. e Hansen, P. (1997). Variable neighborhood search. Computers & operations research, 24(11):1097–1100.",
                "Nagata, Y. (2018). Random partial neighborhood search for the post-enrollment course timetabling problem. Computers & Operations Research, 90:84–96.",
                "Post, G., Ahmadi, S., Daskalaki, S., Kingston, J. H., Kyngas, J., Nurmi, C., e Ranson, D. (2012). An xml format for benchmarks in high school timetabling. Annals of Operations Research, 194:385–397.",
                "Rezaeipanah, A., Matoori, S. S., e Ahmadi, G. (2021). A hybrid algorithm for the university course timetabling problem using the improved parallel genetic algorithm and local search. Applied Intelligence, 51:467–492.",
                "Saviniec, L. e Constantino, A. A. (2017). Effective local search algorithms for high school timetabling problems. Applied Soft Computing, 60:363–373. ISSN 1568-4946. URL https://www.sciencedirect.com/science/article/pii/S1568494617303903.",
                "Saviniec, L., Santos, M. O., Costa, A. M., e Aparecido, A. (2015). Multithreading iterated local search aplicado ao problema de horários escolares. In Proceedings of the Brazilian Symposium on Operations Research, Sobrapo, Rio de Janeiro, Brazil, p. 826–837.",
                "Song, T., Chen, M., Xu, Y., Wang, D., Song, X., e Tang, X. (2021). Competition-guided multi-neighborhood local search algorithm for the university course timetabling problem. Applied Soft Computing, 110:107624.",
                "Song, T., Liu, S., Tang, X., Peng, X., e Chen, M. (2018). An iterated local search algorithm for the university course timetabling problem. Applied Soft Computing, 68:597–608.",
                "Soria-Alcaraz, J. A., Özcan, E., Swan, J., Kendall, G., e Carpio, M. (2016). Iterated local search using an add and delete hyper-heuristic for university course timetabling. Applied Soft Computing, 40:581–593.",
                "Tan, J. S., Goh, S. L., Kendall, G., e Sabar, N. R. (2021). A survey of the state-of-the-art of optimisation methodologies in school timetabling. Expert Systems with Applications, 165:113943."
            ],
            "artigo_completo": "Resolução do Problema de Programação de Horários Escolares Usando Busca Local - Uma Revisão de Literatura. RESUMO Este artigo apresenta uma Revisão Sistemática de Literatura (RLS) sobre a aplicação de algoritmos de busca local para resolver o problema de programação de horários escolares (time- tabling problem). A programação eficiente de horários é um desafio complexo devido às diversas restrições e objetivos envolvidos. O problema é classificado como NP-Difícil, sendo comumente abordado por técnicas heurísticas, dentre elas a busca local. A revisão abrange estudos publicados entre 2014 e 2024, focando em diferentes abordagens e metodologias. Além disso, são analisados os datasets utilizados, incluindo benchmarks públicos como o International Timetabling Compe- tition (ITC) e datasets próprios. A revisão evidencia a importância da utilização de benchmarks padronizados para a reprodutibilidade e comparabilidade das pesquisas, bem como as dificulda- des associadas às diferenças nas restrições dos problemas. Os resultados destacam a diversidade de abordagens e a necessidade de soluções adaptativas para lidar com as especificidades de cada contexto. PALAVRAS CHAVE. Revisão sistemática de literatura, Busca local, Programação de Horários Escolares. https://proceedings.science/p/193614?lang=pt-br DOI: 10.59254/sbpo-2024-193614 1. Introdução A programação eficiente de horários de aulas em instituições educacionais é um desafio complexo que envolve a combinação de vários elementos, como disciplinas, professores e salas de aula, levando em consideração diversas restrições e objetivos. A solução manual deste problema é uma tarefa complexa, demorada e frequentemente resulta em soluções subótimas [Bardadym, 1995]. Automatizar o processo de programação de horários proporciona ganhos significativos em eficiência, permitindo encontrar as melhores combinações de recursos e minimizando janelas de tempo ociosas. Isso resulta em uma rotina mais produtiva e maior satisfação dos envolvidos [Brito et al., 2012]. A otimização combinatória permite encontrar as melhores combinações de disciplinas, professores e salas de aula, considerando restrições como preferências de professores, disponibilidade de salas e limitações de tempo. As janelas de tempo entre aulas, sem atividades programadas, podem ser ineficientes e inconvenientes tanto para alunos quanto para professores. Minimizar ou eliminar essas janelas resulta em uma rotina mais fluida e produtiva, contribuindo para a maior qualidade do ensino e para a satisfação dos envolvidos. Assim, é possível reduzir o tempo e os recursos empregados na elaboração dos horários, além de obter uma programação mais eficiente com o uso racional dos espaços. O problema de programação de horários escolares é um problema de otimização combi- natória classificado como NP-Difícil, ou seja, não possui um algoritmo eficiente conhecido para resolver todas as suas instâncias em tempo polinomial, sendo comumente abordado por técnicas heurísticas [Even et al., 1975]. Os métodos usados para resolver problemas de otimização combinatória dividem-se em dois grandes grupos: métodos exatos, cujo objetivo é encontrar a solução ótima de um problema; e métodos heurísticos, que buscam encontrar a melhor solução possível dentro de um determinado tempo considerado viável. Um método heurístico bastante utilizado é chamado de busca local, que é o foco deste trabalho. A busca local é fundamentada no conceito de vizinhança. O processo de busca local considera uma solução inicial viável para o problema e evolui através de operações so- bre essa solução com o objetivo de obter melhores soluções viáveis. As soluções geradas a partir de operações sobre uma solução qualquer s são chamadas de soluções vizinhas de s. Selecionam-se, dentre as soluções vizinhas, soluções melhores do que a solução corrente por algum critério preesta- belecido. Esse processo é repetido até que a iteração não gere nenhuma solução de aprimoramento, ou seja, até que a busca converja. A solução final de uma busca local é chamada de ótimo local [Aarts et al., 1997]. Esta revisão sistemática de literatura visa explorar as técnicas heurísticas baseadas em busca local aplicadas à resolução do problema de timetabling, destacando as formulações, aborda- gens, metodologias e benchmarks utilizados na última década. 1.1. Descrição do Problema A programação de horários, ou timetabling, envolve a alocação eficiente de recursos como salas de aula, professores e alunos para diferentes eventos acadêmicos dentro de um período es- pecífico, como um semestre ou ano letivo. O objetivo é criar um cronograma que atenda a diversas restrições, incluindo a disponibilidade de recursos, preferências de horário e capacidade das salas [Bashab et al., 2022]. O High School Timetabling Problem (HSTP) é uma variação que trabalha com turmas e horários fixos, sem admitir janelas entre os horários. As turmas permanecem na mesma sala, com apenas os professores se deslocando. Já o University Timetabling Problem (UCTP) é mais flexível quanto aos horários, salas e professores, permitindo que os alunos pertençam a múltiplas turmas e tolerando janelas entre os horários. O Post Enrollment Course Timetabling (PE-CTT) envolve a https://proceedings.science/p/193614?lang=pt-br DOI: 10.59254/sbpo-2024-193614 alocação de cursos em intervalos de tempo e salas, garantindo que os estudantes possam frequentar todos os cursos em que se inscreveram, sem sobreposições [Goh et al., 2020]. 1.2. Objetivos deste Trabalho Este trabalho tem como objetivo realizar uma revisão sistemática de literatura de traba- lhos relacionados a algoritmos de busca local para solução dos problemas de agendamento escolar (Timetabling Problem), concentrando-se em abordagens heurísticas de busca local e suas variações, durante o período de 2014 a 2024. Devido a diferentes contextos culturais e sistemas educacionais, os problemas de agen- damento escolar de ensino médio variam para cada país em termos de requisitos e estrutura de agendamento. Como a evolução do sistema educacional é contínua, novos problemas com novos requisitos aparecem constantemente, exigindo novas metodologias de solução [Post et al., 2012]. Devido à dificuldade em encontrar estudos comparativos entre os algoritmos de busca local para solução dos problemas de agendamento escolar quanto ao sucesso das metodologias, desempenho, vantagens, desvantagens e potenciais melhorias, este artigo apresenta uma revisão abrangente e atu- alizada, bem como uma categorização dos trabalhos de pesquisa mais recentes sobre o problema de agendamento escolar. OS objetivos do trabalho são: • Fornecer a definição, terminologias e restrições envolvidas no problema de agendamento es- colar para promover uma maior compreensão neste domínio. • Apresentar uma revisão técnica abrangente e uma categorização das metodologias baseadas em busca local mais recentes aplicadas a este domínio. • Delinear os conjuntos de dados de referência para problemas de agendamento escolar de ensino médio e os respectivos métodos de estado da arte. 1.3. Organização do Trabalho Este artigo está organizado da seguinte forma: A Seção 2 apresenta métodos heurísticos baseados em busca local. A Seção 3 discute a literatura relevante sobre problemas de timetabling, destacando estudos importantes na área. A Seção 4 detalha a metodologia da revisão sistemática da literatura. A Seção 5 apresenta os resultados da revisão, analisando as abordagens e formulações dos problemas, bem como os datasets utilizados nos estudos. Por fim, a Seção 6 conclui o artigo, resumindo os principais achados e discutindo a importância dos datasets públicos e próprios para a reprodutibilidade e comparabilidade das pesquisas, além das dificuldades decorrentes das diferenças nas restrições utilizadas nos estudos. 2. Métodos Heurísticos baseados em busca local Para solucionar o problema, uma das abordagens utilizadas são os métodos heurísticos. Neste trabalho, abordamos exclusivamente métodos heurísticos baseados em busca local. Descritas a seguir: Local Search: A busca local é uma técnica heurística de otimização utilizada para encon- trar soluções viáveis de um problema baseada em uma solução inicial. A ideia por trás da busca local é encontrar soluções vizinhas que são modificadas a cada movimento e verificadas na função objetivo para determinar se a solução vizinha é melhor que a inicial. Caso a solução vizinha seja superior, o programa substitui a solução inicial pela solução vizinha. Esse processo continua até que nenhuma solução melhor seja encontrada [Johnson et al., 1988]. Tabu Search: A tabu search é uma técnica baseada em busca local que envolve a criação de uma lista de movimentos proibidos. Durante a execução da busca, a tabu search se comporta de https://proceedings.science/p/193614?lang=pt-br DOI: 10.59254/sbpo-2024-193614 maneira semelhante à busca local; no entanto, essa abordagem aceita trocar uma solução boa por outra inferior para, no futuro, encontrar a melhor solução possível [Glover e Laguna, 1998]. Variable Neighborhood Search: Proposto por Mladenovi´c e Hansen em 1997, o VNS é amplamente utilizado em problemas de otimização combinatória. Sua execução consiste em ex- plorar diferentes vizinhanças em busca de uma solução ótima, perturbando uma solução corrente e, em seguida, aplicando uma busca local em várias vizinhanças variáveis. Durante a execução do algoritmo, a busca é realizada em uma estrutura de vizinhança e, caso não haja melhorias, o algo- ritmo altera as estruturas vizinhas, escapando de mínimos locais e explorando diferentes regiões do espaço de solução [Mladenovi´c e Hansen, 1997]. Iterated Local Search: A busca local iterada opera alternando entre a melhoria local (local search) e a perturbação. Na fase da melhoria local, o algoritmo executa uma busca local comum, operando nos vizinhos e buscando novas soluções. A fase de perturbação consiste em escapar de ótimos locais subótimos e explorar novas regiões no espaço de busca, executando novamente o processo de melhoria local [Lourenço et al., 2019]. 3. Trabalhos Relacionados A literatura sobre problemas de timetabling, que envolve a alocação de aulas em horários de maneira a otimizar o uso de recursos e minimizar conflitos, tem se expandido significativamente nas últimas décadas. Este campo abrange diversos contextos, desde o ensino fundamental até uni- versidades, cada um com suas particularidades e desafios. Dentre os trabalhos relevantes nesta área, pode-se destacar quatro revisões importantes: • Babaei et al. [2015] categoriza metodologias aplicadas ao problema de timetabling de cursos universitários, discutindo suas vantagens, desvantagens e potencial para melhorias futuras. As metodologias incluem algoritmos genéticos, programação linear, tabu search, simula- ted annealing, GRASP, VND e hibridizações, com destaque para a predominância de meta- heurísticas e métodos híbridos. • Tan et al. [2021] fornecem uma revisão abrangente das metodologias de otimização aplicadas, apresentando uma análise comparativa de metodologias, desempenho, vantagens, desvanta- gens e perspectivas industriais. As técnicas revisadas incluem meta-heurísticas, otimização matemática, heurísticas e métodos híbridos, com um aumento notável na popularidade de métodos de otimização matemática. • Mais recentemente, no contexto brasileiro, temos o trabalho dos pesquisadores Furtado [2022], que fizeram uma revisão sistemática analisando o problema de alocação de horários escolares no contexto brasileiro, identificando as principais metodologias utilizadas entre 2010 e 2020. O estudo destaca a aplicação prática de algoritmos genéticos, tabu search, simulated annea- ling e heurísticas construtivas, com um foco em soluções adaptadas às particularidades das instituições de ensino brasileiras. Enquanto os estudos relatados exploram uma ampla gama de metodologias, nosso tra- balho se concentra nas abordagens de busca local, fornecendo uma análise detalhada de suas variações, formulações e benchmarks utilizados entre 2014 e 2024, com um olhar específico para as diferenças que influenciam as soluções de timetabling. 4. Revisão sistemática de literatura Para a revisão sistemática de literatura, levantamos as seguintes questões de pesquisa: • Q-1: Quais técnicas são utilizadas para resolver o problema? https://proceedings.science/p/193614?lang=pt-br DOI: 10.59254/sbpo-2024-193614 • Q-2: Quais as características dos problemas resolvidos? • Q-3: Quais as características das instâncias usadas? • Q-4: Quais os benchmarks usados? A seleção de fontes foi conduzida de maneira criteriosa para garantir a inclusão de es- tudos relevantes e de qualidade. A pesquisa foi realizada utilizando o Google Acadêmico como principal motor de busca, devido à sua ampla cobertura de literatura acadêmica em diversas áreas do conhecimento. 4.1. Critérios de Inclusão Os critérios de inclusão foram: • Trabalhos relacionados aos problemas de planejamento de horários em escolas e universida- des. • Trabalhos que relatem o uso de busca local para solução desses problemas. • Trabalhos publicados em revistas científicas indexadas com avaliação Qualis A1, A2, A3 ou A4. • Trabalhos publicados na SBPO. • Trabalhos completos. • Trabalhos de acesso aberto ou disponíveis através dos periódicos Capes. • Trabalhos publicados entre 2014 e 2024. 4.2. Critérios de Exclusão Os critérios de exclusão foram: • Trabalhos não relacionados aos problemas de planejamento de horários em escolas e univer- sidades. • Trabalhos que não relatem o uso de busca local para solução desses problemas. • Trabalhos que não foram publicados em revistas científicas indexadas com avaliação Qualis A1, A2, A3 ou A4, ou que não foram publicados nos proceedings da SBPO. • Trabalhos incompletos, em andamento, resumos ou resumos estendidos. • Trabalhos com acesso pago e indisponíveis através dos periódicos Capes. • Trabalhos publicados fora do período de 2014 e 2024. A string de busca foi formulada para abranger sinônimos e variações terminológicas co- mumente utilizadas na literatura sobre o problema de alocação de horários. Abaixo estão os princi- pais componentes utilizados: Os Termos Principais: ”alocação de horários”, ”timetabling problem”, ”busca local”, ”local search”, ”VNS”, ”Iterated local search”, ”ILS”, ”Tabu Search”. Para cobrir um maior número de artigos relacionados aos termos, algumas variações foram adotadas, o que resultou na seguinte string de busca: https://proceedings.science/p/193614?lang=pt-br DOI: 10.59254/sbpo-2024-193614 (”high school timetabling problem” OR ”university timetabling problem”) AND (”lo- cal search” OR ”VNS” OR ”Iterated local search” OR ”ILS” OR ”Tabu Search”). Ao realizar a pesquisa no Google Scholar para o período de 2014 a 2024 com a palavra- chave ”high school timetabling problem”, encontramos 412 resultados. Quando refinamos a pes- quisa para incluir também ”local search”, o número de resultados diminuiu para 286. Em contraste, a busca com a palavra-chave ”university timetabling problem”retornou 840 artigos, e ao adicionar ”local search”como critério adicional, o número de resultados caiu para 460. Apesar da abundância de literatura, ao aplicarmos os filtros de Revisão Sistemática da Literatura (RSL), como qualidade de publicação e relevância ao tema, apenas 19 artigos atenderam às especificações estabelecidas. Os trabalhos que atendem aos critérios da RSL estão listados na Tabela 1. Tabela 1: Características de todos os trabalhos dos anos de 2014 a 2024 Trabalho Tipo de abordagem Formulação Abuhamdah et al. [2014] Population based Local Search UCTP Cassemiro et al. [2014] Tabu Search and Genetic Algorithm HSTP Fonseca e Santos [2014] Variable Neighborhood Search HSTP Saviniec et al. [2015] Iterated Local Search HSTP Da Fonseca et al. [2016] Hybrid Local Search HSTP Freire e Melo [2016] Local Search UCTP Jardim et al. [2016] Iterated Local Search UCTP Kheiri et al. [2016] Stochastic Local Search HSTP Soria-Alcaraz et al. [2016] ILS using an add and delete hyper-heuristic UCTP Demirovi´c e Musliu [2017] MaxSAT-based Large Neighborhood Search HSTP Goh et al. [2017] Improved local search PE-CTT Saviniec e Constantino [2017] Local Search HSTP Nagata [2018] Random Partial Neighborhood Search PE-CTT Song et al. [2018] Iterated Local Search UCTP Fonseca e Mafia [2020] Backtracking, Local Search UCTP Goh et al. [2020] Hybrid Local Search PE-CTT Song et al. [2021] Competition-guided Multi-neighborhood Local Search UCTP Rezaeipanah et al. [2021] Improved Parallel Genetic Algorithm and LS UCTP Awad et al. [2022] Adaptive Tabu Search PE-CTT 5. Resultados A Tabela 1 fornece uma visão abrangente dos trabalhos de pesquisa publicados entre 2014 e 2024 sobre problemas de timetabling, destacando as abordagens utilizadas e as formulações dos problemas abordados. O número reduzido de trabalhos provavelmente se deve ao contraste entre o número de publicações que não atendiam aos critérios de qualidade estabelecidos. Além disso, muitas das publicações que atendiam aos critérios de qualidade apenas citavam a busca local sem realmente propor uma abordagem com essa técnica para a solução do problema. É importante relatar que propor um operador simples de busca local para o problema de timetabling é consideravelmente mais desafiador do que para problemas clássicos de otimização combinatória, como o Traveling Salesman Problem (TSP), Max-Cut e Max-SAT. Isso se deve à com- plexidade intrínseca do timetabling, que envolve uma maior variedade de restrições rígidas e suaves, além de múltiplas dimensões de alocação (tempo, recursos, preferências). Enquanto operadores de busca local para problemas como TSP podem se concentrar em movimentos simples, como trocar a https://proceedings.science/p/193614?lang=pt-br DOI: 10.59254/sbpo-2024-193614 ordem de visitas em uma rota, o timetabling exige operações mais complexas para considerar simul- taneamente a compatibilidade de horários, a disponibilidade de salas e a distribuição balanceada de aulas. Essas complexidades adicionais tornam a definição e implementação de operadores de busca local para timetabling uma tarefa significativamente mais árdua e sofisticada. Em termos de tipos de abordagem, a busca local (Local Search - LS) é a técnica mais co- mum, aparecendo em diversas variantes como Iterated Local Search (ILS), Improved Local Search e Population-Based Local Search. Estas técnicas são amplamente utilizadas devido à sua eficácia em melhorar iterativamente uma solução inicial. Além disso, metodologias híbridas que combinam diferentes técnicas heurísticas e meta-heurísticas, como aquelas vistas nos trabalhos de Goh et al. [2020], Da Fonseca et al. [2016], e Rezaeipanah et al. [2021], são frequentemente utilizadas para aproveitar as vantagens de cada técnica combinada, resultando em melhor desempenho. Técnicas como Adaptive Tabu Search, utilizada por Awad et al. [2022], empregam uma memória adaptativa para evitar ciclos e melhorar a eficiência. A Variable Neighborhood Search (VNS), como aplicada em Fonseca e Santos [2014], explora diferentes vizinhanças para escapar de ótimos locais e encontrar soluções de melhor qualidade. Abordagens como Random Partial Neigh- borhood Search, vista em Nagata [2018], focam em explorar sub-regiões aleatórias do espaço de soluções para evitar a convergência prematura. A MaxSAT-Based Large Neighborhood Search, utilizada por Demirovi´c e Musliu [2017], combina a formulação de MaxSAT com a busca em grande vizinhança para melhorar a eficácia da busca. A abordagem estocástica, como em Kheiri et al. [2016], introduz aleatoriedade na busca local para diversificar a exploração do espaço de soluções, enquanto a Population-Based Local Search, vista em Abuhamdah et al. [2014], utiliza uma população de soluções e aplica busca local para melhorar cada solução. Além disso, a técnica de Backtracking combinada com busca local, utilizada em Fonseca e Mafia [2020], explora siste- maticamente o espaço de soluções, e a combinação de Tabu Search e algoritmos genéticos, como em Cassemiro et al. [2014], alavanca as vantagens de ambas as técnicas para melhorar a busca de soluções. Em termos de formulação do problema, a maioria dos trabalhos aborda o problema de timetabling em escolas de ensino médio (High School Timetabling Problem - HSTP), refletindo uma necessidade prática significativa. Trabalhos como Saviniec e Constantino [2017], Da Fonseca et al. [2016], Demirovi´c e Musliu [2017], Kheiri et al. [2016], Fonseca e Santos [2014], Saviniec et al. [2015], e Cassemiro et al. [2014] enfocam essa formulação. Outras formulações abordadas incluem o Post-Enrollment Course Timetabling Problem (PE-CTT), presente em trabalhos como Goh et al. [2020], Awad et al. [2022], Nagata [2018] e Goh et al. [2017], que foca na alocação de cursos pós-matrícula em contextos universitários. O University Course Timetabling Problem (UCTP), abordado em trabalhos como Fonseca e Mafia [2020] Song et al. [2018], Soria-Alcaraz et al. [2016], Abuhamdah et al. [2014], Jardim et al. [2016], e Freire e Melo [2016], envolve a distribuição de cursos em horários e salas disponíveis em universidades, garantindo a eficiência na utilização de recursos e a ausência de conflitos de horário. Em conclusão, a Tabela 1 revela uma diversidade de abordagens e formulações na pes- quisa de timetabling ao longo de uma década. A predominância de técnicas de busca local e suas variantes, além de metodologias híbridas, destaca a complexidade dos problemas abordados e a necessidade de soluções robustas e adaptativas. As diferentes formulações de problemas, que vão desde o ensino médio até o ambiente universitário, refletem a aplicação prática das técnicas desen- volvidas. Esta diversidade indica um campo de pesquisa ativo e dinâmico, com contínuos avanços e inovações. A Tabela 2 enumera, dentre os trabalhos pesquisados, o número de trabalhos que utiliza- ram diferentes datasets em suas pesquisas sobre timetabling. De acordo com a tabela, o dataset ITC https://proceedings.science/p/193614?lang=pt-br DOI: 10.59254/sbpo-2024-193614 Tabela 2: Número de trabalhos por dataset Base de dados Número de trabalhos ITC 2002 2 ITC 2007 5 ITC 2011 4 Dataset próprio 10 2002 foi utilizado em 2 trabalhos, o ITC 2007 em 5 trabalhos, o ITC 2011 em 4 trabalhos, e datasets próprios foram utilizados em 10 trabalhos. É importante notar que a soma dos datasets usados (20) é maior que o número total de trabalhos analisados. Isso ocorre porque alguns trabalhos utilizaram mais de um dataset em suas pesquisas, permitindo uma avaliação mais abrangente e comparativa de suas abordagens. A utilização dos datasets do International Timetabling Competition (ITC) é crucial para o estudo do problema de timetabling, pois eles fornecem benchmarks padronizados que permitem a comparação objetiva entre diferentes abordagens. Os datasets do ITC são amplamente reconhecidos e utilizados na comunidade acadêmica devido à sua padronização e à diversidade de problemas que representam. A presença significativa dos datasets ITC 2007 e 2011 nos trabalhos analisados des- taca a importância desses benchmarks na validação e avaliação das técnicas desenvolvidas. Esses datasets fornecem uma base comum que facilita a replicação de estudos e a comparação de resulta- dos. Essa diversidade na escolha dos datasets reflete tanto a utilidade dos benchmarks padronizados do ITC quanto a necessidade de adaptar as instâncias de problemas para contextos particulares, uma vez que muitos trabalhos são desenvolvidos para atender demandas específicas. O uso de datasets públicos, como os fornecidos pelo International Timetabling Competi- tion (ITC), é crucial para a reprodutibilidade e a validação das pesquisas em timetabling. Datasets públicos padronizados permitem que diferentes pesquisadores avaliem e comparem seus algorit- mos em um conjunto consistente de problemas, garantindo que os resultados sejam diretamente comparáveis. Isso promove a transparência e a credibilidade das pesquisas, pois outros pesqui- sadores podem reproduzir os experimentos e verificar os resultados. Além disso, a utilização de benchmarks reconhecidos internacionalmente contribui para o avanço cumulativo do conhecimento, permitindo que as melhorias nas técnicas de otimização sejam avaliadas de maneira objetiva. Em contraste, o uso de datasets próprios, embora necessário para certos contextos específicos, pode dificultar a comparação direta entre estudos devido à falta de padronização e à possível ausência de documentação detalhada sobre as características dos dados. Portanto, o equilíbrio entre o uso de datasets públicos e próprios é fundamental para o progresso contínuo e a validação robusta das soluções de timetabling. Ao comparar as formulações utilizadas nos trabalhos sobre timetabling, especialmente os que abordam o High School Timetabling Problem (HSTP), observamos que as restrições apresen- tam tanto semelhanças quanto diferenças significativas. As semelhanças incluem a necessidade de alocação de tempos e recursos e a consideração da disponibilidade dos recursos, elementos cruci- ais para a viabilidade das soluções. As diferenças, por outro lado, aparecem principalmente nas restrições fracas, que se concentram em melhorar a qualidade da alocação. Essas restrições fracas envolvem aspectos como a compactação e o balanceamento da agenda dos professores, bem como limites específicos para o número de aulas por dia. Essas distinções refletem a diversidade de objeti- vos e prioridades nos estudos de timetabling, que variam desde a viabilidade básica até a otimização da experiência de professores e alunos. https://proceedings.science/p/193614?lang=pt-br DOI: 10.59254/sbpo-2024-193614 Abaixo as restrições fortes presente nos trabalhos que abordam HSTP: R1: Nenhum professor pode estar em dois lugares ao mesmo tempo: Um professor não pode ser alocado para mais de uma turma ou sala em um mesmo horário. R2: Nenhuma sala de aula pode ser utilizada por mais de uma turma simultaneamente: Cada sala deve ser usada apenas por uma turma por vez. R3: Disponibilidade de professores: Os professores só podem ser alocados em horários nos quais estão disponíveis. R4: Alocação de disciplinas obrigatórias: As aulas obrigatórias devem ser alocadas dentro do horário escolar, garantindo que todas as disciplinas previstas sejam ministradas. R5: Limites de capacidade de salas: As turmas alocadas a uma sala devem respeitar o limite de capacidade física do espaço. Para o University Course Timetabling Problem (UCTP), as hard constraints são muito semelhantes entre os trabalhos, com pouca variação e uma média de três restrições por estudo, como mostra a tabela 3. No entanto, há uma variação nas soft constraints, que são menos críticas para o funcionamento do algoritmo e o resultado final, mas ainda influenciam a qualidade da solução. A quantidade e a definição das soft constraints variam significativamente entre os trabalhos, refletindo abordagens diferentes para otimizar a alocação de recursos e horários. Abaixo as restrições fortes presente nos trabalhos que abordam UCTP: R1: Período: não podem existir duas ou mais disciplinas de um mesmo período no mesmo horário. R2: Espaço Físico: o total de atividades de um horário e seus respectivos espaços físicos necessários não podem ultrapassar a quantidade especificada. R3: Disciplina: não podem existir duas ou mais alocações de um determinado professor em um mesmo horário. R4: Capacidade: O número de alunos matriculados no curso deve ser menor ou igual à capacidade da sala. R5: Os eventos devem ser atribuídos apenas aos horários predefinidos como disponíveis. R6: Quando especificado, os eventos devem ser agendados para ocorrer na ordem correta. R7: Determinam que o número de aulas alocadas de cada turma é menor ou igual ao seu número de aulas práticas. R8: Para cada evento, deve-se alocar um professor dentre seu conjunto de professores compatíveis. Tabela 3: Restrições por Trabalhos sobre UCTP Trabalhos R1 R2 R3 R4 R5 R6 R7 R8 Abuhamdah et al. [2014] X X X Freire e Melo [2016] X X X X Jardim et al. [2016] X X X Soria-Alcaraz et al. [2016] X X X X X Song et al. [2018] X X X Fonseca e Mafia [2020]1 X X X X Rezaeipanah et al. [2021] X X X X 1As restrições R1, R2 e R3 se repetem para os alunos e professores. Nesse mesmo contexto, as diferenças entre as restrições também dificultam a comparação dos resultados das pesquisas. Essa dificuldade é justificada devido às características dos locais de aplicação das soluções. Mesmo com restrições rígidas iguais nos casos dos HSTP e UCTP, as diferenças nas restrições suaves causam variações nas funções objetivo e também criam problemas https://proceedings.science/p/193614?lang=pt-br DOI: 10.59254/sbpo-2024-193614 para comparar os resultados das soluções. Portanto, embora as diferenças sejam necessárias para atender às especificidades de cada contexto, elas apresentam desafios adicionais para a avaliação e a replicação dos estudos. Com realação as difereças entre os modelos, as principais diferenças entre o UCTP e o HSTP estão na flexibilidade dos horários e no movimento de alunos e professores. No UCTP, os alunos têm horários mais flexíveis, com janelas entre aulas sendo permitidas, e precisam se deslocar entre diferentes salas e prédios. Já no HSTP, os alunos seguem um cronograma fixo, com horários completos sem janelas, e geralmente permanecem na mesma sala, enquanto os professores se des- locam. Além disso, no UCTP, os alunos escolhem suas disciplinas, resultando em combinações variadas de horários, enquanto no HSTP as turmas têm um conjunto fixo de disciplinas. As restrições rígidas também variam: no UCTP, é crucial evitar conflitos de horários entre disciplinas e garantir que as salas comportem os alunos, enquanto no HSTP há um foco maior na rigidez do cronograma dos alunos e na alocação eficiente de professores e salas. As restrições suaves em ambos os casos envolvem minimizar janelas e balancear a carga horária, mas no UCTP isso é mais flexível, enquanto no HSTP há uma necessidade maior de manter um cronograma estruturado. 6. Conclusão A revisão sistemática da literatura revela uma diversidade de abordagens e formulações de problemas no campo de timetabling. A busca local clássica (Local Search - LS) é a mais usada, destacada em sete estudos, enquanto a Variable Neighborhood Search (VNS) e a Iterated Local Search (ILS) aparecem em três e quatro estudos, respectivamente. Propor um operador de busca local para timetabling é mais complexo do que para problemas como TSP e Max-SAT devido às múltiplas restrições e dimensões envolvidas. Abordagens híbridas, que combinam heurísticas e meta-heurísticas, foram utilizadas em quatro estudos. A maioria dos estudos aborda o problema de timetabling de cursos universitários (UCTP), seguido por timetabling em escolas de ensino médio (HSTP) e cursos pós-matrícula (PE-CTT). Os datasets do International Timetabling Competition (ITC) são amplamente utilizados para validar técnicas de otimização, embora muitos estudos usem datasets próprios para atender a necessida- des específicas. Diferenças nas restrições fracas entre os trabalhos dificultam a comparação dos resultados, mas são justificadas pelas características dos contextos de aplicação. Um trabalho futuro recomendado é implementar e testar os diferentes algoritmos pro- postos sobre os mesmos datasets, obedecendo às mesmas restrições fortes e fracas, com a mesma função objetivo. Assim, estudar a escalabilidade e robustez dos algoritmos em grandes instâncias é essencial para avançar a pesquisa em programação de horários escolares. Em conclusão, a diversidade de abordagens e a utilização de diferentes datasets refle- tem a complexidade e a necessidade de soluções adaptativas para os problemas de timetabling. A combinação de datasets públicos e próprios é fundamental para o avanço contínuo e a validação robusta das soluções, garantindo a reprodutibilidade e a comparabilidade das pesquisas. A análise evidencia que o equilíbrio entre essas práticas é essencial para o desenvolvimento de técnicas de otimização eficazes e generalizáveis para problemas de timetabling."
        }
    ]
}